Question ID,Title,Link,Answer Count,Accepted Answer Score,Answer Chunks,Accepted Answer Body
11227809,Why is processing a sorted array faster than processing an unsorted array?,https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array,25,35099.0,"['You are a victim of branch prediction fail. What is Branch Prediction? Consider a railroad junction: Image by Mecanismo, via Wikimedia Commons. Used under the CC-By-SA 3.0 license. Now for the sake of argument, suppose this is back in the 1800s - before long-distance or radio communication. You are a blind operator of a junction and you hear a train coming. You have no idea which way it is supposed to go. You stop the train to ask the driver which direction they want. And then you set the switch appropriately. Trains are heavy and have a lot of inertia, so they take forever to start up and slow down. Is there a better way? You guess which direction the train will go! If you guessed right, it continues on. If you guessed wrong, the driver will stop, back up, and yell at you to flip the switch. Then it can restart down the other path. If you guess right every time, the train will never have to stop. If you guess wrong too often, the train will spend a lot of time stopping, backing up,', 'Then it can restart down the other path. If you guess right every time, the train will never have to stop. If you guess wrong too often, the train will spend a lot of time stopping, backing up, and restarting. Consider an if-statement: At the processor level, it is a branch instruction: You are a processor and you see a branch. You have no idea which way it will go. What do you do? You halt execution and wait until the previous instructions are complete. Then you continue down the correct path. Modern processors are complicated and have long pipelines. This means they take forever to ""warm up"" and ""slow down"". Is there a better way? You guess which direction the branch will go! If you guessed right, you continue executing. If you guessed wrong, you need to flush the pipeline and roll back to the branch. Then you can restart down the other path. If you guess right every time, the execution will never have to stop. If you guess wrong too often, you spend a lot of time stalling, rolling', ""to the branch. Then you can restart down the other path. If you guess right every time, the execution will never have to stop. If you guess wrong too often, you spend a lot of time stalling, rolling back, and restarting. This is branch prediction. I admit it's not the best analogy since the train could just signal the direction with a flag. But in computers, the processor doesn't know which direction a branch will go until the last moment. How would you strategically guess to minimize the number of times that the train must back up and go down the other path? You look at the past history! If the train goes left 99% of the time, then you guess left. If it alternates, then you alternate your guesses. If it goes one way every three times, you guess the same... In other words, you try to identify a pattern and follow it. This is more or less how branch predictors work. Most applications have well-behaved branches. Therefore, modern branch predictors will typically achieve >90% hit rates."", 'a pattern and follow it. This is more or less how branch predictors work. Most applications have well-behaved branches. Therefore, modern branch predictors will typically achieve >90% hit rates. But when faced with unpredictable branches with no recognizable patterns, branch predictors are virtually useless. Further reading: ""Branch predictor"" article on Wikipedia. As hinted from above, the culprit is this if-statement:', '```\nif (data[c] >= 128)\n    sum += data[c];', '```\n Notice that the data is evenly distributed between 0 and 255. When the data is sorted, roughly the first half of the iterations will not enter the if-statement. After that, they will all enter the if-statement. This is very friendly to the branch predictor since the branch consecutively goes the same direction many times. Even a simple saturating counter will correctly predict the branch except for the few iterations after it switches direction. Quick visualization: \n```\nT = branch taken\nN = branch not taken\n\ndata[] = 0, 1, 2, 3, 4, ... 126, 127, 128, 129, 130, ... 250, 251, 252, ...\nbranch = N  N  N  N  N  ...   N    N    T    T    T  ...   T    T    T  ...\n\n       = NNNNNNNNNNNN ... NNNNNNNTTTTTTTTT ... TTTTTTTTTT  (easy to predict)', ""= NNNNNNNNNNNN ... NNNNNNNTTTTTTTTT ... TTTTTTTTTT  (easy to predict)\n\n```\n However, when the data is completely random, the branch predictor is rendered useless, because it can't predict random data. Thus there will probably be around 50% misprediction (no better than random guessing). \n```\ndata[] = 226, 185, 125, 158, 198, 144, 217, 79, 202, 118,  14, 150, 177, 182, ...\nbranch =   T,   T,   N,   T,   T,   T,   T,  N,   T,   N,   N,   T,   T,   T  ...\n\n       = TTNTTTTNTNNTTT ...   (completely random - impossible to predict)\n\n```\n What can be done? If the compiler isn't able to optimize the branch into a conditional move, you can try some hacks if you are willing to sacrifice readability for performance. Replace: \n```\nif (data[c] >= 128)\n    sum += data[c];\n\n```\n with: \n```\nint t = (data[c] - 128) >> 31;\nsum += ~t & data[c];"", ""```\n This eliminates the branch and replaces it with some bitwise operations. (Note that this hack is not strictly equivalent to the original if-statement. But in this case, it's valid for all the input values of \n```\ndata[]\n```"", '```\ndata[]\n```\n.) Benchmarks: Core i7 920 @ 3.5 GHz C++ - Visual Studio 2010 - x64 Release Scenario Time (seconds) Branching - Random data 11.777 Branching - Sorted data 2.352 Branchless - Random data 2.564 Branchless - Sorted data 2.587 Java - NetBeans 7.1.1 JDK 7 - x64 Scenario Time (seconds) Branching - Random data 10.93293813 Branching - Sorted data 5.643797077 Branchless - Random data 3.113581453 Branchless - Sorted data 3.186068823 Observations: With the Branch: There is a huge difference between the sorted and unsorted data. With the Hack: There is no difference between sorted and unsorted data. In the C++ case, the hack is actually a tad slower than with the branch when the data is sorted. A general rule of thumb is to avoid data-dependent branching in critical loops (such as in this example). Update: GCC 4.6.1 with \n```\n-O3\n```\n or \n```\n-ftree-vectorize\n```', '```\n-O3\n```\n or \n```\n-ftree-vectorize\n```\n on x64 is able to generate a conditional move, so there is no difference between the sorted and unsorted data - both are fast. This is called ""if-conversion"" (to branchless) and is necessary for vectorization but also sometimes good for scalar. (Or somewhat fast: for the already-sorted case, \n```\ncmov\n```\n can be slower especially if GCC puts it on the critical path instead of just \n```\nadd\n```\n, especially on Intel before Broadwell where \n```\ncmov\n```\n has 2-cycle latency: gcc optimization flag -O3 makes code slower than -O2) VC++ 2010 is unable to generate conditional moves for this branch even under \n```\n/Ox\n```', ""```\ncmov\n```\n has 2-cycle latency: gcc optimization flag -O3 makes code slower than -O2) VC++ 2010 is unable to generate conditional moves for this branch even under \n```\n/Ox\n```\n. Intel C++ Compiler (ICC) 11 does something miraculous. It interchanges the two loops, thereby hoisting the unpredictable branch to the outer loop. Not only is it immune to the mispredictions, it's also twice as fast as whatever VC++ and GCC can generate! In other words, ICC took advantage of the test-loop to defeat the benchmark... If you give the Intel compiler the branchless code, it just outright vectorizes it... and is just as fast as with the branch (with the loop interchange). Clang also vectorizes the \n```\nif()\n```\n version, as will GCC 5 and later with \n```\n-O3\n```\n, even though it takes quite a few instructions to sign-extend to the 64-bit sum on x86 without SSE4 or AVX2. (\n```\n-march=x86-64-v2\n```\n or \n```\nv3\n```"", '```\n-O3\n```\n, even though it takes quite a few instructions to sign-extend to the 64-bit sum on x86 without SSE4 or AVX2. (\n```\n-march=x86-64-v2\n```\n or \n```\nv3\n```\n). See Why is processing an unsorted array the same speed as processing a sorted array with modern x86-64 clang? This goes to show that even mature modern compilers can vary wildly in their ability to optimize code...']","You are a victim of branch prediction fail. What is Branch Prediction? Consider a railroad junction: Image by Mecanismo, via Wikimedia Commons. Used under the CC-By-SA 3.0 license. Now for the sake of argument, suppose this is back in the 1800s - before long-distance or radio communication. You are a blind operator of a junction and you hear a train coming. You have no idea which way it is supposed to go. You stop the train to ask the driver which direction they want. And then you set the switch appropriately. Trains are heavy and have a lot of inertia, so they take forever to start up and slow down. Is there a better way? You guess which direction the train will go! If you guessed right, it continues on. If you guessed wrong, the driver will stop, back up, and yell at you to flip the switch. Then it can restart down the other path. If you guess right every time, the train will never have to stop. If you guess wrong too often, the train will spend a lot of time stopping, backing up, and restarting. Consider an if-statement: At the processor level, it is a branch instruction: You are a processor and you see a branch. You have no idea which way it will go. What do you do? You halt execution and wait until the previous instructions are complete. Then you continue down the correct path. Modern processors are complicated and have long pipelines. This means they take forever to ""warm up"" and ""slow down"". Is there a better way? You guess which direction the branch will go! If you guessed right, you continue executing. If you guessed wrong, you need to flush the pipeline and roll back to the branch. Then you can restart down the other path. If you guess right every time, the execution will never have to stop. If you guess wrong too often, you spend a lot of time stalling, rolling back, and restarting. This is branch prediction. I admit it's not the best analogy since the train could just signal the direction with a flag. But in computers, the processor doesn't know which direction a branch will go until the last moment. How would you strategically guess to minimize the number of times that the train must back up and go down the other path? You look at the past history! If the train goes left 99% of the time, then you guess left. If it alternates, then you alternate your guesses. If it goes one way every three times, you guess the same... In other words, you try to identify a pattern and follow it. This is more or less how branch predictors work. Most applications have well-behaved branches. Therefore, modern branch predictors will typically achieve >90% hit rates. But when faced with unpredictable branches with no recognizable patterns, branch predictors are virtually useless. Further reading: ""Branch predictor"" article on Wikipedia. As hinted from above, the culprit is this if-statement: 
```
if (data[c] >= 128)
    sum += data[c];

```
 Notice that the data is evenly distributed between 0 and 255. When the data is sorted, roughly the first half of the iterations will not enter the if-statement. After that, they will all enter the if-statement. This is very friendly to the branch predictor since the branch consecutively goes the same direction many times. Even a simple saturating counter will correctly predict the branch except for the few iterations after it switches direction. Quick visualization: 
```
T = branch taken
N = branch not taken

data[] = 0, 1, 2, 3, 4, ... 126, 127, 128, 129, 130, ... 250, 251, 252, ...
branch = N  N  N  N  N  ...   N    N    T    T    T  ...   T    T    T  ...

       = NNNNNNNNNNNN ... NNNNNNNTTTTTTTTT ... TTTTTTTTTT  (easy to predict)

```
 However, when the data is completely random, the branch predictor is rendered useless, because it can't predict random data. Thus there will probably be around 50% misprediction (no better than random guessing). 
```
data[] = 226, 185, 125, 158, 198, 144, 217, 79, 202, 118,  14, 150, 177, 182, ...
branch =   T,   T,   N,   T,   T,   T,   T,  N,   T,   N,   N,   T,   T,   T  ...

       = TTNTTTTNTNNTTT ...   (completely random - impossible to predict)

```
 What can be done? If the compiler isn't able to optimize the branch into a conditional move, you can try some hacks if you are willing to sacrifice readability for performance. Replace: 
```
if (data[c] >= 128)
    sum += data[c];

```
 with: 
```
int t = (data[c] - 128) >> 31;
sum += ~t & data[c];

```
 This eliminates the branch and replaces it with some bitwise operations. (Note that this hack is not strictly equivalent to the original if-statement. But in this case, it's valid for all the input values of 
```
data[]
```
.) Benchmarks: Core i7 920 @ 3.5 GHz C++ - Visual Studio 2010 - x64 Release Scenario Time (seconds) Branching - Random data 11.777 Branching - Sorted data 2.352 Branchless - Random data 2.564 Branchless - Sorted data 2.587 Java - NetBeans 7.1.1 JDK 7 - x64 Scenario Time (seconds) Branching - Random data 10.93293813 Branching - Sorted data 5.643797077 Branchless - Random data 3.113581453 Branchless - Sorted data 3.186068823 Observations: With the Branch: There is a huge difference between the sorted and unsorted data. With the Hack: There is no difference between sorted and unsorted data. In the C++ case, the hack is actually a tad slower than with the branch when the data is sorted. A general rule of thumb is to avoid data-dependent branching in critical loops (such as in this example). Update: GCC 4.6.1 with 
```
-O3
```
 or 
```
-ftree-vectorize
```
 on x64 is able to generate a conditional move, so there is no difference between the sorted and unsorted data - both are fast. This is called ""if-conversion"" (to branchless) and is necessary for vectorization but also sometimes good for scalar. (Or somewhat fast: for the already-sorted case, 
```
cmov
```
 can be slower especially if GCC puts it on the critical path instead of just 
```
add
```
, especially on Intel before Broadwell where 
```
cmov
```
 has 2-cycle latency: gcc optimization flag -O3 makes code slower than -O2) VC++ 2010 is unable to generate conditional moves for this branch even under 
```
/Ox
```
. Intel C++ Compiler (ICC) 11 does something miraculous. It interchanges the two loops, thereby hoisting the unpredictable branch to the outer loop. Not only is it immune to the mispredictions, it's also twice as fast as whatever VC++ and GCC can generate! In other words, ICC took advantage of the test-loop to defeat the benchmark... If you give the Intel compiler the branchless code, it just outright vectorizes it... and is just as fast as with the branch (with the loop interchange). Clang also vectorizes the 
```
if()
```
 version, as will GCC 5 and later with 
```
-O3
```
, even though it takes quite a few instructions to sign-extend to the 64-bit sum on x86 without SSE4 or AVX2. (
```
-march=x86-64-v2
```
 or 
```
v3
```
). See Why is processing an unsorted array the same speed as processing a sorted array with modern x86-64 clang? This goes to show that even mature modern compilers can vary wildly in their ability to optimize code..."
1642028,What is the '-->' operator in C/C++?,https://stackoverflow.com/questions/1642028/what-is-the-operator-in-c-c,26,9870.0,"[""```\n-->\n```\n is not an operator. It is in fact two separate operators, \n```\n--\n```\n and \n```\n>\n```\n. The code in the condition decrements \n```\nx\n```\n, while returning \n```\nx\n```\n's original (not decremented) value, and then compares the original value with \n```\n0\n```\n using the \n```\n>\n```\n operator. To better understand, the statement could be written as follows: \n```\nwhile( (x--) > 0 )\n\n```""]","
```
-->
```
 is not an operator. It is in fact two separate operators, 
```
--
```
 and 
```
>
```
. The code in the condition decrements 
```
x
```
, while returning 
```
x
```
's original (not decremented) value, and then compares the original value with 
```
0
```
 using the 
```
>
```
 operator. To better understand, the statement could be written as follows: 
```
while( (x--) > 0 )

```
"
388242,The Definitive C++ Book Guide and List,https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list,1,,[],
57483,What are the differences between a pointer variable and a reference variable?,https://stackoverflow.com/questions/57483/what-are-the-differences-between-a-pointer-variable-and-a-reference-variable,44,,[],
121162,What does the explicit keyword mean?,https://stackoverflow.com/questions/121162/what-does-the-explicit-keyword-mean,11,4214.0,"['The compiler is allowed to make one implicit conversion to resolve the parameters to a function. This means that the compiler can use constructors callable with a single parameter to convert from one type to another in order to get the right type for a parameter. Here\'s an example with converting constructors that shows how it works: \n```\nstruct Foo {\n    // Single parameter constructor, can be used as an implicit conversion.\n    // Such a constructor is called ""converting constructor"".\n    Foo(int x) {}\n};\nstruct Faz {\n    // Also a converting constructor.\n    Faz(Foo foo) {}\n};\n\n// The parameter is of type Foo, not of type int, so it looks like\n// we have to pass a Foo.\nvoid bar(Foo foo) {};\n\nint main() {\n    // However, the converting constructor allows us to pass an int.\n    bar(42);\n    // Also allowed thanks to the converting constructor.\n    Foo foo = 42;\n    // Error! This would require two conversions (int -> Foo -> Faz).\n    Faz faz = 42;\n}', '```\n Prefixing the \n```\nexplicit\n```\n keyword to the constructor prevents the compiler from using that constructor for implicit conversions. Adding it to the above class will create a compiler error at the function call \n```\nbar(42)\n```\n. It is now necessary to call for conversion explicitly with \n```\nbar(Foo(42))\n```\n The reason you might want to do this is to avoid accidental construction that can hide bugs. Contrived example: You have a \n```\nMyString\n```\n class with a constructor that constructs a string of the given size. You have a function \n```\nprint(const MyString&)\n```\n (as well as an overload \n```\nprint (char *string)\n```\n), and you call \n```\nprint(3)\n```\n (when you actually intended to call \n```\nprint(""3"")\n```\n). You expect it to print ""3"", but it prints an empty string of length 3 instead.']","The compiler is allowed to make one implicit conversion to resolve the parameters to a function. This means that the compiler can use constructors callable with a single parameter to convert from one type to another in order to get the right type for a parameter. Here's an example with converting constructors that shows how it works: 
```
struct Foo {
    // Single parameter constructor, can be used as an implicit conversion.
    // Such a constructor is called ""converting constructor"".
    Foo(int x) {}
};
struct Faz {
    // Also a converting constructor.
    Faz(Foo foo) {}
};

// The parameter is of type Foo, not of type int, so it looks like
// we have to pass a Foo.
void bar(Foo foo) {};

int main() {
    // However, the converting constructor allows us to pass an int.
    bar(42);
    // Also allowed thanks to the converting constructor.
    Foo foo = 42;
    // Error! This would require two conversions (int -> Foo -> Faz).
    Faz faz = 42;
}

```
 Prefixing the 
```
explicit
```
 keyword to the constructor prevents the compiler from using that constructor for implicit conversions. Adding it to the above class will create a compiler error at the function call 
```
bar(42)
```
. It is now necessary to call for conversion explicitly with 
```
bar(Foo(42))
```
 The reason you might want to do this is to avoid accidental construction that can hide bugs. Contrived example: You have a 
```
MyString
```
 class with a constructor that constructs a string of the given size. You have a function 
```
print(const MyString&)
```
 (as well as an overload 
```
print (char *string)
```
), and you call 
```
print(3)
```
 (when you actually intended to call 
```
print(""3"")
```
). You expect it to print ""3"", but it prints an empty string of length 3 instead."
1452721,"What's the problem with ""using namespace std;""?",https://stackoverflow.com/questions/1452721/whats-the-problem-with-using-namespace-std,41,2884.0,"[""Consider two libraries called Foo and Bar: \n```\nusing namespace foo;\nusing namespace bar;\n\n```\n Everything works fine, and you can call \n```\nBlah()\n```\n from Foo and \n```\nQuux()\n```\n from Bar without problems. But one day you upgrade to a new version of Foo 2.0, which now offers a function called \n```\nQuux()\n```\n. Now you've got a conflict: Both Foo 2.0 and Bar import \n```\nQuux()\n```\n into your global namespace. This is going to take some effort to fix, especially if the function parameters happen to match. If you had used \n```\nfoo::Blah()\n```\n and \n```\nbar::Quux()\n```\n, then the introduction of \n```\nfoo::Quux()\n```\n would have been a non-event.""]","Consider two libraries called Foo and Bar: 
```
using namespace foo;
using namespace bar;

```
 Everything works fine, and you can call 
```
Blah()
```
 from Foo and 
```
Quux()
```
 from Bar without problems. But one day you upgrade to a new version of Foo 2.0, which now offers a function called 
```
Quux()
```
. Now you've got a conflict: Both Foo 2.0 and Bar import 
```
Quux()
```
 into your global namespace. This is going to take some effort to fix, especially if the function parameters happen to match. If you had used 
```
foo::Blah()
```
 and 
```
bar::Quux()
```
, then the introduction of 
```
foo::Quux()
```
 would have been a non-event."
236129,How do I iterate over the words of a string?,https://stackoverflow.com/questions/236129/how-do-i-iterate-over-the-words-of-a-string,84,1513.0,"['For what it\'s worth, here\'s another way to extract tokens from an input string, relying only on standard library facilities. It\'s an example of the power and elegance behind the design of the STL. \n```\n#include <iostream>\n#include <string>\n#include <sstream>\n#include <algorithm>\n#include <iterator>\n\nint main() {\n    using namespace std;\n    string sentence = ""And I feel fine..."";\n    istringstream iss(sentence);\n    copy(istream_iterator<string>(iss),\n         istream_iterator<string>(),\n         ostream_iterator<string>(cout, ""\\n""));\n}\n\n```\n Instead of copying the extracted tokens to an output stream, one could insert them into a container, using the same generic \n```\ncopy\n```\n algorithm. \n```\nvector<string> tokens;\ncopy(istream_iterator<string>(iss),\n     istream_iterator<string>(),\n     back_inserter(tokens));\n\n```\n ... or create the \n```\nvector\n```\n directly: \n```\nvector<string> tokens{istream_iterator<string>{iss},\n                      istream_iterator<string>{}};\n\n```']","For what it's worth, here's another way to extract tokens from an input string, relying only on standard library facilities. It's an example of the power and elegance behind the design of the STL. 
```
#include <iostream>
#include <string>
#include <sstream>
#include <algorithm>
#include <iterator>

int main() {
    using namespace std;
    string sentence = ""And I feel fine..."";
    istringstream iss(sentence);
    copy(istream_iterator<string>(iss),
         istream_iterator<string>(),
         ostream_iterator<string>(cout, ""\n""));
}

```
 Instead of copying the extracted tokens to an output stream, one could insert them into a container, using the same generic 
```
copy
```
 algorithm. 
```
vector<string> tokens;
copy(istream_iterator<string>(iss),
     istream_iterator<string>(),
     back_inserter(tokens));

```
 ... or create the 
```
vector
```
 directly: 
```
vector<string> tokens{istream_iterator<string>{iss},
                      istream_iterator<string>{}};

```
"
47981,"How to set, clear, and toggle a single bit",https://stackoverflow.com/questions/47981/how-to-set-clear-and-toggle-a-single-bit,28,4369.0,"[""Setting a bit Use the bitwise OR operator (\n```\n|\n```\n) to set \n```\nn\n```\nth bit of \n```\nnumber\n```\n to \n```\n1\n```\n. \n```\n// Can be whatever unsigned integer type you want, but\n// it's important to use the same type everywhere to avoid\n// performance issues caused by mixing integer types.\ntypedef unsigned long Uint;\n\n// In C++, this can be template.\n// In C11, you can make it generic with _Generic, or with macros prior to C11.\ninline Uint bit_set(Uint number, Uint n) {\n    return number | ((Uint)1 << n);\n}\n\n```\n Note that it's undefined behavior to shift by more than the width of a \n```\nUint\n```\n. The same applies to all remaining examples. Clearing a bit Use the bitwise AND operator (\n```\n&\n```\n) to set the \n```\nn\n```\nth bit of \n```\nnumber\n```\n to \n```\n0\n```\n. \n```\ninline Uint bit_clear(Uint number, Uint n) {\n    return number & ~((Uint)1 << n);\n}"", ""```\n You must invert the bit string with the bitwise NOT operator (\n```\n~\n```\n), then AND it. Toggling a bit Use the bitwise XOR operator (\n```\n^\n```\n) to toggle the \n```\nn\n```\nth bit of \n```\nnumber\n```\n. \n```\ninline Uint bit_toggle(Uint number, Uint n) {\n    return number ^ ((Uint)1 << n);\n}\n\n```\n Checking a bit You didn't ask for this, but I might as well add it. To check a bit, shift \n```\nnumber\n```\n \n```\nn\n```\n to the right, then bitwise AND it: \n```\n// bool requires #include <stdbool.h> prior to C23\ninline bool bit_check(Uint number, Uint n) {\n    return (number >> n) & (Uint)1;\n}\n\n```\n Changing the nth bit to x There are alternatives with worse codegen, but the best way is to clear the bit like in \n```\nbit_clear\n```\n, then set the bit to value, similar to \n```\nbit_set\n```\n. \n```\ninline Uint bit_set_to(Uint number, Uint n, bool x) {\n    return (number & ~((Uint)1 << n)) | ((Uint)x << n);\n}"", '```\n All solutions have been tested to provide optimal codegen with GCC and clang. See https://godbolt.org/z/Wfzh8xsjW.']","Setting a bit Use the bitwise OR operator (
```
|
```
) to set 
```
n
```
th bit of 
```
number
```
 to 
```
1
```
. 
```
// Can be whatever unsigned integer type you want, but
// it's important to use the same type everywhere to avoid
// performance issues caused by mixing integer types.
typedef unsigned long Uint;

// In C++, this can be template.
// In C11, you can make it generic with _Generic, or with macros prior to C11.
inline Uint bit_set(Uint number, Uint n) {
    return number | ((Uint)1 << n);
}

```
 Note that it's undefined behavior to shift by more than the width of a 
```
Uint
```
. The same applies to all remaining examples. Clearing a bit Use the bitwise AND operator (
```
&
```
) to set the 
```
n
```
th bit of 
```
number
```
 to 
```
0
```
. 
```
inline Uint bit_clear(Uint number, Uint n) {
    return number & ~((Uint)1 << n);
}

```
 You must invert the bit string with the bitwise NOT operator (
```
~
```
), then AND it. Toggling a bit Use the bitwise XOR operator (
```
^
```
) to toggle the 
```
n
```
th bit of 
```
number
```
. 
```
inline Uint bit_toggle(Uint number, Uint n) {
    return number ^ ((Uint)1 << n);
}

```
 Checking a bit You didn't ask for this, but I might as well add it. To check a bit, shift 
```
number
```
 
```
n
```
 to the right, then bitwise AND it: 
```
// bool requires #include <stdbool.h> prior to C23
inline bool bit_check(Uint number, Uint n) {
    return (number >> n) & (Uint)1;
}

```
 Changing the nth bit to x There are alternatives with worse codegen, but the best way is to clear the bit like in 
```
bit_clear
```
, then set the bit to value, similar to 
```
bit_set
```
. 
```
inline Uint bit_set_to(Uint number, Uint n, bool x) {
    return (number & ~((Uint)1 << n)) | ((Uint)x << n);
}

```
 All solutions have been tested to provide optimal codegen with GCC and clang. See https://godbolt.org/z/Wfzh8xsjW."
332030,"When should static_cast, dynamic_cast, const_cast, and reinterpret_cast be used?",https://stackoverflow.com/questions/332030/when-should-static-cast-dynamic-cast-const-cast-and-reinterpret-cast-be-used,12,3097.0,"[""```\nstatic_cast\n```\n \n```\nstatic_cast\n```\n is the first cast you should attempt to use. It does things like implicit conversions between types (such as \n```\nint\n```\n to \n```\nfloat\n```\n, or pointer to \n```\nvoid*\n```\n), and it can also call explicit conversion functions (or implicit ones). In many cases, explicitly stating \n```\nstatic_cast\n```\n isn't necessary, but it's important to note that the \n```\nT(something)\n```\n syntax is equivalent to \n```\n(T)something\n```\n and should be avoided (more on that later). A \n```\nT(something, something_else)\n```\n is safe, however, and guaranteed to call the constructor. \n```\nstatic_cast\n```\n can also cast through inheritance hierarchies. It is unnecessary when casting upwards (towards a base class), but when casting downwards it can be used as long as it doesn't cast through \n```\nvirtual\n```\n inheritance. It does not do checking, however, and it is undefined behavior to \n```\nstatic_cast\n```"", ""```\nvirtual\n```\n inheritance. It does not do checking, however, and it is undefined behavior to \n```\nstatic_cast\n```\n down a hierarchy to a type that isn't actually the type of the object. \n```\nconst_cast\n```\n \n```\nconst_cast\n```\n can be used to remove or add \n```\nconst\n```\n to a variable; no other C++ cast is capable of removing it (not even \n```\nreinterpret_cast\n```\n). It is important to note that modifying a formerly \n```\nconst\n```\n value is only undefined if the original variable is \n```\nconst\n```\n; if you use it to take the \n```\nconst\n```\n off a reference to something that wasn't declared with \n```\nconst\n```\n, it is safe. This can be useful when overloading member functions based on \n```\nconst\n```\n, for instance. It can also be used to add \n```\nconst\n```\n to an object, such as to call a member function overload. \n```\nconst_cast\n```\n also works similarly on \n```\nvolatile\n```\n, though that's less common. \n```\ndynamic_cast\n```\n \n```\ndynamic_cast\n```"", ""```\n to an object, such as to call a member function overload. \n```\nconst_cast\n```\n also works similarly on \n```\nvolatile\n```\n, though that's less common. \n```\ndynamic_cast\n```\n \n```\ndynamic_cast\n```\n is exclusively used for handling polymorphism. You can cast a pointer or reference to any polymorphic type to any other class type (a polymorphic type has at least one virtual function, declared or inherited). You can use it for more than just casting downwards – you can cast sideways or even up another chain. The \n```\ndynamic_cast\n```\n will seek out the desired object and return it if possible. If it can't, it will return \n```\nnullptr\n```\n in the case of a pointer, or throw \n```\nstd::bad_cast\n```\n in the case of a reference. \n```\ndynamic_cast\n```\n has some limitations, though. It doesn't work if there are multiple objects of the same type in the inheritance hierarchy (the so-called 'dreaded diamond') and you aren't using \n```\nvirtual\n```"", ""```\n has some limitations, though. It doesn't work if there are multiple objects of the same type in the inheritance hierarchy (the so-called 'dreaded diamond') and you aren't using \n```\nvirtual\n```\n inheritance. It also can only go through public inheritance - it will always fail to travel through \n```\nprotected\n```\n or \n```\nprivate\n```\n inheritance. This is rarely an issue, however, as such forms of inheritance are rare. \n```\nreinterpret_cast\n```\n \n```\nreinterpret_cast\n```\n is the most dangerous cast, and should be used very sparingly. It turns one type directly into another — such as casting the value from one pointer to another, or storing a pointer in an \n```\nint\n```\n, or all sorts of other nasty things. Largely, the only guarantee you get with \n```\nreinterpret_cast\n```\n is that normally if you cast the result back to the original type, you will get the exact same value (but not if the intermediate type is smaller than the original type). There are a number of conversions that"", ""```\nreinterpret_cast\n```\n cannot do, too. It's often abused for particularly weird conversions and bit manipulations, like turning a raw data stream into actual data, or storing data in the low bits of a pointer to aligned data. For those cases, see \n```\nstd::bit_cast\n```\n. C-Style Cast and Function-Style Cast C-style cast and function-style cast are casts using \n```\n(type)object\n```\n or \n```\ntype(object)\n```\n, respectively, and are functionally equivalent. They are defined as the first of the following which succeeds: \n```\nconst_cast\n```\n \n```\nstatic_cast\n```\n (though ignoring access restrictions) \n```\nstatic_cast\n```\n (see above), then \n```\nconst_cast\n```\n \n```\nreinterpret_cast\n```\n \n```\nreinterpret_cast\n```\n, then \n```\nconst_cast\n```\n It can therefore be used as a replacement for other casts in some instances, but can be extremely dangerous because of the ability to devolve into a \n```\nreinterpret_cast\n```"", ""```\nconst_cast\n```\n It can therefore be used as a replacement for other casts in some instances, but can be extremely dangerous because of the ability to devolve into a \n```\nreinterpret_cast\n```\n, and the latter should be preferred when explicit casting is needed, unless you are sure \n```\nstatic_cast\n```\n will succeed or \n```\nreinterpret_cast\n```\n will fail. Even then, consider the longer, more explicit option. C-style casts also ignore access control when performing a \n```\nstatic_cast\n```\n, which means that they have the ability to perform an operation that no other cast can. This is mostly a kludge, though, and in my mind is just another reason to avoid C-style casts. \n```\nstd::bit_cast\n```\n [C++20] \n```\nstd::bit_cast\n```\n copies the bits and bytes of the source object (its representation) directly into a new object of the target type. It's a standards-compliant way to do type punning. If you find yourself writing \n```\n*reinterpret_cast<SomeType*>(&x)\n```\n, you probably should use"", ""```\n*reinterpret_cast<SomeType*>(&x)\n```\n, you probably should use \n```\nstd::bit_cast<SomeType>(x)\n```\n instead. \n```\nstd::bit_cast\n```\n is declared in \n```\n<bit>\n```\n. The objects must be the same size and be trivially copyable. If you can't yet use C++20, use \n```\nmemcpy\n```\n to copy the source value into a variable of the desired type.""]","
```
static_cast
```
 
```
static_cast
```
 is the first cast you should attempt to use. It does things like implicit conversions between types (such as 
```
int
```
 to 
```
float
```
, or pointer to 
```
void*
```
), and it can also call explicit conversion functions (or implicit ones). In many cases, explicitly stating 
```
static_cast
```
 isn't necessary, but it's important to note that the 
```
T(something)
```
 syntax is equivalent to 
```
(T)something
```
 and should be avoided (more on that later). A 
```
T(something, something_else)
```
 is safe, however, and guaranteed to call the constructor. 
```
static_cast
```
 can also cast through inheritance hierarchies. It is unnecessary when casting upwards (towards a base class), but when casting downwards it can be used as long as it doesn't cast through 
```
virtual
```
 inheritance. It does not do checking, however, and it is undefined behavior to 
```
static_cast
```
 down a hierarchy to a type that isn't actually the type of the object. 
```
const_cast
```
 
```
const_cast
```
 can be used to remove or add 
```
const
```
 to a variable; no other C++ cast is capable of removing it (not even 
```
reinterpret_cast
```
). It is important to note that modifying a formerly 
```
const
```
 value is only undefined if the original variable is 
```
const
```
; if you use it to take the 
```
const
```
 off a reference to something that wasn't declared with 
```
const
```
, it is safe. This can be useful when overloading member functions based on 
```
const
```
, for instance. It can also be used to add 
```
const
```
 to an object, such as to call a member function overload. 
```
const_cast
```
 also works similarly on 
```
volatile
```
, though that's less common. 
```
dynamic_cast
```
 
```
dynamic_cast
```
 is exclusively used for handling polymorphism. You can cast a pointer or reference to any polymorphic type to any other class type (a polymorphic type has at least one virtual function, declared or inherited). You can use it for more than just casting downwards – you can cast sideways or even up another chain. The 
```
dynamic_cast
```
 will seek out the desired object and return it if possible. If it can't, it will return 
```
nullptr
```
 in the case of a pointer, or throw 
```
std::bad_cast
```
 in the case of a reference. 
```
dynamic_cast
```
 has some limitations, though. It doesn't work if there are multiple objects of the same type in the inheritance hierarchy (the so-called 'dreaded diamond') and you aren't using 
```
virtual
```
 inheritance. It also can only go through public inheritance - it will always fail to travel through 
```
protected
```
 or 
```
private
```
 inheritance. This is rarely an issue, however, as such forms of inheritance are rare. 
```
reinterpret_cast
```
 
```
reinterpret_cast
```
 is the most dangerous cast, and should be used very sparingly. It turns one type directly into another — such as casting the value from one pointer to another, or storing a pointer in an 
```
int
```
, or all sorts of other nasty things. Largely, the only guarantee you get with 
```
reinterpret_cast
```
 is that normally if you cast the result back to the original type, you will get the exact same value (but not if the intermediate type is smaller than the original type). There are a number of conversions that 
```
reinterpret_cast
```
 cannot do, too. It's often abused for particularly weird conversions and bit manipulations, like turning a raw data stream into actual data, or storing data in the low bits of a pointer to aligned data. For those cases, see 
```
std::bit_cast
```
. C-Style Cast and Function-Style Cast C-style cast and function-style cast are casts using 
```
(type)object
```
 or 
```
type(object)
```
, respectively, and are functionally equivalent. They are defined as the first of the following which succeeds: 
```
const_cast
```
 
```
static_cast
```
 (though ignoring access restrictions) 
```
static_cast
```
 (see above), then 
```
const_cast
```
 
```
reinterpret_cast
```
 
```
reinterpret_cast
```
, then 
```
const_cast
```
 It can therefore be used as a replacement for other casts in some instances, but can be extremely dangerous because of the ability to devolve into a 
```
reinterpret_cast
```
, and the latter should be preferred when explicit casting is needed, unless you are sure 
```
static_cast
```
 will succeed or 
```
reinterpret_cast
```
 will fail. Even then, consider the longer, more explicit option. C-style casts also ignore access control when performing a 
```
static_cast
```
, which means that they have the ability to perform an operation that no other cast can. This is mostly a kludge, though, and in my mind is just another reason to avoid C-style casts. 
```
std::bit_cast
```
 [C++20] 
```
std::bit_cast
```
 copies the bits and bytes of the source object (its representation) directly into a new object of the target type. It's a standards-compliant way to do type punning. If you find yourself writing 
```
*reinterpret_cast<SomeType*>(&x)
```
, you probably should use 
```
std::bit_cast<SomeType>(x)
```
 instead. 
```
std::bit_cast
```
 is declared in 
```
<bit>
```
. The objects must be the same size and be trivially copyable. If you can't yet use C++20, use 
```
memcpy
```
 to copy the source value into a variable of the desired type."
21593,"What is the difference between #include <filename> and #include ""filename""?",https://stackoverflow.com/questions/21593/what-is-the-difference-between-include-filename-and-include-filename,30,,[],
4172722,What is The Rule of Three?,https://stackoverflow.com/questions/4172722/what-is-the-rule-of-three,8,2139.0,"['Introduction C++ treats variables of user-defined types with value semantics. This means that objects are implicitly copied in various contexts, and we should understand what ""copying an object"" actually means. Let us consider a simple example: \n```\nclass person\n{\n    std::string name;\n    int age;\n\npublic:\n\n    person(const std::string& name, int age) : name(name), age(age)\n    {\n    }\n};\n\nint main()\n{\n    person a(""Bjarne Stroustrup"", 60);\n    person b(a);   // What happens here?\n    b = a;         // And here?\n}', '```\n (If you are puzzled by the \n```\nname(name), age(age)\n```\n part, this is called a member initializer list.) Special member functions What does it mean to copy a \n```\nperson\n```\n object? The \n```\nmain\n```\n function shows two distinct copying scenarios. The initialization \n```\nperson b(a);\n```\n is performed by the copy constructor. Its job is to construct a fresh object based on the state of an existing object. The assignment \n```\nb = a\n```', 'is performed by the copy assignment operator. Its job is generally a little more complicated because the target object is already in some valid state that needs to be dealt with. Since we declared neither the copy constructor nor the assignment operator (nor the destructor) ourselves, these are implicitly defined for us. Quote from the standard: The [...] copy constructor and copy assignment operator, [...] and destructor are special member functions. [ Note: The implementation will implicitly declare these member functions for some class types when the program does not explicitly declare them. The implementation will implicitly define them if they are used. [...] end note ] [n3126.pdf section 12 §1] By default, copying an object means copying its members: The implicitly-defined copy constructor for a non-union class X performs a memberwise copy of its subobjects. [n3126.pdf section 12.8 §16] The implicitly-defined copy assignment operator for a non-union class X performs memberwise', 'for a non-union class X performs a memberwise copy of its subobjects. [n3126.pdf section 12.8 §16] The implicitly-defined copy assignment operator for a non-union class X performs memberwise copy assignment of its subobjects. [n3126.pdf section 12.8 §30] Implicit definitions The implicitly-defined special member functions for', '```\nperson\n```\n look like this: \n```\n// 1. copy constructor\nperson(const person& that) : name(that.name), age(that.age)\n{\n}', '// 2. copy assignment operator\nperson& operator=(const person& that)\n{\n    name = that.name;\n    age = that.age;\n    return *this;\n}\n\n// 3. destructor\n~person()\n{\n}', ""```\n Memberwise copying is exactly what we want in this case: \n```\nname\n```\n and \n```\nage\n```\n are copied, so we get a self-contained, independent \n```\nperson\n```\n object. The implicitly-defined destructor is always empty. This is also fine in this case since we did not acquire any resources in the constructor. The members' destructors are implicitly called after the \n```\nperson\n```"", ""```\nperson\n```\n destructor is finished: After executing the body of the destructor and destroying any automatic objects allocated within the body, a destructor for class X calls the destructors for X's direct [...] members [n3126.pdf 12.4 §6] Managing resources So when should we declare those special member functions explicitly? When our class manages a resource, that is, when an object of the class is responsible for that resource. That usually means the resource is acquired in the constructor (or passed into the constructor) and released in the destructor. Let us go back in time to pre-standard C++. There was no such thing as \n```\nstd::string\n```\n, and programmers were in love with pointers. The \n```\nperson\n```\n class might have looked like this: \n```\nclass person\n{\n    char* name;\n    int age;"", 'public:\n\n    // the constructor acquires a resource:\n    // in this case, dynamic memory obtained via new[]\n    person(const char* the_name, int the_age)\n    {\n        name = new char[strlen(the_name) + 1];\n        strcpy(name, the_name);\n        age = the_age;\n    }\n\n    // the destructor must release this resource via delete[]\n    ~person()\n    {\n        delete[] name;\n    }\n};', '```\n Even today, people still write classes in this style and get into trouble: ""I pushed a person into a vector and now I get crazy memory errors!"" Remember that by default, copying an object means copying its members, but copying the \n```\nname\n```\n member merely copies a pointer, not the character array it points to! This has several unpleasant effects: Changes via \n```\na\n```\n can be observed via \n```\nb\n```\n. Once \n```\nb\n```\n is destroyed, \n```\na.name\n```\n is a dangling pointer. If \n```\na\n```\n is destroyed, deleting the dangling pointer yields undefined behavior. Since the assignment does not take into account what \n```\nname\n```\n pointed to before the assignment, sooner or later you will get memory leaks all over the place. Explicit definitions Since memberwise copying does not have the desired effect, we must define the copy constructor and the copy assignment operator explicitly to make deep copies of the character array: \n```\n// 1. copy constructor\nperson(const person& that)\n{', '```\n// 1. copy constructor\nperson(const person& that)\n{\n    name = new char[strlen(that.name) + 1];\n    strcpy(name, that.name);\n    age = that.age;\n}', '// 2. copy assignment operator\nperson& operator=(const person& that)\n{\n    if (this != &that)\n    {\n        delete[] name;\n        // This is a dangerous point in the flow of execution!\n        // We have temporarily invalidated the class invariants,\n        // and the next statement might throw an exception,\n        // leaving the object in an invalid state :(\n        name = new char[strlen(that.name) + 1];\n        strcpy(name, that.name);\n        age = that.age;\n    }\n    return *this;\n}', '```\n Note the difference between initialization and assignment: we must tear down the old state before assigning it to \n```\nname\n```\n to prevent memory leaks. Also, we have to protect against the self-assignment of the form \n```\nx = x\n```\n. Without that check, \n```\ndelete[] name\n```\n would delete the array containing the source string, because when you write \n```\nx = x\n```\n, both \n```\nthis->name\n```\n and \n```\nthat.name\n```\n contain the same pointer. Exception safety Unfortunately, this solution will fail if \n```\nnew char[...]\n```\n throws an exception due to memory exhaustion. One possible solution is to introduce a local variable and reorder the statements: \n```\n// 2. copy assignment operator\nperson& operator=(const person& that)\n{\n    char* local_name = new char[strlen(that.name) + 1];\n    // If the above statement throws,\n    // the object is still in the same state as before.\n    // None of the following statements will throw an exception :)\n    strcpy(local_name, that.name);', '// If the above statement throws,\n    // the object is still in the same state as before.\n    // None of the following statements will throw an exception :)\n    strcpy(local_name, that.name);\n    delete[] name;\n    name = local_name;\n    age = that.age;\n    return *this;\n}', '```\n This also takes care of self-assignment without an explicit check. An even more robust solution to this problem is the copy-and-swap idiom, but I will not go into the details of exception safety here. I only mentioned exceptions to make the following point: Writing classes that manage resources is hard. Noncopyable resources Some resources cannot or should not be copied, such as file handles or mutexes. In that case, simply declare the copy constructor and copy assignment operator as \n```\nprivate\n```\n without giving a definition: \n```\nprivate:\n\n    person(const person& that);\n    person& operator=(const person& that);\n\n```\n Alternatively, you can inherit from \n```\nboost::noncopyable\n```\n or declare them as deleted (in C++11 and above): \n```\nperson(const person& that) = delete;\nperson& operator=(const person& that) = delete;', '```\n The rule of three Sometimes you need to implement a class that manages a resource. (Never manage multiple resources in a single class, this will only lead to pain.) In that case, remember the rule of three: If you need to explicitly declare either the destructor, copy constructor or copy assignment operator yourself, you probably need to explicitly declare all three of them. (Unfortunately, this ""rule"" is not enforced by the C++ standard or any compiler I am aware of.) The rule of five From C++11 on, an object has 2 extra special member functions: the move constructor and move assignment. The rule of five states to implement these functions as well. An example with the signatures: \n```\nclass person\n{\n    std::string name;\n    int age;', 'public:\n    person(const std::string& name, int age);        // Ctor\n    person(const person &) = default;                // 1/5: Copy Ctor\n    person(person &&) noexcept = default;            // 4/5: Move Ctor\n    person& operator=(const person &) = default;     // 2/5: Copy Assignment\n    person& operator=(person &&) noexcept = default; // 5/5: Move Assignment\n    ~person() noexcept = default;                    // 3/5: Dtor\n};', '```\n The rule of zero The rule of 3/5 is also referred to as the rule of 0/3/5. The zero part of the rule states that you are allowed to not write any of the special member functions when creating your class. Advice Most of the time, you do not need to manage a resource yourself, because an existing class such as \n```\nstd::string\n```\n already does it for you. Just compare the simple code using a \n```\nstd::string\n```\n member to the convoluted and error-prone alternative using a \n```\nchar*\n```\n and you should be convinced. As long as you stay away from raw pointer members, the rule of three is unlikely to concern your own code.']","Introduction C++ treats variables of user-defined types with value semantics. This means that objects are implicitly copied in various contexts, and we should understand what ""copying an object"" actually means. Let us consider a simple example: 
```
class person
{
    std::string name;
    int age;

public:

    person(const std::string& name, int age) : name(name), age(age)
    {
    }
};

int main()
{
    person a(""Bjarne Stroustrup"", 60);
    person b(a);   // What happens here?
    b = a;         // And here?
}

```
 (If you are puzzled by the 
```
name(name), age(age)
```
 part, this is called a member initializer list.) Special member functions What does it mean to copy a 
```
person
```
 object? The 
```
main
```
 function shows two distinct copying scenarios. The initialization 
```
person b(a);
```
 is performed by the copy constructor. Its job is to construct a fresh object based on the state of an existing object. The assignment 
```
b = a
```
 is performed by the copy assignment operator. Its job is generally a little more complicated because the target object is already in some valid state that needs to be dealt with. Since we declared neither the copy constructor nor the assignment operator (nor the destructor) ourselves, these are implicitly defined for us. Quote from the standard: The [...] copy constructor and copy assignment operator, [...] and destructor are special member functions. [ Note: The implementation will implicitly declare these member functions for some class types when the program does not explicitly declare them. The implementation will implicitly define them if they are used. [...] end note ] [n3126.pdf section 12 §1] By default, copying an object means copying its members: The implicitly-defined copy constructor for a non-union class X performs a memberwise copy of its subobjects. [n3126.pdf section 12.8 §16] The implicitly-defined copy assignment operator for a non-union class X performs memberwise copy assignment of its subobjects. [n3126.pdf section 12.8 §30] Implicit definitions The implicitly-defined special member functions for 
```
person
```
 look like this: 
```
// 1. copy constructor
person(const person& that) : name(that.name), age(that.age)
{
}

// 2. copy assignment operator
person& operator=(const person& that)
{
    name = that.name;
    age = that.age;
    return *this;
}

// 3. destructor
~person()
{
}

```
 Memberwise copying is exactly what we want in this case: 
```
name
```
 and 
```
age
```
 are copied, so we get a self-contained, independent 
```
person
```
 object. The implicitly-defined destructor is always empty. This is also fine in this case since we did not acquire any resources in the constructor. The members' destructors are implicitly called after the 
```
person
```
 destructor is finished: After executing the body of the destructor and destroying any automatic objects allocated within the body, a destructor for class X calls the destructors for X's direct [...] members [n3126.pdf 12.4 §6] Managing resources So when should we declare those special member functions explicitly? When our class manages a resource, that is, when an object of the class is responsible for that resource. That usually means the resource is acquired in the constructor (or passed into the constructor) and released in the destructor. Let us go back in time to pre-standard C++. There was no such thing as 
```
std::string
```
, and programmers were in love with pointers. The 
```
person
```
 class might have looked like this: 
```
class person
{
    char* name;
    int age;

public:

    // the constructor acquires a resource:
    // in this case, dynamic memory obtained via new[]
    person(const char* the_name, int the_age)
    {
        name = new char[strlen(the_name) + 1];
        strcpy(name, the_name);
        age = the_age;
    }

    // the destructor must release this resource via delete[]
    ~person()
    {
        delete[] name;
    }
};

```
 Even today, people still write classes in this style and get into trouble: ""I pushed a person into a vector and now I get crazy memory errors!"" Remember that by default, copying an object means copying its members, but copying the 
```
name
```
 member merely copies a pointer, not the character array it points to! This has several unpleasant effects: Changes via 
```
a
```
 can be observed via 
```
b
```
. Once 
```
b
```
 is destroyed, 
```
a.name
```
 is a dangling pointer. If 
```
a
```
 is destroyed, deleting the dangling pointer yields undefined behavior. Since the assignment does not take into account what 
```
name
```
 pointed to before the assignment, sooner or later you will get memory leaks all over the place. Explicit definitions Since memberwise copying does not have the desired effect, we must define the copy constructor and the copy assignment operator explicitly to make deep copies of the character array: 
```
// 1. copy constructor
person(const person& that)
{
    name = new char[strlen(that.name) + 1];
    strcpy(name, that.name);
    age = that.age;
}

// 2. copy assignment operator
person& operator=(const person& that)
{
    if (this != &that)
    {
        delete[] name;
        // This is a dangerous point in the flow of execution!
        // We have temporarily invalidated the class invariants,
        // and the next statement might throw an exception,
        // leaving the object in an invalid state :(
        name = new char[strlen(that.name) + 1];
        strcpy(name, that.name);
        age = that.age;
    }
    return *this;
}

```
 Note the difference between initialization and assignment: we must tear down the old state before assigning it to 
```
name
```
 to prevent memory leaks. Also, we have to protect against the self-assignment of the form 
```
x = x
```
. Without that check, 
```
delete[] name
```
 would delete the array containing the source string, because when you write 
```
x = x
```
, both 
```
this->name
```
 and 
```
that.name
```
 contain the same pointer. Exception safety Unfortunately, this solution will fail if 
```
new char[...]
```
 throws an exception due to memory exhaustion. One possible solution is to introduce a local variable and reorder the statements: 
```
// 2. copy assignment operator
person& operator=(const person& that)
{
    char* local_name = new char[strlen(that.name) + 1];
    // If the above statement throws,
    // the object is still in the same state as before.
    // None of the following statements will throw an exception :)
    strcpy(local_name, that.name);
    delete[] name;
    name = local_name;
    age = that.age;
    return *this;
}

```
 This also takes care of self-assignment without an explicit check. An even more robust solution to this problem is the copy-and-swap idiom, but I will not go into the details of exception safety here. I only mentioned exceptions to make the following point: Writing classes that manage resources is hard. Noncopyable resources Some resources cannot or should not be copied, such as file handles or mutexes. In that case, simply declare the copy constructor and copy assignment operator as 
```
private
```
 without giving a definition: 
```
private:

    person(const person& that);
    person& operator=(const person& that);

```
 Alternatively, you can inherit from 
```
boost::noncopyable
```
 or declare them as deleted (in C++11 and above): 
```
person(const person& that) = delete;
person& operator=(const person& that) = delete;

```
 The rule of three Sometimes you need to implement a class that manages a resource. (Never manage multiple resources in a single class, this will only lead to pain.) In that case, remember the rule of three: If you need to explicitly declare either the destructor, copy constructor or copy assignment operator yourself, you probably need to explicitly declare all three of them. (Unfortunately, this ""rule"" is not enforced by the C++ standard or any compiler I am aware of.) The rule of five From C++11 on, an object has 2 extra special member functions: the move constructor and move assignment. The rule of five states to implement these functions as well. An example with the signatures: 
```
class person
{
    std::string name;
    int age;

public:
    person(const std::string& name, int age);        // Ctor
    person(const person &) = default;                // 1/5: Copy Ctor
    person(person &&) noexcept = default;            // 4/5: Move Ctor
    person& operator=(const person &) = default;     // 2/5: Copy Assignment
    person& operator=(person &&) noexcept = default; // 5/5: Move Assignment
    ~person() noexcept = default;                    // 3/5: Dtor
};

```
 The rule of zero The rule of 3/5 is also referred to as the rule of 0/3/5. The zero part of the rule states that you are allowed to not write any of the special member functions when creating your class. Advice Most of the time, you do not need to manage a resource yourself, because an existing class such as 
```
std::string
```
 already does it for you. Just compare the simple code using a 
```
std::string
```
 member to the convoluted and error-prone alternative using a 
```
char*
```
 and you should be convinced. As long as you stay away from raw pointer members, the rule of three is unlikely to concern your own code."
4421706,What are the basic rules and idioms for operator overloading?,https://stackoverflow.com/questions/4421706/what-are-the-basic-rules-and-idioms-for-operator-overloading,10,,[],
8547778,Why are elementwise additions much faster in separate loops than in a combined loop?,https://stackoverflow.com/questions/8547778/why-are-elementwise-additions-much-faster-in-separate-loops-than-in-a-combined-l,11,1790.0,"[""Upon further analysis of this, I believe this is (at least partially) caused by the data alignment of the four-pointers. This will cause some level of cache bank/way conflicts. If I've guessed correctly on how you are allocating your arrays, they are likely to be aligned to the page line. This means that all your accesses in each loop will fall on the same cache way. However, Intel processors have had 8-way L1 cache associativity for a while. But in reality, the performance isn't completely uniform. Accessing 4-ways is still slower than say 2-ways. EDIT: It does in fact look like you are allocating all the arrays separately. Usually when such large allocations are requested, the allocator will request fresh pages from the OS. Therefore, there is a high chance that large allocations will appear at the same offset from a page-boundary. Here's the test code: \n```\nint main(){\n    const int n = 100000;"", '#ifdef ALLOCATE_SEPERATE\n    double *a1 = (double*)malloc(n * sizeof(double));\n    double *b1 = (double*)malloc(n * sizeof(double));\n    double *c1 = (double*)malloc(n * sizeof(double));\n    double *d1 = (double*)malloc(n * sizeof(double));\n#else\n    double *a1 = (double*)malloc(n * sizeof(double) * 4);\n    double *b1 = a1 + n;\n    double *c1 = b1 + n;\n    double *d1 = c1 + n;\n#endif\n\n    //  Zero the data to prevent any chance of denormals.\n    memset(a1,0,n * sizeof(double));\n    memset(b1,0,n * sizeof(double));\n    memset(c1,0,n * sizeof(double));\n    memset(d1,0,n * sizeof(double));\n\n    //  Print the addresses\n    cout << a1 << endl;\n    cout << b1 << endl;\n    cout << c1 << endl;\n    cout << d1 << endl;\n\n    clock_t start = clock();\n\n    int c = 0;\n    while (c++ < 10000){', '//  Print the addresses\n    cout << a1 << endl;\n    cout << b1 << endl;\n    cout << c1 << endl;\n    cout << d1 << endl;\n\n    clock_t start = clock();\n\n    int c = 0;\n    while (c++ < 10000){\n\n#if ONE_LOOP\n        for(int j=0;j<n;j++){\n            a1[j] += b1[j];\n            c1[j] += d1[j];\n        }\n#else\n        for(int j=0;j<n;j++){\n            a1[j] += b1[j];\n        }\n        for(int j=0;j<n;j++){\n            c1[j] += d1[j];\n        }\n#endif\n\n    }\n\n    clock_t end = clock();\n    cout << ""seconds = "" << (double)(end - start) / CLOCKS_PER_SEC << endl;\n\n    system(""pause"");\n    return 0;\n}\n\n```\n Benchmark Results: EDIT: Results on an actual Core 2 architecture machine: 2 x Intel Xeon X5482 Harpertown @ 3.2 GHz: \n```\n#define ALLOCATE_SEPERATE\n#define ONE_LOOP\n00600020\n006D0020\n007A0020\n00870020\nseconds = 6.206\n\n#define ALLOCATE_SEPERATE\n//#define ONE_LOOP\n005E0020\n006B0020\n00780020\n00850020\nseconds = 2.116', '#define ALLOCATE_SEPERATE\n//#define ONE_LOOP\n005E0020\n006B0020\n00780020\n00850020\nseconds = 2.116\n\n//#define ALLOCATE_SEPERATE\n#define ONE_LOOP\n00570020\n00633520\n006F6A20\n007B9F20\nseconds = 1.894\n\n//#define ALLOCATE_SEPERATE\n//#define ONE_LOOP\n008C0020\n00983520\n00A46A20\n00B09F20\nseconds = 1.993', '```', ""Observations: 6.206 seconds with one loop and 2.116 seconds with two loops. This reproduces the OP's results exactly. In the first two tests, the arrays are allocated separately. You'll notice that they all have the same alignment relative to the page. In the second two tests, the arrays are packed together to break that alignment. Here you'll notice both loops are faster. Furthermore, the second (double) loop is now the slower one as you would normally expect. As @Stephen Cannon points out in the comments, there is a very likely possibility that this alignment causes false aliasing in the load/store units or the cache. I Googled around for this and found that Intel actually has a hardware counter for partial address aliasing stalls: http://software.intel.com/sites/products/documentation/doclib/stdxe/2013/~amplifierxe/pmw_dp/events/partial_address_alias.html 5 Regions - Explanations Region 1: This one is easy. The dataset is so small that the performance is dominated by overhead like"", '5 Regions - Explanations Region 1: This one is easy. The dataset is so small that the performance is dominated by overhead like looping and branching. Region 2: Here, as the data sizes increase, the amount of relative overhead goes down and the performance ""saturates"". Here two loops is slower because it has twice as much loop and branching overhead. I\'m not sure exactly what\'s going on here... Alignment could still play an effect as Agner Fog mentions cache bank conflicts. (That link is about Sandy Bridge, but the idea should still be applicable to Core 2.) Region 3: At this point, the data no longer fits in the L1 cache. So performance is capped by the L1 <-> L2 cache bandwidth. Region 4: The performance drop in the single-loop is what we are observing. And as mentioned, this is due to the alignment which (most likely) causes false aliasing stalls in the processor load/store units. However, in order for false aliasing to occur, there must be a large enough stride between the', ""due to the alignment which (most likely) causes false aliasing stalls in the processor load/store units. However, in order for false aliasing to occur, there must be a large enough stride between the datasets. This is why you don't see this in region 3. Region 5: At this point, nothing fits in the cache. So you're bound by memory bandwidth.""]","Upon further analysis of this, I believe this is (at least partially) caused by the data alignment of the four-pointers. This will cause some level of cache bank/way conflicts. If I've guessed correctly on how you are allocating your arrays, they are likely to be aligned to the page line. This means that all your accesses in each loop will fall on the same cache way. However, Intel processors have had 8-way L1 cache associativity for a while. But in reality, the performance isn't completely uniform. Accessing 4-ways is still slower than say 2-ways. EDIT: It does in fact look like you are allocating all the arrays separately. Usually when such large allocations are requested, the allocator will request fresh pages from the OS. Therefore, there is a high chance that large allocations will appear at the same offset from a page-boundary. Here's the test code: 
```
int main(){
    const int n = 100000;

#ifdef ALLOCATE_SEPERATE
    double *a1 = (double*)malloc(n * sizeof(double));
    double *b1 = (double*)malloc(n * sizeof(double));
    double *c1 = (double*)malloc(n * sizeof(double));
    double *d1 = (double*)malloc(n * sizeof(double));
#else
    double *a1 = (double*)malloc(n * sizeof(double) * 4);
    double *b1 = a1 + n;
    double *c1 = b1 + n;
    double *d1 = c1 + n;
#endif

    //  Zero the data to prevent any chance of denormals.
    memset(a1,0,n * sizeof(double));
    memset(b1,0,n * sizeof(double));
    memset(c1,0,n * sizeof(double));
    memset(d1,0,n * sizeof(double));

    //  Print the addresses
    cout << a1 << endl;
    cout << b1 << endl;
    cout << c1 << endl;
    cout << d1 << endl;

    clock_t start = clock();

    int c = 0;
    while (c++ < 10000){

#if ONE_LOOP
        for(int j=0;j<n;j++){
            a1[j] += b1[j];
            c1[j] += d1[j];
        }
#else
        for(int j=0;j<n;j++){
            a1[j] += b1[j];
        }
        for(int j=0;j<n;j++){
            c1[j] += d1[j];
        }
#endif

    }

    clock_t end = clock();
    cout << ""seconds = "" << (double)(end - start) / CLOCKS_PER_SEC << endl;

    system(""pause"");
    return 0;
}

```
 Benchmark Results: EDIT: Results on an actual Core 2 architecture machine: 2 x Intel Xeon X5482 Harpertown @ 3.2 GHz: 
```
#define ALLOCATE_SEPERATE
#define ONE_LOOP
00600020
006D0020
007A0020
00870020
seconds = 6.206

#define ALLOCATE_SEPERATE
//#define ONE_LOOP
005E0020
006B0020
00780020
00850020
seconds = 2.116

//#define ALLOCATE_SEPERATE
#define ONE_LOOP
00570020
00633520
006F6A20
007B9F20
seconds = 1.894

//#define ALLOCATE_SEPERATE
//#define ONE_LOOP
008C0020
00983520
00A46A20
00B09F20
seconds = 1.993

```
 Observations: 6.206 seconds with one loop and 2.116 seconds with two loops. This reproduces the OP's results exactly. In the first two tests, the arrays are allocated separately. You'll notice that they all have the same alignment relative to the page. In the second two tests, the arrays are packed together to break that alignment. Here you'll notice both loops are faster. Furthermore, the second (double) loop is now the slower one as you would normally expect. As @Stephen Cannon points out in the comments, there is a very likely possibility that this alignment causes false aliasing in the load/store units or the cache. I Googled around for this and found that Intel actually has a hardware counter for partial address aliasing stalls: http://software.intel.com/sites/products/documentation/doclib/stdxe/2013/~amplifierxe/pmw_dp/events/partial_address_alias.html 5 Regions - Explanations Region 1: This one is easy. The dataset is so small that the performance is dominated by overhead like looping and branching. Region 2: Here, as the data sizes increase, the amount of relative overhead goes down and the performance ""saturates"". Here two loops is slower because it has twice as much loop and branching overhead. I'm not sure exactly what's going on here... Alignment could still play an effect as Agner Fog mentions cache bank conflicts. (That link is about Sandy Bridge, but the idea should still be applicable to Core 2.) Region 3: At this point, the data no longer fits in the L1 cache. So performance is capped by the L1 <-> L2 cache bandwidth. Region 4: The performance drop in the single-loop is what we are observing. And as mentioned, this is due to the alignment which (most likely) causes false aliasing stalls in the processor load/store units. However, in order for false aliasing to occur, there must be a large enough stride between the datasets. This is why you don't see this in region 3. Region 5: At this point, nothing fits in the cache. So you're bound by memory bandwidth."
3279543,What is the copy-and-swap idiom?,https://stackoverflow.com/questions/3279543/what-is-the-copy-and-swap-idiom,5,2603.0,"[""Overview Why do we need the copy-and-swap idiom? Any class that manages a resource (a wrapper, like a smart pointer) needs to implement The Big Three. While the goals and implementation of the copy-constructor and destructor are straightforward, the copy-assignment operator is arguably the most nuanced and difficult. How should it be done? What pitfalls need to be avoided? The copy-and-swap idiom is the solution, and elegantly assists the assignment operator in achieving two things: avoiding code duplication, and providing a strong exception guarantee. How does it work? Conceptually, it works by using the copy-constructor's functionality to create a local copy of the data, then takes the copied data with a \n```\nswap\n```"", ""```\nswap\n```\n function, swapping the old data with the new data. The temporary copy then destructs, taking the old data with it. We are left with a copy of the new data. In order to use the copy-and-swap idiom, we need three things: a working copy-constructor, a working destructor (both are the basis of any wrapper, so should be complete anyway), and a \n```\nswap\n```\n function. A swap function is a non-throwing function that swaps two objects of a class, member for member. We might be tempted to use \n```\nstd::swap\n```\n instead of providing our own, but this would be impossible; \n```\nstd::swap\n```\n uses the copy-constructor and copy-assignment operator within its implementation, and we'd ultimately be trying to define the assignment operator in terms of itself! (Not only that, but unqualified calls to \n```\nswap\n```\n will use our custom swap operator, skipping over the unnecessary construction and destruction of our class that \n```\nstd::swap\n```"", ""```\nswap\n```\n will use our custom swap operator, skipping over the unnecessary construction and destruction of our class that \n```\nstd::swap\n```\n would entail.) An in-depth explanation The goal Let's consider a concrete case. We want to manage, in an otherwise useless class, a dynamic array. We start with a working constructor, copy-constructor, and destructor: \n```\n#include <algorithm> // std::copy\n#include <cstddef> // std::size_t"", 'class dumb_array\n{\npublic:\n    // (default) constructor\n    dumb_array(std::size_t size = 0)\n        : mSize(size),\n          mArray(mSize ? new int[mSize]() : nullptr)\n    {\n    }\n\n    // copy-constructor\n    dumb_array(const dumb_array& other)\n        : mSize(other.mSize),\n          mArray(mSize ? new int[mSize] : nullptr)\n    {\n        // note that this is non-throwing, because of the data\n        // types being used; more attention to detail with regards\n        // to exceptions must be given in a more general case, however\n        std::copy(other.mArray, other.mArray + mSize, mArray);\n    }\n\n    // destructor\n    ~dumb_array()\n    {\n        delete [] mArray;\n    }\n\nprivate:\n    std::size_t mSize;\n    int* mArray;\n};', ""// destructor\n    ~dumb_array()\n    {\n        delete [] mArray;\n    }\n\nprivate:\n    std::size_t mSize;\n    int* mArray;\n};\n\n```\n This class almost manages the array successfully, but it needs \n```\noperator=\n```\n to work correctly. A failed solution Here's how a naive implementation might look: \n```\n// the hard part\ndumb_array& operator=(const dumb_array& other)\n{\n    if (this != &other) // (1)\n    {\n        // get rid of the old data...\n        delete [] mArray; // (2)\n        mArray = nullptr; // (2) *(see footnote for rationale)\n\n        // ...and put in the new\n        mSize = other.mSize; // (3)\n        mArray = mSize ? new int[mSize] : nullptr; // (3)\n        std::copy(other.mArray, other.mArray + mSize, mArray); // (3)\n    }\n\n    return *this;\n}"", ""```\n And we say we're finished; this now manages an array, without leaks. However, it suffers from three problems, marked sequentially in the code as \n```\n(n)\n```\n. The first is the self-assignment test. This check serves two purposes: it's an easy way to prevent us from running needless code on self-assignment, and it protects us from subtle bugs (such as deleting the array only to try and copy it). But in all other cases it merely serves to slow the program down, and act as noise in the code; self-assignment rarely occurs, so most of the time this check is a waste. It would be better if the operator could work properly without it. The second is that it only provides a basic exception guarantee. If \n```\nnew int[mSize]\n```\n fails, \n```\n*this\n```\n will have been modified. (Namely, the size is wrong and the data is gone!) For a strong exception guarantee, it would need to be something akin to: \n```\n dumb_array& operator=(const dumb_array& other)\n {\n     if (this != &other) // (1)"", '```\n dumb_array& operator=(const dumb_array& other)\n {\n     if (this != &other) // (1)\n     {\n         // get the new data ready before we replace the old\n         std::size_t newSize = other.mSize;\n         int* newArray = newSize ? new int[newSize]() : nullptr; // (3)\n         std::copy(other.mArray, other.mArray + newSize, newArray); // (3)', '// replace the old data (all are non-throwing)\n         delete [] mArray;\n         mSize = newSize;\n         mArray = newArray;\n     }\n\n     return *this;\n }', ""```\n The code has expanded! Which leads us to the third problem: code duplication. Our assignment operator effectively duplicates all the code we've already written elsewhere, and that's a terrible thing. In our case, the core of it is only two lines (the allocation and the copy), but with more complex resources this code bloat can be quite a hassle. We should strive to never repeat ourselves. (One might wonder: if this much code is needed to manage one resource correctly, what if my class manages more than one? While this may seem to be a valid concern, and indeed it requires non-trivial \n```\ntry\n```\n/\n```\ncatch\n```\n clauses, this is a non-issue. That's because a class should manage one resource only!) A successful solution As mentioned, the copy-and-swap idiom will fix all these issues. But right now, we have all the requirements except one: a \n```\nswap\n```"", '```\nswap\n```\n function. While The Rule of Three successfully entails the existence of our copy-constructor, assignment operator, and destructor, it should really be called ""The Big Three and A Half"": any time your class manages a resource it also makes sense to provide a \n```\nswap\n```\n function. We need to add swap functionality to our class, and we do that as follows†: \n```\nclass dumb_array\n{\npublic:\n    // ...', ""friend void swap(dumb_array& first, dumb_array& second) // nothrow\n    {\n        // enable ADL (not necessary in our case, but good practice)\n        using std::swap;\n\n        // by swapping the members of two objects,\n        // the two objects are effectively swapped\n        swap(first.mSize, second.mSize);\n        swap(first.mArray, second.mArray);\n    }\n\n    // ...\n};\n\n```\n (Here is the explanation why \n```\npublic friend swap\n```\n.) Now not only can we swap our \n```\ndumb_array\n```\n's, but swaps in general can be more efficient; it merely swaps pointers and sizes, rather than allocating and copying entire arrays. Aside from this bonus in functionality and efficiency, we are now ready to implement the copy-and-swap idiom. Without further ado, our assignment operator is: \n```\ndumb_array& operator=(dumb_array other) // (1)\n{\n    swap(*this, other); // (2)\n\n    return *this;\n}"", ""return *this;\n}\n\n```\n And that's it! With one fell swoop, all three problems are elegantly tackled at once. Why does it work? We first notice an important choice: the parameter argument is taken by-value. While one could just as easily do the following (and indeed, many naive implementations of the idiom do): \n```\ndumb_array& operator=(const dumb_array& other)\n{\n    dumb_array temp(other);\n    swap(*this, temp);\n\n    return *this;\n}"", ""```\n We lose an important optimization opportunity. Not only that, but this choice is critical in C++11, which is discussed later. (On a general note, a remarkably useful guideline is as follows: if you're going to make a copy of something in a function, let the compiler do it in the parameter list.‡) Either way, this method of obtaining our resource is the key to eliminating code duplication: we get to use the code from the copy-constructor to make the copy, and never need to repeat any bit of it. Now that the copy is made, we are ready to swap. Observe that upon entering the function that all the new data is already allocated, copied, and ready to be used. This is what gives us a strong exception guarantee for free: we won't even enter the function if construction of the copy fails, and it's therefore not possible to alter the state of \n```\n*this\n```"", ""```\n*this\n```\n. (What we did manually before for a strong exception guarantee, the compiler is doing for us now; how kind.) At this point we are home-free, because \n```\nswap\n```\n is non-throwing. We swap our current data with the copied data, safely altering our state, and the old data gets put into the temporary. The old data is then released when the function returns. (Where upon the parameter's scope ends and its destructor is called.) Because the idiom repeats no code, we cannot introduce bugs within the operator. Note that this means we are rid of the need for a self-assignment check, allowing a single uniform implementation of \n```\noperator=\n```"", '```\noperator=\n```\n. (Additionally, we no longer have a performance penalty on non-self-assignments.) And that is the copy-and-swap idiom. What about C++11? The next version of C++, C++11, makes one very important change to how we manage resources: the Rule of Three is now The Rule of Four (and a half). Why? Because not only do we need to be able to copy-construct our resource, we need to move-construct it as well. Luckily for us, this is easy: \n```\nclass dumb_array\n{\npublic:\n    // ...', '// move constructor\n    dumb_array(dumb_array&& other) noexcept ††\n        : dumb_array() // initialize via default constructor, C++11 only\n    {\n        swap(*this, other);\n    }\n\n    // ...\n};', ""// ...\n};\n\n```\n What's going on here? Recall the goal of move-construction: to take the resources from another instance of the class, leaving it in a state guaranteed to be assignable and destructible. So what we've done is simple: initialize via the default constructor (a C++11 feature), then swap with \n```\nother\n```\n; we know a default constructed instance of our class can safely be assigned and destructed, so we know \n```\nother\n```\n will be able to do the same, after swapping. (Note that some compilers do not support constructor delegation; in this case, we have to manually default construct the class. This is an unfortunate but luckily trivial task.) Why does that work? That is the only change we need to make to our class, so why does it work? Remember the ever-important decision we made to make the parameter a value and not a reference: \n```\ndumb_array& operator=(dumb_array other); // (1)"", ""```\n Now, if \n```\nother\n```\n is being initialized with an rvalue, it will be move-constructed. Perfect. In the same way C++03 let us re-use our copy-constructor functionality by taking the argument by-value, C++11 will automatically pick the move-constructor when appropriate as well. (And, of course, as mentioned in previously linked article, the copying/moving of the value may simply be elided altogether.) And so concludes the copy-and-swap idiom. Footnotes *Why do we set \n```\nmArray\n```\n to null? Because if any further code in the operator throws, the destructor of \n```\ndumb_array\n```\n might be called; and if that happens without setting it to null, we attempt to delete memory that's already been deleted! We avoid this by setting it to null, as deleting null is a no-operation. †There are other claims that we should specialize \n```\nstd::swap\n```\n for our type, provide an in-class \n```\nswap\n```\n along-side a free-function \n```\nswap\n```"", ""```\nstd::swap\n```\n for our type, provide an in-class \n```\nswap\n```\n along-side a free-function \n```\nswap\n```\n, etc. But this is all unnecessary: any proper use of \n```\nswap\n```\n will be through an unqualified call, and our function will be found through ADL. One function will do. ‡The reason is simple: once you have the resource to yourself, you may swap and/or move it (C++11) anywhere it needs to be. And by making the copy in the parameter list, you maximize optimization. ††The move constructor should generally be \n```\nnoexcept\n```\n, otherwise some code (e.g. \n```\nstd::vector\n```\n resizing logic) will use the copy constructor even when a move would make sense. Of course, only mark it noexcept if the code inside doesn't throw exceptions.""]","Overview Why do we need the copy-and-swap idiom? Any class that manages a resource (a wrapper, like a smart pointer) needs to implement The Big Three. While the goals and implementation of the copy-constructor and destructor are straightforward, the copy-assignment operator is arguably the most nuanced and difficult. How should it be done? What pitfalls need to be avoided? The copy-and-swap idiom is the solution, and elegantly assists the assignment operator in achieving two things: avoiding code duplication, and providing a strong exception guarantee. How does it work? Conceptually, it works by using the copy-constructor's functionality to create a local copy of the data, then takes the copied data with a 
```
swap
```
 function, swapping the old data with the new data. The temporary copy then destructs, taking the old data with it. We are left with a copy of the new data. In order to use the copy-and-swap idiom, we need three things: a working copy-constructor, a working destructor (both are the basis of any wrapper, so should be complete anyway), and a 
```
swap
```
 function. A swap function is a non-throwing function that swaps two objects of a class, member for member. We might be tempted to use 
```
std::swap
```
 instead of providing our own, but this would be impossible; 
```
std::swap
```
 uses the copy-constructor and copy-assignment operator within its implementation, and we'd ultimately be trying to define the assignment operator in terms of itself! (Not only that, but unqualified calls to 
```
swap
```
 will use our custom swap operator, skipping over the unnecessary construction and destruction of our class that 
```
std::swap
```
 would entail.) An in-depth explanation The goal Let's consider a concrete case. We want to manage, in an otherwise useless class, a dynamic array. We start with a working constructor, copy-constructor, and destructor: 
```
#include <algorithm> // std::copy
#include <cstddef> // std::size_t

class dumb_array
{
public:
    // (default) constructor
    dumb_array(std::size_t size = 0)
        : mSize(size),
          mArray(mSize ? new int[mSize]() : nullptr)
    {
    }

    // copy-constructor
    dumb_array(const dumb_array& other)
        : mSize(other.mSize),
          mArray(mSize ? new int[mSize] : nullptr)
    {
        // note that this is non-throwing, because of the data
        // types being used; more attention to detail with regards
        // to exceptions must be given in a more general case, however
        std::copy(other.mArray, other.mArray + mSize, mArray);
    }

    // destructor
    ~dumb_array()
    {
        delete [] mArray;
    }

private:
    std::size_t mSize;
    int* mArray;
};

```
 This class almost manages the array successfully, but it needs 
```
operator=
```
 to work correctly. A failed solution Here's how a naive implementation might look: 
```
// the hard part
dumb_array& operator=(const dumb_array& other)
{
    if (this != &other) // (1)
    {
        // get rid of the old data...
        delete [] mArray; // (2)
        mArray = nullptr; // (2) *(see footnote for rationale)

        // ...and put in the new
        mSize = other.mSize; // (3)
        mArray = mSize ? new int[mSize] : nullptr; // (3)
        std::copy(other.mArray, other.mArray + mSize, mArray); // (3)
    }

    return *this;
}

```
 And we say we're finished; this now manages an array, without leaks. However, it suffers from three problems, marked sequentially in the code as 
```
(n)
```
. The first is the self-assignment test. This check serves two purposes: it's an easy way to prevent us from running needless code on self-assignment, and it protects us from subtle bugs (such as deleting the array only to try and copy it). But in all other cases it merely serves to slow the program down, and act as noise in the code; self-assignment rarely occurs, so most of the time this check is a waste. It would be better if the operator could work properly without it. The second is that it only provides a basic exception guarantee. If 
```
new int[mSize]
```
 fails, 
```
*this
```
 will have been modified. (Namely, the size is wrong and the data is gone!) For a strong exception guarantee, it would need to be something akin to: 
```
 dumb_array& operator=(const dumb_array& other)
 {
     if (this != &other) // (1)
     {
         // get the new data ready before we replace the old
         std::size_t newSize = other.mSize;
         int* newArray = newSize ? new int[newSize]() : nullptr; // (3)
         std::copy(other.mArray, other.mArray + newSize, newArray); // (3)

         // replace the old data (all are non-throwing)
         delete [] mArray;
         mSize = newSize;
         mArray = newArray;
     }

     return *this;
 }

```
 The code has expanded! Which leads us to the third problem: code duplication. Our assignment operator effectively duplicates all the code we've already written elsewhere, and that's a terrible thing. In our case, the core of it is only two lines (the allocation and the copy), but with more complex resources this code bloat can be quite a hassle. We should strive to never repeat ourselves. (One might wonder: if this much code is needed to manage one resource correctly, what if my class manages more than one? While this may seem to be a valid concern, and indeed it requires non-trivial 
```
try
```
/
```
catch
```
 clauses, this is a non-issue. That's because a class should manage one resource only!) A successful solution As mentioned, the copy-and-swap idiom will fix all these issues. But right now, we have all the requirements except one: a 
```
swap
```
 function. While The Rule of Three successfully entails the existence of our copy-constructor, assignment operator, and destructor, it should really be called ""The Big Three and A Half"": any time your class manages a resource it also makes sense to provide a 
```
swap
```
 function. We need to add swap functionality to our class, and we do that as follows†: 
```
class dumb_array
{
public:
    // ...

    friend void swap(dumb_array& first, dumb_array& second) // nothrow
    {
        // enable ADL (not necessary in our case, but good practice)
        using std::swap;

        // by swapping the members of two objects,
        // the two objects are effectively swapped
        swap(first.mSize, second.mSize);
        swap(first.mArray, second.mArray);
    }

    // ...
};

```
 (Here is the explanation why 
```
public friend swap
```
.) Now not only can we swap our 
```
dumb_array
```
's, but swaps in general can be more efficient; it merely swaps pointers and sizes, rather than allocating and copying entire arrays. Aside from this bonus in functionality and efficiency, we are now ready to implement the copy-and-swap idiom. Without further ado, our assignment operator is: 
```
dumb_array& operator=(dumb_array other) // (1)
{
    swap(*this, other); // (2)

    return *this;
}

```
 And that's it! With one fell swoop, all three problems are elegantly tackled at once. Why does it work? We first notice an important choice: the parameter argument is taken by-value. While one could just as easily do the following (and indeed, many naive implementations of the idiom do): 
```
dumb_array& operator=(const dumb_array& other)
{
    dumb_array temp(other);
    swap(*this, temp);

    return *this;
}

```
 We lose an important optimization opportunity. Not only that, but this choice is critical in C++11, which is discussed later. (On a general note, a remarkably useful guideline is as follows: if you're going to make a copy of something in a function, let the compiler do it in the parameter list.‡) Either way, this method of obtaining our resource is the key to eliminating code duplication: we get to use the code from the copy-constructor to make the copy, and never need to repeat any bit of it. Now that the copy is made, we are ready to swap. Observe that upon entering the function that all the new data is already allocated, copied, and ready to be used. This is what gives us a strong exception guarantee for free: we won't even enter the function if construction of the copy fails, and it's therefore not possible to alter the state of 
```
*this
```
. (What we did manually before for a strong exception guarantee, the compiler is doing for us now; how kind.) At this point we are home-free, because 
```
swap
```
 is non-throwing. We swap our current data with the copied data, safely altering our state, and the old data gets put into the temporary. The old data is then released when the function returns. (Where upon the parameter's scope ends and its destructor is called.) Because the idiom repeats no code, we cannot introduce bugs within the operator. Note that this means we are rid of the need for a self-assignment check, allowing a single uniform implementation of 
```
operator=
```
. (Additionally, we no longer have a performance penalty on non-self-assignments.) And that is the copy-and-swap idiom. What about C++11? The next version of C++, C++11, makes one very important change to how we manage resources: the Rule of Three is now The Rule of Four (and a half). Why? Because not only do we need to be able to copy-construct our resource, we need to move-construct it as well. Luckily for us, this is easy: 
```
class dumb_array
{
public:
    // ...

    // move constructor
    dumb_array(dumb_array&& other) noexcept ††
        : dumb_array() // initialize via default constructor, C++11 only
    {
        swap(*this, other);
    }

    // ...
};

```
 What's going on here? Recall the goal of move-construction: to take the resources from another instance of the class, leaving it in a state guaranteed to be assignable and destructible. So what we've done is simple: initialize via the default constructor (a C++11 feature), then swap with 
```
other
```
; we know a default constructed instance of our class can safely be assigned and destructed, so we know 
```
other
```
 will be able to do the same, after swapping. (Note that some compilers do not support constructor delegation; in this case, we have to manually default construct the class. This is an unfortunate but luckily trivial task.) Why does that work? That is the only change we need to make to our class, so why does it work? Remember the ever-important decision we made to make the parameter a value and not a reference: 
```
dumb_array& operator=(dumb_array other); // (1)

```
 Now, if 
```
other
```
 is being initialized with an rvalue, it will be move-constructed. Perfect. In the same way C++03 let us re-use our copy-constructor functionality by taking the argument by-value, C++11 will automatically pick the move-constructor when appropriate as well. (And, of course, as mentioned in previously linked article, the copying/moving of the value may simply be elided altogether.) And so concludes the copy-and-swap idiom. Footnotes *Why do we set 
```
mArray
```
 to null? Because if any further code in the operator throws, the destructor of 
```
dumb_array
```
 might be called; and if that happens without setting it to null, we attempt to delete memory that's already been deleted! We avoid this by setting it to null, as deleting null is a no-operation. †There are other claims that we should specialize 
```
std::swap
```
 for our type, provide an in-class 
```
swap
```
 along-side a free-function 
```
swap
```
, etc. But this is all unnecessary: any proper use of 
```
swap
```
 will be through an unqualified call, and our function will be found through ADL. One function will do. ‡The reason is simple: once you have the resource to yourself, you may swap and/or move it (C++11) anywhere it needs to be. And by making the copy in the parameter list, you maximize optimization. ††The move constructor should generally be 
```
noexcept
```
, otherwise some code (e.g. 
```
std::vector
```
 resizing logic) will use the copy constructor even when a move would make sense. Of course, only mark it noexcept if the code inside doesn't throw exceptions."
495021,Why can templates only be implemented in the header file?,https://stackoverflow.com/questions/495021/why-can-templates-only-be-implemented-in-the-header-file,19,2013.0,"[""Caveat: It is not necessary to put the implementation in the header file, see the alternative solution at the end of this answer. Anyway, the reason your code is failing is that, when instantiating a template, the compiler creates a new class with the given template argument. For example: \n```\ntemplate<typename T>\nstruct Foo\n{\n    T bar;\n    void doSomething(T param) {/* do stuff using T */}\n};\n\n// somewhere in a .cpp\nFoo<int> f; \n\n```\n When reading this line, the compiler will create a new class (let's call it \n```\nFooInt\n```\n), which is equivalent to the following: \n```\nstruct FooInt\n{\n    int bar;\n    void doSomething(int param) {/* do stuff using int */}\n};"", '```\n Consequently, the compiler needs to have access to the implementation of the methods, to instantiate them with the template argument (in this case \n```\nint\n```\n). If these implementations were not in the header, they wouldn\'t be accessible, and therefore the compiler wouldn\'t be able to instantiate the template. A common solution to this is to write the template declaration in a header file, then implement the class in an implementation file (for example .tpp), and include this implementation file at the end of the header. Foo.h \n```\ntemplate <typename T>\nstruct Foo\n{\n    void doSomething(T param);\n};\n\n#include ""Foo.tpp""\n\n```\n Foo.tpp \n```\ntemplate <typename T>\nvoid Foo<T>::doSomething(T param)\n{\n    //implementation\n}', '#include ""Foo.tpp""\n\n```\n Foo.tpp \n```\ntemplate <typename T>\nvoid Foo<T>::doSomething(T param)\n{\n    //implementation\n}\n\n```\n This way, implementation is still separated from declaration, but is accessible to the compiler. Alternative solution Another solution is to keep the implementation separated, and explicitly instantiate all the template instances you\'ll need: Foo.h \n```\n// no implementation\ntemplate <typename T> struct Foo { ... };\n\n```\n Foo.cpp \n```\n// implementation of Foo\'s methods\n\n// explicit instantiations\ntemplate class Foo<int>;\ntemplate class Foo<float>;\n// You will only be able to use Foo with int or float\n\n```\n If my explanation isn\'t clear enough, you can have a look at the C++ Super-FAQ on this subject.']","Caveat: It is not necessary to put the implementation in the header file, see the alternative solution at the end of this answer. Anyway, the reason your code is failing is that, when instantiating a template, the compiler creates a new class with the given template argument. For example: 
```
template<typename T>
struct Foo
{
    T bar;
    void doSomething(T param) {/* do stuff using T */}
};

// somewhere in a .cpp
Foo<int> f; 

```
 When reading this line, the compiler will create a new class (let's call it 
```
FooInt
```
), which is equivalent to the following: 
```
struct FooInt
{
    int bar;
    void doSomething(int param) {/* do stuff using int */}
};

```
 Consequently, the compiler needs to have access to the implementation of the methods, to instantiate them with the template argument (in this case 
```
int
```
). If these implementations were not in the header, they wouldn't be accessible, and therefore the compiler wouldn't be able to instantiate the template. A common solution to this is to write the template declaration in a header file, then implement the class in an implementation file (for example .tpp), and include this implementation file at the end of the header. Foo.h 
```
template <typename T>
struct Foo
{
    void doSomething(T param);
};

#include ""Foo.tpp""

```
 Foo.tpp 
```
template <typename T>
void Foo<T>::doSomething(T param)
{
    //implementation
}

```
 This way, implementation is still separated from declaration, but is accessible to the compiler. Alternative solution Another solution is to keep the implementation separated, and explicitly instantiate all the template instances you'll need: Foo.h 
```
// no implementation
template <typename T> struct Foo { ... };

```
 Foo.cpp 
```
// implementation of Foo's methods

// explicit instantiations
template class Foo<int>;
template class Foo<float>;
// You will only be able to use Foo with int or float

```
 If my explanation isn't clear enough, you can have a look at the C++ Super-FAQ on this subject."
6319146,C++11 introduced a standardized memory model. What does it mean? And how is it going to affect C++ programming?,https://stackoverflow.com/questions/6319146/c11-introduced-a-standardized-memory-model-what-does-it-mean-and-how-is-it-g,9,2562.0,"['First, you have to learn to think like a Language Lawyer. The C++ specification does not make reference to any particular compiler, operating system, or CPU. It makes reference to an abstract machine that is a generalization of actual systems. In the Language Lawyer world, the job of the programmer is to write code for the abstract machine; the job of the compiler is to actualize that code on a concrete machine. By coding rigidly to the spec, you can be certain that your code will compile and run without modification on any system with a compliant C++ compiler, whether today or 50 years from now. The abstract machine in the C++98/C++03 specification is fundamentally single-threaded. So it is not possible to write multi-threaded C++ code that is ""fully portable"" with respect to the spec. The spec does not even say anything about the atomicity of memory loads and stores or the order in which loads and stores might happen, never mind things like mutexes. Of course, you can write', 'spec. The spec does not even say anything about the atomicity of memory loads and stores or the order in which loads and stores might happen, never mind things like mutexes. Of course, you can write multi-threaded code in practice for particular concrete systems – like pthreads or Windows. But there is no standard way to write multi-threaded code for C++98/C++03. The abstract machine in C++11 is multi-threaded by design. It also has a well-defined memory model; that is, it says what the compiler may and may not do when it comes to accessing memory. Consider the following example, where a pair of global variables are accessed concurrently by two threads:', '```\n           Global\n           int x, y;', 'Thread 1            Thread 2\nx = 17;             cout << y << "" "";\ny = 37;             cout << x << endl;\n\n```\n What might Thread 2 output? Under C++98/C++03, this is not even Undefined Behavior; the question itself is meaningless because the standard does not contemplate anything called a ""thread"". Under C++11, the result is Undefined Behavior, because loads and stores need not be atomic in general. Which may not seem like much of an improvement... And by itself, it\'s not. But with C++11, you can write this: \n```\n           Global\n           atomic<int> x, y;\n\nThread 1                 Thread 2\nx.store(17);             cout << y.load() << "" "";\ny.store(37);             cout << x.load() << endl;', '```\n Now things get much more interesting. First of all, the behavior here is defined. Thread 2 could now print \n```\n0 0\n```\n (if it runs before Thread 1), \n```\n37 17\n```\n (if it runs after Thread 1), or \n```\n0 17\n```\n (if it runs after Thread 1 assigns to x but before it assigns to y). What it cannot print is \n```\n37 0\n```', '```\n37 17\n```\n (if it runs after Thread 1), or \n```\n0 17\n```\n (if it runs after Thread 1 assigns to x but before it assigns to y). What it cannot print is \n```\n37 0\n```\n, because the default mode for atomic loads/stores in C++11 is to enforce sequential consistency. This just means all loads and stores must be ""as if"" they happened in the order you wrote them within each thread, while operations among threads can be interleaved however the system likes. So the default behavior of atomics provides both atomicity and ordering for loads and stores. Now, on a modern CPU, ensuring sequential consistency can be expensive. In particular, the compiler is likely to emit full-blown memory barriers between every access here. But if your algorithm can tolerate out-of-order loads and stores; i.e., if it requires atomicity but not ordering; i.e., if it can tolerate \n```\n37 0\n```\n as output from this program, then you can write this: \n```\n           Global\n           atomic<int> x, y;', 'Thread 1                            Thread 2\nx.store(17,memory_order_relaxed);   cout << y.load(memory_order_relaxed) << "" "";\ny.store(37,memory_order_relaxed);   cout << x.load(memory_order_relaxed) << endl;\n\n```\n The more modern the CPU, the more likely this is to be faster than the previous example. Finally, if you just need to keep particular loads and stores in order, you can write: \n```\n           Global\n           atomic<int> x, y;\n\nThread 1                            Thread 2\nx.store(17,memory_order_release);   cout << y.load(memory_order_acquire) << "" "";\ny.store(37,memory_order_release);   cout << x.load(memory_order_acquire) << endl;', '```\n This takes us back to the ordered loads and stores – so \n```\n37 0\n```\n is no longer a possible output – but it does so with minimal overhead. (In this trivial example, the result is the same as full-blown sequential consistency; in a larger program, it would not be.) Of course, if the only outputs you want to see are \n```\n0 0\n```\n or \n```\n37 17\n```', "", you can just wrap a mutex around the original code. But if you have read this far, I bet you already know how that works, and this answer is already longer than I intended :-). So, bottom line. Mutexes are great, and C++11 standardizes them. But sometimes for performance reasons you want lower-level primitives (e.g., the classic double-checked locking pattern). The new standard provides high-level gadgets like mutexes and condition variables, and it also provides low-level gadgets like atomic types and the various flavors of memory barrier. So now you can write sophisticated, high-performance concurrent routines entirely within the language specified by the standard, and you can be certain your code will compile and run unchanged on both today's systems and tomorrow's. Although to be frank, unless you are an expert and working on some serious low-level code, you should probably stick to mutexes and condition variables. That's what I intend to do. For more on this stuff, see this"", ""frank, unless you are an expert and working on some serious low-level code, you should probably stick to mutexes and condition variables. That's what I intend to do. For more on this stuff, see this blog post.""]","First, you have to learn to think like a Language Lawyer. The C++ specification does not make reference to any particular compiler, operating system, or CPU. It makes reference to an abstract machine that is a generalization of actual systems. In the Language Lawyer world, the job of the programmer is to write code for the abstract machine; the job of the compiler is to actualize that code on a concrete machine. By coding rigidly to the spec, you can be certain that your code will compile and run without modification on any system with a compliant C++ compiler, whether today or 50 years from now. The abstract machine in the C++98/C++03 specification is fundamentally single-threaded. So it is not possible to write multi-threaded C++ code that is ""fully portable"" with respect to the spec. The spec does not even say anything about the atomicity of memory loads and stores or the order in which loads and stores might happen, never mind things like mutexes. Of course, you can write multi-threaded code in practice for particular concrete systems – like pthreads or Windows. But there is no standard way to write multi-threaded code for C++98/C++03. The abstract machine in C++11 is multi-threaded by design. It also has a well-defined memory model; that is, it says what the compiler may and may not do when it comes to accessing memory. Consider the following example, where a pair of global variables are accessed concurrently by two threads: 
```
           Global
           int x, y;

Thread 1            Thread 2
x = 17;             cout << y << "" "";
y = 37;             cout << x << endl;

```
 What might Thread 2 output? Under C++98/C++03, this is not even Undefined Behavior; the question itself is meaningless because the standard does not contemplate anything called a ""thread"". Under C++11, the result is Undefined Behavior, because loads and stores need not be atomic in general. Which may not seem like much of an improvement... And by itself, it's not. But with C++11, you can write this: 
```
           Global
           atomic<int> x, y;

Thread 1                 Thread 2
x.store(17);             cout << y.load() << "" "";
y.store(37);             cout << x.load() << endl;

```
 Now things get much more interesting. First of all, the behavior here is defined. Thread 2 could now print 
```
0 0
```
 (if it runs before Thread 1), 
```
37 17
```
 (if it runs after Thread 1), or 
```
0 17
```
 (if it runs after Thread 1 assigns to x but before it assigns to y). What it cannot print is 
```
37 0
```
, because the default mode for atomic loads/stores in C++11 is to enforce sequential consistency. This just means all loads and stores must be ""as if"" they happened in the order you wrote them within each thread, while operations among threads can be interleaved however the system likes. So the default behavior of atomics provides both atomicity and ordering for loads and stores. Now, on a modern CPU, ensuring sequential consistency can be expensive. In particular, the compiler is likely to emit full-blown memory barriers between every access here. But if your algorithm can tolerate out-of-order loads and stores; i.e., if it requires atomicity but not ordering; i.e., if it can tolerate 
```
37 0
```
 as output from this program, then you can write this: 
```
           Global
           atomic<int> x, y;

Thread 1                            Thread 2
x.store(17,memory_order_relaxed);   cout << y.load(memory_order_relaxed) << "" "";
y.store(37,memory_order_relaxed);   cout << x.load(memory_order_relaxed) << endl;

```
 The more modern the CPU, the more likely this is to be faster than the previous example. Finally, if you just need to keep particular loads and stores in order, you can write: 
```
           Global
           atomic<int> x, y;

Thread 1                            Thread 2
x.store(17,memory_order_release);   cout << y.load(memory_order_acquire) << "" "";
y.store(37,memory_order_release);   cout << x.load(memory_order_acquire) << endl;

```
 This takes us back to the ordered loads and stores – so 
```
37 0
```
 is no longer a possible output – but it does so with minimal overhead. (In this trivial example, the result is the same as full-blown sequential consistency; in a larger program, it would not be.) Of course, if the only outputs you want to see are 
```
0 0
```
 or 
```
37 17
```
, you can just wrap a mutex around the original code. But if you have read this far, I bet you already know how that works, and this answer is already longer than I intended :-). So, bottom line. Mutexes are great, and C++11 standardizes them. But sometimes for performance reasons you want lower-level primitives (e.g., the classic double-checked locking pattern). The new standard provides high-level gadgets like mutexes and condition variables, and it also provides low-level gadgets like atomic types and the various flavors of memory barrier. So now you can write sophisticated, high-performance concurrent routines entirely within the language specified by the standard, and you can be certain your code will compile and run unchanged on both today's systems and tomorrow's. Although to be frank, unless you are an expert and working on some serious low-level code, you should probably stick to mutexes and condition variables. That's what I intend to do. For more on this stuff, see this blog post."
9371238,Why is reading lines from stdin much slower in C++ than Python?,https://stackoverflow.com/questions/9371238/why-is-reading-lines-from-stdin-much-slower-in-c-than-python,11,1950.0,"['tl;dr: Because of different default settings in C++ requiring more system calls. By default, \n```\ncin\n```\n is synchronized with stdio, which causes it to avoid any input buffering. If you add this to the top of your main, you should see much better performance: \n```\nstd::ios_base::sync_with_stdio(false);\n\n```\n Normally, when an input stream is buffered, instead of reading one character at a time, the stream will be read in larger chunks. This reduces the number of system calls, which are typically relatively expensive. However, since the \n```\nFILE*\n```\n based \n```\nstdio\n```\n and \n```\niostreams\n```\n often have separate implementations and therefore separate buffers, this could lead to a problem if both were used together. For example: \n```\nint myvalue1;\ncin >> myvalue1;\nint myvalue2;\nscanf(""%d"",&myvalue2);', ""```\n If more input was read by \n```\ncin\n```\n than it actually needed, then the second integer value wouldn't be available for the \n```\nscanf\n```\n function, which has its own independent buffer. This would lead to unexpected results. To avoid this, by default, streams are synchronized with \n```\nstdio\n```\n. One common way to achieve this is to have \n```\ncin\n```\n read each character one at a time as needed using \n```\nstdio\n```\n functions. Unfortunately, this introduces a lot of overhead. For small amounts of input, this isn't a big problem, but when you are reading millions of lines, the performance penalty is significant. Fortunately, the library designers decided that you should also be able to disable this feature to get improved performance if you knew what you were doing, so they provided the \n```\nsync_with_stdio\n```"", '```\nsync_with_stdio\n```\n method. From this link (emphasis added): If the synchronization is turned off, the C++ standard streams are allowed to buffer their I/O independently, which may be considerably faster in some cases.']","tl;dr: Because of different default settings in C++ requiring more system calls. By default, 
```
cin
```
 is synchronized with stdio, which causes it to avoid any input buffering. If you add this to the top of your main, you should see much better performance: 
```
std::ios_base::sync_with_stdio(false);

```
 Normally, when an input stream is buffered, instead of reading one character at a time, the stream will be read in larger chunks. This reduces the number of system calls, which are typically relatively expensive. However, since the 
```
FILE*
```
 based 
```
stdio
```
 and 
```
iostreams
```
 often have separate implementations and therefore separate buffers, this could lead to a problem if both were used together. For example: 
```
int myvalue1;
cin >> myvalue1;
int myvalue2;
scanf(""%d"",&myvalue2);

```
 If more input was read by 
```
cin
```
 than it actually needed, then the second integer value wouldn't be available for the 
```
scanf
```
 function, which has its own independent buffer. This would lead to unexpected results. To avoid this, by default, streams are synchronized with 
```
stdio
```
. One common way to achieve this is to have 
```
cin
```
 read each character one at a time as needed using 
```
stdio
```
 functions. Unfortunately, this introduces a lot of overhead. For small amounts of input, this isn't a big problem, but when you are reading millions of lines, the performance penalty is significant. Fortunately, the library designers decided that you should also be able to disable this feature to get improved performance if you knew what you were doing, so they provided the 
```
sync_with_stdio
```
 method. From this link (emphasis added): If the synchronization is turned off, the C++ standard streams are allowed to buffer their I/O independently, which may be considerably faster in some cases."
106508,What is a smart pointer and when should I use one?,https://stackoverflow.com/questions/106508/what-is-a-smart-pointer-and-when-should-i-use-one,14,2054.0,"['UPDATE This answer is rather old, and so describes what was \'good\' at the time, which was smart pointers provided by the Boost library. Since C++11, the standard library has provided sufficient smart pointers types, and so you should favour the use of \n```\nstd::unique_ptr\n```\n, \n```\nstd::shared_ptr\n```\n and \n```\nstd::weak_ptr\n```\n. There was also \n```\nstd::auto_ptr\n```\n. It was very much like a scoped pointer, except that it also had the ""special"" dangerous ability to be copied — which also unexpectedly transfers ownership. It was deprecated in C++11 and removed in C++17, so you shouldn\'t use it. \n```\nstd::auto_ptr<MyObject> p1 (new MyObject());\nstd::auto_ptr<MyObject> p2 = p1; // Copy and transfer ownership. \n                                 // p1 gets set to empty!\np2->DoSomething(); // Works.\np1->DoSomething(); // Oh oh. Hopefully raises some NULL pointer exception.', ""```\n OLD ANSWER A smart pointer is a class that wraps a 'raw' (or 'bare') C++ pointer, to manage the lifetime of the object being pointed to. There is no single smart pointer type, but all of them try to abstract a raw pointer in a practical way. Smart pointers should be preferred over raw pointers. If you feel you need to use pointers (first consider if you really do), you would normally want to use a smart pointer as this can alleviate many of the problems with raw pointers, mainly forgetting to delete the object and leaking memory. With raw pointers, the programmer has to explicitly destroy the object when it is no longer useful. \n```\n// Need to create the object to achieve some goal\nMyObject* ptr = new MyObject(); \nptr->DoSomething(); // Use the object in some way\ndelete ptr; // Destroy the object. Done with it.\n// Wait, what if DoSomething() raises an exception...?"", '```\n A smart pointer by comparison defines a policy as to when the object is destroyed. You still have to create the object, but you no longer have to worry about destroying it. \n```\nSomeSmartPtr<MyObject> ptr(new MyObject());\nptr->DoSomething(); // Use the object in some way.\n\n// Destruction of the object happens, depending \n// on the policy the smart pointer class uses.\n\n// Destruction would happen even if DoSomething() \n// raises an exception\n\n```\n The simplest policy in use involves the scope of the smart pointer wrapper object, such as implemented by \n```\nboost::scoped_ptr\n```\n or \n```\nstd::unique_ptr\n```\n. \n```\nvoid f()\n{\n    {\n       std::unique_ptr<MyObject> ptr(new MyObject());\n       ptr->DoSomethingUseful();\n    } // ptr goes out of scope -- \n      // the MyObject is automatically destroyed.\n\n    // ptr->Oops(); // Compile error: ""ptr"" not defined\n                    // since it is no longer in scope.\n}', '```\n Note that \n```\nstd::unique_ptr\n```\n instances cannot be copied. This prevents the pointer from being deleted multiple times (incorrectly). You can, however, pass references to it around to other functions you call. \n```\nstd::unique_ptr\n```\ns are useful when you want to tie the lifetime of the object to a particular block of code, or if you embedded it as member data inside another object, the lifetime of that other object. The object exists until the containing block of code is exited, or until the containing object is itself destroyed. A more complex smart pointer policy involves reference counting the pointer. This does allow the pointer to be copied. When the last ""reference"" to the object is destroyed, the object is deleted. This policy is implemented by \n```\nboost::shared_ptr\n```\n and \n```\nstd::shared_ptr\n```\n. \n```\nvoid f()\n{\n    typedef std::shared_ptr<MyObject> MyObjectPtr; // nice short alias\n    MyObjectPtr p1; // Empty', '{\n        MyObjectPtr p2(new MyObject());\n        // There is now one ""reference"" to the created object\n        p1 = p2; // Copy the pointer.\n        // There are now two references to the object.\n    } // p2 is destroyed, leaving one reference to the object.\n} // p1 is destroyed, leaving a reference count of zero. \n  // The object is deleted.\n\n```\n Reference counted pointers are very useful when the lifetime of your object is much more complicated, and is not tied directly to a particular section of code or to another object. There is one drawback to reference counted pointers — the possibility of creating a dangling reference: \n```\n// Create the smart pointer on the heap\nMyObjectPtr* pp = new MyObjectPtr(new MyObject())\n// Hmm, we forgot to destroy the smart pointer,\n// because of that, the object is never destroyed!\n\n```\n Another possibility is creating circular references: \n```\nstruct Owner {\n   std::shared_ptr<Owner> other;\n};', '```\n Another possibility is creating circular references: \n```\nstruct Owner {\n   std::shared_ptr<Owner> other;\n};\n\nstd::shared_ptr<Owner> p1 (new Owner());\nstd::shared_ptr<Owner> p2 (new Owner());\np1->other = p2; // p1 references p2\np2->other = p1; // p2 references p1\n\n// Oops, the reference count of of p1 and p2 never goes to zero!\n// The objects are never destroyed!\n\n```\n To work around this problem, both Boost and C++11 have defined a \n```\nweak_ptr\n```\n to define a weak (uncounted) reference to a \n```\nshared_ptr\n```\n.']","UPDATE This answer is rather old, and so describes what was 'good' at the time, which was smart pointers provided by the Boost library. Since C++11, the standard library has provided sufficient smart pointers types, and so you should favour the use of 
```
std::unique_ptr
```
, 
```
std::shared_ptr
```
 and 
```
std::weak_ptr
```
. There was also 
```
std::auto_ptr
```
. It was very much like a scoped pointer, except that it also had the ""special"" dangerous ability to be copied — which also unexpectedly transfers ownership. It was deprecated in C++11 and removed in C++17, so you shouldn't use it. 
```
std::auto_ptr<MyObject> p1 (new MyObject());
std::auto_ptr<MyObject> p2 = p1; // Copy and transfer ownership. 
                                 // p1 gets set to empty!
p2->DoSomething(); // Works.
p1->DoSomething(); // Oh oh. Hopefully raises some NULL pointer exception.

```
 OLD ANSWER A smart pointer is a class that wraps a 'raw' (or 'bare') C++ pointer, to manage the lifetime of the object being pointed to. There is no single smart pointer type, but all of them try to abstract a raw pointer in a practical way. Smart pointers should be preferred over raw pointers. If you feel you need to use pointers (first consider if you really do), you would normally want to use a smart pointer as this can alleviate many of the problems with raw pointers, mainly forgetting to delete the object and leaking memory. With raw pointers, the programmer has to explicitly destroy the object when it is no longer useful. 
```
// Need to create the object to achieve some goal
MyObject* ptr = new MyObject(); 
ptr->DoSomething(); // Use the object in some way
delete ptr; // Destroy the object. Done with it.
// Wait, what if DoSomething() raises an exception...?

```
 A smart pointer by comparison defines a policy as to when the object is destroyed. You still have to create the object, but you no longer have to worry about destroying it. 
```
SomeSmartPtr<MyObject> ptr(new MyObject());
ptr->DoSomething(); // Use the object in some way.

// Destruction of the object happens, depending 
// on the policy the smart pointer class uses.

// Destruction would happen even if DoSomething() 
// raises an exception

```
 The simplest policy in use involves the scope of the smart pointer wrapper object, such as implemented by 
```
boost::scoped_ptr
```
 or 
```
std::unique_ptr
```
. 
```
void f()
{
    {
       std::unique_ptr<MyObject> ptr(new MyObject());
       ptr->DoSomethingUseful();
    } // ptr goes out of scope -- 
      // the MyObject is automatically destroyed.

    // ptr->Oops(); // Compile error: ""ptr"" not defined
                    // since it is no longer in scope.
}

```
 Note that 
```
std::unique_ptr
```
 instances cannot be copied. This prevents the pointer from being deleted multiple times (incorrectly). You can, however, pass references to it around to other functions you call. 
```
std::unique_ptr
```
s are useful when you want to tie the lifetime of the object to a particular block of code, or if you embedded it as member data inside another object, the lifetime of that other object. The object exists until the containing block of code is exited, or until the containing object is itself destroyed. A more complex smart pointer policy involves reference counting the pointer. This does allow the pointer to be copied. When the last ""reference"" to the object is destroyed, the object is deleted. This policy is implemented by 
```
boost::shared_ptr
```
 and 
```
std::shared_ptr
```
. 
```
void f()
{
    typedef std::shared_ptr<MyObject> MyObjectPtr; // nice short alias
    MyObjectPtr p1; // Empty

    {
        MyObjectPtr p2(new MyObject());
        // There is now one ""reference"" to the created object
        p1 = p2; // Copy the pointer.
        // There are now two references to the object.
    } // p2 is destroyed, leaving one reference to the object.
} // p1 is destroyed, leaving a reference count of zero. 
  // The object is deleted.

```
 Reference counted pointers are very useful when the lifetime of your object is much more complicated, and is not tied directly to a particular section of code or to another object. There is one drawback to reference counted pointers — the possibility of creating a dangling reference: 
```
// Create the smart pointer on the heap
MyObjectPtr* pp = new MyObjectPtr(new MyObject())
// Hmm, we forgot to destroy the smart pointer,
// because of that, the object is never destroyed!

```
 Another possibility is creating circular references: 
```
struct Owner {
   std::shared_ptr<Owner> other;
};

std::shared_ptr<Owner> p1 (new Owner());
std::shared_ptr<Owner> p2 (new Owner());
p1->other = p2; // p1 references p2
p2->other = p1; // p2 references p1

// Oops, the reference count of of p1 and p2 never goes to zero!
// The objects are never destroyed!

```
 To work around this problem, both Boost and C++11 have defined a 
```
weak_ptr
```
 to define a weak (uncounted) reference to a 
```
shared_ptr
```
."
5590381,How to convert int to string in C++?,https://stackoverflow.com/questions/5590381/how-to-convert-int-to-string-in-c,25,2837.0,"['C++11 introduces \n```\nstd::stoi\n```\n (and variants for each numeric type) and \n```\nstd::to_string\n```\n, the counterparts of the C \n```\natoi\n```\n and \n```\nitoa\n```\n but expressed in term of \n```\nstd::string\n```\n. \n```\n#include <string> \n\nstd::string s = std::to_string(42);\n\n```\n is therefore the shortest way I can think of. You can even omit naming the type, using the \n```\nauto\n```\n keyword: \n```\nauto s = std::to_string(42);\n\n```\n Note: see [string.conversions] (21.5 in n3242)']","C++11 introduces 
```
std::stoi
```
 (and variants for each numeric type) and 
```
std::to_string
```
, the counterparts of the C 
```
atoi
```
 and 
```
itoa
```
 but expressed in term of 
```
std::string
```
. 
```
#include <string> 

std::string s = std::to_string(42);

```
 is therefore the shortest way I can think of. You can even omit naming the type, using the 
```
auto
```
 keyword: 
```
auto s = std::to_string(42);

```
 Note: see [string.conversions] (21.5 in n3242)"
375913,How do I profile C++ code running on Linux?,https://stackoverflow.com/questions/375913/how-do-i-profile-c-code-running-on-linux,20,1622.0,"[""If your goal is to use a profiler, use one of the suggested ones. However, if you're in a hurry and you can manually interrupt your program under the debugger while it's being subjectively slow, there's a simple way to find performance problems. Execute your code in a debugger like gdb, halt it and each time look at the call stack (e.g. backtrace) several times. If there is some code that is wasting some percentage of the time, 20% or 50% or whatever, that is the probability that you will catch it in the act on each sample. So, that is roughly the percentage of samples on which you will see it. There is no educated guesswork required. If you do have a guess as to what the problem is, this will prove or disprove it. You probably have multiple performance problems of different sizes. If you clean out any one of them, the remaining ones will take a larger percentage, and be easier to spot, on subsequent passes. This magnification effect, when compounded over multiple problems, can lead to"", ""out any one of them, the remaining ones will take a larger percentage, and be easier to spot, on subsequent passes. This magnification effect, when compounded over multiple problems, can lead to truly massive speedup factors. Caveat: Programmers tend to be skeptical of this technique unless they've used it themselves. They will say that profilers give you this information, but that is only true if they sample the entire call stack, and then let you examine a random set of samples. (The summaries are where the insight is lost.) Call graphs don't give you the same information, because They don't summarize at the instruction level, and They give confusing summaries in the presence of recursion. They will also say it only works on toy programs, when actually it works on any program, and it seems to work better on bigger programs, because they tend to have more problems to find. They will say it sometimes finds things that aren't problems, but that is only true if you see something once."", 'to work better on bigger programs, because they tend to have more problems to find. They will say it sometimes finds things that aren\'t problems, but that is only true if you see something once. If you see a problem on more than one sample, it is real. P.S. This can also be done on multi-thread programs if there is a way to collect call-stack samples of the thread pool at a point in time, as there is in Java. P.P.S As a rough generality, the more layers of abstraction you have in your software, the more likely you are to find that that is the cause of performance problems (and the opportunity to get speedup). Added: It might not be obvious, but the stack sampling technique works equally well in the presence of recursion. The reason is that the time that would be saved by removal of an instruction is approximated by the fraction of samples containing it, regardless of the number of times it may occur within a sample. Another objection I often hear is: ""It will stop someplace random,', 'is approximated by the fraction of samples containing it, regardless of the number of times it may occur within a sample. Another objection I often hear is: ""It will stop someplace random, and it will miss the real problem"". This comes from having a prior concept of what the real problem is. A key property of performance problems is that they defy expectations. Sampling tells you something is a problem, and your first reaction is disbelief. That is natural, but you can be sure if it finds a problem it is real, and vice-versa. Added: Let me make a Bayesian explanation of how it works. Suppose there is some instruction', ""```\nI\n```\n (call or otherwise) which is on the call stack some fraction \n```\nf\n```\n of the time (and thus costs that much). For simplicity, suppose we don't know what \n```\nf\n```\n is, but assume it is either 0.1, 0.2, 0.3, ... 0.9, 1.0, and the prior probability of each of these possibilities is 0.1, so all of these costs are equally likely a-priori. Then suppose we take just 2 stack samples, and we see instruction \n```\nI\n```\n on both samples, designated observation \n```\no=2/2\n```\n. This gives us new estimates of the frequency \n```\nf\n```\n of \n```\nI\n```\n, according to this: \n```\nPrior                                    \nP(f=x) x  P(o=2/2|f=x) P(o=2/2&&f=x)  P(o=2/2&&f >= x)  P(f >= x | o=2/2)"", '0.1    1     1             0.1          0.1            0.25974026\n0.1    0.9   0.81          0.081        0.181          0.47012987\n0.1    0.8   0.64          0.064        0.245          0.636363636\n0.1    0.7   0.49          0.049        0.294          0.763636364\n0.1    0.6   0.36          0.036        0.33           0.857142857\n0.1    0.5   0.25          0.025        0.355          0.922077922\n0.1    0.4   0.16          0.016        0.371          0.963636364\n0.1    0.3   0.09          0.009        0.38           0.987012987\n0.1    0.2   0.04          0.004        0.384          0.997402597\n0.1    0.1   0.01          0.001        0.385          1\n\n                  P(o=2/2) 0.385', 'P(o=2/2) 0.385                \n\n```\n The last column says that, for example, the probability that \n```\nf\n```\n >= 0.5 is 92%, up from the prior assumption of 60%. Suppose the prior assumptions are different. Suppose we assume \n```\nP(f=0.1)\n```\n is .991 (nearly certain), and all the other possibilities are almost impossible (0.001). In other words, our prior certainty is that \n```\nI\n```\n is cheap. Then we get: \n```\nPrior                                    \nP(f=x) x  P(o=2/2|f=x) P(o=2/2&& f=x)  P(o=2/2&&f >= x)  P(f >= x | o=2/2)', '0.001  1    1              0.001        0.001          0.072727273\n0.001  0.9  0.81           0.00081      0.00181        0.131636364\n0.001  0.8  0.64           0.00064      0.00245        0.178181818\n0.001  0.7  0.49           0.00049      0.00294        0.213818182\n0.001  0.6  0.36           0.00036      0.0033         0.24\n0.001  0.5  0.25           0.00025      0.00355        0.258181818\n0.001  0.4  0.16           0.00016      0.00371        0.269818182\n0.001  0.3  0.09           0.00009      0.0038         0.276363636\n0.001  0.2  0.04           0.00004      0.00384        0.279272727\n0.991  0.1  0.01           0.00991      0.01375        1\n\n                  P(o=2/2) 0.01375', ""```\n Now it says \n```\nP(f >= 0.5)\n```\n is 26%, up from the prior assumption of 0.6%. So Bayes allows us to update our estimate of the probable cost of \n```\nI\n```\n. If the amount of data is small, it doesn't tell us accurately what the cost is, only that it is big enough to be worth fixing. Yet another way to look at it is called the Rule Of Succession. If you flip a coin 2 times, and it comes up heads both times, what does that tell you about the probable weighting of the coin? The respected way to answer is to say that it's a Beta distribution, with average value \n```\n(number of hits + 1) / (number of tries + 2) = (2+1)/(2+2) = 75%\n```\n. (The key is that we see \n```\nI\n```\n more than once. If we only see it once, that doesn't tell us much except that \n```\nf\n```\n > 0.) So, even a very small number of samples can tell us a lot about the cost of instructions that it sees. (And it will see them with a frequency, on average, proportional to their cost. If \n```\nn\n```"", '```\nn\n```\n samples are taken, and \n```\nf\n```\n is the cost, then \n```\nI\n```\n will appear on \n```\nnf+/-sqrt(nf(1-f))\n```\n samples. Example, \n```\nn=10\n```\n, \n```\nf=0.3\n```\n, that is \n```\n3+/-1.4\n```', 'samples.) Added: To give an intuitive feel for the difference between measuring and random stack sampling: There are profilers now that sample the stack, even on wall-clock time, but what comes out is measurements (or hot path, or hot spot, from which a ""bottleneck"" can easily hide). What they don\'t show you (and they easily could) is the actual samples themselves. And if your goal is to find the bottleneck, the number of them you need to see is, on average, 2 divided by the fraction of time it takes. So if it takes 30% of time, 2/.3 = 6.7 samples, on average, will show it, and the chance that 20 samples will show it is 99.2%. Here is an off-the-cuff illustration of the difference between examining measurements and examining stack samples. The bottleneck could be one big blob like this, or numerous small ones, it makes no difference. Measurement is horizontal; it tells you what fraction of time specific routines take. Sampling is vertical. If there is any way to avoid what the whole', ""or numerous small ones, it makes no difference. Measurement is horizontal; it tells you what fraction of time specific routines take. Sampling is vertical. If there is any way to avoid what the whole program is doing at that moment, and if you see it on a second sample, you've found the bottleneck. That's what makes the difference - seeing the whole reason for the time being spent, not just how much.""]","If your goal is to use a profiler, use one of the suggested ones. However, if you're in a hurry and you can manually interrupt your program under the debugger while it's being subjectively slow, there's a simple way to find performance problems. Execute your code in a debugger like gdb, halt it and each time look at the call stack (e.g. backtrace) several times. If there is some code that is wasting some percentage of the time, 20% or 50% or whatever, that is the probability that you will catch it in the act on each sample. So, that is roughly the percentage of samples on which you will see it. There is no educated guesswork required. If you do have a guess as to what the problem is, this will prove or disprove it. You probably have multiple performance problems of different sizes. If you clean out any one of them, the remaining ones will take a larger percentage, and be easier to spot, on subsequent passes. This magnification effect, when compounded over multiple problems, can lead to truly massive speedup factors. Caveat: Programmers tend to be skeptical of this technique unless they've used it themselves. They will say that profilers give you this information, but that is only true if they sample the entire call stack, and then let you examine a random set of samples. (The summaries are where the insight is lost.) Call graphs don't give you the same information, because They don't summarize at the instruction level, and They give confusing summaries in the presence of recursion. They will also say it only works on toy programs, when actually it works on any program, and it seems to work better on bigger programs, because they tend to have more problems to find. They will say it sometimes finds things that aren't problems, but that is only true if you see something once. If you see a problem on more than one sample, it is real. P.S. This can also be done on multi-thread programs if there is a way to collect call-stack samples of the thread pool at a point in time, as there is in Java. P.P.S As a rough generality, the more layers of abstraction you have in your software, the more likely you are to find that that is the cause of performance problems (and the opportunity to get speedup). Added: It might not be obvious, but the stack sampling technique works equally well in the presence of recursion. The reason is that the time that would be saved by removal of an instruction is approximated by the fraction of samples containing it, regardless of the number of times it may occur within a sample. Another objection I often hear is: ""It will stop someplace random, and it will miss the real problem"". This comes from having a prior concept of what the real problem is. A key property of performance problems is that they defy expectations. Sampling tells you something is a problem, and your first reaction is disbelief. That is natural, but you can be sure if it finds a problem it is real, and vice-versa. Added: Let me make a Bayesian explanation of how it works. Suppose there is some instruction 
```
I
```
 (call or otherwise) which is on the call stack some fraction 
```
f
```
 of the time (and thus costs that much). For simplicity, suppose we don't know what 
```
f
```
 is, but assume it is either 0.1, 0.2, 0.3, ... 0.9, 1.0, and the prior probability of each of these possibilities is 0.1, so all of these costs are equally likely a-priori. Then suppose we take just 2 stack samples, and we see instruction 
```
I
```
 on both samples, designated observation 
```
o=2/2
```
. This gives us new estimates of the frequency 
```
f
```
 of 
```
I
```
, according to this: 
```
Prior                                    
P(f=x) x  P(o=2/2|f=x) P(o=2/2&&f=x)  P(o=2/2&&f >= x)  P(f >= x | o=2/2)

0.1    1     1             0.1          0.1            0.25974026
0.1    0.9   0.81          0.081        0.181          0.47012987
0.1    0.8   0.64          0.064        0.245          0.636363636
0.1    0.7   0.49          0.049        0.294          0.763636364
0.1    0.6   0.36          0.036        0.33           0.857142857
0.1    0.5   0.25          0.025        0.355          0.922077922
0.1    0.4   0.16          0.016        0.371          0.963636364
0.1    0.3   0.09          0.009        0.38           0.987012987
0.1    0.2   0.04          0.004        0.384          0.997402597
0.1    0.1   0.01          0.001        0.385          1

                  P(o=2/2) 0.385                

```
 The last column says that, for example, the probability that 
```
f
```
 >= 0.5 is 92%, up from the prior assumption of 60%. Suppose the prior assumptions are different. Suppose we assume 
```
P(f=0.1)
```
 is .991 (nearly certain), and all the other possibilities are almost impossible (0.001). In other words, our prior certainty is that 
```
I
```
 is cheap. Then we get: 
```
Prior                                    
P(f=x) x  P(o=2/2|f=x) P(o=2/2&& f=x)  P(o=2/2&&f >= x)  P(f >= x | o=2/2)

0.001  1    1              0.001        0.001          0.072727273
0.001  0.9  0.81           0.00081      0.00181        0.131636364
0.001  0.8  0.64           0.00064      0.00245        0.178181818
0.001  0.7  0.49           0.00049      0.00294        0.213818182
0.001  0.6  0.36           0.00036      0.0033         0.24
0.001  0.5  0.25           0.00025      0.00355        0.258181818
0.001  0.4  0.16           0.00016      0.00371        0.269818182
0.001  0.3  0.09           0.00009      0.0038         0.276363636
0.001  0.2  0.04           0.00004      0.00384        0.279272727
0.991  0.1  0.01           0.00991      0.01375        1

                  P(o=2/2) 0.01375                

```
 Now it says 
```
P(f >= 0.5)
```
 is 26%, up from the prior assumption of 0.6%. So Bayes allows us to update our estimate of the probable cost of 
```
I
```
. If the amount of data is small, it doesn't tell us accurately what the cost is, only that it is big enough to be worth fixing. Yet another way to look at it is called the Rule Of Succession. If you flip a coin 2 times, and it comes up heads both times, what does that tell you about the probable weighting of the coin? The respected way to answer is to say that it's a Beta distribution, with average value 
```
(number of hits + 1) / (number of tries + 2) = (2+1)/(2+2) = 75%
```
. (The key is that we see 
```
I
```
 more than once. If we only see it once, that doesn't tell us much except that 
```
f
```
 > 0.) So, even a very small number of samples can tell us a lot about the cost of instructions that it sees. (And it will see them with a frequency, on average, proportional to their cost. If 
```
n
```
 samples are taken, and 
```
f
```
 is the cost, then 
```
I
```
 will appear on 
```
nf+/-sqrt(nf(1-f))
```
 samples. Example, 
```
n=10
```
, 
```
f=0.3
```
, that is 
```
3+/-1.4
```
 samples.) Added: To give an intuitive feel for the difference between measuring and random stack sampling: There are profilers now that sample the stack, even on wall-clock time, but what comes out is measurements (or hot path, or hot spot, from which a ""bottleneck"" can easily hide). What they don't show you (and they easily could) is the actual samples themselves. And if your goal is to find the bottleneck, the number of them you need to see is, on average, 2 divided by the fraction of time it takes. So if it takes 30% of time, 2/.3 = 6.7 samples, on average, will show it, and the chance that 20 samples will show it is 99.2%. Here is an off-the-cuff illustration of the difference between examining measurements and examining stack samples. The bottleneck could be one big blob like this, or numerous small ones, it makes no difference. Measurement is horizontal; it tells you what fraction of time specific routines take. Sampling is vertical. If there is any way to avoid what the whole program is doing at that moment, and if you see it on a second sample, you've found the bottleneck. That's what makes the difference - seeing the whole reason for the time being spent, not just how much."
1041866,"What is the effect of extern ""C"" in C++?",https://stackoverflow.com/questions/1041866/what-is-the-effect-of-extern-c-in-c,18,2026.0,"['```\nextern ""C""\n```\n makes a function-name in C++ have C linkage (compiler does not mangle the name) so that client C code can link to (use) your function using a C compatible header file that contains just the declaration of your function. Your function definition is contained in a binary format (that was compiled by your C++ compiler) that the client C linker will then link to using the C name. Since C++ has overloading of function names and C does not, the C++ compiler cannot just use the function name as a unique id to link to, so it mangles the name by adding information about the arguments. A C compiler does not need to mangle the name since you can not overload function names in C. When you state that a function has \n```\nextern ""C""\n```\n linkage in C++, the C++ compiler does not add argument/parameter type information to the name used for linkage. Just so you know, you can specify \n```\nextern ""C""\n```', '```\nextern ""C""\n```\n linkage in C++, the C++ compiler does not add argument/parameter type information to the name used for linkage. Just so you know, you can specify \n```\nextern ""C""\n```\n linkage to each individual declaration/definition explicitly or use a block to group a sequence of declarations/definitions to have a certain linkage: \n```\nextern ""C"" void foo(int);\nextern ""C""\n{\n   void g(char);\n   int i;\n}', '```\n If you care about the technicalities, they are listed in section 7.5 of the C++03 standard, here is a brief summary (with emphasis on \n```\nextern ""C""\n```\n): \n```\nextern ""C""\n```\n is a linkage-specification Every compiler is required to provide ""C"" linkage A linkage specification shall occur only in namespace scope All function types, function names and variable names have a language linkage See Richard\'s Comment: Only function names and variable names with external linkage have a language linkage Two function types with distinct language linkages are distinct types even if otherwise identical Linkage specs nest, inner one determines the final linkage \n```\nextern ""C""\n```\n is ignored for class members At most one function with a particular name can have ""C"" linkage (regardless of namespace) \n```\nextern ""C""\n```\n forces a function to have external linkage (cannot make it static) See Richard\'s comment: \n```\nstatic\n```\n inside \n```\nextern ""C""\n```', '```\nextern ""C""\n```\n forces a function to have external linkage (cannot make it static) See Richard\'s comment: \n```\nstatic\n```\n inside \n```\nextern ""C""\n```\n is valid; an entity so declared has internal linkage, and so does not have a language linkage Linkage from C++ to objects defined in other languages and to objects defined in C++ from other languages is implementation-defined and language-dependent. Only where the object layout strategies of two language implementations are similar enough can such linkage be achieved']","
```
extern ""C""
```
 makes a function-name in C++ have C linkage (compiler does not mangle the name) so that client C code can link to (use) your function using a C compatible header file that contains just the declaration of your function. Your function definition is contained in a binary format (that was compiled by your C++ compiler) that the client C linker will then link to using the C name. Since C++ has overloading of function names and C does not, the C++ compiler cannot just use the function name as a unique id to link to, so it mangles the name by adding information about the arguments. A C compiler does not need to mangle the name since you can not overload function names in C. When you state that a function has 
```
extern ""C""
```
 linkage in C++, the C++ compiler does not add argument/parameter type information to the name used for linkage. Just so you know, you can specify 
```
extern ""C""
```
 linkage to each individual declaration/definition explicitly or use a block to group a sequence of declarations/definitions to have a certain linkage: 
```
extern ""C"" void foo(int);
extern ""C""
{
   void g(char);
   int i;
}

```
 If you care about the technicalities, they are listed in section 7.5 of the C++03 standard, here is a brief summary (with emphasis on 
```
extern ""C""
```
): 
```
extern ""C""
```
 is a linkage-specification Every compiler is required to provide ""C"" linkage A linkage specification shall occur only in namespace scope All function types, function names and variable names have a language linkage See Richard's Comment: Only function names and variable names with external linkage have a language linkage Two function types with distinct language linkages are distinct types even if otherwise identical Linkage specs nest, inner one determines the final linkage 
```
extern ""C""
```
 is ignored for class members At most one function with a particular name can have ""C"" linkage (regardless of namespace) 
```
extern ""C""
```
 forces a function to have external linkage (cannot make it static) See Richard's comment: 
```
static
```
 inside 
```
extern ""C""
```
 is valid; an entity so declared has internal linkage, and so does not have a language linkage Linkage from C++ to objects defined in other languages and to objects defined in C++ from other languages is implementation-defined and language-dependent. Only where the object layout strategies of two language implementations are similar enough can such linkage be achieved"
3106110,What is move semantics?,https://stackoverflow.com/questions/3106110/what-is-move-semantics,12,2977.0,"[""I find it easiest to understand move semantics with example code. Let's start with a very simple string class which only holds a pointer to a heap-allocated block of memory: \n```\n#include <cstring>\n#include <algorithm>\n\nclass string\n{\n    char* data;\n\npublic:\n\n    string(const char* p)\n    {\n        size_t size = std::strlen(p) + 1;\n        data = new char[size];\n        std::memcpy(data, p, size);\n    }\n\n```\n Since we chose to manage the memory ourselves, we need to follow the rule of three. I am going to defer writing the assignment operator and only implement the destructor and the copy constructor for now: \n```\n    ~string()\n    {\n        delete[] data;\n    }\n\n    string(const string& that)\n    {\n        size_t size = std::strlen(that.data) + 1;\n        data = new char[size];\n        std::memcpy(data, that.data, size);\n    }"", 'string(const string& that)\n    {\n        size_t size = std::strlen(that.data) + 1;\n        data = new char[size];\n        std::memcpy(data, that.data, size);\n    }\n\n```\n The copy constructor defines what it means to copy string objects. The parameter \n```\nconst string& that\n```\n binds to all expressions of type string which allows you to make copies in the following examples: \n```\nstring a(x);                                    // Line 1\nstring b(x + y);                                // Line 2\nstring c(some_function_returning_a_string());   // Line 3', '```\n Now comes the key insight into move semantics. Note that only in the first line where we copy \n```\nx\n```\n is this deep copy really necessary, because we might want to inspect \n```\nx\n```\n later and would be very surprised if \n```\nx\n```\n had changed somehow. Did you notice how I just said \n```\nx\n```\n three times (four times if you include this sentence) and meant the exact same object every time? We call expressions such as \n```\nx\n```\n ""lvalues"". The arguments in lines 2 and 3 are not lvalues, but rvalues, because the underlying string objects have no names, so the client has no way to inspect them again at a later point in time. rvalues denote temporary objects which are destroyed at the next semicolon (to be more precise: at the end of the full-expression that lexically contains the rvalue). This is important because during the initialization of \n```\nb\n```\n and \n```\nc\n```', '```\nb\n```\n and \n```\nc\n```\n, we could do whatever we wanted with the source string, and the client couldn\'t tell a difference! C++0x introduces a new mechanism called ""rvalue reference"" which, among other things, allows us to detect rvalue arguments via function overloading. All we have to do is write a constructor with an rvalue reference parameter. Inside that constructor we can do anything we want with the source, as long as we leave it in some valid state: \n```\n    string(string&& that)   // string&& is an rvalue reference to a string\n    {\n        data = that.data;\n        that.data = nullptr;\n    }', '```\n What have we done here? Instead of deeply copying the heap data, we have just copied the pointer and then set the original pointer to null (to prevent \'delete[]\' from source object\'s destructor from releasing our \'just stolen data\'). In effect, we have ""stolen"" the data that originally belonged to the source string. Again, the key insight is that under no circumstance could the client detect that the source had been modified. Since we don\'t really do a copy here, we call this constructor a ""move constructor"". Its job is to move resources from one object to another instead of copying them. Congratulations, you now understand the basics of move semantics! Let\'s continue by implementing the assignment operator. If you\'re unfamiliar with the copy and swap idiom, learn it and come back, because it\'s an awesome C++ idiom related to exception safety. \n```\n    string& operator=(string that)\n    {\n        std::swap(data, that.data);\n        return *this;\n    }\n};', '```\n Huh, that\'s it? ""Where\'s the rvalue reference?"" you might ask. ""We don\'t need it here!"" is my answer :) Note that we pass the parameter \n```\nthat\n```\n by value, so \n```\nthat\n```\n has to be initialized just like any other string object. Exactly how is \n```\nthat\n```\n going to be initialized? In the olden days of C++98, the answer would have been ""by the copy constructor"". In C++0x, the compiler chooses between the copy constructor and the move constructor based on whether the argument to the assignment operator is an lvalue or an rvalue. So if you say \n```\na = b\n```\n, the copy constructor will initialize \n```\nthat\n```\n (because the expression \n```\nb\n```\n is an lvalue), and the assignment operator swaps the contents with a freshly created, deep copy. That is the very definition of the copy and swap idiom -- make a copy, swap the contents with the copy, and then get rid of the copy by leaving the scope. Nothing new here. But if you say \n```\na = x + y\n```', ""```\na = x + y\n```\n, the move constructor will initialize \n```\nthat\n```\n (because the expression \n```\nx + y\n```\n is an rvalue), so there is no deep copy involved, only an efficient move. \n```\nthat\n```\n is still an independent object from the argument, but its construction was trivial, since the heap data didn't have to be copied, just moved. It wasn't necessary to copy it because \n```\nx + y\n```"", 'is still an independent object from the argument, but its construction was trivial, since the heap data didn\'t have to be copied, just moved. It wasn\'t necessary to copy it because \n```\nx + y\n```\n is an rvalue, and again, it is okay to move from string objects denoted by rvalues. To summarize, the copy constructor makes a deep copy, because the source must remain untouched. The move constructor, on the other hand, can just copy the pointer and then set the pointer in the source to null. It is okay to ""nullify"" the source object in this manner, because the client has no way of inspecting the object again. I hope this example got the main point across. There is a lot more to rvalue references and move semantics which I intentionally left out to keep it simple. If you want more details please see my supplementary answer.']","I find it easiest to understand move semantics with example code. Let's start with a very simple string class which only holds a pointer to a heap-allocated block of memory: 
```
#include <cstring>
#include <algorithm>

class string
{
    char* data;

public:

    string(const char* p)
    {
        size_t size = std::strlen(p) + 1;
        data = new char[size];
        std::memcpy(data, p, size);
    }

```
 Since we chose to manage the memory ourselves, we need to follow the rule of three. I am going to defer writing the assignment operator and only implement the destructor and the copy constructor for now: 
```
    ~string()
    {
        delete[] data;
    }

    string(const string& that)
    {
        size_t size = std::strlen(that.data) + 1;
        data = new char[size];
        std::memcpy(data, that.data, size);
    }

```
 The copy constructor defines what it means to copy string objects. The parameter 
```
const string& that
```
 binds to all expressions of type string which allows you to make copies in the following examples: 
```
string a(x);                                    // Line 1
string b(x + y);                                // Line 2
string c(some_function_returning_a_string());   // Line 3

```
 Now comes the key insight into move semantics. Note that only in the first line where we copy 
```
x
```
 is this deep copy really necessary, because we might want to inspect 
```
x
```
 later and would be very surprised if 
```
x
```
 had changed somehow. Did you notice how I just said 
```
x
```
 three times (four times if you include this sentence) and meant the exact same object every time? We call expressions such as 
```
x
```
 ""lvalues"". The arguments in lines 2 and 3 are not lvalues, but rvalues, because the underlying string objects have no names, so the client has no way to inspect them again at a later point in time. rvalues denote temporary objects which are destroyed at the next semicolon (to be more precise: at the end of the full-expression that lexically contains the rvalue). This is important because during the initialization of 
```
b
```
 and 
```
c
```
, we could do whatever we wanted with the source string, and the client couldn't tell a difference! C++0x introduces a new mechanism called ""rvalue reference"" which, among other things, allows us to detect rvalue arguments via function overloading. All we have to do is write a constructor with an rvalue reference parameter. Inside that constructor we can do anything we want with the source, as long as we leave it in some valid state: 
```
    string(string&& that)   // string&& is an rvalue reference to a string
    {
        data = that.data;
        that.data = nullptr;
    }

```
 What have we done here? Instead of deeply copying the heap data, we have just copied the pointer and then set the original pointer to null (to prevent 'delete[]' from source object's destructor from releasing our 'just stolen data'). In effect, we have ""stolen"" the data that originally belonged to the source string. Again, the key insight is that under no circumstance could the client detect that the source had been modified. Since we don't really do a copy here, we call this constructor a ""move constructor"". Its job is to move resources from one object to another instead of copying them. Congratulations, you now understand the basics of move semantics! Let's continue by implementing the assignment operator. If you're unfamiliar with the copy and swap idiom, learn it and come back, because it's an awesome C++ idiom related to exception safety. 
```
    string& operator=(string that)
    {
        std::swap(data, that.data);
        return *this;
    }
};

```
 Huh, that's it? ""Where's the rvalue reference?"" you might ask. ""We don't need it here!"" is my answer :) Note that we pass the parameter 
```
that
```
 by value, so 
```
that
```
 has to be initialized just like any other string object. Exactly how is 
```
that
```
 going to be initialized? In the olden days of C++98, the answer would have been ""by the copy constructor"". In C++0x, the compiler chooses between the copy constructor and the move constructor based on whether the argument to the assignment operator is an lvalue or an rvalue. So if you say 
```
a = b
```
, the copy constructor will initialize 
```
that
```
 (because the expression 
```
b
```
 is an lvalue), and the assignment operator swaps the contents with a freshly created, deep copy. That is the very definition of the copy and swap idiom -- make a copy, swap the contents with the copy, and then get rid of the copy by leaving the scope. Nothing new here. But if you say 
```
a = x + y
```
, the move constructor will initialize 
```
that
```
 (because the expression 
```
x + y
```
 is an rvalue), so there is no deep copy involved, only an efficient move. 
```
that
```
 is still an independent object from the argument, but its construction was trivial, since the heap data didn't have to be copied, just moved. It wasn't necessary to copy it because 
```
x + y
```
 is an rvalue, and again, it is okay to move from string objects denoted by rvalues. To summarize, the copy constructor makes a deep copy, because the source must remain untouched. The move constructor, on the other hand, can just copy the pointer and then set the pointer in the source to null. It is okay to ""nullify"" the source object in this manner, because the client has no way of inspecting the object again. I hope this example got the main point across. There is a lot more to rvalue references and move semantics which I intentionally left out to keep it simple. If you want more details please see my supplementary answer."
28002,Regular cast vs. static_cast vs. dynamic_cast,https://stackoverflow.com/questions/28002/regular-cast-vs-static-cast-vs-dynamic-cast,8,1869.0,"['static_cast \n```\nstatic_cast\n```\n is used for cases where you basically want to reverse an implicit conversion, with a few restrictions and additions. \n```\nstatic_cast\n```\n performs no runtime checks. This should be used if you know that you refer to an object of a specific type, and thus a check would be unnecessary. Example: \n```\nvoid func(void *data) {\n  // Conversion from MyClass* -> void* is implicit\n  MyClass *c = static_cast<MyClass*>(data);\n  ...\n}\n\nint main() {\n  MyClass c;\n  start_thread(&func, &c)  // func(&c) will be called\n      .join();\n}', ""int main() {\n  MyClass c;\n  start_thread(&func, &c)  // func(&c) will be called\n      .join();\n}\n\n```\n In this example, you know that you passed a \n```\nMyClass\n```\n object, and thus there isn't any need for a runtime check to ensure this. dynamic_cast \n```\ndynamic_cast\n```\n is useful when you don't know what the dynamic type of the object is. It returns a null pointer if the object referred to doesn't contain the type casted to as a base class (when you cast to a reference, a \n```\nbad_cast\n```\n exception is thrown in that case). \n```\nif (JumpStm *j = dynamic_cast<JumpStm*>(&stm)) {\n  ...\n} else if (ExprStm *e = dynamic_cast<ExprStm*>(&stm)) {\n  ...\n}"", ""```\n You can not use \n```\ndynamic_cast\n```\n for downcast (casting to a derived class) if the argument type is not polymorphic. For example, the following code is not valid, because \n```\nBase\n```\n doesn't contain any virtual function: \n```\nstruct Base { };\nstruct Derived : Base { };\nint main() {\n  Derived d; Base *b = &d;\n  dynamic_cast<Derived*>(b); // Invalid\n}"", '```\n An ""up-cast"" (cast to the base class) is always valid with both \n```\nstatic_cast\n```\n and \n```\ndynamic_cast\n```\n, and also without any cast, as an ""up-cast"" is an implicit conversion (assuming the base class is accessible, i.e. it\'s a \n```\npublic\n```\n inheritance). Regular Cast These casts are also called C-style cast. A C-style cast is basically identical to trying out a range of sequences of C++ casts, and taking the first C++ cast that works, without ever considering \n```\ndynamic_cast\n```\n. Needless to say, this is much more powerful as it combines all of \n```\nconst_cast\n```\n, \n```\nstatic_cast\n```\n and \n```\nreinterpret_cast\n```\n, but it\'s also unsafe, because it does not use \n```\ndynamic_cast\n```\n. In addition, C-style casts not only allow you to do this, but they also allow you to safely cast to a private base-class, while the ""equivalent"" \n```\nstatic_cast\n```', '```\ndynamic_cast\n```\n. In addition, C-style casts not only allow you to do this, but they also allow you to safely cast to a private base-class, while the ""equivalent"" \n```\nstatic_cast\n```\n sequence would give you a compile-time error for that. Some people prefer C-style casts because of their brevity. I use them for numeric casts only, and use the appropriate C++ casts when user defined types are involved, as they provide stricter checking.']","static_cast 
```
static_cast
```
 is used for cases where you basically want to reverse an implicit conversion, with a few restrictions and additions. 
```
static_cast
```
 performs no runtime checks. This should be used if you know that you refer to an object of a specific type, and thus a check would be unnecessary. Example: 
```
void func(void *data) {
  // Conversion from MyClass* -> void* is implicit
  MyClass *c = static_cast<MyClass*>(data);
  ...
}

int main() {
  MyClass c;
  start_thread(&func, &c)  // func(&c) will be called
      .join();
}

```
 In this example, you know that you passed a 
```
MyClass
```
 object, and thus there isn't any need for a runtime check to ensure this. dynamic_cast 
```
dynamic_cast
```
 is useful when you don't know what the dynamic type of the object is. It returns a null pointer if the object referred to doesn't contain the type casted to as a base class (when you cast to a reference, a 
```
bad_cast
```
 exception is thrown in that case). 
```
if (JumpStm *j = dynamic_cast<JumpStm*>(&stm)) {
  ...
} else if (ExprStm *e = dynamic_cast<ExprStm*>(&stm)) {
  ...
}

```
 You can not use 
```
dynamic_cast
```
 for downcast (casting to a derived class) if the argument type is not polymorphic. For example, the following code is not valid, because 
```
Base
```
 doesn't contain any virtual function: 
```
struct Base { };
struct Derived : Base { };
int main() {
  Derived d; Base *b = &d;
  dynamic_cast<Derived*>(b); // Invalid
}

```
 An ""up-cast"" (cast to the base class) is always valid with both 
```
static_cast
```
 and 
```
dynamic_cast
```
, and also without any cast, as an ""up-cast"" is an implicit conversion (assuming the base class is accessible, i.e. it's a 
```
public
```
 inheritance). Regular Cast These casts are also called C-style cast. A C-style cast is basically identical to trying out a range of sequences of C++ casts, and taking the first C++ cast that works, without ever considering 
```
dynamic_cast
```
. Needless to say, this is much more powerful as it combines all of 
```
const_cast
```
, 
```
static_cast
```
 and 
```
reinterpret_cast
```
, but it's also unsafe, because it does not use 
```
dynamic_cast
```
. In addition, C-style casts not only allow you to do this, but they also allow you to safely cast to a private base-class, while the ""equivalent"" 
```
static_cast
```
 sequence would give you a compile-time error for that. Some people prefer C-style casts because of their brevity. I use them for numeric casts only, and use the appropriate C++ casts when user defined types are involved, as they provide stricter checking."
461203,When to use virtual destructors?,https://stackoverflow.com/questions/461203/when-to-use-virtual-destructors,21,1952.0,"[""Virtual destructors are useful when you might potentially delete an instance of a derived class through a pointer to base class: \n```\nclass Base \n{\n    // some virtual methods\n};\n\nclass Derived : public Base\n{\n    ~Derived()\n    {\n        // Do some important cleanup\n    }\n};\n\n```\n Here, you'll notice that I didn't declare Base's destructor to be \n```\nvirtual\n```\n. Now, let's have a look at the following snippet: \n```\nBase *b = new Derived();\n// use b\ndelete b; // Here's the problem!"", ""```\n Since Base's destructor is not \n```\nvirtual\n```\n and \n```\nb\n```\n is a \n```\nBase*\n```\n pointing to a \n```\nDerived\n```\n object, \n```\ndelete b\n```\n has undefined behaviour: [In \n```\ndelete b\n```\n], if the static type of the object to be deleted is different from its dynamic type, the static type shall be a base class of the dynamic type of the object to be deleted and the static type shall have a virtual destructor or the behavior is undefined. In most implementations, the call to the destructor will be resolved like any non-virtual code, meaning that the destructor of the base class will be called but not the one of the derived class, resulting in a resources leak. To sum up, always make base classes' destructors \n```\nvirtual\n```\n when they're meant to be manipulated polymorphically. If you want to prevent the deletion of an instance through a base class pointer, you can make the base class destructor protected and nonvirtual; by doing so, the compiler won't let you call \n```"", '```\ndelete\n```\n on a base class pointer. You can learn more about virtuality and virtual base class destructor in this article from Herb Sutter.']","Virtual destructors are useful when you might potentially delete an instance of a derived class through a pointer to base class: 
```
class Base 
{
    // some virtual methods
};

class Derived : public Base
{
    ~Derived()
    {
        // Do some important cleanup
    }
};

```
 Here, you'll notice that I didn't declare Base's destructor to be 
```
virtual
```
. Now, let's have a look at the following snippet: 
```
Base *b = new Derived();
// use b
delete b; // Here's the problem!

```
 Since Base's destructor is not 
```
virtual
```
 and 
```
b
```
 is a 
```
Base*
```
 pointing to a 
```
Derived
```
 object, 
```
delete b
```
 has undefined behaviour: [In 
```
delete b
```
], if the static type of the object to be deleted is different from its dynamic type, the static type shall be a base class of the dynamic type of the object to be deleted and the static type shall have a virtual destructor or the behavior is undefined. In most implementations, the call to the destructor will be resolved like any non-virtual code, meaning that the destructor of the base class will be called but not the one of the derived class, resulting in a resources leak. To sum up, always make base classes' destructors 
```
virtual
```
 when they're meant to be manipulated polymorphically. If you want to prevent the deletion of an instance through a base class pointer, you can make the base class destructor protected and nonvirtual; by doing so, the compiler won't let you call 
```
delete
```
 on a base class pointer. You can learn more about virtuality and virtual base class destructor in this article from Herb Sutter."
10168686,Image Processing: Algorithm Improvement for 'Coca-Cola Can' Recognition,https://stackoverflow.com/questions/10168686/image-processing-algorithm-improvement-for-coca-cola-can-recognition,23,780.0,"['An alternative approach would be to extract features (keypoints) using the scale-invariant feature transform (SIFT) or Speeded Up Robust Features (SURF). You can find a nice OpenCV code example in Java, C++, and Python on this page: Features2D + Homography to find a known object Both algorithms are invariant to scaling and rotation. Since they work with features, you can also handle occlusion (as long as enough keypoints are visible). Image source: tutorial example The processing takes a few hundred ms for SIFT, SURF is bit faster, but it not suitable for real-time applications. ORB uses FAST which is weaker regarding rotation invariance. The original papers SURF: Speeded Up Robust Features Distinctive Image Features from Scale-Invariant Keypoints ORB: an efficient alternative to SIFT or SURF']","An alternative approach would be to extract features (keypoints) using the scale-invariant feature transform (SIFT) or Speeded Up Robust Features (SURF). You can find a nice OpenCV code example in Java, C++, and Python on this page: Features2D + Homography to find a known object Both algorithms are invariant to scaling and rotation. Since they work with features, you can also handle occlusion (as long as enough keypoints are visible). Image source: tutorial example The processing takes a few hundred ms for SIFT, SURF is bit faster, but it not suitable for real-time applications. ORB uses FAST which is weaker regarding rotation invariance. The original papers SURF: Speeded Up Robust Features Distinctive Image Features from Scale-Invariant Keypoints ORB: an efficient alternative to SIFT or SURF"
22146094,Why should I use a pointer rather than the object itself?,https://stackoverflow.com/questions/22146094/why-should-i-use-a-pointer-rather-than-the-object-itself,24,1843.0,"[""It's very unfortunate that you see dynamic allocation so often. That just shows how many bad C++ programmers there are. In a sense, you have two questions bundled up into one. The first is when should we use dynamic allocation (using \n```\nnew\n```\n)? The second is when should we use pointers? The important take-home message is that you should always use the appropriate tool for the job. In almost all situations, there is something more appropriate and safer than performing manual dynamic allocation and/or using raw pointers. Dynamic allocation In your question, you've demonstrated two ways of creating an object. The main difference is the storage duration of the object. When doing \n```\nObject myObject;\n```\n within a block, the object is created with automatic storage duration, which means it will be destroyed automatically when it goes out of scope. When you do \n```\nnew Object()\n```\n, the object has dynamic storage duration, which means it stays alive until you explicitly \n```\ndelete"", '```\nnew Object()\n```\n, the object has dynamic storage duration, which means it stays alive until you explicitly \n```\ndelete\n```', ""it. You should only use dynamic storage duration when you need it. That is, you should always prefer creating objects with automatic storage duration when you can. The main two situations in which you might require dynamic allocation: You need the object to outlive the current scope - that specific object at that specific memory location, not a copy of it. If you're okay with copying/moving the object (most of the time you should be), you should prefer an automatic object. You need to allocate a lot of memory, which may easily fill up the stack. It would be nice if we didn't have to concern ourselves with this (most of the time you shouldn't have to), as it's really outside the purview of C++, but unfortunately, we have to deal with the reality of the systems we're developing for. When you do absolutely require dynamic allocation, you should encapsulate it in a smart pointer or some other type that performs RAII (like the standard containers). Smart pointers provide ownership"", 'When you do absolutely require dynamic allocation, you should encapsulate it in a smart pointer or some other type that performs RAII (like the standard containers). Smart pointers provide ownership semantics of dynamically allocated objects. Take a look at', '```\nstd::unique_ptr\n```\n and \n```\nstd::shared_ptr\n```', "", for example. If you use them appropriately, you can almost entirely avoid performing your own memory management (see the Rule of Zero). Pointers However, there are other more general uses for raw pointers beyond dynamic allocation, but most have alternatives that you should prefer. As before, always prefer the alternatives unless you really need pointers. You need reference semantics. Sometimes you want to pass an object using a pointer (regardless of how it was allocated) because you want the function to which you're passing it to have access that that specific object (not a copy of it). However, in most situations, you should prefer reference types to pointers, because this is specifically what they're designed for. Note this is not necessarily about extending the lifetime of the object beyond the current scope, as in situation 1 above. As before, if you're okay with passing a copy of the object, you don't need reference semantics. You need polymorphism. You can only call"", ""the object beyond the current scope, as in situation 1 above. As before, if you're okay with passing a copy of the object, you don't need reference semantics. You need polymorphism. You can only call functions polymorphically (that is, according to the dynamic type of an object) through a pointer or reference to the object. If that's the behavior you need, then you need to use pointers or references. Again, references should be preferred. You want to represent that an object is optional by allowing a"", ""```\nnullptr\n```\n to be passed when the object is being omitted. If it's an argument, you should prefer to use default arguments or function overloads. Otherwise, you should preferably use a type that encapsulates this behavior, such as \n```\nstd::optional\n```\n (introduced in C++17 - with earlier C++ standards, use \n```\nboost::optional\n```\n). You want to decouple compilation units to improve compilation time. The useful property of a pointer is that you only require a forward declaration of the pointed-to type (to actually use the object, you'll need a definition). This allows you to decouple parts of your compilation process, which may significantly improve compilation time. See the Pimpl idiom. You need to interface with a C library or a C-style library. At this point, you're forced to use raw pointers. The best thing you can do is make sure you only let your raw pointers loose at the last possible moment. You can get a raw pointer from a smart pointer, for example, by using its \n```"", '```\nget\n```\n member function. If a library performs some allocation for you which it expects you to deallocate via a handle, you can often wrap the handle up in a smart pointer with a custom deleter that will deallocate the object appropriately.']","It's very unfortunate that you see dynamic allocation so often. That just shows how many bad C++ programmers there are. In a sense, you have two questions bundled up into one. The first is when should we use dynamic allocation (using 
```
new
```
)? The second is when should we use pointers? The important take-home message is that you should always use the appropriate tool for the job. In almost all situations, there is something more appropriate and safer than performing manual dynamic allocation and/or using raw pointers. Dynamic allocation In your question, you've demonstrated two ways of creating an object. The main difference is the storage duration of the object. When doing 
```
Object myObject;
```
 within a block, the object is created with automatic storage duration, which means it will be destroyed automatically when it goes out of scope. When you do 
```
new Object()
```
, the object has dynamic storage duration, which means it stays alive until you explicitly 
```
delete
```
 it. You should only use dynamic storage duration when you need it. That is, you should always prefer creating objects with automatic storage duration when you can. The main two situations in which you might require dynamic allocation: You need the object to outlive the current scope - that specific object at that specific memory location, not a copy of it. If you're okay with copying/moving the object (most of the time you should be), you should prefer an automatic object. You need to allocate a lot of memory, which may easily fill up the stack. It would be nice if we didn't have to concern ourselves with this (most of the time you shouldn't have to), as it's really outside the purview of C++, but unfortunately, we have to deal with the reality of the systems we're developing for. When you do absolutely require dynamic allocation, you should encapsulate it in a smart pointer or some other type that performs RAII (like the standard containers). Smart pointers provide ownership semantics of dynamically allocated objects. Take a look at 
```
std::unique_ptr
```
 and 
```
std::shared_ptr
```
, for example. If you use them appropriately, you can almost entirely avoid performing your own memory management (see the Rule of Zero). Pointers However, there are other more general uses for raw pointers beyond dynamic allocation, but most have alternatives that you should prefer. As before, always prefer the alternatives unless you really need pointers. You need reference semantics. Sometimes you want to pass an object using a pointer (regardless of how it was allocated) because you want the function to which you're passing it to have access that that specific object (not a copy of it). However, in most situations, you should prefer reference types to pointers, because this is specifically what they're designed for. Note this is not necessarily about extending the lifetime of the object beyond the current scope, as in situation 1 above. As before, if you're okay with passing a copy of the object, you don't need reference semantics. You need polymorphism. You can only call functions polymorphically (that is, according to the dynamic type of an object) through a pointer or reference to the object. If that's the behavior you need, then you need to use pointers or references. Again, references should be preferred. You want to represent that an object is optional by allowing a 
```
nullptr
```
 to be passed when the object is being omitted. If it's an argument, you should prefer to use default arguments or function overloads. Otherwise, you should preferably use a type that encapsulates this behavior, such as 
```
std::optional
```
 (introduced in C++17 - with earlier C++ standards, use 
```
boost::optional
```
). You want to decouple compilation units to improve compilation time. The useful property of a pointer is that you only require a forward declaration of the pointed-to type (to actually use the object, you'll need a definition). This allows you to decouple parts of your compilation process, which may significantly improve compilation time. See the Pimpl idiom. You need to interface with a C library or a C-style library. At this point, you're forced to use raw pointers. The best thing you can do is make sure you only let your raw pointers loose at the last possible moment. You can get a raw pointer from a smart pointer, for example, by using its 
```
get
```
 member function. If a library performs some allocation for you which it expects you to deallocate via a handle, you can often wrap the handle up in a smart pointer with a custom deleter that will deallocate the object appropriately."
1143262,"What is the difference between const int*, const int * const, and int * const?",https://stackoverflow.com/questions/1143262/what-is-the-difference-between-const-int-const-int-const-and-int-const,23,2877.0,"[""Read it backwards (as driven by Clockwise/Spiral Rule): \n```\nint*\n```\n - pointer to int \n```\nint const *\n```\n - pointer to const int \n```\nint * const\n```\n - const pointer to int \n```\nint const * const\n```\n - const pointer to const int Now the first \n```\nconst\n```\n can be on either side of the type so: \n```\nconst int *\n```\n == \n```\nint const *\n```\n \n```\nconst int * const\n```\n == \n```\nint const * const\n```\n If you want to go really crazy you can do things like this: \n```\nint **\n```\n - pointer to pointer to int \n```\nint ** const\n```\n - a const pointer to a pointer to an int \n```\nint * const *\n```\n - a pointer to a const pointer to an int \n```\nint const **\n```\n - a pointer to a pointer to a const int \n```\nint * const * const\n```\n - a const pointer to a const pointer to an int ... If you're ever uncertain, you can use a tool like cdecl+ to convert declarations to prose automatically. To make sure we are clear on the meaning of \n```\nconst\n```\n: \n```\nint a = 5, b = 10, c = 15;"", ""const int* foo;     // pointer to constant int.\nfoo = &a;           // assignment to where foo points to.\n\n/* dummy statement*/\n*foo = 6;           // the value of a can´t get changed through the pointer.\n\nfoo = &b;           // the pointer foo can be changed.\n\n\n\nint *const bar = &c;  // constant pointer to int \n                      // note, you actually need to set the pointer \n                      // here because you can't change it later ;)\n\n*bar = 16;            // the value of c can be changed through the pointer.    \n\n/* dummy statement*/\nbar = &a;             // not possible because bar is a constant pointer."", ""*bar = 16;            // the value of c can be changed through the pointer.    \n\n/* dummy statement*/\nbar = &a;             // not possible because bar is a constant pointer.           \n\n```\n \n```\nfoo\n```\n is a variable pointer to a constant integer. This lets you change what you point to but not the value that you point to. Most often this is seen with C-style strings where you have a pointer to a \n```\nconst char\n```\n. You may change which string you point to but you can't change the content of these strings. This is important when the string itself is in the data segment of a program and shouldn't be changed. \n```\nbar\n```\n is a constant or fixed pointer to a value that can be changed. This is like a reference without the extra syntactic sugar. Because of this fact, usually you would use a reference where you would use a \n```\nT* const\n```\n pointer unless you need to allow \n```\nNULL\n```\n pointers.""]","Read it backwards (as driven by Clockwise/Spiral Rule): 
```
int*
```
 - pointer to int 
```
int const *
```
 - pointer to const int 
```
int * const
```
 - const pointer to int 
```
int const * const
```
 - const pointer to const int Now the first 
```
const
```
 can be on either side of the type so: 
```
const int *
```
 == 
```
int const *
```
 
```
const int * const
```
 == 
```
int const * const
```
 If you want to go really crazy you can do things like this: 
```
int **
```
 - pointer to pointer to int 
```
int ** const
```
 - a const pointer to a pointer to an int 
```
int * const *
```
 - a pointer to a const pointer to an int 
```
int const **
```
 - a pointer to a pointer to a const int 
```
int * const * const
```
 - a const pointer to a const pointer to an int ... If you're ever uncertain, you can use a tool like cdecl+ to convert declarations to prose automatically. To make sure we are clear on the meaning of 
```
const
```
: 
```
int a = 5, b = 10, c = 15;

const int* foo;     // pointer to constant int.
foo = &a;           // assignment to where foo points to.

/* dummy statement*/
*foo = 6;           // the value of a can´t get changed through the pointer.

foo = &b;           // the pointer foo can be changed.



int *const bar = &c;  // constant pointer to int 
                      // note, you actually need to set the pointer 
                      // here because you can't change it later ;)

*bar = 16;            // the value of c can be changed through the pointer.    

/* dummy statement*/
bar = &a;             // not possible because bar is a constant pointer.           

```
 
```
foo
```
 is a variable pointer to a constant integer. This lets you change what you point to but not the value that you point to. Most often this is seen with C-style strings where you have a pointer to a 
```
const char
```
. You may change which string you point to but you can't change the content of these strings. This is important when the string itself is in the data segment of a program and shouldn't be changed. 
```
bar
```
 is a constant or fixed pointer to a value that can be changed. This is like a reference without the extra syntactic sugar. Because of this fact, usually you would use a reference where you would use a 
```
T* const
```
 pointer unless you need to allow 
```
NULL
```
 pointers."
12573816,What is an undefined reference/unresolved external symbol error and how do I fix it?,https://stackoverflow.com/questions/12573816/what-is-an-undefined-reference-unresolved-external-symbol-error-and-how-do-i-fix,40,1026.0,"[""Say you have the following code: \n```\n// a.cpp\nint get() { return 0; }\n\n```\n \n```\n// b.cpp\nint get(); // usually, one doesn't write this directly, but gets these\n           // declarations from included header files\nint x = get();"", ""```\n When compiling \n```\nb.cpp\n```\n, the compiler simply assumes that \n```\nget()\n```\n symbol was defined somewhere, but it doesn't yet care where. The linking phase is responsible for finding the symbol and correctly linking the object files produced from \n```\na.cpp\n```\n and \n```\nb.cpp\n```\n. If \n```\na.cpp\n```\n didn't define \n```\nget\n```"", 'and \n```\nb.cpp\n```\n. If \n```\na.cpp\n```\n didn\'t define \n```\nget\n```\n, you would get a linker error saying ""undefined reference"" or ""unresolved external symbol"". C++ Standard Wording Compiling a C++ program takes place in several phases specified in [lex.phases], the last of which is relevant: 9. All external entity references are resolved. Library components are linked to satisfy external references to entities not defined in the current translation. All such translator output is collected into a program image which contains information needed for execution in its execution environment. See Keith Thompson\'s answer for a summary of these phases. The specified errors occur during this last stage of compilation, most commonly referred to as linking. It basically means that you compiled a bunch of source files into object files or libraries, and now you want to get them to work together. Linker Errors in Practice If you\'re using Microsoft Visual Studio, you\'ll see that projects generate', '```\n.lib\n```\n files. These contain a table of exported symbols, and a table of imported symbols. The imported symbols are resolved against the libraries you link against, and the exported symbols are provided for the libraries that use that \n```\n.lib\n```\n (if any). Similar mechanisms exist for other compilers/ platforms. Common error messages are \n```\nerror LNK2001\n```\n, \n```\nerror LNK1120\n```\n, \n```\nerror LNK2019\n```\n for Microsoft Visual Studio and \n```\nundefined reference to\n```\n symbolName for GCC. The code: \n```\nstruct X\n{\n   virtual void foo();\n};\nstruct Y : X\n{\n   void foo() {}\n};\nstruct A\n{\n   virtual ~A() = 0;\n};\nstruct B: A\n{\n   virtual ~B(){}\n};\nextern int x;\nvoid foo();\nint main()\n{\n   x = 0;\n   foo();\n   Y y;\n   B b;\n}', ""```\n will generate the following errors with GCC: \n```\n/home/AbiSfw/ccvvuHoX.o: In function `main':\nprog.cpp:(.text+0x10): undefined reference to `x'\nprog.cpp:(.text+0x19): undefined reference to `foo()'\nprog.cpp:(.text+0x2d): undefined reference to `A::~A()'\n/home/AbiSfw/ccvvuHoX.o: In function `B::~B()':\nprog.cpp:(.text._ZN1BD1Ev[B::~B()]+0xb): undefined reference to `A::~A()'\n/home/AbiSfw/ccvvuHoX.o: In function `B::~B()':\nprog.cpp:(.text._ZN1BD0Ev[B::~B()]+0x12): undefined reference to `A::~A()'\n/home/AbiSfw/ccvvuHoX.o:(.rodata._ZTI1Y[typeinfo for Y]+0x8): undefined reference to `typeinfo for X'\n/home/AbiSfw/ccvvuHoX.o:(.rodata._ZTI1B[typeinfo for B]+0x8): undefined reference to `typeinfo for A'\ncollect2: ld returned 1 exit status"", '```\n and similar errors with Microsoft Visual Studio: \n```\n1>test2.obj : error LNK2001: unresolved external symbol ""void __cdecl foo(void)"" (?foo@@YAXXZ)\n1>test2.obj : error LNK2001: unresolved external symbol ""int x"" (?x@@3HA)\n1>test2.obj : error LNK2001: unresolved external symbol ""public: virtual __thiscall A::~A(void)"" (??1A@@UAE@XZ)\n1>test2.obj : error LNK2001: unresolved external symbol ""public: virtual void __thiscall X::foo(void)"" (?foo@X@@UAEXXZ)\n1>...\\test2.exe : fatal error LNK1120: 4 unresolved externals', ""```\n Common Causes Failure to link against appropriate libraries/object files or compile implementation files Declared and undefined variable or function. Common issues with class-type members Template implementations not visible. Symbols were defined in a C program and used in C++ code. Incorrectly importing/exporting methods/classes across modules/dll. (MSVS specific) Circular library dependency undefined reference to `WinMain@16' Interdependent library order Multiple source files of the same name Mistyping or not including the .lib extension when using the \n```\n#pragma\n```\n (Microsoft Visual Studio) Problems with template friends Inconsistent \n```\nUNICODE\n```"", '```\n#pragma\n```\n (Microsoft Visual Studio) Problems with template friends Inconsistent \n```\nUNICODE\n```\n definitions Missing ""extern"" in const variable declarations/definitions (C++ only) Visual Studio Code not configured for a multiple file project Errors on Mac OS X when building a dylib, but a .so on other Unix-y systems is OK Your linkage consumes libraries before the object files that refer to them Your linkage contains C++ object files and C++ libraries originating from different C++ compilers']","Say you have the following code: 
```
// a.cpp
int get() { return 0; }

```
 
```
// b.cpp
int get(); // usually, one doesn't write this directly, but gets these
           // declarations from included header files
int x = get();

```
 When compiling 
```
b.cpp
```
, the compiler simply assumes that 
```
get()
```
 symbol was defined somewhere, but it doesn't yet care where. The linking phase is responsible for finding the symbol and correctly linking the object files produced from 
```
a.cpp
```
 and 
```
b.cpp
```
. If 
```
a.cpp
```
 didn't define 
```
get
```
, you would get a linker error saying ""undefined reference"" or ""unresolved external symbol"". C++ Standard Wording Compiling a C++ program takes place in several phases specified in [lex.phases], the last of which is relevant: 9. All external entity references are resolved. Library components are linked to satisfy external references to entities not defined in the current translation. All such translator output is collected into a program image which contains information needed for execution in its execution environment. See Keith Thompson's answer for a summary of these phases. The specified errors occur during this last stage of compilation, most commonly referred to as linking. It basically means that you compiled a bunch of source files into object files or libraries, and now you want to get them to work together. Linker Errors in Practice If you're using Microsoft Visual Studio, you'll see that projects generate 
```
.lib
```
 files. These contain a table of exported symbols, and a table of imported symbols. The imported symbols are resolved against the libraries you link against, and the exported symbols are provided for the libraries that use that 
```
.lib
```
 (if any). Similar mechanisms exist for other compilers/ platforms. Common error messages are 
```
error LNK2001
```
, 
```
error LNK1120
```
, 
```
error LNK2019
```
 for Microsoft Visual Studio and 
```
undefined reference to
```
 symbolName for GCC. The code: 
```
struct X
{
   virtual void foo();
};
struct Y : X
{
   void foo() {}
};
struct A
{
   virtual ~A() = 0;
};
struct B: A
{
   virtual ~B(){}
};
extern int x;
void foo();
int main()
{
   x = 0;
   foo();
   Y y;
   B b;
}

```
 will generate the following errors with GCC: 
```
/home/AbiSfw/ccvvuHoX.o: In function `main':
prog.cpp:(.text+0x10): undefined reference to `x'
prog.cpp:(.text+0x19): undefined reference to `foo()'
prog.cpp:(.text+0x2d): undefined reference to `A::~A()'
/home/AbiSfw/ccvvuHoX.o: In function `B::~B()':
prog.cpp:(.text._ZN1BD1Ev[B::~B()]+0xb): undefined reference to `A::~A()'
/home/AbiSfw/ccvvuHoX.o: In function `B::~B()':
prog.cpp:(.text._ZN1BD0Ev[B::~B()]+0x12): undefined reference to `A::~A()'
/home/AbiSfw/ccvvuHoX.o:(.rodata._ZTI1Y[typeinfo for Y]+0x8): undefined reference to `typeinfo for X'
/home/AbiSfw/ccvvuHoX.o:(.rodata._ZTI1B[typeinfo for B]+0x8): undefined reference to `typeinfo for A'
collect2: ld returned 1 exit status

```
 and similar errors with Microsoft Visual Studio: 
```
1>test2.obj : error LNK2001: unresolved external symbol ""void __cdecl foo(void)"" (?foo@@YAXXZ)
1>test2.obj : error LNK2001: unresolved external symbol ""int x"" (?x@@3HA)
1>test2.obj : error LNK2001: unresolved external symbol ""public: virtual __thiscall A::~A(void)"" (??1A@@UAE@XZ)
1>test2.obj : error LNK2001: unresolved external symbol ""public: virtual void __thiscall X::foo(void)"" (?foo@X@@UAEXXZ)
1>...\test2.exe : fatal error LNK1120: 4 unresolved externals

```
 Common Causes Failure to link against appropriate libraries/object files or compile implementation files Declared and undefined variable or function. Common issues with class-type members Template implementations not visible. Symbols were defined in a C program and used in C++ code. Incorrectly importing/exporting methods/classes across modules/dll. (MSVS specific) Circular library dependency undefined reference to `WinMain@16' Interdependent library order Multiple source files of the same name Mistyping or not including the .lib extension when using the 
```
#pragma
```
 (Microsoft Visual Studio) Problems with template friends Inconsistent 
```
UNICODE
```
 definitions Missing ""extern"" in const variable declarations/definitions (C++ only) Visual Studio Code not configured for a multiple file project Errors on Mac OS X when building a dylib, but a .so on other Unix-y systems is OK Your linkage consumes libraries before the object files that refer to them Your linkage contains C++ object files and C++ libraries originating from different C++ compilers"
12135518,Is < faster than <=?,https://stackoverflow.com/questions/12135518/is-faster-than,15,1845.0,"[""No, it will not be faster on most architectures. You didn't specify, but on x86, all of the integral comparisons will be typically implemented in two machine instructions: A \n```\ntest\n```\n or \n```\ncmp\n```\n instruction, which sets \n```\nEFLAGS\n```\n And a \n```\nJcc\n```\n (jump) instruction, depending on the comparison type (and code layout): \n```\njne\n```\n - Jump if not equal --> \n```\nZF = 0\n```\n \n```\njz\n```\n - Jump if zero (equal) --> \n```\nZF = 1\n```\n \n```\njg\n```\n - Jump if greater --> \n```\nZF = 0 and SF = OF\n```\n (etc...) Example (Edited for brevity) Compiled with \n```\n$ gcc -m32 -S -masm=intel test.c\n```\n \n```\n    if (a < b) {\n        // Do something 1\n    }\n\n```\n Compiles to: \n```\n    mov     eax, DWORD PTR [esp+24]      ; a\n    cmp     eax, DWORD PTR [esp+28]      ; b\n    jge     .L2                          ; jump if a is >= b\n    ; Do something 1\n.L2:\n\n```\n And \n```\n    if (a <= b) {\n        // Do something 2\n    }"", '```\n And \n```\n    if (a <= b) {\n        // Do something 2\n    }\n\n```\n Compiles to: \n```\n    mov     eax, DWORD PTR [esp+24]      ; a\n    cmp     eax, DWORD PTR [esp+28]      ; b\n    jg      .L5                          ; jump if a is > b\n    ; Do something 2\n.L5:', ""```\n So the only difference between the two is a \n```\njg\n```\n versus a \n```\njge\n```\n instruction. The two will take the same amount of time. I'd like to address the comment that nothing indicates that the different jump instructions take the same amount of time. This one is a little tricky to answer, but here's what I can give: In the Intel Instruction Set Reference, they are all grouped together under one common instruction, \n```\nJcc\n```\n (Jump if condition is met). The same grouping is made together under the Optimization Reference Manual, in Appendix C. Latency and Throughput. Latency — The number of clock cycles that are required for the execution core to complete the execution of all of the μops that form an instruction. Throughput — The number of clock cycles required to wait before the issue ports are free to accept the same instruction again. For many instructions, the throughput of an instruction can be significantly less than its latency The values for \n```\nJcc\n```\n are:"", '```\nJcc\n```\n are: \n```\n      Latency   Throughput\nJcc     N/A        0.5', '```\n with the following footnote on \n```\nJcc\n```\n: Selection of conditional jump instructions should be based on the recommendation of section Section 3.4.1, “Branch Prediction Optimization,” to improve the predictability of branches. When branches are predicted successfully, the latency of \n```\njcc\n```\n is effectively zero. So, nothing in the Intel docs ever treats one \n```\nJcc\n```\n instruction any differently from the others. If one thinks about the actual circuitry used to implement the instructions, one can assume that there would be simple AND/OR gates on the different bits in \n```\nEFLAGS\n```\n, to determine whether the conditions are met. There is then, no reason that an instruction testing two bits should take any more or less time than one testing only one (Ignoring gate propagation delay, which is much less than the clock period.) Edit: Floating Point This holds true for x87 floating point as well: (Pretty much same code as above, but with \n```\ndouble\n```\n instead of \n```\nint', '```\ndouble\n```\n instead of \n```\nint\n```\n.) \n```\n        fld     QWORD PTR [esp+32]\n        fld     QWORD PTR [esp+40]\n        fucomip st, st(1)              ; Compare ST(0) and ST(1), and set CF, PF, ZF in EFLAGS\n        fstp    st(0)\n        seta    al                     ; Set al if above (CF=0 and ZF=0).\n        test    al, al\n        je      .L2\n        ; Do something 1\n.L2:', 'fld     QWORD PTR [esp+32]\n        fld     QWORD PTR [esp+40]\n        fucomip st, st(1)              ; (same thing as above)\n        fstp    st(0)\n        setae   al                     ; Set al if above or equal (CF=0).\n        test    al, al\n        je      .L5\n        ; Do something 2\n.L5:\n        leave\n        ret\n\n```']","No, it will not be faster on most architectures. You didn't specify, but on x86, all of the integral comparisons will be typically implemented in two machine instructions: A 
```
test
```
 or 
```
cmp
```
 instruction, which sets 
```
EFLAGS
```
 And a 
```
Jcc
```
 (jump) instruction, depending on the comparison type (and code layout): 
```
jne
```
 - Jump if not equal --> 
```
ZF = 0
```
 
```
jz
```
 - Jump if zero (equal) --> 
```
ZF = 1
```
 
```
jg
```
 - Jump if greater --> 
```
ZF = 0 and SF = OF
```
 (etc...) Example (Edited for brevity) Compiled with 
```
$ gcc -m32 -S -masm=intel test.c
```
 
```
    if (a < b) {
        // Do something 1
    }

```
 Compiles to: 
```
    mov     eax, DWORD PTR [esp+24]      ; a
    cmp     eax, DWORD PTR [esp+28]      ; b
    jge     .L2                          ; jump if a is >= b
    ; Do something 1
.L2:

```
 And 
```
    if (a <= b) {
        // Do something 2
    }

```
 Compiles to: 
```
    mov     eax, DWORD PTR [esp+24]      ; a
    cmp     eax, DWORD PTR [esp+28]      ; b
    jg      .L5                          ; jump if a is > b
    ; Do something 2
.L5:

```
 So the only difference between the two is a 
```
jg
```
 versus a 
```
jge
```
 instruction. The two will take the same amount of time. I'd like to address the comment that nothing indicates that the different jump instructions take the same amount of time. This one is a little tricky to answer, but here's what I can give: In the Intel Instruction Set Reference, they are all grouped together under one common instruction, 
```
Jcc
```
 (Jump if condition is met). The same grouping is made together under the Optimization Reference Manual, in Appendix C. Latency and Throughput. Latency — The number of clock cycles that are required for the execution core to complete the execution of all of the μops that form an instruction. Throughput — The number of clock cycles required to wait before the issue ports are free to accept the same instruction again. For many instructions, the throughput of an instruction can be significantly less than its latency The values for 
```
Jcc
```
 are: 
```
      Latency   Throughput
Jcc     N/A        0.5

```
 with the following footnote on 
```
Jcc
```
: Selection of conditional jump instructions should be based on the recommendation of section Section 3.4.1, “Branch Prediction Optimization,” to improve the predictability of branches. When branches are predicted successfully, the latency of 
```
jcc
```
 is effectively zero. So, nothing in the Intel docs ever treats one 
```
Jcc
```
 instruction any differently from the others. If one thinks about the actual circuitry used to implement the instructions, one can assume that there would be simple AND/OR gates on the different bits in 
```
EFLAGS
```
, to determine whether the conditions are met. There is then, no reason that an instruction testing two bits should take any more or less time than one testing only one (Ignoring gate propagation delay, which is much less than the clock period.) Edit: Floating Point This holds true for x87 floating point as well: (Pretty much same code as above, but with 
```
double
```
 instead of 
```
int
```
.) 
```
        fld     QWORD PTR [esp+32]
        fld     QWORD PTR [esp+40]
        fucomip st, st(1)              ; Compare ST(0) and ST(1), and set CF, PF, ZF in EFLAGS
        fstp    st(0)
        seta    al                     ; Set al if above (CF=0 and ZF=0).
        test    al, al
        je      .L2
        ; Do something 1
.L2:

        fld     QWORD PTR [esp+32]
        fld     QWORD PTR [esp+40]
        fucomip st, st(1)              ; (same thing as above)
        fstp    st(0)
        setae   al                     ; Set al if above or equal (CF=0).
        test    al, al
        je      .L5
        ; Do something 2
.L5:
        leave
        ret

```
"
7627098,"What is a lambda expression, and when should I use one?",https://stackoverflow.com/questions/7627098/what-is-a-lambda-expression-and-when-should-i-use-one,11,1791.0,"['The problem C++ includes useful generic functions like \n```\nstd::for_each\n```\n and \n```\nstd::transform\n```\n, which can be very handy. Unfortunately they can also be quite cumbersome to use, particularly if the functor you would like to apply is unique to the particular function. \n```\n#include <algorithm>\n#include <vector>\n\nnamespace {\n  struct f {\n    void operator()(int) {\n      // do something\n    }\n  };\n}\n\nvoid func(std::vector<int>& v) {\n  f f;\n  std::for_each(v.begin(), v.end(), f);\n}\n\n```\n If you only use \n```\nf\n```\n once and in that specific place it seems overkill to be writing a whole class just to do something trivial and one off. In C++03 you might be tempted to write something like the following, to keep the functor local: \n```\nvoid func2(std::vector<int>& v) {\n  struct {\n    void operator()(int) {\n       // do something\n    }\n  } f;\n  std::for_each(v.begin(), v.end(), f);\n}', '```\n however this is not allowed, \n```\nf\n```\n cannot be passed to a template function in C++03. The new solution C++11 introduces lambdas allow you to write an inline, anonymous functor to replace the \n```\nstruct f\n```\n. For small simple examples this can be cleaner to read (it keeps everything in one place) and potentially simpler to maintain, for example in the simplest form: \n```\nvoid func3(std::vector<int>& v) {\n  std::for_each(v.begin(), v.end(), [](int) { /* do something here*/ });\n}\n\n```\n Lambda functions are just syntactic sugar for anonymous functors. Return types In simple cases the return type of the lambda is deduced for you, e.g.: \n```\nvoid func4(std::vector<double>& v) {\n  std::transform(v.begin(), v.end(), v.begin(),\n                 [](double d) { return d < 0.00001 ? 0 : d; }\n                 );\n}', '```\n however when you start to write more complex lambdas you will quickly encounter cases where the return type cannot be deduced by the compiler, e.g.: \n```\nvoid func4(std::vector<double>& v) {\n    std::transform(v.begin(), v.end(), v.begin(),\n        [](double d) {\n            if (d < 0.0001) {\n                return 0;\n            } else {\n                return d;\n            }\n        });\n}\n\n```\n To resolve this you are allowed to explicitly specify a return type for a lambda function, using \n```\n-> T\n```\n: \n```\nvoid func4(std::vector<double>& v) {\n    std::transform(v.begin(), v.end(), v.begin(),\n        [](double d) -> double {\n            if (d < 0.0001) {\n                return 0;\n            } else {\n                return d;\n            }\n        });\n}', '```\n ""Capturing"" variables So far we\'ve not used anything other than what was passed to the lambda within it, but we can also use other variables, within the lambda. If you want to access other variables you can use the capture clause (the \n```\n[]\n```\n of the expression), which has so far been unused in these examples, e.g.: \n```\nvoid func5(std::vector<double>& v, const double& epsilon) {\n    std::transform(v.begin(), v.end(), v.begin(),\n        [epsilon](double d) -> double {\n            if (d < epsilon) {\n                return 0;\n            } else {\n                return d;\n            }\n        });\n}', '```\n You can capture by both reference and value, which you can specify using \n```\n&\n```\n and \n```\n=\n```\n respectively: \n```\n[&epsilon, zeta]\n```\n captures epsilon by reference and zeta by value \n```\n[&]\n```\n captures all variables used in the lambda by reference \n```\n[=]\n```\n captures all variables used in the lambda by value \n```\n[&, epsilon]\n```\n captures all variables used in the lambda by reference but captures epsilon by value \n```\n[=, &epsilon]\n```\n captures all variables used in the lambda by value but captures epsilon by reference The generated \n```\noperator()\n```\n is \n```\nconst\n```\n by default, with the implication that captures will be \n```\nconst\n```\n when you access them by default. This has the effect that each call with the same input would produce the same result, however you can mark the lambda as \n```\nmutable\n```\n to request that the \n```\noperator()\n```\n that is produced is not \n```\nconst\n```\n.']","The problem C++ includes useful generic functions like 
```
std::for_each
```
 and 
```
std::transform
```
, which can be very handy. Unfortunately they can also be quite cumbersome to use, particularly if the functor you would like to apply is unique to the particular function. 
```
#include <algorithm>
#include <vector>

namespace {
  struct f {
    void operator()(int) {
      // do something
    }
  };
}

void func(std::vector<int>& v) {
  f f;
  std::for_each(v.begin(), v.end(), f);
}

```
 If you only use 
```
f
```
 once and in that specific place it seems overkill to be writing a whole class just to do something trivial and one off. In C++03 you might be tempted to write something like the following, to keep the functor local: 
```
void func2(std::vector<int>& v) {
  struct {
    void operator()(int) {
       // do something
    }
  } f;
  std::for_each(v.begin(), v.end(), f);
}

```
 however this is not allowed, 
```
f
```
 cannot be passed to a template function in C++03. The new solution C++11 introduces lambdas allow you to write an inline, anonymous functor to replace the 
```
struct f
```
. For small simple examples this can be cleaner to read (it keeps everything in one place) and potentially simpler to maintain, for example in the simplest form: 
```
void func3(std::vector<int>& v) {
  std::for_each(v.begin(), v.end(), [](int) { /* do something here*/ });
}

```
 Lambda functions are just syntactic sugar for anonymous functors. Return types In simple cases the return type of the lambda is deduced for you, e.g.: 
```
void func4(std::vector<double>& v) {
  std::transform(v.begin(), v.end(), v.begin(),
                 [](double d) { return d < 0.00001 ? 0 : d; }
                 );
}

```
 however when you start to write more complex lambdas you will quickly encounter cases where the return type cannot be deduced by the compiler, e.g.: 
```
void func4(std::vector<double>& v) {
    std::transform(v.begin(), v.end(), v.begin(),
        [](double d) {
            if (d < 0.0001) {
                return 0;
            } else {
                return d;
            }
        });
}

```
 To resolve this you are allowed to explicitly specify a return type for a lambda function, using 
```
-> T
```
: 
```
void func4(std::vector<double>& v) {
    std::transform(v.begin(), v.end(), v.begin(),
        [](double d) -> double {
            if (d < 0.0001) {
                return 0;
            } else {
                return d;
            }
        });
}

```
 ""Capturing"" variables So far we've not used anything other than what was passed to the lambda within it, but we can also use other variables, within the lambda. If you want to access other variables you can use the capture clause (the 
```
[]
```
 of the expression), which has so far been unused in these examples, e.g.: 
```
void func5(std::vector<double>& v, const double& epsilon) {
    std::transform(v.begin(), v.end(), v.begin(),
        [epsilon](double d) -> double {
            if (d < epsilon) {
                return 0;
            } else {
                return d;
            }
        });
}

```
 You can capture by both reference and value, which you can specify using 
```
&
```
 and 
```
=
```
 respectively: 
```
[&epsilon, zeta]
```
 captures epsilon by reference and zeta by value 
```
[&]
```
 captures all variables used in the lambda by reference 
```
[=]
```
 captures all variables used in the lambda by value 
```
[&, epsilon]
```
 captures all variables used in the lambda by reference but captures epsilon by value 
```
[=, &epsilon]
```
 captures all variables used in the lambda by value but captures epsilon by reference The generated 
```
operator()
```
 is 
```
const
```
 by default, with the implication that captures will be 
```
const
```
 when you access them by default. This has the effect that each call with the same input would produce the same result, however you can mark the lambda as 
```
mutable
```
 to request that the 
```
operator()
```
 that is produced is not 
```
const
```
."
3601602,"What are rvalues, lvalues, xvalues, glvalues, and prvalues?",https://stackoverflow.com/questions/3601602/what-are-rvalues-lvalues-xvalues-glvalues-and-prvalues,16,,[],
9314534,Why does changing 0.1f to 0 slow down performance by 10x?,https://stackoverflow.com/questions/9314534/why-does-changing-0-1f-to-0-slow-down-performance-by-10x,7,1733.0,"[""Welcome to the world of denormalized floating-point! They can wreak havoc on performance!!! Denormal (or subnormal) numbers are kind of a hack to get some extra values very close to zero out of the floating point representation. Operations on denormalized floating-point can be tens to hundreds of times slower than on normalized floating-point. This is because many processors can't handle them directly and must trap and resolve them using microcode. If you print out the numbers after 10,000 iterations, you will see that they have converged to different values depending on whether \n```\n0\n```\n or \n```\n0.1\n```\n is used. Here's the test code compiled on x64: \n```\nint main() {\n\n    double start = omp_get_wtime();"", 'double start = omp_get_wtime();\n\n    const float x[16]={1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5,2.6};\n    const float z[16]={1.123,1.234,1.345,156.467,1.578,1.689,1.790,1.812,1.923,2.034,2.145,2.256,2.367,2.478,2.589,2.690};\n    float y[16];\n    for(int i=0;i<16;i++)\n    {\n        y[i]=x[i];\n    }\n    for(int j=0;j<9000000;j++)\n    {\n        for(int i=0;i<16;i++)\n        {\n            y[i]*=x[i];\n            y[i]/=z[i];\n#ifdef FLOATING\n            y[i]=y[i]+0.1f;\n            y[i]=y[i]-0.1f;\n#else\n            y[i]=y[i]+0;\n            y[i]=y[i]-0;\n#endif\n\n            if (j > 10000)\n                cout << y[i] << ""  "";\n        }\n        if (j > 10000)\n            cout << endl;\n    }\n\n    double end = omp_get_wtime();\n    cout << end - start << endl;\n\n    system(""pause"");\n    return 0;\n}', 'double end = omp_get_wtime();\n    cout << end - start << endl;\n\n    system(""pause"");\n    return 0;\n}\n\n```\n Output: \n```\n#define FLOATING\n1.78814e-007  1.3411e-007  1.04308e-007  0  7.45058e-008  6.70552e-008  6.70552e-008  5.58794e-007  3.05474e-007  2.16067e-007  1.71363e-007  1.49012e-007  1.2666e-007  1.11759e-007  1.04308e-007  1.04308e-007\n1.78814e-007  1.3411e-007  1.04308e-007  0  7.45058e-008  6.70552e-008  6.70552e-008  5.58794e-007  3.05474e-007  2.16067e-007  1.71363e-007  1.49012e-007  1.2666e-007  1.11759e-007  1.04308e-007  1.04308e-007', ""//#define FLOATING\n6.30584e-044  3.92364e-044  3.08286e-044  0  1.82169e-044  1.54143e-044  2.10195e-044  2.46842e-029  7.56701e-044  4.06377e-044  3.92364e-044  3.22299e-044  3.08286e-044  2.66247e-044  2.66247e-044  2.24208e-044\n6.30584e-044  3.92364e-044  3.08286e-044  0  1.82169e-044  1.54143e-044  2.10195e-044  2.45208e-029  7.56701e-044  4.06377e-044  3.92364e-044  3.22299e-044  3.08286e-044  2.66247e-044  2.66247e-044  2.24208e-044\n\n```\n Note how in the second run the numbers are very close to zero. Denormalized numbers are generally rare and thus most processors don't try to handle them efficiently. To demonstrate that this has everything to do with denormalized numbers, if we flush denormals to zero by adding this to the start of the code: \n```\n_MM_SET_FLUSH_ZERO_MODE(_MM_FLUSH_ZERO_ON);"", ""```\n Then the version with \n```\n0\n```\n is no longer 10x slower and actually becomes faster. (This requires that the code be compiled with SSE enabled.) This means that rather than using these weird lower precision almost-zero values, we just round to zero instead. Timings: Core i7 920 @ 3.5 GHz: \n```\n//  Don't flush denormals to zero.\n0.1f: 0.564067\n0   : 26.7669\n\n//  Flush denormals to zero.\n0.1f: 0.587117\n0   : 0.341406\n\n```\n In the end, this really has nothing to do with whether it's an integer or floating-point. The \n```\n0\n```\n or \n```\n0.1f\n```\n is converted/stored into a register outside of both loops. So that has no effect on performance.""]","Welcome to the world of denormalized floating-point! They can wreak havoc on performance!!! Denormal (or subnormal) numbers are kind of a hack to get some extra values very close to zero out of the floating point representation. Operations on denormalized floating-point can be tens to hundreds of times slower than on normalized floating-point. This is because many processors can't handle them directly and must trap and resolve them using microcode. If you print out the numbers after 10,000 iterations, you will see that they have converged to different values depending on whether 
```
0
```
 or 
```
0.1
```
 is used. Here's the test code compiled on x64: 
```
int main() {

    double start = omp_get_wtime();

    const float x[16]={1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5,2.6};
    const float z[16]={1.123,1.234,1.345,156.467,1.578,1.689,1.790,1.812,1.923,2.034,2.145,2.256,2.367,2.478,2.589,2.690};
    float y[16];
    for(int i=0;i<16;i++)
    {
        y[i]=x[i];
    }
    for(int j=0;j<9000000;j++)
    {
        for(int i=0;i<16;i++)
        {
            y[i]*=x[i];
            y[i]/=z[i];
#ifdef FLOATING
            y[i]=y[i]+0.1f;
            y[i]=y[i]-0.1f;
#else
            y[i]=y[i]+0;
            y[i]=y[i]-0;
#endif

            if (j > 10000)
                cout << y[i] << ""  "";
        }
        if (j > 10000)
            cout << endl;
    }

    double end = omp_get_wtime();
    cout << end - start << endl;

    system(""pause"");
    return 0;
}

```
 Output: 
```
#define FLOATING
1.78814e-007  1.3411e-007  1.04308e-007  0  7.45058e-008  6.70552e-008  6.70552e-008  5.58794e-007  3.05474e-007  2.16067e-007  1.71363e-007  1.49012e-007  1.2666e-007  1.11759e-007  1.04308e-007  1.04308e-007
1.78814e-007  1.3411e-007  1.04308e-007  0  7.45058e-008  6.70552e-008  6.70552e-008  5.58794e-007  3.05474e-007  2.16067e-007  1.71363e-007  1.49012e-007  1.2666e-007  1.11759e-007  1.04308e-007  1.04308e-007

//#define FLOATING
6.30584e-044  3.92364e-044  3.08286e-044  0  1.82169e-044  1.54143e-044  2.10195e-044  2.46842e-029  7.56701e-044  4.06377e-044  3.92364e-044  3.22299e-044  3.08286e-044  2.66247e-044  2.66247e-044  2.24208e-044
6.30584e-044  3.92364e-044  3.08286e-044  0  1.82169e-044  1.54143e-044  2.10195e-044  2.45208e-029  7.56701e-044  4.06377e-044  3.92364e-044  3.22299e-044  3.08286e-044  2.66247e-044  2.66247e-044  2.24208e-044

```
 Note how in the second run the numbers are very close to zero. Denormalized numbers are generally rare and thus most processors don't try to handle them efficiently. To demonstrate that this has everything to do with denormalized numbers, if we flush denormals to zero by adding this to the start of the code: 
```
_MM_SET_FLUSH_ZERO_MODE(_MM_FLUSH_ZERO_ON);

```
 Then the version with 
```
0
```
 is no longer 10x slower and actually becomes faster. (This requires that the code be compiled with SSE enabled.) This means that rather than using these weird lower precision almost-zero values, we just round to zero instead. Timings: Core i7 920 @ 3.5 GHz: 
```
//  Don't flush denormals to zero.
0.1f: 0.564067
0   : 26.7669

//  Flush denormals to zero.
0.1f: 0.587117
0   : 0.341406

```
 In the end, this really has nothing to do with whether it's an integer or floating-point. The 
```
0
```
 or 
```
0.1f
```
 is converted/stored into a register outside of both loops. So that has no effect on performance."
2391679,Why do we need virtual functions in C++?,https://stackoverflow.com/questions/2391679/why-do-we-need-virtual-functions-in-c,28,847.0,"['Without \n```\nvirtual\n```\n you get ""early binding"". Which implementation of the method is used gets decided at compile time based on the type of the pointer that you call through. With \n```\nvirtual\n```\n you get ""late binding"". Which implementation of the method is used gets decided at run time based on the type of the pointed-to object - what it was originally constructed as. This is not necessarily what you\'d think based on the type of the pointer that points to that object. \n```\nclass Base\n{\n  public:\n            void Method1 ()  {  std::cout << ""Base::Method1"" << std::endl;  }\n    virtual void Method2 ()  {  std::cout << ""Base::Method2"" << std::endl;  }\n};\n\nclass Derived : public Base\n{\n  public:\n    void Method1 ()          {  std::cout << ""Derived::Method1"" << std::endl;  }\n    void Method2 () override {  std::cout << ""Derived::Method2"" << std::endl;  }\n    // Note - override is optional; adding it to Method1 would result in an error\n};', 'Base* basePtr = new Derived ();\n// Note - constructed as Derived, but pointer stored as Base*\n\nbasePtr->Method1 ();  //  Prints ""Base::Method1""\nbasePtr->Method2 ();  //  Prints ""Derived::Method2""\n\n```\n See Also What is the difference between Early and Late Binding? LEARN C++ - Early binding and late binding']","Without 
```
virtual
```
 you get ""early binding"". Which implementation of the method is used gets decided at compile time based on the type of the pointer that you call through. With 
```
virtual
```
 you get ""late binding"". Which implementation of the method is used gets decided at run time based on the type of the pointed-to object - what it was originally constructed as. This is not necessarily what you'd think based on the type of the pointer that points to that object. 
```
class Base
{
  public:
            void Method1 ()  {  std::cout << ""Base::Method1"" << std::endl;  }
    virtual void Method2 ()  {  std::cout << ""Base::Method2"" << std::endl;  }
};

class Derived : public Base
{
  public:
    void Method1 ()          {  std::cout << ""Derived::Method1"" << std::endl;  }
    void Method2 () override {  std::cout << ""Derived::Method2"" << std::endl;  }
    // Note - override is optional; adding it to Method1 would result in an error
};

Base* basePtr = new Derived ();
// Note - constructed as Derived, but pointer stored as Base*

basePtr->Method1 ();  //  Prints ""Base::Method1""
basePtr->Method2 ();  //  Prints ""Derived::Method2""

```
 See Also What is the difference between Early and Late Binding? LEARN C++ - Early binding and late binding"
25078285,Replacing a 32-bit loop counter with 64-bit introduces crazy performance deviations with _mm_popcnt_u64 on Intel CPUs,https://stackoverflow.com/questions/25078285/replacing-a-32-bit-loop-counter-with-64-bit-introduces-crazy-performance-deviati,11,1754.0,"[""Culprit: False Data Dependency (and the compiler isn't even aware of it) On Sandy/Ivy Bridge and Haswell processors, the instruction: \n```\npopcnt  src, dest"", ""```\n appears to have a false dependency on the destination register \n```\ndest\n```\n. Even though the instruction only writes to it, the instruction will wait until \n```\ndest\n```\n is ready before executing. This false dependency is (now) documented by Intel as erratum HSD146 (Haswell) and SKL029 (Skylake) Skylake fixed this for \n```\nlzcnt\n```\n and \n```\ntzcnt\n```\n. Cannon Lake (and Ice Lake) fixed this for \n```\npopcnt\n```\n. \n```\nbsf\n```\n/\n```\nbsr\n```\n have a true output dependency: output unmodified for input=0. (But no way to take advantage of that with intrinsics - only AMD documents it and compilers don't expose it.) (Yes, these instructions all run on the same execution unit). This dependency doesn't just hold up the 4 \n```\npopcnt\n```\ns from a single loop iteration. It can carry across loop iterations making it impossible for the processor to parallelize different loop iterations. The \n```\nunsigned\n```\n vs. \n```\nuint64_t\n```"", ""```\ns from a single loop iteration. It can carry across loop iterations making it impossible for the processor to parallelize different loop iterations. The \n```\nunsigned\n```\n vs. \n```\nuint64_t\n```\n and other tweaks don't directly affect the problem. But they influence the register allocator which assigns the registers to the variables. In your case, the speeds are a direct result of what is stuck to the (false) dependency chain depending on what the register allocator decided to do. 13 GB/s has a chain: \n```\npopcnt\n```\n-\n```\nadd\n```\n-\n```\npopcnt\n```\n-\n```\npopcnt\n```\n → next iteration 15 GB/s has a chain: \n```\npopcnt\n```\n-\n```\nadd\n```\n-\n```\npopcnt\n```\n-\n```\nadd\n```\n → next iteration 20 GB/s has a chain: \n```\npopcnt\n```\n-\n```\npopcnt\n```\n → next iteration 26 GB/s has a chain: \n```\npopcnt\n```\n-\n```\npopcnt\n```"", 'popcnt\n```\n-\n```\nadd\n```\n-\n```\npopcnt\n```\n-\n```\nadd\n```\n → next iteration 20 GB/s has a chain: \n```\npopcnt\n```\n-\n```\npopcnt\n```\n → next iteration 26 GB/s has a chain: \n```\npopcnt\n```\n-\n```\npopcnt\n```\n → next iteration The difference between 20 GB/s and 26 GB/s seems to be a minor artifact of the indirect addressing. Either way, the processor starts to hit other bottlenecks once you reach this speed. To test this, I used inline assembly to bypass the compiler and get exactly the assembly I want. I also split up the \n```\ncount\n```\n variable to break all other dependencies that might mess with the benchmarks. Here are the results: Sandy Bridge Xeon @ 3.5 GHz: (full test code can be found at the bottom) GCC 4.6.3: \n```\ng++ popcnt.cpp -std=c++0x -O3 -save-temps -march=native\n```\n Ubuntu 12 Different Registers: 18.6195 GB/s \n```\n.L4:\n    movq    (%rbx,%rax,8), %r8\n    movq    8(%rbx,%rax,8), %r9\n    movq    16(%rbx,%rax,8), %r10\n    movq    24(%rbx,%rax,8), %r11\n    addq    $4, %rax', 'popcnt %r8, %r8\n    add    %r8, %rdx\n    popcnt %r9, %r9\n    add    %r9, %rcx\n    popcnt %r10, %r10\n    add    %r10, %rdi\n    popcnt %r11, %r11\n    add    %r11, %rsi\n\n    cmpq    $131072, %rax\n    jne .L4\n\n```\n Same Register: 8.49272 GB/s \n```\n.L9:\n    movq    (%rbx,%rdx,8), %r9\n    movq    8(%rbx,%rdx,8), %r10\n    movq    16(%rbx,%rdx,8), %r11\n    movq    24(%rbx,%rdx,8), %rbp\n    addq    $4, %rdx\n\n    # This time reuse ""rax"" for all the popcnts.\n    popcnt %r9, %rax\n    add    %rax, %rcx\n    popcnt %r10, %rax\n    add    %rax, %rsi\n    popcnt %r11, %rax\n    add    %rax, %r8\n    popcnt %rbp, %rax\n    add    %rax, %rdi\n\n    cmpq    $131072, %rdx\n    jne .L9\n\n```\n Same Register with broken chain: 17.8869 GB/s \n```\n.L14:\n    movq    (%rbx,%rdx,8), %r9\n    movq    8(%rbx,%rdx,8), %r10\n    movq    16(%rbx,%rdx,8), %r11\n    movq    24(%rbx,%rdx,8), %rbp\n    addq    $4, %rdx', '# Reuse ""rax"" for all the popcnts.\n    xor    %rax, %rax    # Break the cross-iteration dependency by zeroing ""rax"".\n    popcnt %r9, %rax\n    add    %rax, %rcx\n    popcnt %r10, %rax\n    add    %rax, %rsi\n    popcnt %r11, %rax\n    add    %rax, %r8\n    popcnt %rbp, %rax\n    add    %rax, %rdi\n\n    cmpq    $131072, %rdx\n    jne .L14', ""```\n So what went wrong with the compiler? It seems that neither GCC nor Visual Studio are aware that \n```\npopcnt\n```\n has such a false dependency. Nevertheless, these false dependencies aren't uncommon. It's just a matter of whether the compiler is aware of it. \n```\npopcnt\n```"", ""```\npopcnt\n```\n has such a false dependency. Nevertheless, these false dependencies aren't uncommon. It's just a matter of whether the compiler is aware of it. \n```\npopcnt\n```\n isn't exactly the most used instruction. So it's not really a surprise that a major compiler could miss something like this. There also appears to be no documentation anywhere that mentions this problem. If Intel doesn't disclose it, then nobody outside will know until someone runs into it by chance. (Update: As of version 4.9.2, GCC is aware of this false-dependency and generates code to compensate it when optimizations are enabled. Major compilers from other vendors, including Clang, MSVC, and even Intel's own ICC are not yet aware of this microarchitectural erratum and will not emit code that compensates for it.) Why does the CPU have such a false dependency? We can speculate: it runs on the same execution unit as \n```\nbsf\n```\n / \n```\nbsr\n```"", '```\nbsf\n```\n / \n```\nbsr\n```\n which do have an output dependency. (How is POPCNT implemented in hardware?). For those instructions, Intel documents the integer result for input=0 as ""undefined"" (with ZF=1), but Intel hardware actually gives a stronger guarantee to avoid breaking old software: output unmodified. AMD documents this behaviour. Presumably it was somehow inconvenient to make some uops for this execution unit dependent on the output but others not. AMD processors do not appear to have this false dependency. The full test code is below for reference: \n```\n#include <iostream>\n#include <chrono>\n#include <x86intrin.h>', 'int main(int argc, char* argv[]) {\n\n   using namespace std;\n   uint64_t size=1<<20;\n\n   uint64_t* buffer = new uint64_t[size/8];\n   char* charbuffer=reinterpret_cast<char*>(buffer);\n   for (unsigned i=0;i<size;++i) charbuffer[i]=rand()%256;', 'uint64_t count,duration;\n   chrono::time_point<chrono::system_clock> startP,endP;\n   {\n      uint64_t c0 = 0;\n      uint64_t c1 = 0;\n      uint64_t c2 = 0;\n      uint64_t c3 = 0;\n      startP = chrono::system_clock::now();\n      for( unsigned k = 0; k < 10000; k++){\n         for (uint64_t i=0;i<size/8;i+=4) {\n            uint64_t r0 = buffer[i + 0];\n            uint64_t r1 = buffer[i + 1];\n            uint64_t r2 = buffer[i + 2];\n            uint64_t r3 = buffer[i + 3];\n            __asm__(\n                ""popcnt %4, %4  \\n\\t""\n                ""add %4, %0     \\n\\t""\n                ""popcnt %5, %5  \\n\\t""\n                ""add %5, %1     \\n\\t""\n                ""popcnt %6, %6  \\n\\t""\n                ""add %6, %2     \\n\\t""\n                ""popcnt %7, %7  \\n\\t""\n                ""add %7, %3     \\n\\t""\n                : ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)\n                : ""r""  (r0), ""r""  (r1), ""r""  (r2), ""r""  (r3)\n            );\n         }\n      }\n      count = c0 + c1 + c2 + c3;', ': ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)\n                : ""r""  (r0), ""r""  (r1), ""r""  (r2), ""r""  (r3)\n            );\n         }\n      }\n      count = c0 + c1 + c2 + c3;\n      endP = chrono::system_clock::now();\n      duration=chrono::duration_cast<std::chrono::nanoseconds>(endP-startP).count();\n      cout << ""No Chain\\t"" << count << \'\\t\' << (duration/1.0E9) << "" sec \\t""\n            << (10000.0*size)/(duration) << "" GB/s"" << endl;\n   }\n   {\n      uint64_t c0 = 0;\n      uint64_t c1 = 0;\n      uint64_t c2 = 0;\n      uint64_t c3 = 0;\n      startP = chrono::system_clock::now();\n      for( unsigned k = 0; k < 10000; k++){\n         for (uint64_t i=0;i<size/8;i+=4) {\n            uint64_t r0 = buffer[i + 0];\n            uint64_t r1 = buffer[i + 1];\n            uint64_t r2 = buffer[i + 2];\n            uint64_t r3 = buffer[i + 3];\n            __asm__(\n                ""popcnt %4, %%rax   \\n\\t""\n                ""add %%rax, %0      \\n\\t""\n                ""popcnt %5, %%rax   \\n\\t""', 'uint64_t r3 = buffer[i + 3];\n            __asm__(\n                ""popcnt %4, %%rax   \\n\\t""\n                ""add %%rax, %0      \\n\\t""\n                ""popcnt %5, %%rax   \\n\\t""\n                ""add %%rax, %1      \\n\\t""\n                ""popcnt %6, %%rax   \\n\\t""\n                ""add %%rax, %2      \\n\\t""\n                ""popcnt %7, %%rax   \\n\\t""\n                ""add %%rax, %3      \\n\\t""\n                : ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)\n                : ""r""  (r0), ""r""  (r1), ""r""  (r2), ""r""  (r3)\n                : ""rax""\n            );\n         }\n      }\n      count = c0 + c1 + c2 + c3;\n      endP = chrono::system_clock::now();\n      duration=chrono::duration_cast<std::chrono::nanoseconds>(endP-startP).count();\n      cout << ""Chain 4   \\t""  << count << \'\\t\' << (duration/1.0E9) << "" sec \\t""\n            << (10000.0*size)/(duration) << "" GB/s"" << endl;\n   }\n   {\n      uint64_t c0 = 0;\n      uint64_t c1 = 0;\n      uint64_t c2 = 0;\n      uint64_t c3 = 0;', '<< (10000.0*size)/(duration) << "" GB/s"" << endl;\n   }\n   {\n      uint64_t c0 = 0;\n      uint64_t c1 = 0;\n      uint64_t c2 = 0;\n      uint64_t c3 = 0;\n      startP = chrono::system_clock::now();\n      for( unsigned k = 0; k < 10000; k++){\n         for (uint64_t i=0;i<size/8;i+=4) {\n            uint64_t r0 = buffer[i + 0];\n            uint64_t r1 = buffer[i + 1];\n            uint64_t r2 = buffer[i + 2];\n            uint64_t r3 = buffer[i + 3];\n            __asm__(\n                ""xor %%rax, %%rax   \\n\\t""   // <--- Break the chain.\n                ""popcnt %4, %%rax   \\n\\t""\n                ""add %%rax, %0      \\n\\t""\n                ""popcnt %5, %%rax   \\n\\t""\n                ""add %%rax, %1      \\n\\t""\n                ""popcnt %6, %%rax   \\n\\t""\n                ""add %%rax, %2      \\n\\t""\n                ""popcnt %7, %%rax   \\n\\t""\n                ""add %%rax, %3      \\n\\t""\n                : ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)', '""add %%rax, %2      \\n\\t""\n                ""popcnt %7, %%rax   \\n\\t""\n                ""add %%rax, %3      \\n\\t""\n                : ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)\n                : ""r""  (r0), ""r""  (r1), ""r""  (r2), ""r""  (r3)\n                : ""rax""\n            );\n         }\n      }\n      count = c0 + c1 + c2 + c3;\n      endP = chrono::system_clock::now();\n      duration=chrono::duration_cast<std::chrono::nanoseconds>(endP-startP).count();\n      cout << ""Broken Chain\\t""  << count << \'\\t\' << (duration/1.0E9) << "" sec \\t""\n            << (10000.0*size)/(duration) << "" GB/s"" << endl;\n   }', 'free(charbuffer);\n}\n\n```\n An equally interesting benchmark can be found here: http://pastebin.com/kbzgL8si This benchmark varies the number of \n```\npopcnt\n```\ns that are in the (false) dependency chain. \n```\nFalse Chain 0:  41959360000 0.57748 sec     18.1578 GB/s\nFalse Chain 1:  41959360000 0.585398 sec    17.9122 GB/s\nFalse Chain 2:  41959360000 0.645483 sec    16.2448 GB/s\nFalse Chain 3:  41959360000 0.929718 sec    11.2784 GB/s\nFalse Chain 4:  41959360000 1.23572 sec     8.48557 GB/s\n\n```']","Culprit: False Data Dependency (and the compiler isn't even aware of it) On Sandy/Ivy Bridge and Haswell processors, the instruction: 
```
popcnt  src, dest

```
 appears to have a false dependency on the destination register 
```
dest
```
. Even though the instruction only writes to it, the instruction will wait until 
```
dest
```
 is ready before executing. This false dependency is (now) documented by Intel as erratum HSD146 (Haswell) and SKL029 (Skylake) Skylake fixed this for 
```
lzcnt
```
 and 
```
tzcnt
```
. Cannon Lake (and Ice Lake) fixed this for 
```
popcnt
```
. 
```
bsf
```
/
```
bsr
```
 have a true output dependency: output unmodified for input=0. (But no way to take advantage of that with intrinsics - only AMD documents it and compilers don't expose it.) (Yes, these instructions all run on the same execution unit). This dependency doesn't just hold up the 4 
```
popcnt
```
s from a single loop iteration. It can carry across loop iterations making it impossible for the processor to parallelize different loop iterations. The 
```
unsigned
```
 vs. 
```
uint64_t
```
 and other tweaks don't directly affect the problem. But they influence the register allocator which assigns the registers to the variables. In your case, the speeds are a direct result of what is stuck to the (false) dependency chain depending on what the register allocator decided to do. 13 GB/s has a chain: 
```
popcnt
```
-
```
add
```
-
```
popcnt
```
-
```
popcnt
```
 → next iteration 15 GB/s has a chain: 
```
popcnt
```
-
```
add
```
-
```
popcnt
```
-
```
add
```
 → next iteration 20 GB/s has a chain: 
```
popcnt
```
-
```
popcnt
```
 → next iteration 26 GB/s has a chain: 
```
popcnt
```
-
```
popcnt
```
 → next iteration The difference between 20 GB/s and 26 GB/s seems to be a minor artifact of the indirect addressing. Either way, the processor starts to hit other bottlenecks once you reach this speed. To test this, I used inline assembly to bypass the compiler and get exactly the assembly I want. I also split up the 
```
count
```
 variable to break all other dependencies that might mess with the benchmarks. Here are the results: Sandy Bridge Xeon @ 3.5 GHz: (full test code can be found at the bottom) GCC 4.6.3: 
```
g++ popcnt.cpp -std=c++0x -O3 -save-temps -march=native
```
 Ubuntu 12 Different Registers: 18.6195 GB/s 
```
.L4:
    movq    (%rbx,%rax,8), %r8
    movq    8(%rbx,%rax,8), %r9
    movq    16(%rbx,%rax,8), %r10
    movq    24(%rbx,%rax,8), %r11
    addq    $4, %rax

    popcnt %r8, %r8
    add    %r8, %rdx
    popcnt %r9, %r9
    add    %r9, %rcx
    popcnt %r10, %r10
    add    %r10, %rdi
    popcnt %r11, %r11
    add    %r11, %rsi

    cmpq    $131072, %rax
    jne .L4

```
 Same Register: 8.49272 GB/s 
```
.L9:
    movq    (%rbx,%rdx,8), %r9
    movq    8(%rbx,%rdx,8), %r10
    movq    16(%rbx,%rdx,8), %r11
    movq    24(%rbx,%rdx,8), %rbp
    addq    $4, %rdx

    # This time reuse ""rax"" for all the popcnts.
    popcnt %r9, %rax
    add    %rax, %rcx
    popcnt %r10, %rax
    add    %rax, %rsi
    popcnt %r11, %rax
    add    %rax, %r8
    popcnt %rbp, %rax
    add    %rax, %rdi

    cmpq    $131072, %rdx
    jne .L9

```
 Same Register with broken chain: 17.8869 GB/s 
```
.L14:
    movq    (%rbx,%rdx,8), %r9
    movq    8(%rbx,%rdx,8), %r10
    movq    16(%rbx,%rdx,8), %r11
    movq    24(%rbx,%rdx,8), %rbp
    addq    $4, %rdx

    # Reuse ""rax"" for all the popcnts.
    xor    %rax, %rax    # Break the cross-iteration dependency by zeroing ""rax"".
    popcnt %r9, %rax
    add    %rax, %rcx
    popcnt %r10, %rax
    add    %rax, %rsi
    popcnt %r11, %rax
    add    %rax, %r8
    popcnt %rbp, %rax
    add    %rax, %rdi

    cmpq    $131072, %rdx
    jne .L14

```
 So what went wrong with the compiler? It seems that neither GCC nor Visual Studio are aware that 
```
popcnt
```
 has such a false dependency. Nevertheless, these false dependencies aren't uncommon. It's just a matter of whether the compiler is aware of it. 
```
popcnt
```
 isn't exactly the most used instruction. So it's not really a surprise that a major compiler could miss something like this. There also appears to be no documentation anywhere that mentions this problem. If Intel doesn't disclose it, then nobody outside will know until someone runs into it by chance. (Update: As of version 4.9.2, GCC is aware of this false-dependency and generates code to compensate it when optimizations are enabled. Major compilers from other vendors, including Clang, MSVC, and even Intel's own ICC are not yet aware of this microarchitectural erratum and will not emit code that compensates for it.) Why does the CPU have such a false dependency? We can speculate: it runs on the same execution unit as 
```
bsf
```
 / 
```
bsr
```
 which do have an output dependency. (How is POPCNT implemented in hardware?). For those instructions, Intel documents the integer result for input=0 as ""undefined"" (with ZF=1), but Intel hardware actually gives a stronger guarantee to avoid breaking old software: output unmodified. AMD documents this behaviour. Presumably it was somehow inconvenient to make some uops for this execution unit dependent on the output but others not. AMD processors do not appear to have this false dependency. The full test code is below for reference: 
```
#include <iostream>
#include <chrono>
#include <x86intrin.h>

int main(int argc, char* argv[]) {

   using namespace std;
   uint64_t size=1<<20;

   uint64_t* buffer = new uint64_t[size/8];
   char* charbuffer=reinterpret_cast<char*>(buffer);
   for (unsigned i=0;i<size;++i) charbuffer[i]=rand()%256;

   uint64_t count,duration;
   chrono::time_point<chrono::system_clock> startP,endP;
   {
      uint64_t c0 = 0;
      uint64_t c1 = 0;
      uint64_t c2 = 0;
      uint64_t c3 = 0;
      startP = chrono::system_clock::now();
      for( unsigned k = 0; k < 10000; k++){
         for (uint64_t i=0;i<size/8;i+=4) {
            uint64_t r0 = buffer[i + 0];
            uint64_t r1 = buffer[i + 1];
            uint64_t r2 = buffer[i + 2];
            uint64_t r3 = buffer[i + 3];
            __asm__(
                ""popcnt %4, %4  \n\t""
                ""add %4, %0     \n\t""
                ""popcnt %5, %5  \n\t""
                ""add %5, %1     \n\t""
                ""popcnt %6, %6  \n\t""
                ""add %6, %2     \n\t""
                ""popcnt %7, %7  \n\t""
                ""add %7, %3     \n\t""
                : ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)
                : ""r""  (r0), ""r""  (r1), ""r""  (r2), ""r""  (r3)
            );
         }
      }
      count = c0 + c1 + c2 + c3;
      endP = chrono::system_clock::now();
      duration=chrono::duration_cast<std::chrono::nanoseconds>(endP-startP).count();
      cout << ""No Chain\t"" << count << '\t' << (duration/1.0E9) << "" sec \t""
            << (10000.0*size)/(duration) << "" GB/s"" << endl;
   }
   {
      uint64_t c0 = 0;
      uint64_t c1 = 0;
      uint64_t c2 = 0;
      uint64_t c3 = 0;
      startP = chrono::system_clock::now();
      for( unsigned k = 0; k < 10000; k++){
         for (uint64_t i=0;i<size/8;i+=4) {
            uint64_t r0 = buffer[i + 0];
            uint64_t r1 = buffer[i + 1];
            uint64_t r2 = buffer[i + 2];
            uint64_t r3 = buffer[i + 3];
            __asm__(
                ""popcnt %4, %%rax   \n\t""
                ""add %%rax, %0      \n\t""
                ""popcnt %5, %%rax   \n\t""
                ""add %%rax, %1      \n\t""
                ""popcnt %6, %%rax   \n\t""
                ""add %%rax, %2      \n\t""
                ""popcnt %7, %%rax   \n\t""
                ""add %%rax, %3      \n\t""
                : ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)
                : ""r""  (r0), ""r""  (r1), ""r""  (r2), ""r""  (r3)
                : ""rax""
            );
         }
      }
      count = c0 + c1 + c2 + c3;
      endP = chrono::system_clock::now();
      duration=chrono::duration_cast<std::chrono::nanoseconds>(endP-startP).count();
      cout << ""Chain 4   \t""  << count << '\t' << (duration/1.0E9) << "" sec \t""
            << (10000.0*size)/(duration) << "" GB/s"" << endl;
   }
   {
      uint64_t c0 = 0;
      uint64_t c1 = 0;
      uint64_t c2 = 0;
      uint64_t c3 = 0;
      startP = chrono::system_clock::now();
      for( unsigned k = 0; k < 10000; k++){
         for (uint64_t i=0;i<size/8;i+=4) {
            uint64_t r0 = buffer[i + 0];
            uint64_t r1 = buffer[i + 1];
            uint64_t r2 = buffer[i + 2];
            uint64_t r3 = buffer[i + 3];
            __asm__(
                ""xor %%rax, %%rax   \n\t""   // <--- Break the chain.
                ""popcnt %4, %%rax   \n\t""
                ""add %%rax, %0      \n\t""
                ""popcnt %5, %%rax   \n\t""
                ""add %%rax, %1      \n\t""
                ""popcnt %6, %%rax   \n\t""
                ""add %%rax, %2      \n\t""
                ""popcnt %7, %%rax   \n\t""
                ""add %%rax, %3      \n\t""
                : ""+r"" (c0), ""+r"" (c1), ""+r"" (c2), ""+r"" (c3)
                : ""r""  (r0), ""r""  (r1), ""r""  (r2), ""r""  (r3)
                : ""rax""
            );
         }
      }
      count = c0 + c1 + c2 + c3;
      endP = chrono::system_clock::now();
      duration=chrono::duration_cast<std::chrono::nanoseconds>(endP-startP).count();
      cout << ""Broken Chain\t""  << count << '\t' << (duration/1.0E9) << "" sec \t""
            << (10000.0*size)/(duration) << "" GB/s"" << endl;
   }

   free(charbuffer);
}

```
 An equally interesting benchmark can be found here: http://pastebin.com/kbzgL8si This benchmark varies the number of 
```
popcnt
```
s that are in the (false) dependency chain. 
```
False Chain 0:  41959360000 0.57748 sec     18.1578 GB/s
False Chain 1:  41959360000 0.585398 sec    17.9122 GB/s
False Chain 2:  41959360000 0.645483 sec    16.2448 GB/s
False Chain 3:  41959360000 0.929718 sec    11.2784 GB/s
False Chain 4:  41959360000 1.23572 sec     8.48557 GB/s

```
"
36827659,Compiling an application for use in highly radioactive environments,https://stackoverflow.com/questions/36827659/compiling-an-application-for-use-in-highly-radioactive-environments,24,911.0,"['Working for about 4-5 years with software/firmware development and environment testing of miniaturized satellites*, I would like to share my experience here. *(miniaturized satellites are a lot more prone to single event upsets than bigger satellites due to its relatively small, limited sizes for its electronic components) To be very concise and direct: there is no mechanism to recover from detectable, erroneous situation by the software/firmware itself without, at least, one copy of minimum working version of the software/firmware somewhere for recovery purpose - and with the hardware supporting the recovery (functional). Now, this situation is normally handled both in the hardware and software level. Here, as you request, I will share what we can do in the software level. ...recovery purpose.... Provide ability to update/recompile/reflash your software/firmware in real environment. This is an almost must-have feature for any software/firmware in highly ionized environment. Without', ""Provide ability to update/recompile/reflash your software/firmware in real environment. This is an almost must-have feature for any software/firmware in highly ionized environment. Without this, you could have redundant software/hardware as many as you want but at one point, they are all going to blow up. So, prepare this feature! ...minimum working version... Have responsive, multiple copies, minimum version of the software/firmware in your code. This is like Safe mode in Windows. Instead of having only one, fully functional version of your software, have multiple copies of the minimum version of your software/firmware. The minimum copy will usually having much less size than the full copy and almost always have only the following two or three features: capable of listening to command from external system, capable of updating the current software/firmware, capable of monitoring the basic operation's housekeeping data. ...copy... somewhere... Have redundant software/firmware"", ""from external system, capable of updating the current software/firmware, capable of monitoring the basic operation's housekeeping data. ...copy... somewhere... Have redundant software/firmware somewhere. You could, with or without redundant hardware, try to have redundant software/firmware in your ARM uC. This is normally done by having two or more identical software/firmware in separate addresses which sending heartbeat to each other - but only one will be active at a time. If one or more software/firmware is known to be unresponsive, switch to the other software/firmware. The benefit of using this approach is we can have functional replacement immediately after an error occurs - without any contact with whatever external system/party who is responsible to detect and to repair the error (in satellite case, it is usually the Mission Control Centre (MCC)). Strictly speaking, without redundant hardware, the disadvantage of doing this is you actually cannot eliminate all single point of"", '(in satellite case, it is usually the Mission Control Centre (MCC)). Strictly speaking, without redundant hardware, the disadvantage of doing this is you actually cannot eliminate all single point of failures. At the very least, you will still have one single point of failure, which is the switch itself (or often the beginning of the code). Nevertheless, for a device limited by size in a highly ionized environment (such as pico/femto satellites), the reduction of the single point of failures to one point without additional hardware will still be worth considering. Somemore, the piece of code for the switching would certainly be much less than the code for the whole program - significantly reducing the risk of getting Single Event in it. But if you are not doing this, you should have at least one copy in your external system which can come in contact with the device and update the software/firmware (in the satellite case, it is again the mission control centre). You could also have the', ""one copy in your external system which can come in contact with the device and update the software/firmware (in the satellite case, it is again the mission control centre). You could also have the copy in your permanent memory storage in your device which can be triggered to restore the running system's software/firmware ...detectable erroneous situation.. The error must be detectable, usually by the hardware error correction/detection circuit or by a small piece of code for error correction/detection. It is best to put such code small, multiple, and independent from the main software/firmware. Its main task is only for checking/correcting. If the hardware circuit/firmware is reliable (such as it is more radiation hardened than the rests - or having multiple circuits/logics), then you might consider making error-correction with it. But if it is not, it is better to make it as error-detection. The correction can be by external system/device. For the error correction, you could consider"", ""consider making error-correction with it. But if it is not, it is better to make it as error-detection. The correction can be by external system/device. For the error correction, you could consider making use of a basic error correction algorithm like Hamming/Golay23, because they can be implemented more easily both in the circuit/software. But it ultimately depends on your team's capability. For error detection, normally CRC is used. ...hardware supporting the recovery Now, comes to the most difficult aspect on this issue. Ultimately, the recovery requires the hardware which is responsible for the recovery to be at least functional. If the hardware is permanently broken (normally happen after its Total ionizing dose reaches certain level), then there is (sadly) no way for the software to help in recovery. Thus, hardware is rightly the utmost importance concern for a device exposed to high radiation level (such as satellite). In addition to the suggestion for above anticipating"", ""to help in recovery. Thus, hardware is rightly the utmost importance concern for a device exposed to high radiation level (such as satellite). In addition to the suggestion for above anticipating firmware's error due to single event upset, I would also like to suggest you to have: Error detection and/or error correction algorithm in the inter-subsystem communication protocol. This is another almost must have in order to avoid incomplete/wrong signals received from other system Filter in your ADC reading. Do not use the ADC reading directly. Filter it by median filter, mean filter, or any other filters - never trust single reading value. Sample more, not less - reasonably.""]","Working for about 4-5 years with software/firmware development and environment testing of miniaturized satellites*, I would like to share my experience here. *(miniaturized satellites are a lot more prone to single event upsets than bigger satellites due to its relatively small, limited sizes for its electronic components) To be very concise and direct: there is no mechanism to recover from detectable, erroneous situation by the software/firmware itself without, at least, one copy of minimum working version of the software/firmware somewhere for recovery purpose - and with the hardware supporting the recovery (functional). Now, this situation is normally handled both in the hardware and software level. Here, as you request, I will share what we can do in the software level. ...recovery purpose.... Provide ability to update/recompile/reflash your software/firmware in real environment. This is an almost must-have feature for any software/firmware in highly ionized environment. Without this, you could have redundant software/hardware as many as you want but at one point, they are all going to blow up. So, prepare this feature! ...minimum working version... Have responsive, multiple copies, minimum version of the software/firmware in your code. This is like Safe mode in Windows. Instead of having only one, fully functional version of your software, have multiple copies of the minimum version of your software/firmware. The minimum copy will usually having much less size than the full copy and almost always have only the following two or three features: capable of listening to command from external system, capable of updating the current software/firmware, capable of monitoring the basic operation's housekeeping data. ...copy... somewhere... Have redundant software/firmware somewhere. You could, with or without redundant hardware, try to have redundant software/firmware in your ARM uC. This is normally done by having two or more identical software/firmware in separate addresses which sending heartbeat to each other - but only one will be active at a time. If one or more software/firmware is known to be unresponsive, switch to the other software/firmware. The benefit of using this approach is we can have functional replacement immediately after an error occurs - without any contact with whatever external system/party who is responsible to detect and to repair the error (in satellite case, it is usually the Mission Control Centre (MCC)). Strictly speaking, without redundant hardware, the disadvantage of doing this is you actually cannot eliminate all single point of failures. At the very least, you will still have one single point of failure, which is the switch itself (or often the beginning of the code). Nevertheless, for a device limited by size in a highly ionized environment (such as pico/femto satellites), the reduction of the single point of failures to one point without additional hardware will still be worth considering. Somemore, the piece of code for the switching would certainly be much less than the code for the whole program - significantly reducing the risk of getting Single Event in it. But if you are not doing this, you should have at least one copy in your external system which can come in contact with the device and update the software/firmware (in the satellite case, it is again the mission control centre). You could also have the copy in your permanent memory storage in your device which can be triggered to restore the running system's software/firmware ...detectable erroneous situation.. The error must be detectable, usually by the hardware error correction/detection circuit or by a small piece of code for error correction/detection. It is best to put such code small, multiple, and independent from the main software/firmware. Its main task is only for checking/correcting. If the hardware circuit/firmware is reliable (such as it is more radiation hardened than the rests - or having multiple circuits/logics), then you might consider making error-correction with it. But if it is not, it is better to make it as error-detection. The correction can be by external system/device. For the error correction, you could consider making use of a basic error correction algorithm like Hamming/Golay23, because they can be implemented more easily both in the circuit/software. But it ultimately depends on your team's capability. For error detection, normally CRC is used. ...hardware supporting the recovery Now, comes to the most difficult aspect on this issue. Ultimately, the recovery requires the hardware which is responsible for the recovery to be at least functional. If the hardware is permanently broken (normally happen after its Total ionizing dose reaches certain level), then there is (sadly) no way for the software to help in recovery. Thus, hardware is rightly the utmost importance concern for a device exposed to high radiation level (such as satellite). In addition to the suggestion for above anticipating firmware's error due to single event upset, I would also like to suggest you to have: Error detection and/or error correction algorithm in the inter-subsystem communication protocol. This is another almost must have in order to avoid incomplete/wrong signals received from other system Filter in your ADC reading. Do not use the ADC reading directly. Filter it by median filter, mean filter, or any other filters - never trust single reading value. Sample more, not less - reasonably."
6163683,Cycles in family tree software,https://stackoverflow.com/questions/6163683/cycles-in-family-tree-software,18,724.0,"[""It seems you (and/or your company) have a fundamental misunderstanding of what a family tree is supposed to be. Let me clarify, I also work for a company that has (as one of its products) a family tree in its portfolio, and we have been struggling with similar problems. The problem, in our case, and I assume your case as well, comes from the GEDCOM format that is extremely opinionated about what a family should be. However this format contains some severe misconceptions about what a family tree really looks like. GEDCOM has many issues, such as incompatibility with same sex relations, incest, etc... Which in real life happens more often than you'd imagine (especially when going back in time to the 1700-1800). We have modeled our family tree to what happens in the real world: Events (for example, births, weddings, engagement, unions, deaths, adoptions, etc.). We do not put any restrictions on these, except for logically impossible ones (for example, one can't be one's own parent,"", 'example, births, weddings, engagement, unions, deaths, adoptions, etc.). We do not put any restrictions on these, except for logically impossible ones (for example, one can\'t be one\'s own parent, relations need two individuals, etc...) The lack of validations gives us a more ""real world"", simpler and more flexible solution. As for this specific case, I would suggest removing the assertions as they do not hold universally. For displaying issues (that will arise) I would suggest drawing the same node as many times as needed, hinting at the duplication by lighting up all the copies on selecting one of them.']","It seems you (and/or your company) have a fundamental misunderstanding of what a family tree is supposed to be. Let me clarify, I also work for a company that has (as one of its products) a family tree in its portfolio, and we have been struggling with similar problems. The problem, in our case, and I assume your case as well, comes from the GEDCOM format that is extremely opinionated about what a family should be. However this format contains some severe misconceptions about what a family tree really looks like. GEDCOM has many issues, such as incompatibility with same sex relations, incest, etc... Which in real life happens more often than you'd imagine (especially when going back in time to the 1700-1800). We have modeled our family tree to what happens in the real world: Events (for example, births, weddings, engagement, unions, deaths, adoptions, etc.). We do not put any restrictions on these, except for logically impossible ones (for example, one can't be one's own parent, relations need two individuals, etc...) The lack of validations gives us a more ""real world"", simpler and more flexible solution. As for this specific case, I would suggest removing the assertions as they do not hold universally. For displaying issues (that will arise) I would suggest drawing the same node as many times as needed, hinting at the duplication by lighting up all the copies on selecting one of them."
610245,"Where and why do I have to put the ""template"" and ""typename"" keywords?",https://stackoverflow.com/questions/610245/where-and-why-do-i-have-to-put-the-template-and-typename-keywords,10,1444.0,"['(See here also for my C++11 answer) In order to parse a C++ program, the compiler needs to know whether certain names are types or not. The following example demonstrates that: \n```\nt * f;', ""```\n How should this be parsed? For many languages a compiler doesn't need to know the meaning of a name in order to parse and basically know what action a line of code does. In C++, the above however can yield vastly different interpretations depending on what \n```\nt\n```\n means. If it's a type, then it will be a declaration of a pointer \n```\nf\n```\n. However if it's not a type, it will be a multiplication. So the C++ Standard says at paragraph (3/7): Some names denote types or templates. In general, whenever a name is encountered it is necessary to determine whether that name denotes one of these entities before continuing to parse the program that contains it. The process that determines this is called name lookup. How will the compiler find out what a name \n```\nt::x\n```\n refers to, if \n```\nt\n```\n refers to a template type parameter? \n```\nx\n```"", '```\nt::x\n```\n refers to, if \n```\nt\n```\n refers to a template type parameter? \n```\nx\n```\n could be a static int data member that could be multiplied or could equally well be a nested class or typedef that could yield to a declaration. If a name has this property - that it can\'t be looked up until the actual template arguments are known - then it\'s called a dependent name (it ""depends"" on the template parameters). You might recommend to just wait till the user instantiates the template: Let\'s wait until the user instantiates the template, and then later find out the real meaning of \n```\nt::x * f;\n```', '```\nt::x * f;\n```\n. This will work and actually is allowed by the Standard as a possible implementation approach. These compilers basically copy the template\'s text into an internal buffer, and only when an instantiation is needed, they parse the template and possibly detect errors in the definition. But instead of bothering the template\'s users (poor colleagues!) with errors made by a template\'s author, other implementations choose to check templates early on and give errors in the definition as soon as possible, before an instantiation even takes place. So there has to be a way to tell the compiler that certain names are types and that certain names aren\'t. The ""typename"" keyword The answer is: We decide how the compiler should parse this. If \n```\nt::x\n```\n is a dependent name, then we need to prefix it by \n```\ntypename\n```', '```\nt::x\n```\n is a dependent name, then we need to prefix it by \n```\ntypename\n```\n to tell the compiler to parse it in a certain way. The Standard says at (14.6/2): A name used in a template declaration or definition and that is dependent on a template-parameter is assumed not to name a type unless the applicable name lookup finds a type name or the name is qualified by the keyword typename. There are many names for which \n```\ntypename\n```\n is not necessary, because the compiler can, with the applicable name lookup in the template definition, figure out how to parse a construct itself - for example with \n```\nT *f;\n```\n, when \n```\nT\n```\n is a type template parameter. But for \n```\nt::x * f;\n```\n to be a declaration, it must be written as \n```\ntypename t::x *f;\n```', '```\nT *f;\n```\n, when \n```\nT\n```\n is a type template parameter. But for \n```\nt::x * f;\n```\n to be a declaration, it must be written as \n```\ntypename t::x *f;\n```\n. If you omit the keyword and the name is taken to be a non-type, but when instantiation finds it denotes a type, the usual error messages are emitted by the compiler. Sometimes, the error consequently is given at definition time: \n```\n// t::x is taken as non-type, but as an expression the following misses an\n// operator between the two names or a semicolon separating them.\nt::x f;', '```\n The syntax allows \n```\ntypename\n```\n only before qualified names - it is therefor taken as granted that unqualified names are always known to refer to types if they do so. A similar gotcha exists for names that denote templates, as hinted at by the introductory text. The ""template"" keyword Remember the initial quote above and how the Standard requires special handling for templates as well? Let\'s take the following innocent-looking example: \n```\nboost::function< int() > f;\n\n```\n It might look obvious to a human reader. Not so for the compiler. Imagine the following arbitrary definition of \n```\nboost::function\n```\n and \n```\nf\n```\n: \n```\nnamespace boost { int function = 0; }\nint main() { \n  int f = 0;\n  boost::function< int() > f; \n}', ""```\n That's actually a valid expression! It uses the less-than operator to compare \n```\nboost::function\n```\n against zero (\n```\nint()\n```\n), and then uses the greater-than operator to compare the resulting \n```\nbool\n```\n against \n```\nf\n```\n. However as you might well know, \n```\nboost::function\n```\n in real life is a template, so the compiler knows (14.2/3): After name lookup (3.4) finds that a name is a template-name, if this name is followed by a <, the < is always taken as the beginning of a template-argument-list and never as a name followed by the less-than operator. Now we are back to the same problem as with \n```\ntypename\n```\n. What if we can't know yet whether the name is a template when parsing the code? We will need to insert \n```\ntemplate\n```\n immediately before the template name, as specified by \n```\n14.2/4\n```\n. This looks like: \n```\nt::template f<int>(); // call a function template"", '```\n Template names can not only occur after a \n```\n::\n```\n but also after a \n```\n->\n```\n or \n```\n.\n```\n in a class member access. You need to insert the keyword there too: \n```\nthis->template f<int>(); // call a function template', ""```\n Dependencies For the people that have thick Standardese books on their shelf and that want to know what exactly I was talking about, I'll talk a bit about how this is specified in the Standard. In template declarations some constructs have different meanings depending on what template arguments you use to instantiate the template: Expressions may have different types or values, variables may have different types or function calls might end up calling different functions. Such constructs are generally said to depend on template parameters. The Standard defines precisely the rules by whether a construct is dependent or not. It separates them into logically different groups: One catches types, another catches expressions. Expressions may depend by their value and/or their type. So we have, with typical examples appended: Dependent types (e.g: a type template parameter \n```\nT\n```\n) Value-dependent expressions (e.g: a non-type template parameter \n```\nN\n```"", '```\nT\n```\n) Value-dependent expressions (e.g: a non-type template parameter \n```\nN\n```\n) Type-dependent expressions (e.g: a cast to a type template parameter \n```\n(T)0\n```\n) Most of the rules are intuitive and are built up recursively: For example, a type constructed as \n```\nT[N]\n```\n is a dependent type if \n```\nN\n```\n is a value-dependent expression or \n```\nT\n```\n is a dependent type. The details of this can be read in section \n```\n(14.6.2/1\n```\n) for dependent types, \n```\n(14.6.2.2)\n```\n for type-dependent expressions and \n```\n(14.6.2.3)\n```\n for value-dependent expressions. Dependent names The Standard is a bit unclear about what exactly is a dependent name. On a simple read (you know, the principle of least surprise), all it defines as a dependent name is the special case for function names below. But since clearly \n```\nT::x\n```', '```\nT::x\n```\n also needs to be looked up in the instantiation context, it also needs to be a dependent name (fortunately, as of mid C++14 the committee has started to look into how to fix this confusing definition). To avoid this problem, I have resorted to a simple interpretation of the Standard text. Of all the constructs that denote dependent types or expressions, a subset of them represent names. Those names are therefore ""dependent names"". A name can take different forms - the Standard says: A name is a use of an identifier (2.11), operator-function-id (13.5), conversion-function-id (12.3.2), or template-id (14.2) that denotes an entity or label (6.6.4, 6.1) An identifier is just a plain sequence of characters / digits, while the next two are the \n```\noperator +\n```\n and \n```\noperator type\n```\n form. The last form is \n```\ntemplate-name <argument list>\n```', '```\noperator +\n```\n and \n```\noperator type\n```\n form. The last form is \n```\ntemplate-name <argument list>\n```\n. All these are names, and by conventional use in the Standard, a name can also include qualifiers that say what namespace or class a name should be looked up in. A value dependent expression \n```\n1 + N\n```\n is not a name, but \n```\nN\n```\n is. The subset of all dependent constructs that are names is called dependent name. Function names, however, may have different meaning in different instantiations of a template, but unfortunately are not caught by this general rule. Dependent function names Not primarily a concern of this article, but still worth mentioning: Function names are an exception that are handled separately. An identifier function name is dependent not by itself, but by the type dependent argument expressions used in a call. In the example \n```\nf((T)0)\n```\n, \n```\nf\n```\n is a dependent name. In the Standard, this is specified at \n```\n(14.6.2/1)\n```', '```\nf((T)0)\n```\n, \n```\nf\n```\n is a dependent name. In the Standard, this is specified at \n```\n(14.6.2/1)\n```\n. Additional notes and examples In enough cases we need both of \n```\ntypename\n```\n and \n```\ntemplate\n```\n. Your code should look like the following \n```\ntemplate <typename T, typename Tail>\nstruct UnionNode : public Tail {\n    // ...\n    template<typename U> struct inUnion {\n        typedef typename Tail::template inUnion<U> dummy;\n    };\n    // ...\n};', ""```\n The keyword \n```\ntemplate\n```\n doesn't always have to appear in the last part of a name. It can appear in the middle before a class name that's used as a scope, like in the following example \n```\ntypename t::template iterator<int>::value_type v;\n\n```\n In some cases, the keywords are forbidden, as detailed below On the name of a dependent base class you are not allowed to write \n```\ntypename\n```\n. It's assumed that the name given is a class type name. This is true for both names in the base-class list and the constructor initializer list: \n```\n template <typename T>\n struct derive_from_Has_type : /* typename */ SomeBase<T>::type \n { };\n\n```\n In using-declarations it's not possible to use \n```\ntemplate\n```\n after the last \n```\n::\n```\n, and the C++ committee said not to work on a solution. \n```\n template <typename T>\n struct derive_from_Has_type : SomeBase<T> {\n    using SomeBase<T>::template type; // error\n    using typename SomeBase<T>::type; // typename *is* allowed\n };\n\n```""]","(See here also for my C++11 answer) In order to parse a C++ program, the compiler needs to know whether certain names are types or not. The following example demonstrates that: 
```
t * f;

```
 How should this be parsed? For many languages a compiler doesn't need to know the meaning of a name in order to parse and basically know what action a line of code does. In C++, the above however can yield vastly different interpretations depending on what 
```
t
```
 means. If it's a type, then it will be a declaration of a pointer 
```
f
```
. However if it's not a type, it will be a multiplication. So the C++ Standard says at paragraph (3/7): Some names denote types or templates. In general, whenever a name is encountered it is necessary to determine whether that name denotes one of these entities before continuing to parse the program that contains it. The process that determines this is called name lookup. How will the compiler find out what a name 
```
t::x
```
 refers to, if 
```
t
```
 refers to a template type parameter? 
```
x
```
 could be a static int data member that could be multiplied or could equally well be a nested class or typedef that could yield to a declaration. If a name has this property - that it can't be looked up until the actual template arguments are known - then it's called a dependent name (it ""depends"" on the template parameters). You might recommend to just wait till the user instantiates the template: Let's wait until the user instantiates the template, and then later find out the real meaning of 
```
t::x * f;
```
. This will work and actually is allowed by the Standard as a possible implementation approach. These compilers basically copy the template's text into an internal buffer, and only when an instantiation is needed, they parse the template and possibly detect errors in the definition. But instead of bothering the template's users (poor colleagues!) with errors made by a template's author, other implementations choose to check templates early on and give errors in the definition as soon as possible, before an instantiation even takes place. So there has to be a way to tell the compiler that certain names are types and that certain names aren't. The ""typename"" keyword The answer is: We decide how the compiler should parse this. If 
```
t::x
```
 is a dependent name, then we need to prefix it by 
```
typename
```
 to tell the compiler to parse it in a certain way. The Standard says at (14.6/2): A name used in a template declaration or definition and that is dependent on a template-parameter is assumed not to name a type unless the applicable name lookup finds a type name or the name is qualified by the keyword typename. There are many names for which 
```
typename
```
 is not necessary, because the compiler can, with the applicable name lookup in the template definition, figure out how to parse a construct itself - for example with 
```
T *f;
```
, when 
```
T
```
 is a type template parameter. But for 
```
t::x * f;
```
 to be a declaration, it must be written as 
```
typename t::x *f;
```
. If you omit the keyword and the name is taken to be a non-type, but when instantiation finds it denotes a type, the usual error messages are emitted by the compiler. Sometimes, the error consequently is given at definition time: 
```
// t::x is taken as non-type, but as an expression the following misses an
// operator between the two names or a semicolon separating them.
t::x f;

```
 The syntax allows 
```
typename
```
 only before qualified names - it is therefor taken as granted that unqualified names are always known to refer to types if they do so. A similar gotcha exists for names that denote templates, as hinted at by the introductory text. The ""template"" keyword Remember the initial quote above and how the Standard requires special handling for templates as well? Let's take the following innocent-looking example: 
```
boost::function< int() > f;

```
 It might look obvious to a human reader. Not so for the compiler. Imagine the following arbitrary definition of 
```
boost::function
```
 and 
```
f
```
: 
```
namespace boost { int function = 0; }
int main() { 
  int f = 0;
  boost::function< int() > f; 
}

```
 That's actually a valid expression! It uses the less-than operator to compare 
```
boost::function
```
 against zero (
```
int()
```
), and then uses the greater-than operator to compare the resulting 
```
bool
```
 against 
```
f
```
. However as you might well know, 
```
boost::function
```
 in real life is a template, so the compiler knows (14.2/3): After name lookup (3.4) finds that a name is a template-name, if this name is followed by a <, the < is always taken as the beginning of a template-argument-list and never as a name followed by the less-than operator. Now we are back to the same problem as with 
```
typename
```
. What if we can't know yet whether the name is a template when parsing the code? We will need to insert 
```
template
```
 immediately before the template name, as specified by 
```
14.2/4
```
. This looks like: 
```
t::template f<int>(); // call a function template

```
 Template names can not only occur after a 
```
::
```
 but also after a 
```
->
```
 or 
```
.
```
 in a class member access. You need to insert the keyword there too: 
```
this->template f<int>(); // call a function template

```
 Dependencies For the people that have thick Standardese books on their shelf and that want to know what exactly I was talking about, I'll talk a bit about how this is specified in the Standard. In template declarations some constructs have different meanings depending on what template arguments you use to instantiate the template: Expressions may have different types or values, variables may have different types or function calls might end up calling different functions. Such constructs are generally said to depend on template parameters. The Standard defines precisely the rules by whether a construct is dependent or not. It separates them into logically different groups: One catches types, another catches expressions. Expressions may depend by their value and/or their type. So we have, with typical examples appended: Dependent types (e.g: a type template parameter 
```
T
```
) Value-dependent expressions (e.g: a non-type template parameter 
```
N
```
) Type-dependent expressions (e.g: a cast to a type template parameter 
```
(T)0
```
) Most of the rules are intuitive and are built up recursively: For example, a type constructed as 
```
T[N]
```
 is a dependent type if 
```
N
```
 is a value-dependent expression or 
```
T
```
 is a dependent type. The details of this can be read in section 
```
(14.6.2/1
```
) for dependent types, 
```
(14.6.2.2)
```
 for type-dependent expressions and 
```
(14.6.2.3)
```
 for value-dependent expressions. Dependent names The Standard is a bit unclear about what exactly is a dependent name. On a simple read (you know, the principle of least surprise), all it defines as a dependent name is the special case for function names below. But since clearly 
```
T::x
```
 also needs to be looked up in the instantiation context, it also needs to be a dependent name (fortunately, as of mid C++14 the committee has started to look into how to fix this confusing definition). To avoid this problem, I have resorted to a simple interpretation of the Standard text. Of all the constructs that denote dependent types or expressions, a subset of them represent names. Those names are therefore ""dependent names"". A name can take different forms - the Standard says: A name is a use of an identifier (2.11), operator-function-id (13.5), conversion-function-id (12.3.2), or template-id (14.2) that denotes an entity or label (6.6.4, 6.1) An identifier is just a plain sequence of characters / digits, while the next two are the 
```
operator +
```
 and 
```
operator type
```
 form. The last form is 
```
template-name <argument list>
```
. All these are names, and by conventional use in the Standard, a name can also include qualifiers that say what namespace or class a name should be looked up in. A value dependent expression 
```
1 + N
```
 is not a name, but 
```
N
```
 is. The subset of all dependent constructs that are names is called dependent name. Function names, however, may have different meaning in different instantiations of a template, but unfortunately are not caught by this general rule. Dependent function names Not primarily a concern of this article, but still worth mentioning: Function names are an exception that are handled separately. An identifier function name is dependent not by itself, but by the type dependent argument expressions used in a call. In the example 
```
f((T)0)
```
, 
```
f
```
 is a dependent name. In the Standard, this is specified at 
```
(14.6.2/1)
```
. Additional notes and examples In enough cases we need both of 
```
typename
```
 and 
```
template
```
. Your code should look like the following 
```
template <typename T, typename Tail>
struct UnionNode : public Tail {
    // ...
    template<typename U> struct inUnion {
        typedef typename Tail::template inUnion<U> dummy;
    };
    // ...
};

```
 The keyword 
```
template
```
 doesn't always have to appear in the last part of a name. It can appear in the middle before a class name that's used as a scope, like in the following example 
```
typename t::template iterator<int>::value_type v;

```
 In some cases, the keywords are forbidden, as detailed below On the name of a dependent base class you are not allowed to write 
```
typename
```
. It's assumed that the name given is a class type name. This is true for both names in the base-class list and the constructor initializer list: 
```
 template <typename T>
 struct derive_from_Has_type : /* typename */ SomeBase<T>::type 
 { };

```
 In using-declarations it's not possible to use 
```
template
```
 after the last 
```
::
```
, and the C++ committee said not to work on a solution. 
```
 template <typename T>
 struct derive_from_Has_type : SomeBase<T> {
    using SomeBase<T>::template type; // error
    using typename SomeBase<T>::type; // typename *is* allowed
 };

```
"
10747810,What is the difference between 'typedef' and 'using'?,https://stackoverflow.com/questions/10747810/what-is-the-difference-between-typedef-and-using,8,179.0,"['All standard references below refers to N4659: March 2017 post-Kona working draft/C++17 DIS. Typedef declarations can, whereas (until C++23) alias declarations cannot, be used as initialization statements But, with the first two non-template examples, are there any other subtle differences in the standard? Differences in semantics: none. Differences in allowed contexts(+): C++20 and earlier: some. C++23 and onwards: none(++). (+) Not including the examples of alias templates, which has already been mentioned in the original post. (++) P2360R0 (Extend init-statement to allow alias-declaration) has been approved by CWG and as of C++23, this inconsistency between typedef declarations and alias declarations will have been removed. Same semantics As governed by [dcl.typedef]/2 [extract, emphasis mine] [dcl.typedef]/2 A typedef-name can also be introduced by an alias-declaration. The identifier following the \n```\nusing\n```', '```\nusing\n```\n keyword becomes a typedef-name and the optional attribute-specifier-seq following the identifier appertains to that typedef-name. Such a typedef-name has the same semantics as if it were introduced by the \n```\ntypedef\n```\n specifier. [...] a typedef-name introduced by an alias-declaration has the same semantics as if it were introduced by the \n```\ntypedef\n```\n declaration. Subtle difference in allowed contexts However, this does not imply that the two variations have the same restrictions with regard to the contexts in which they may be used. And indeed, albeit a corner case, a typedef declaration is an init-statement and may thus be used in contexts which allow initialization statements \n```\n// C++11 (C++03) (init. statement in for loop iteration statements).\nfor (typedef int Foo; Foo{} != 0;)\n//   ^^^^^^^^^^^^^^^ init-statement\n{\n}', '// C++17 (if and switch initialization statements).\nif (typedef int Foo; true)\n//  ^^^^^^^^^^^^^^^ init-statement\n{\n    (void)Foo{};\n}\n\nswitch (typedef int Foo; 0)\n//      ^^^^^^^^^^^^^^^ init-statement\n{\n    case 0: (void)Foo{};\n}\n\n// C++20 (range-based for loop initialization statements).\nstd::vector<int> v{1, 2, 3};\nfor (typedef int Foo; Foo f : v)\n//   ^^^^^^^^^^^^^^^ init-statement\n{\n    (void)f;\n}\n\nfor (typedef struct { int x; int y;} P; auto [x, y] : {P{1, 1}, {1, 2}, {3, 5}})\n//   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ init-statement\n{\n    (void)x;\n    (void)y;\n}\n\n```\n whereas before C++23 (this answer may have prompted P2360R0 which addressed this niche subtlety in C++23) an alias-declaration is not an init-statement, and thus may not be used in contexts which allows initialization statements \n```\n// C++ 11.\nfor (using Foo = int; Foo{} != 0;) {}\n//   ^^^^^^^^^^^^^^^ error: expected expression', '// C++17 (initialization expressions in switch and if statements).\nif (using Foo = int; true) { (void)Foo{}; }\n//  ^^^^^^^^^^^^^^^ error: expected expression\n\nswitch (using Foo = int; 0) { case 0: (void)Foo{}; }\n//      ^^^^^^^^^^^^^^^ error: expected expression\n\n// C++20 (range-based for loop initialization statements).\nstd::vector<int> v{1, 2, 3};\nfor (using Foo = int; Foo f : v) { (void)f; }\n//   ^^^^^^^^^^^^^^^ error: expected expression\n\n```']","All standard references below refers to N4659: March 2017 post-Kona working draft/C++17 DIS. Typedef declarations can, whereas (until C++23) alias declarations cannot, be used as initialization statements But, with the first two non-template examples, are there any other subtle differences in the standard? Differences in semantics: none. Differences in allowed contexts(+): C++20 and earlier: some. C++23 and onwards: none(++). (+) Not including the examples of alias templates, which has already been mentioned in the original post. (++) P2360R0 (Extend init-statement to allow alias-declaration) has been approved by CWG and as of C++23, this inconsistency between typedef declarations and alias declarations will have been removed. Same semantics As governed by [dcl.typedef]/2 [extract, emphasis mine] [dcl.typedef]/2 A typedef-name can also be introduced by an alias-declaration. The identifier following the 
```
using
```
 keyword becomes a typedef-name and the optional attribute-specifier-seq following the identifier appertains to that typedef-name. Such a typedef-name has the same semantics as if it were introduced by the 
```
typedef
```
 specifier. [...] a typedef-name introduced by an alias-declaration has the same semantics as if it were introduced by the 
```
typedef
```
 declaration. Subtle difference in allowed contexts However, this does not imply that the two variations have the same restrictions with regard to the contexts in which they may be used. And indeed, albeit a corner case, a typedef declaration is an init-statement and may thus be used in contexts which allow initialization statements 
```
// C++11 (C++03) (init. statement in for loop iteration statements).
for (typedef int Foo; Foo{} != 0;)
//   ^^^^^^^^^^^^^^^ init-statement
{
}

// C++17 (if and switch initialization statements).
if (typedef int Foo; true)
//  ^^^^^^^^^^^^^^^ init-statement
{
    (void)Foo{};
}

switch (typedef int Foo; 0)
//      ^^^^^^^^^^^^^^^ init-statement
{
    case 0: (void)Foo{};
}

// C++20 (range-based for loop initialization statements).
std::vector<int> v{1, 2, 3};
for (typedef int Foo; Foo f : v)
//   ^^^^^^^^^^^^^^^ init-statement
{
    (void)f;
}

for (typedef struct { int x; int y;} P; auto [x, y] : {P{1, 1}, {1, 2}, {3, 5}})
//   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ init-statement
{
    (void)x;
    (void)y;
}

```
 whereas before C++23 (this answer may have prompted P2360R0 which addressed this niche subtlety in C++23) an alias-declaration is not an init-statement, and thus may not be used in contexts which allows initialization statements 
```
// C++ 11.
for (using Foo = int; Foo{} != 0;) {}
//   ^^^^^^^^^^^^^^^ error: expected expression

// C++17 (initialization expressions in switch and if statements).
if (using Foo = int; true) { (void)Foo{}; }
//  ^^^^^^^^^^^^^^^ error: expected expression

switch (using Foo = int; 0) { case 0: (void)Foo{}; }
//      ^^^^^^^^^^^^^^^ error: expected expression

// C++20 (range-based for loop initialization statements).
std::vector<int> v{1, 2, 3};
for (using Foo = int; Foo f : v) { (void)f; }
//   ^^^^^^^^^^^^^^^ error: expected expression

```
"
54585,When should you use a class vs a struct in C++?,https://stackoverflow.com/questions/54585/when-should-you-use-a-class-vs-a-struct-in-c,27,1119.0,"['The differences between a \n```\nclass\n```\n and a \n```\nstruct\n```\n in C++ are: \n```\nstruct\n```\n members and base classes/structs are \n```\npublic\n```\n by default. \n```\nclass\n```\n members and base classes/structs are \n```\nprivate\n```\n by default. Both classes and structs can have a mixture of \n```\npublic\n```\n, \n```\nprotected\n```\n and \n```\nprivate\n```\n members, can use inheritance, and can have member functions. I would recommend you: use \n```\nstruct\n```\n for plain-old-data structures without any class-like features; use \n```\nclass\n```\n when you make use of features such as \n```\nprivate\n```\n or \n```\nprotected\n```\n members, non-default constructors and operators, etc.']","The differences between a 
```
class
```
 and a 
```
struct
```
 in C++ are: 
```
struct
```
 members and base classes/structs are 
```
public
```
 by default. 
```
class
```
 members and base classes/structs are 
```
private
```
 by default. Both classes and structs can have a mixture of 
```
public
```
, 
```
protected
```
 and 
```
private
```
 members, can use inheritance, and can have member functions. I would recommend you: use 
```
struct
```
 for plain-old-data structures without any class-like features; use 
```
class
```
 when you make use of features such as 
```
private
```
 or 
```
protected
```
 members, non-default constructors and operators, etc."
860339,"What is the difference between public, private, and protected inheritance?",https://stackoverflow.com/questions/860339/what-is-the-difference-between-public-private-and-protected-inheritance,17,1204.0,"['To answer that question, I\'d like to describe member\'s accessors first in my own words. If you already know this, skip to the heading ""next:"". There are three accessors that I\'m aware of: \n```\npublic\n```\n, \n```\nprotected\n```\n and \n```\nprivate\n```\n. Let: \n```\nclass Base {\n    public:\n        int publicMember;\n    protected:\n        int protectedMember;\n    private:\n        int privateMember;\n};', '```\n Everything that is aware of \n```\nBase\n```\n is also aware that \n```\nBase\n```\n contains \n```\npublicMember\n```\n. Only the children (and their children) are aware that \n```\nBase\n```\n contains \n```\nprotectedMember\n```\n. No one but \n```\nBase\n```\n is aware of \n```\nprivateMember\n```\n. By ""is aware of"", I mean ""acknowledge the existence of, and thus be able to access"". next: The same happens with public, private and protected inheritance. Let\'s consider a class \n```\nBase\n```\n and a class \n```\nChild\n```\n that inherits from \n```\nBase\n```\n. If the inheritance is \n```\npublic\n```\n, everything that is aware of \n```\nBase\n```\n and \n```\nChild\n```\n is also aware that \n```\nChild\n```\n inherits from \n```\nBase\n```\n. If the inheritance is \n```\nprotected\n```\n, only \n```\nChild\n```\n, and its children, are aware that they inherit from \n```\nBase\n```\n. If the inheritance is \n```\nprivate\n```\n, no one other than \n```\nChild\n```\n is aware of the inheritance.']","To answer that question, I'd like to describe member's accessors first in my own words. If you already know this, skip to the heading ""next:"". There are three accessors that I'm aware of: 
```
public
```
, 
```
protected
```
 and 
```
private
```
. Let: 
```
class Base {
    public:
        int publicMember;
    protected:
        int protectedMember;
    private:
        int privateMember;
};

```
 Everything that is aware of 
```
Base
```
 is also aware that 
```
Base
```
 contains 
```
publicMember
```
. Only the children (and their children) are aware that 
```
Base
```
 contains 
```
protectedMember
```
. No one but 
```
Base
```
 is aware of 
```
privateMember
```
. By ""is aware of"", I mean ""acknowledge the existence of, and thus be able to access"". next: The same happens with public, private and protected inheritance. Let's consider a class 
```
Base
```
 and a class 
```
Child
```
 that inherits from 
```
Base
```
. If the inheritance is 
```
public
```
, everything that is aware of 
```
Base
```
 and 
```
Child
```
 is also aware that 
```
Child
```
 inherits from 
```
Base
```
. If the inheritance is 
```
protected
```
, only 
```
Child
```
, and its children, are aware that they inherit from 
```
Base
```
. If the inheritance is 
```
private
```
, no one other than 
```
Child
```
 is aware of the inheritance."
1433204,How do I use extern to share variables between source files?,https://stackoverflow.com/questions/1433204/how-do-i-use-extern-to-share-variables-between-source-files,19,,[],
146452,What are POD types in C++?,https://stackoverflow.com/questions/146452/what-are-pod-types-in-c,9,860.0,"[""POD stands for Plain Old Data - that is, a class (whether defined with the keyword \n```\nstruct\n```\n or the keyword \n```\nclass\n```\n) without constructors, destructors and virtual members functions. Wikipedia's article on POD goes into a bit more detail and defines it as: A Plain Old Data Structure in C++ is an aggregate class that contains only PODS as members, has no user-defined destructor, no user-defined copy assignment operator, and no nonstatic members of pointer-to-member type. Greater detail can be found in this answer for C++98/03. C++11 changed the rules surrounding POD, relaxing them greatly, thus necessitating a follow-up answer here.""]","POD stands for Plain Old Data - that is, a class (whether defined with the keyword 
```
struct
```
 or the keyword 
```
class
```
) without constructors, destructors and virtual members functions. Wikipedia's article on POD goes into a bit more detail and defines it as: A Plain Old Data Structure in C++ is an aggregate class that contains only PODS as members, has no user-defined destructor, no user-defined copy assignment operator, and no nonstatic members of pointer-to-member type. Greater detail can be found in this answer for C++98/03. C++11 changed the rules surrounding POD, relaxing them greatly, thus necessitating a follow-up answer here."
4303513,push_back vs emplace_back,https://stackoverflow.com/questions/4303513/push-back-vs-emplace-back,8,852.0,"[""In addition to what visitor said : The function \n```\nvoid emplace_back(Type&& _Val)\n```\n provided by MSCV10 is non-conforming and redundant because as you noted it is strictly equivalent to \n```\npush_back(Type&& _Val)\n```\n. But the real C++0x form of \n```\nemplace_back\n```\n is really useful: \n```\nvoid emplace_back(Args&&...)\n```\n; Instead of taking a \n```\nvalue_type\n```\n, it takes a variadic list of arguments, so that means that you can now perfectly forward the arguments and construct directly an object into a container without a temporary at all. That's useful because no matter how much cleverness RVO and move semantics bring to the table, there are still complicated cases where a \n```\npush_back\n```\n is likely to make unnecessary copies (or move). For example, with the traditional \n```\ninsert()\n```\n function of a \n```\nstd::map\n```\n, you have to create a temporary, which will then be copied into a \n```\nstd::pair<Key, Value>\n```\n, which will then be copied into the map : \n```"", '```\ninsert()\n```\n function of a \n```\nstd::map\n```\n, you have to create a temporary, which will then be copied into a \n```\nstd::pair<Key, Value>\n```\n, which will then be copied into the map : \n```\nstd::map<int, Complicated> m;\nint anInt = 4;\ndouble aDouble = 5.0;\nstd::string aString = ""C++"";\n    \n// cross your finger so that the optimizer is really good\nm.insert(std::make_pair(4, Complicated(anInt, aDouble, aString)));', '// should be easier for the optimizer\nm.emplace(4, anInt, aDouble, aString);', ""```\n So why didn't they implement the right version of \n```\nemplace_back\n```\n in MSVC? Actually, it bugged me too a while ago, so I asked the same question on the Visual C++ blog. Here is the answer from Stephan T Lavavej, the official maintainer of the Visual C++ standard library implementation at Microsoft. Q: Are beta 2 emplace functions just some kind of placeholder right now? A: As you may know, variadic templates aren't implemented in VC10. We simulate them with preprocessor machinery for things like \n```\nmake_shared<T>()\n```\n, tuple, and the new things in \n```\n<functional>\n```"", ""```\nmake_shared<T>()\n```\n, tuple, and the new things in \n```\n<functional>\n```\n. This preprocessor machinery is relatively difficult to use and maintain. Also, it significantly affects compilation speed, as we have to repeatedly include subheaders. Due to a combination of our time constraints and compilation speed concerns, we haven't simulated variadic templates in our emplace functions. When variadic templates are implemented in the compiler, you can expect that we'll take advantage of them in the libraries, including in our emplace functions. We take conformance very seriously, but unfortunately, we can't do everything all at once. It's an understandable decision. Everyone who tried just once to emulate variadic template with preprocessor horrible tricks knows how disgusting this stuff gets.""]","In addition to what visitor said : The function 
```
void emplace_back(Type&& _Val)
```
 provided by MSCV10 is non-conforming and redundant because as you noted it is strictly equivalent to 
```
push_back(Type&& _Val)
```
. But the real C++0x form of 
```
emplace_back
```
 is really useful: 
```
void emplace_back(Args&&...)
```
; Instead of taking a 
```
value_type
```
, it takes a variadic list of arguments, so that means that you can now perfectly forward the arguments and construct directly an object into a container without a temporary at all. That's useful because no matter how much cleverness RVO and move semantics bring to the table, there are still complicated cases where a 
```
push_back
```
 is likely to make unnecessary copies (or move). For example, with the traditional 
```
insert()
```
 function of a 
```
std::map
```
, you have to create a temporary, which will then be copied into a 
```
std::pair<Key, Value>
```
, which will then be copied into the map : 
```
std::map<int, Complicated> m;
int anInt = 4;
double aDouble = 5.0;
std::string aString = ""C++"";
    
// cross your finger so that the optimizer is really good
m.insert(std::make_pair(4, Complicated(anInt, aDouble, aString))); 

// should be easier for the optimizer
m.emplace(4, anInt, aDouble, aString);

```
 So why didn't they implement the right version of 
```
emplace_back
```
 in MSVC? Actually, it bugged me too a while ago, so I asked the same question on the Visual C++ blog. Here is the answer from Stephan T Lavavej, the official maintainer of the Visual C++ standard library implementation at Microsoft. Q: Are beta 2 emplace functions just some kind of placeholder right now? A: As you may know, variadic templates aren't implemented in VC10. We simulate them with preprocessor machinery for things like 
```
make_shared<T>()
```
, tuple, and the new things in 
```
<functional>
```
. This preprocessor machinery is relatively difficult to use and maintain. Also, it significantly affects compilation speed, as we have to repeatedly include subheaders. Due to a combination of our time constraints and compilation speed concerns, we haven't simulated variadic templates in our emplace functions. When variadic templates are implemented in the compiler, you can expect that we'll take advantage of them in the libraries, including in our emplace functions. We take conformance very seriously, but unfortunately, we can't do everything all at once. It's an understandable decision. Everyone who tried just once to emulate variadic template with preprocessor horrible tricks knows how disgusting this stuff gets."
172587,What is the difference between g++ and gcc?,https://stackoverflow.com/questions/172587/what-is-the-difference-between-g-and-gcc,11,947.0,"[""```\ngcc\n```\n and \n```\ng++\n```\n are compiler-drivers of the GNU Compiler Collection (which was once upon a time just the GNU C Compiler). Even though they automatically determine which backends (\n```\ncc1\n```\n \n```\ncc1plus\n```\n ...) to call depending on the file-type, unless overridden with \n```\n-x language\n```\n, they have some differences. The probably most important difference in their defaults is which libraries they link against automatically. According to GCC's online documentation link options and how g++ is invoked, \n```\ng++\n```\n is roughly equivalent to \n```\ngcc -xc++ -lstdc++ -shared-libgcc\n```\n (the 1st is a compiler option, the 2nd two are linker options). This can be checked by running both with the \n```\n-v\n```\n option (it displays the backend toolchain commands being run). By default (and unlike \n```\ngcc\n```\n), g++ also adds linker option \n```\n-lm\n```\n -- to link against \n```\nlibm\n```\n which contains implementations for \n```\nmath.h\n```\n.""]","
```
gcc
```
 and 
```
g++
```
 are compiler-drivers of the GNU Compiler Collection (which was once upon a time just the GNU C Compiler). Even though they automatically determine which backends (
```
cc1
```
 
```
cc1plus
```
 ...) to call depending on the file-type, unless overridden with 
```
-x language
```
, they have some differences. The probably most important difference in their defaults is which libraries they link against automatically. According to GCC's online documentation link options and how g++ is invoked, 
```
g++
```
 is roughly equivalent to 
```
gcc -xc++ -lstdc++ -shared-libgcc
```
 (the 1st is a compiler option, the 2nd two are linker options). This can be checked by running both with the 
```
-v
```
 option (it displays the backend toolchain commands being run). By default (and unlike 
```
gcc
```
), g++ also adds linker option 
```
-lm
```
 -- to link against 
```
libm
```
 which contains implementations for 
```
math.h
```
."
6441218,Can a local variable's memory be accessed outside its scope?,https://stackoverflow.com/questions/6441218/can-a-local-variables-memory-be-accessed-outside-its-scope,21,5020.0,"['How can it be? Isn\'t the memory of a local variable inaccessible outside its function? You rent a hotel room. You put a book in the top drawer of the bedside table and go to sleep. You check out the next morning, but ""forget"" to give back your key. You steal the key! A week later, you return to the hotel, do not check in, sneak into your old room with your stolen key, and look in the drawer. Your book is still there. Astonishing! How can that be? Aren\'t the contents of a hotel room drawer inaccessible if you haven\'t rented the room? Well, obviously that scenario can happen in the real world no problem. There is no mysterious force that causes your book to disappear when you are no longer authorized to be in the room. Nor is there a mysterious force that prevents you from entering a room with a stolen key. The hotel management is not required to remove your book. You didn\'t make a contract with them that said that if you leave stuff behind, they\'ll shred it for you. If you illegally', 'with a stolen key. The hotel management is not required to remove your book. You didn\'t make a contract with them that said that if you leave stuff behind, they\'ll shred it for you. If you illegally re-enter your room with a stolen key to get it back, the hotel security staff is not required to catch you sneaking in. You didn\'t make a contract with them that said ""if I try to sneak back into my room later, you are required to stop me."" Rather, you signed a contract with them that said ""I promise not to sneak back into my room later"", a contract which you broke. In this situation anything can happen. The book can be there—you got lucky. Someone else\'s book can be there and yours could be in the hotel\'s furnace. Someone could be there right when you come in, tearing your book to pieces. The hotel could have removed the table and book entirely and replaced it with a wardrobe. The entire hotel could be just about to be torn down and replaced with a football stadium, and you are going to', ""hotel could have removed the table and book entirely and replaced it with a wardrobe. The entire hotel could be just about to be torn down and replaced with a football stadium, and you are going to die in an explosion while you are sneaking around. You don't know what is going to happen; when you checked out of the hotel and stole a key to illegally use later, you gave up the right to live in a predictable, safe world because you chose to break the rules of the system. C++ is not a safe language. It will cheerfully allow you to break the rules of the system. If you try to do something illegal and foolish like going back into a room you're not authorized to be in and rummaging through a desk that might not even be there anymore, C++ is not going to stop you. Safer languages than C++ solve this problem by restricting your power—by having much stricter control over keys, for example. Compilers are in the business of generating code which manages the storage of the data manipulated by"", 'this problem by restricting your power—by having much stricter control over keys, for example. Compilers are in the business of generating code which manages the storage of the data manipulated by that program. There are lots of different ways of generating code to manage memory, but over time two basic techniques have become entrenched. The first is to have some sort of ""long lived"" storage area where the ""lifetime"" of each byte in the storage—that is, the period of time when it is validly associated with some program variable—cannot be easily predicted ahead of time. The compiler generates calls into a ""heap manager"" that knows how to dynamically allocate storage when it is needed and reclaim it when it is no longer needed. The second method is to have a “short-lived” storage area where the lifetime of each byte is well known. Here, the lifetimes follow a “nesting” pattern. The longest-lived of these short-lived variables will be allocated before any other short-lived variables, and', 'the lifetime of each byte is well known. Here, the lifetimes follow a “nesting” pattern. The longest-lived of these short-lived variables will be allocated before any other short-lived variables, and will be freed last. Shorter-lived variables will be allocated after the longest-lived ones, and will be freed before them. The lifetime of these shorter-lived variables is “nested” within the lifetime of longer-lived ones. Local variables follow the latter pattern; when a method is entered, its local variables come alive. When that method calls another method, the new method\'s local variables come alive. They\'ll be dead before the first method\'s local variables are dead. The relative order of the beginnings and endings of lifetimes of storages associated with local variables can be worked out ahead of time. For this reason, local variables are usually generated as storage on a ""stack"" data structure, because a stack has the property that the first thing pushed on it is going to be the', 'out ahead of time. For this reason, local variables are usually generated as storage on a ""stack"" data structure, because a stack has the property that the first thing pushed on it is going to be the last thing popped off. It\'s like the hotel decides to only rent out rooms sequentially, and you can\'t check out until everyone with a room number higher than you has checked out. So let\'s think about the stack. In many operating systems you get one stack per thread and the stack is allocated to be a certain fixed size. When you call a method, stuff is pushed onto the stack. If you then pass a pointer to the stack back out of your method, as the original poster does here, that\'s just a pointer to the middle of some entirely valid million-byte memory block. In our analogy, you check out of the hotel; when you do, you just checked out of the highest-numbered occupied room. If no one else checks in after you, and you go back to your room illegally, all your stuff is guaranteed to still be', 'hotel; when you do, you just checked out of the highest-numbered occupied room. If no one else checks in after you, and you go back to your room illegally, all your stuff is guaranteed to still be there in this particular hotel. We use stacks for temporary stores because they are really cheap and easy. An implementation of C++ is not required to use a stack for storage of locals; it could use the heap. It doesn\'t, because that would make the program slower. An implementation of C++ is not required to leave the garbage you left on the stack untouched so that you can come back for it later illegally; it is perfectly legal for the compiler to generate code that turns back to zero everything in the ""room"" that you just vacated. It doesn\'t because again, that would be expensive. An implementation of C++ is not required to ensure that when the stack logically shrinks, the addresses that used to be valid are still mapped into memory. The implementation is allowed to tell the operating system', 'of C++ is not required to ensure that when the stack logically shrinks, the addresses that used to be valid are still mapped into memory. The implementation is allowed to tell the operating system ""we\'re done using this page of stack now. Until I say otherwise, issue an exception that destroys the process if anyone touches the previously-valid stack page"". Again, implementations do not actually do that because it is slow and unnecessary. Instead, implementations let you make mistakes and get away with it. Most of the time. Until one day something truly awful goes wrong and the process explodes. This is problematic. There are a lot of rules and it is very easy to break them accidentally. I certainly have many times. And worse, the problem often only surfaces when memory is detected to be corrupt billions of nanoseconds after the corruption happened, when it is very hard to figure out who messed it up. More memory-safe languages solve this problem by restricting your power. In ""normal""', 'billions of nanoseconds after the corruption happened, when it is very hard to figure out who messed it up. More memory-safe languages solve this problem by restricting your power. In ""normal"" C# there simply is no way to take the address of a local and return it or store it for later. You can take the address of a local, but the language is cleverly designed so that it is impossible to use it after the lifetime of the local ends. In order to take the address of a local and pass it back, you have to put the compiler in a special ""unsafe"" mode, and put the word ""unsafe"" in your program, to call attention to the fact that you are probably doing something dangerous that could be breaking the rules. For further reading: What if C# did allow returning references? Coincidentally that is the subject of today\'s blog post: Ref returns and ref locals Why do we use stacks to manage memory? Are value types in C# always stored on the stack? How does virtual memory work? And many more topics in how', ""of today's blog post: Ref returns and ref locals Why do we use stacks to manage memory? Are value types in C# always stored on the stack? How does virtual memory work? And many more topics in how the C# memory manager works. Many of these articles are also germane to C++ programmers: Memory management""]","How can it be? Isn't the memory of a local variable inaccessible outside its function? You rent a hotel room. You put a book in the top drawer of the bedside table and go to sleep. You check out the next morning, but ""forget"" to give back your key. You steal the key! A week later, you return to the hotel, do not check in, sneak into your old room with your stolen key, and look in the drawer. Your book is still there. Astonishing! How can that be? Aren't the contents of a hotel room drawer inaccessible if you haven't rented the room? Well, obviously that scenario can happen in the real world no problem. There is no mysterious force that causes your book to disappear when you are no longer authorized to be in the room. Nor is there a mysterious force that prevents you from entering a room with a stolen key. The hotel management is not required to remove your book. You didn't make a contract with them that said that if you leave stuff behind, they'll shred it for you. If you illegally re-enter your room with a stolen key to get it back, the hotel security staff is not required to catch you sneaking in. You didn't make a contract with them that said ""if I try to sneak back into my room later, you are required to stop me."" Rather, you signed a contract with them that said ""I promise not to sneak back into my room later"", a contract which you broke. In this situation anything can happen. The book can be there—you got lucky. Someone else's book can be there and yours could be in the hotel's furnace. Someone could be there right when you come in, tearing your book to pieces. The hotel could have removed the table and book entirely and replaced it with a wardrobe. The entire hotel could be just about to be torn down and replaced with a football stadium, and you are going to die in an explosion while you are sneaking around. You don't know what is going to happen; when you checked out of the hotel and stole a key to illegally use later, you gave up the right to live in a predictable, safe world because you chose to break the rules of the system. C++ is not a safe language. It will cheerfully allow you to break the rules of the system. If you try to do something illegal and foolish like going back into a room you're not authorized to be in and rummaging through a desk that might not even be there anymore, C++ is not going to stop you. Safer languages than C++ solve this problem by restricting your power—by having much stricter control over keys, for example. Compilers are in the business of generating code which manages the storage of the data manipulated by that program. There are lots of different ways of generating code to manage memory, but over time two basic techniques have become entrenched. The first is to have some sort of ""long lived"" storage area where the ""lifetime"" of each byte in the storage—that is, the period of time when it is validly associated with some program variable—cannot be easily predicted ahead of time. The compiler generates calls into a ""heap manager"" that knows how to dynamically allocate storage when it is needed and reclaim it when it is no longer needed. The second method is to have a “short-lived” storage area where the lifetime of each byte is well known. Here, the lifetimes follow a “nesting” pattern. The longest-lived of these short-lived variables will be allocated before any other short-lived variables, and will be freed last. Shorter-lived variables will be allocated after the longest-lived ones, and will be freed before them. The lifetime of these shorter-lived variables is “nested” within the lifetime of longer-lived ones. Local variables follow the latter pattern; when a method is entered, its local variables come alive. When that method calls another method, the new method's local variables come alive. They'll be dead before the first method's local variables are dead. The relative order of the beginnings and endings of lifetimes of storages associated with local variables can be worked out ahead of time. For this reason, local variables are usually generated as storage on a ""stack"" data structure, because a stack has the property that the first thing pushed on it is going to be the last thing popped off. It's like the hotel decides to only rent out rooms sequentially, and you can't check out until everyone with a room number higher than you has checked out. So let's think about the stack. In many operating systems you get one stack per thread and the stack is allocated to be a certain fixed size. When you call a method, stuff is pushed onto the stack. If you then pass a pointer to the stack back out of your method, as the original poster does here, that's just a pointer to the middle of some entirely valid million-byte memory block. In our analogy, you check out of the hotel; when you do, you just checked out of the highest-numbered occupied room. If no one else checks in after you, and you go back to your room illegally, all your stuff is guaranteed to still be there in this particular hotel. We use stacks for temporary stores because they are really cheap and easy. An implementation of C++ is not required to use a stack for storage of locals; it could use the heap. It doesn't, because that would make the program slower. An implementation of C++ is not required to leave the garbage you left on the stack untouched so that you can come back for it later illegally; it is perfectly legal for the compiler to generate code that turns back to zero everything in the ""room"" that you just vacated. It doesn't because again, that would be expensive. An implementation of C++ is not required to ensure that when the stack logically shrinks, the addresses that used to be valid are still mapped into memory. The implementation is allowed to tell the operating system ""we're done using this page of stack now. Until I say otherwise, issue an exception that destroys the process if anyone touches the previously-valid stack page"". Again, implementations do not actually do that because it is slow and unnecessary. Instead, implementations let you make mistakes and get away with it. Most of the time. Until one day something truly awful goes wrong and the process explodes. This is problematic. There are a lot of rules and it is very easy to break them accidentally. I certainly have many times. And worse, the problem often only surfaces when memory is detected to be corrupt billions of nanoseconds after the corruption happened, when it is very hard to figure out who messed it up. More memory-safe languages solve this problem by restricting your power. In ""normal"" C# there simply is no way to take the address of a local and return it or store it for later. You can take the address of a local, but the language is cleverly designed so that it is impossible to use it after the lifetime of the local ends. In order to take the address of a local and pass it back, you have to put the compiler in a special ""unsafe"" mode, and put the word ""unsafe"" in your program, to call attention to the fact that you are probably doing something dangerous that could be breaking the rules. For further reading: What if C# did allow returning references? Coincidentally that is the subject of today's blog post: Ref returns and ref locals Why do we use stacks to manage memory? Are value types in C# always stored on the stack? How does virtual memory work? And many more topics in how the C# memory manager works. Many of these articles are also germane to C++ programmers: Memory management"
3413470,"What is std::move(), and when should it be used?",https://stackoverflow.com/questions/3413470/what-is-stdmove-and-when-should-it-be-used,9,432.0,"['Wikipedia Page on C++11 R-value references and move constructors In C++11, in addition to copy constructors, objects can have move constructors. (And in addition to copy assignment operators, they have move assignment operators.) The move constructor is used instead of the copy constructor, if the object has type ""rvalue-reference"" (\n```\nType &&\n```\n). \n```\nstd::move()\n```\n is a cast that produces an rvalue-reference to an object, to enable moving from it. It\'s a new C++ way to avoid copies. For example, using a move constructor, a \n```\nstd::vector\n```\n could just copy its internal pointer to data to the new object, leaving the moved object in an moved from state, therefore not copying all the data. This would be C++-valid. Try googling for move semantics, rvalue, perfect forwarding.']","Wikipedia Page on C++11 R-value references and move constructors In C++11, in addition to copy constructors, objects can have move constructors. (And in addition to copy assignment operators, they have move assignment operators.) The move constructor is used instead of the copy constructor, if the object has type ""rvalue-reference"" (
```
Type &&
```
). 
```
std::move()
```
 is a cast that produces an rvalue-reference to an object, to enable moving from it. It's a new C++ way to avoid copies. For example, using a move constructor, a 
```
std::vector
```
 could just copy its internal pointer to data to the new object, leaving the moved object in an moved from state, therefore not copying all the data. This would be C++-valid. Try googling for move semantics, rvalue, perfect forwarding."
308276,Can I call a constructor from another constructor (do constructor chaining) in C++?,https://stackoverflow.com/questions/308276/can-i-call-a-constructor-from-another-constructor-do-constructor-chaining-in-c,15,1537.0,"[""C++11: Yes! C++11 and onwards has this same feature (called delegating constructors). The syntax is slightly different from C#: \n```\nclass Foo {\npublic: \n  Foo(char x, int y) {}\n  Foo(int y) : Foo('a', y) {}\n};\n\n```\n C++03: No Unfortunately, there's no way to do this in C++03, but there are two ways of simulating this: You can combine two (or more) constructors via default parameters: \n```\nclass Foo {\npublic:\n  Foo(char x, int y=0);  // combines two constructors (char) and (char, int)\n  // ...\n};\n\n```\n Use an init method to share common code: \n```\nclass Foo {\npublic:\n  Foo(char x);\n  Foo(char x, int y);\n  // ...\nprivate:\n  void init(char x, int y);\n};\n\nFoo::Foo(char x)\n{\n  init(x, int(x) + 7);\n  // ...\n}\n\nFoo::Foo(char x, int y)\n{\n  init(x, y);\n  // ...\n}\n\nvoid Foo::init(char x, int y)\n{\n  // ...\n}\n\n```\n See the C++FAQ entry for reference.""]","C++11: Yes! C++11 and onwards has this same feature (called delegating constructors). The syntax is slightly different from C#: 
```
class Foo {
public: 
  Foo(char x, int y) {}
  Foo(int y) : Foo('a', y) {}
};

```
 C++03: No Unfortunately, there's no way to do this in C++03, but there are two ways of simulating this: You can combine two (or more) constructors via default parameters: 
```
class Foo {
public:
  Foo(char x, int y=0);  // combines two constructors (char) and (char, int)
  // ...
};

```
 Use an init method to share common code: 
```
class Foo {
public:
  Foo(char x);
  Foo(char x, int y);
  // ...
private:
  void init(char x, int y);
};

Foo::Foo(char x)
{
  init(x, int(x) + 7);
  // ...
}

Foo::Foo(char x, int y)
{
  init(x, y);
  // ...
}

void Foo::init(char x, int y)
{
  // ...
}

```
 See the C++FAQ entry for reference."
92396,Why can't variables be declared in a switch statement?,https://stackoverflow.com/questions/92396/why-cant-variables-be-declared-in-a-switch-statement,23,1360.0,"['```\nCase\n```\n statements are only labels. This means the compiler will interpret this as a jump directly to the label. In C++, the problem here is one of scope. Your curly brackets define the scope as everything inside the \n```\nswitch\n```\n statement. This means that you are left with a scope where a jump will be performed further into the code skipping the initialization. The correct way to handle this is to define a scope specific to that \n```\ncase\n```\n statement and define your variable within it: \n```\nswitch (val)\n{   \ncase VAL:  \n{\n  // This will work\n  int newVal = 42;  \n  break;\n}\ncase ANOTHER_VAL:  \n...\nbreak;\n}\n\n```']","
```
Case
```
 statements are only labels. This means the compiler will interpret this as a jump directly to the label. In C++, the problem here is one of scope. Your curly brackets define the scope as everything inside the 
```
switch
```
 statement. This means that you are left with a scope where a jump will be performed further into the code skipping the initialization. The correct way to handle this is to define a scope specific to that 
```
case
```
 statement and define your variable within it: 
```
switch (val)
{   
case VAL:  
{
  // This will work
  int newVal = 42;  
  break;
}
case ANOTHER_VAL:  
...
break;
}

```
"
620137,Do the parentheses after the type name make a difference with new?,https://stackoverflow.com/questions/620137/do-the-parentheses-after-the-type-name-make-a-difference-with-new,8,1039.0,"[""Let's get pedantic, because there are differences that can actually affect your code's behavior. Much of the following is taken from comments made to an Old New Thing article Sometimes the memory returned by the new operator will be initialized, and sometimes it won't depending on whether the type you're newing up is a POD (plain old data), or if it's a class that contains POD members and is using a compiler-generated default constructor. In C++1998 there are 2 types of initialization: zero and default In C++2003 a 3rd type of initialization, value initialization was added. Assume: \n```\nstruct A { int m; }; // POD\nstruct B { ~B(); int m; }; // non-POD, compiler generated default ctor\nstruct C { C() : m() {}; ~C(); int m; }; // non-POD, default-initialising m"", ""```\n In a C++98 compiler, the following should occur: \n```\nnew A\n```\n - indeterminate value \n```\nnew A()\n```\n - zero-initialize \n```\nnew B\n```\n - default construct (B::m is uninitialized) \n```\nnew B()\n```\n - default construct (B::m is uninitialized) \n```\nnew C\n```\n - default construct (C::m is zero-initialized) \n```\nnew C()\n```\n - default construct (C::m is zero-initialized) In a C++03 conformant compiler, things should work like so: \n```\nnew A\n```\n - indeterminate value \n```\nnew A()\n```\n - value-initialize A, which is zero-initialization since it's a POD. \n```\nnew B\n```\n - default-initializes (leaves B::m uninitialized) \n```\nnew B()\n```\n - value-initializes B which zero-initializes all fields since its default ctor is compiler generated as opposed to user-defined. \n```\nnew C\n```\n - default-initializes C, which calls the default ctor. \n```\nnew C()\n```\n - value-initializes C, which calls the default ctor. So in all versions of C++ there's a difference between \n```\nnew A\n```\n and \n```"", ""```\nnew C()\n```\n - value-initializes C, which calls the default ctor. So in all versions of C++ there's a difference between \n```\nnew A\n```\n and \n```\nnew A()\n```\n because A is a POD. And there's a difference in behavior between C++98 and C++03 for the case \n```\nnew B()\n```\n. This is one of the dusty corners of C++ that can drive you crazy. When constructing an object, sometimes you want/need the parens, sometimes you absolutely cannot have them, and sometimes it doesn't matter.""]","Let's get pedantic, because there are differences that can actually affect your code's behavior. Much of the following is taken from comments made to an Old New Thing article Sometimes the memory returned by the new operator will be initialized, and sometimes it won't depending on whether the type you're newing up is a POD (plain old data), or if it's a class that contains POD members and is using a compiler-generated default constructor. In C++1998 there are 2 types of initialization: zero and default In C++2003 a 3rd type of initialization, value initialization was added. Assume: 
```
struct A { int m; }; // POD
struct B { ~B(); int m; }; // non-POD, compiler generated default ctor
struct C { C() : m() {}; ~C(); int m; }; // non-POD, default-initialising m

```
 In a C++98 compiler, the following should occur: 
```
new A
```
 - indeterminate value 
```
new A()
```
 - zero-initialize 
```
new B
```
 - default construct (B::m is uninitialized) 
```
new B()
```
 - default construct (B::m is uninitialized) 
```
new C
```
 - default construct (C::m is zero-initialized) 
```
new C()
```
 - default construct (C::m is zero-initialized) In a C++03 conformant compiler, things should work like so: 
```
new A
```
 - indeterminate value 
```
new A()
```
 - value-initialize A, which is zero-initialization since it's a POD. 
```
new B
```
 - default-initializes (leaves B::m uninitialized) 
```
new B()
```
 - value-initializes B which zero-initializes all fields since its default ctor is compiler generated as opposed to user-defined. 
```
new C
```
 - default-initializes C, which calls the default ctor. 
```
new C()
```
 - value-initializes C, which calls the default ctor. So in all versions of C++ there's a difference between 
```
new A
```
 and 
```
new A()
```
 because A is a POD. And there's a difference in behavior between C++98 and C++03 for the case 
```
new B()
```
. This is one of the dusty corners of C++ that can drive you crazy. When constructing an object, sometimes you want/need the parens, sometimes you absolutely cannot have them, and sometimes it doesn't matter."
5481539,What does T&& (double ampersand) mean in C++11?,https://stackoverflow.com/questions/5481539/what-does-t-double-ampersand-mean-in-c11,4,872.0,"['It declares an rvalue reference (standards proposal doc). Here\'s an introduction to rvalue references. Here\'s a fantastic in-depth look at rvalue references by one of Microsoft\'s standard library developers. CAUTION: the linked article on MSDN (""Rvalue References: C++0x Features in VC10, Part 2"") is a very clear introduction to Rvalue references, but makes statements about Rvalue references that were once true in the draft C++11 standard, but are not true for the final one! Specifically, it says at various points that rvalue references can bind to lvalues, which was once true, but was changed.(e.g. int x; int &&rrx = x; no longer compiles in GCC) – drewbarbs Jul 13 \'14 at 16:12 The biggest difference between a C++03 reference (now called an lvalue reference in C++11) is that it can bind to an rvalue like a temporary without having to be const. Thus, this syntax is now legal: \n```\nT&& r = T();', '```\n rvalue references primarily provide for the following: Move semantics. A move constructor and move assignment operator can now be defined that takes an rvalue reference instead of the usual const-lvalue reference. A move functions like a copy, except it is not obliged to keep the source unchanged; in fact, it usually modifies the source such that it no longer owns the moved resources. This is great for eliminating extraneous copies, especially in standard library implementations. For example, a copy constructor might look like this: \n```\nfoo(foo const& other)\n{\n    this->length = other.length;\n    this->ptr = new int[other.length];\n    copy(other.ptr, other.ptr + other.length, this->ptr);\n}', ""```\n If this constructor were passed a temporary, the copy would be unnecessary because we know the temporary will just be destroyed; why not make use of the resources the temporary already allocated? In C++03, there's no way to prevent the copy as we cannot determine whether we were passed a temporary. In C++11, we can overload a move constructor: \n```\nfoo(foo&& other)\n{\n   this->length = other.length;\n   this->ptr = other.ptr;\n   other.length = 0;\n   other.ptr = nullptr;\n}"", '```\n Notice the big difference here: the move constructor actually modifies its argument. This would effectively ""move"" the temporary into the object being constructed, thereby eliminating the unnecessary copy. The move constructor would be used for temporaries and for non-const lvalue references that are explicitly converted to rvalue references using the \n```\nstd::move\n```\n function (it just performs the conversion). The following code both invoke the move constructor for \n```\nf1\n```\n and \n```\nf2\n```\n: \n```\nfoo f1((foo())); // Move a temporary into f1; temporary becomes ""empty""\nfoo f2 = std::move(f1); // Move f1 into f2; f1 is now ""empty""\n\n```\n Perfect forwarding. rvalue references allow us to properly forward arguments for templated functions. Take for example this factory function: \n```\ntemplate <typename T, typename A1>\nstd::unique_ptr<T> factory(A1& a1)\n{\n    return std::unique_ptr<T>(new T(a1));\n}', ""```\n If we called \n```\nfactory<foo>(5)\n```\n, the argument will be deduced to be \n```\nint&\n```\n, which will not bind to a literal 5, even if \n```\nfoo\n```\n's constructor takes an \n```\nint\n```\n. Well, we could instead use \n```\nA1 const&\n```\n, but what if \n```\nfoo\n```\n takes the constructor argument by non-const reference? To make a truly generic factory function, we would have to overload factory on \n```\nA1&\n```\n and on \n```\nA1 const&\n```\n. That might be fine if factory takes 1 parameter type, but each additional parameter type would multiply the necessary overload set by 2. That's very quickly unmaintainable. rvalue references fix this problem by allowing the standard library to define a \n```\nstd::forward\n```\n function that can properly forward lvalue/rvalue references. For more information about how \n```\nstd::forward\n```\n works, see this excellent answer. This enables us to define the factory function like this: \n```\ntemplate <typename T, typename A1>"", '```\nstd::forward\n```\n works, see this excellent answer. This enables us to define the factory function like this: \n```\ntemplate <typename T, typename A1>\nstd::unique_ptr<T> factory(A1&& a1)\n{\n    return std::unique_ptr<T>(new T(std::forward<A1>(a1)));\n}', ""```\n Now the argument's rvalue/lvalue-ness is preserved when passed to \n```\nT\n```\n's constructor. That means that if factory is called with an rvalue, \n```\nT\n```\n's constructor is called with an rvalue. If factory is called with an lvalue, \n```\nT\n```\n's constructor is called with an lvalue. The improved factory function works because of one special rule: When the function parameter type is of the form \n```\nT&&\n```\n where \n```\nT\n```\n is a template parameter, and the function argument is an lvalue of type \n```\nA\n```\n, the type \n```\nA&\n```\n is used for template argument deduction. Thus, we can use factory like so: \n```\nauto p1 = factory<foo>(foo()); // calls foo(foo&&)\nauto p2 = factory<foo>(*p1);   // calls foo(foo const&)"", '```\n Important rvalue reference properties: For overload resolution, lvalues prefer binding to lvalue references and rvalues prefer binding to rvalue references. Hence why temporaries prefer invoking a move constructor / move assignment operator over a copy constructor / assignment operator. rvalue references will implicitly bind to rvalues and to temporaries that are the result of an implicit conversion. i.e. \n```\nfloat f = 0f; int&& i = f;\n```\n is well formed because float is implicitly convertible to int; the reference would be to a temporary that is the result of the conversion. Named rvalue references are lvalues. Unnamed rvalue references are rvalues. This is important to understand why the \n```\nstd::move\n```\n call is necessary in: \n```\nfoo&& r = foo(); foo f = std::move(r);\n```']","It declares an rvalue reference (standards proposal doc). Here's an introduction to rvalue references. Here's a fantastic in-depth look at rvalue references by one of Microsoft's standard library developers. CAUTION: the linked article on MSDN (""Rvalue References: C++0x Features in VC10, Part 2"") is a very clear introduction to Rvalue references, but makes statements about Rvalue references that were once true in the draft C++11 standard, but are not true for the final one! Specifically, it says at various points that rvalue references can bind to lvalues, which was once true, but was changed.(e.g. int x; int &&rrx = x; no longer compiles in GCC) – drewbarbs Jul 13 '14 at 16:12 The biggest difference between a C++03 reference (now called an lvalue reference in C++11) is that it can bind to an rvalue like a temporary without having to be const. Thus, this syntax is now legal: 
```
T&& r = T();

```
 rvalue references primarily provide for the following: Move semantics. A move constructor and move assignment operator can now be defined that takes an rvalue reference instead of the usual const-lvalue reference. A move functions like a copy, except it is not obliged to keep the source unchanged; in fact, it usually modifies the source such that it no longer owns the moved resources. This is great for eliminating extraneous copies, especially in standard library implementations. For example, a copy constructor might look like this: 
```
foo(foo const& other)
{
    this->length = other.length;
    this->ptr = new int[other.length];
    copy(other.ptr, other.ptr + other.length, this->ptr);
}

```
 If this constructor were passed a temporary, the copy would be unnecessary because we know the temporary will just be destroyed; why not make use of the resources the temporary already allocated? In C++03, there's no way to prevent the copy as we cannot determine whether we were passed a temporary. In C++11, we can overload a move constructor: 
```
foo(foo&& other)
{
   this->length = other.length;
   this->ptr = other.ptr;
   other.length = 0;
   other.ptr = nullptr;
}

```
 Notice the big difference here: the move constructor actually modifies its argument. This would effectively ""move"" the temporary into the object being constructed, thereby eliminating the unnecessary copy. The move constructor would be used for temporaries and for non-const lvalue references that are explicitly converted to rvalue references using the 
```
std::move
```
 function (it just performs the conversion). The following code both invoke the move constructor for 
```
f1
```
 and 
```
f2
```
: 
```
foo f1((foo())); // Move a temporary into f1; temporary becomes ""empty""
foo f2 = std::move(f1); // Move f1 into f2; f1 is now ""empty""

```
 Perfect forwarding. rvalue references allow us to properly forward arguments for templated functions. Take for example this factory function: 
```
template <typename T, typename A1>
std::unique_ptr<T> factory(A1& a1)
{
    return std::unique_ptr<T>(new T(a1));
}

```
 If we called 
```
factory<foo>(5)
```
, the argument will be deduced to be 
```
int&
```
, which will not bind to a literal 5, even if 
```
foo
```
's constructor takes an 
```
int
```
. Well, we could instead use 
```
A1 const&
```
, but what if 
```
foo
```
 takes the constructor argument by non-const reference? To make a truly generic factory function, we would have to overload factory on 
```
A1&
```
 and on 
```
A1 const&
```
. That might be fine if factory takes 1 parameter type, but each additional parameter type would multiply the necessary overload set by 2. That's very quickly unmaintainable. rvalue references fix this problem by allowing the standard library to define a 
```
std::forward
```
 function that can properly forward lvalue/rvalue references. For more information about how 
```
std::forward
```
 works, see this excellent answer. This enables us to define the factory function like this: 
```
template <typename T, typename A1>
std::unique_ptr<T> factory(A1&& a1)
{
    return std::unique_ptr<T>(new T(std::forward<A1>(a1)));
}

```
 Now the argument's rvalue/lvalue-ness is preserved when passed to 
```
T
```
's constructor. That means that if factory is called with an rvalue, 
```
T
```
's constructor is called with an rvalue. If factory is called with an lvalue, 
```
T
```
's constructor is called with an lvalue. The improved factory function works because of one special rule: When the function parameter type is of the form 
```
T&&
```
 where 
```
T
```
 is a template parameter, and the function argument is an lvalue of type 
```
A
```
, the type 
```
A&
```
 is used for template argument deduction. Thus, we can use factory like so: 
```
auto p1 = factory<foo>(foo()); // calls foo(foo&&)
auto p2 = factory<foo>(*p1);   // calls foo(foo const&)

```
 Important rvalue reference properties: For overload resolution, lvalues prefer binding to lvalue references and rvalues prefer binding to rvalue references. Hence why temporaries prefer invoking a move constructor / move assignment operator over a copy constructor / assignment operator. rvalue references will implicitly bind to rvalues and to temporaries that are the result of an implicit conversion. i.e. 
```
float f = 0f; int&& i = f;
```
 is well formed because float is implicitly convertible to int; the reference would be to a temporary that is the result of the conversion. Named rvalue references are lvalues. Unnamed rvalue references are rvalues. This is important to understand why the 
```
std::move
```
 call is necessary in: 
```
foo&& r = foo(); foo f = std::move(r);
```
"
347949,How to convert a std::string to const char* or char*,https://stackoverflow.com/questions/347949/how-to-convert-a-stdstring-to-const-char-or-char,11,1295.0,"[""If you just want to pass a \n```\nstd::string\n```\n to a function that needs \n```\nconst char *\n```\n, you can use \n```\n.c_str()\n```\n: \n```\nstd::string str;\nconst char * c = str.c_str();\n\n```\n And if you need a non-const \n```\nchar *\n```\n, call \n```\n.data()\n```\n: \n```\nstd::string str;\nchar * c = str.data();\n\n```\n \n```\n.data()\n```\n was added in C++17. Before that, you can use \n```\n&str[0]\n```\n. Note that if the \n```\nstd::string\n```\n is \n```\nconst\n```\n, \n```\n.data()\n```\n will return \n```\nconst char *\n```\n instead, like \n```\n.c_str()\n```\n. The pointer becomes invalid if the string is destroyed or reallocates memory. The pointer points to a null-terminated string, and the terminator doesn't count against \n```\nstr.size()\n```\n. You're not allowed to assign a non-null character to the terminator.""]","If you just want to pass a 
```
std::string
```
 to a function that needs 
```
const char *
```
, you can use 
```
.c_str()
```
: 
```
std::string str;
const char * c = str.c_str();

```
 And if you need a non-const 
```
char *
```
, call 
```
.data()
```
: 
```
std::string str;
char * c = str.data();

```
 
```
.data()
```
 was added in C++17. Before that, you can use 
```
&str[0]
```
. Note that if the 
```
std::string
```
 is 
```
const
```
, 
```
.data()
```
 will return 
```
const char *
```
 instead, like 
```
.c_str()
```
. The pointer becomes invalid if the string is destroyed or reallocates memory. The pointer points to a null-terminated string, and the terminator doesn't count against 
```
str.size()
```
. You're not allowed to assign a non-null character to the terminator."
356950,What are C++ functors and their uses?,https://stackoverflow.com/questions/356950/what-are-c-functors-and-their-uses,14,1230.0,"['A functor is pretty much just a class which defines the \n```\noperator()\n```\n. That lets you create objects which ""look like"" a function: \n```\n// this is a functor\nstruct add_x {\n  add_x(int val) : x(val) {}  // Constructor\n  int operator()(int y) const { return x + y; }\n\nprivate:\n  int x;\n};\n\n// Now you can use it like this:\nadd_x add42(42); // create an instance of the functor class\nint i = add42(8); // and ""call"" it\nassert(i == 50); // and it added 42 to its argument\n\nstd::vector<int> in; // assume this contains a bunch of values)\nstd::vector<int> out(in.size());\n// Pass a functor to std::transform, which calls the functor on every element \n// in the input sequence, and stores the result to the output sequence\nstd::transform(in.begin(), in.end(), out.begin(), add_x(1)); \nassert(out[i] == in[i] + 1); // for all i', '```', 'There are a couple of nice things about functors. One is that unlike regular functions, they can contain state. The above example creates a function which adds 42 to whatever you give it. But that value 42 is not hardcoded, it was specified as a constructor argument when we created our functor instance. I could create another adder, which added 27, just by calling the constructor with a different value. This makes them nicely customizable. As the last lines show, you often pass functors as arguments to other functions such as std::transform or the other standard library algorithms. You could do the same with a regular function pointer except, as I said above, functors can be ""customized"" because they contain state, making them more flexible (If I wanted to use a function pointer, I\'d have to write a function which added exactly 1 to its argument. The functor is general, and adds whatever you initialized it with), and they are also potentially more efficient. In the above example, the', 'to write a function which added exactly 1 to its argument. The functor is general, and adds whatever you initialized it with), and they are also potentially more efficient. In the above example, the compiler knows exactly which function', ""```\nstd::transform\n```\n should call. It should call \n```\nadd_x::operator()\n```\n. That means it can inline that function call. And that makes it just as efficient as if I had manually called the function on each value of the vector. If I had passed a function pointer instead, the compiler couldn't immediately see which function it points to, so unless it performs some fairly complex global optimizations, it'd have to dereference the pointer at runtime, and then make the call.""]","A functor is pretty much just a class which defines the 
```
operator()
```
. That lets you create objects which ""look like"" a function: 
```
// this is a functor
struct add_x {
  add_x(int val) : x(val) {}  // Constructor
  int operator()(int y) const { return x + y; }

private:
  int x;
};

// Now you can use it like this:
add_x add42(42); // create an instance of the functor class
int i = add42(8); // and ""call"" it
assert(i == 50); // and it added 42 to its argument

std::vector<int> in; // assume this contains a bunch of values)
std::vector<int> out(in.size());
// Pass a functor to std::transform, which calls the functor on every element 
// in the input sequence, and stores the result to the output sequence
std::transform(in.begin(), in.end(), out.begin(), add_x(1)); 
assert(out[i] == in[i] + 1); // for all i

```
 There are a couple of nice things about functors. One is that unlike regular functions, they can contain state. The above example creates a function which adds 42 to whatever you give it. But that value 42 is not hardcoded, it was specified as a constructor argument when we created our functor instance. I could create another adder, which added 27, just by calling the constructor with a different value. This makes them nicely customizable. As the last lines show, you often pass functors as arguments to other functions such as std::transform or the other standard library algorithms. You could do the same with a regular function pointer except, as I said above, functors can be ""customized"" because they contain state, making them more flexible (If I wanted to use a function pointer, I'd have to write a function which added exactly 1 to its argument. The functor is general, and adds whatever you initialized it with), and they are also potentially more efficient. In the above example, the compiler knows exactly which function 
```
std::transform
```
 should call. It should call 
```
add_x::operator()
```
. That means it can inline that function call. And that makes it just as efficient as if I had manually called the function on each value of the vector. If I had passed a function pointer instead, the compiler couldn't immediately see which function it points to, so unless it performs some fairly complex global optimizations, it'd have to dereference the pointer at runtime, and then make the call."
4176328,"What are sequence points, and how do they relate to undefined behavior?",https://stackoverflow.com/questions/4176328/what-are-sequence-points-and-how-do-they-relate-to-undefined-behavior,6,732.0,"[""C++98 and C++03 This answer is for the older versions of the C++ standard. The C++11 and C++14 versions of the standard do not formally contain 'sequence points'; operations are 'sequenced before' or 'unsequenced' or 'indeterminately sequenced' instead. The net effect is essentially the same, but the terminology is different. Disclaimer : TL'DR. Pre-requisites : An elementary knowledge of C++ Standard What are Sequence Points? The Standard says At certain specified points in the execution sequence called sequence points, all side effects of previous evaluations shall be complete and no side effects of subsequent evaluations shall have taken place. (§1.9/7) Side effects? What are side effects? Evaluation of an expression produces something and if in addition there is a change in the state of the execution environment it is said that the expression (its evaluation) has some side effect(s). For example: \n```\nint x = y++; //where y is also an int"", '```\n In addition to the initialization operation the value of \n```\ny\n```\n gets changed due to the side effect of \n```\n++\n```\n operator. So far so good. Moving on to sequence points. An alternation definition of seq-points given by the comp.lang.c author \n```\nSteve Summit\n```\n: Sequence point is a point in time at which the dust has settled and all side effects which have been seen so far are guaranteed to be complete. What are the common sequence points listed in the C++ Standard? Those are: at the end of the evaluation of full expression (\n```\n§1.9/16\n```\n) (A full-expression is an expression that is not a subexpression of another expression.)1 Example : \n```\nint a = 5; // ; is a sequence point here', ""```\n in the evaluation of each of the following expressions after the evaluation of the first expression (\n```\n§1.9/18\n```\n) 2 \n```\na && b (§5.14)\n```\n \n```\na || b (§5.15)\n```\n \n```\na ? b : c (§5.16)\n```\n \n```\na , b (§5.18)\n```\n (here a , b is a comma operator; in \n```\nfunc(a,a++)\n```\n \n```\n,\n```\n is not a comma operator, it's merely a separator between the arguments \n```\na\n```\n and \n```\na++\n```\n. Thus the behaviour is undefined in that case (if \n```\na\n```\n is considered to be a primitive type)) at a function call (whether or not the function is inline), after the evaluation of all function arguments (if any) which takes place before execution of any expressions or statements in the function body (\n```\n§1.9/17\n```"", '```\n§1.9/17\n```\n). 1 : Note : the evaluation of a full-expression can include the evaluation of subexpressions that are not lexically part of the full-expression. For example, subexpressions involved in evaluating default argument expressions (8.3.6) are considered to be created in the expression that calls the function, not the expression that defines the default argument 2 : The operators indicated are the built-in operators, as described in clause 5. When one of these operators is overloaded (clause 13) in a valid context, thus designating a user-defined operator function, the expression designates a function invocation and the operands form an argument list, without an implied sequence point between them. What is Undefined Behaviour? The Standard defines Undefined Behaviour in Section \n```\n§1.3.12\n```', '```\n§1.3.12\n```\n as behavior, such as might arise upon use of an erroneous program construct or erroneous data, for which this International Standard imposes no requirements 3. Undefined behavior may also be expected when this International Standard omits the description of any explicit definition of behavior. 3 : permissible undefined behavior ranges from ignoring the situation completely with unpredictable results, to behaving during translation or program execution in a documented manner characteristic of the environment (with or with- out the issuance of a diagnostic message), to terminating a translation or execution (with the issuance of a diagnostic message). What is the relation between Undefined Behaviour and Sequence Points? Before I get into that you must know the difference(s) between Undefined Behaviour, Unspecified Behaviour and Implementation Defined Behaviour. You must also know that \n```', '```\nthe order of evaluation of operands of individual operators and subexpressions of individual expressions, and the order in which side effects take place, is unspecified\n```\n. For example: \n```\nint x = 5, y = 6;', 'int z = x++ + y++; //it is unspecified whether x++ or y++ will be evaluated first.\n\n```\n Another example here. Now the Standard in \n```\n§5/4\n```\n says Between the previous and next sequence point a scalar object shall have its stored value modified at most once by the evaluation of an expression. What does it mean? Informally it means that between two sequence points a variable must not be modified more than once. In an expression statement, the \n```\nnext sequence point\n```\n is usually at the terminating semicolon, and the \n```\nprevious sequence point\n```\n is at the end of the previous statement. An expression may also contain intermediate \n```\nsequence points\n```\n. From the above sentence the following expressions invoke Undefined Behaviour: \n```\ni++ * ++i;   // UB, i is modified more than once btw two SPs\ni = ++i;     // UB, same as above\n++i = 2;     // UB, same as above\ni = ++i + 1; // UB, same as above\n++++++i;     // UB, parsed as (++(++(++i)))', ""i = (i, ++i, ++i); // UB, there's no SP between `++i` (right most) and assignment to `i` (`i` is modified more than once btw two SPs)\n\n```\n But the following expressions are fine: \n```\ni = (i, ++i, 1) + 1; // well defined (AFAIK)\ni = (++i, i++, i);   // well defined \nint j = i;\nj = (++i, i++, j*i); // well defined"", '```\n But the following expressions are fine: \n```\ni = (i, ++i, 1) + 1; // well defined (AFAIK)\ni = (++i, i++, i);   // well defined \nint j = i;\nj = (++i, i++, j*i); // well defined\n\n```\n Furthermore, the prior value shall be accessed only to determine the value to be stored. What does it mean? It means if an object is written to within a full expression, any and all accesses to it within the same expression must be directly involved in the computation of the value to be written. For example in \n```\ni = i + 1\n```\n all the access of \n```\ni\n```\n (in L.H.S and in R.H.S) are directly involved in computation of the value to be written. So it is fine. This rule effectively constrains legal expressions to those in which the accesses demonstrably precede the modification. Example 1: \n```\nstd::printf(""%d %d"", i,++i); // invokes Undefined Behaviour because of Rule no 2\n\n```\n Example 2: \n```\na[i] = i++ // or a[++i] = i or a[i++] = ++i etc', ""```\n Example 2: \n```\na[i] = i++ // or a[++i] = i or a[i++] = ++i etc\n\n```\n is disallowed because one of the accesses of \n```\ni\n```\n (the one in \n```\na[i]\n```\n) has nothing to do with the value which ends up being stored in i (which happens over in \n```\ni++\n```\n), and so there's no good way to define--either for our understanding or the compiler's--whether the access should take place before or after the incremented value is stored. So the behaviour is undefined. Example 3 : \n```\nint x = i + i++ ;// Similar to above\n\n```\n Follow up answer for C++11 here.""]","C++98 and C++03 This answer is for the older versions of the C++ standard. The C++11 and C++14 versions of the standard do not formally contain 'sequence points'; operations are 'sequenced before' or 'unsequenced' or 'indeterminately sequenced' instead. The net effect is essentially the same, but the terminology is different. Disclaimer : TL'DR. Pre-requisites : An elementary knowledge of C++ Standard What are Sequence Points? The Standard says At certain specified points in the execution sequence called sequence points, all side effects of previous evaluations shall be complete and no side effects of subsequent evaluations shall have taken place. (§1.9/7) Side effects? What are side effects? Evaluation of an expression produces something and if in addition there is a change in the state of the execution environment it is said that the expression (its evaluation) has some side effect(s). For example: 
```
int x = y++; //where y is also an int

```
 In addition to the initialization operation the value of 
```
y
```
 gets changed due to the side effect of 
```
++
```
 operator. So far so good. Moving on to sequence points. An alternation definition of seq-points given by the comp.lang.c author 
```
Steve Summit
```
: Sequence point is a point in time at which the dust has settled and all side effects which have been seen so far are guaranteed to be complete. What are the common sequence points listed in the C++ Standard? Those are: at the end of the evaluation of full expression (
```
§1.9/16
```
) (A full-expression is an expression that is not a subexpression of another expression.)1 Example : 
```
int a = 5; // ; is a sequence point here

```
 in the evaluation of each of the following expressions after the evaluation of the first expression (
```
§1.9/18
```
) 2 
```
a && b (§5.14)
```
 
```
a || b (§5.15)
```
 
```
a ? b : c (§5.16)
```
 
```
a , b (§5.18)
```
 (here a , b is a comma operator; in 
```
func(a,a++)
```
 
```
,
```
 is not a comma operator, it's merely a separator between the arguments 
```
a
```
 and 
```
a++
```
. Thus the behaviour is undefined in that case (if 
```
a
```
 is considered to be a primitive type)) at a function call (whether or not the function is inline), after the evaluation of all function arguments (if any) which takes place before execution of any expressions or statements in the function body (
```
§1.9/17
```
). 1 : Note : the evaluation of a full-expression can include the evaluation of subexpressions that are not lexically part of the full-expression. For example, subexpressions involved in evaluating default argument expressions (8.3.6) are considered to be created in the expression that calls the function, not the expression that defines the default argument 2 : The operators indicated are the built-in operators, as described in clause 5. When one of these operators is overloaded (clause 13) in a valid context, thus designating a user-defined operator function, the expression designates a function invocation and the operands form an argument list, without an implied sequence point between them. What is Undefined Behaviour? The Standard defines Undefined Behaviour in Section 
```
§1.3.12
```
 as behavior, such as might arise upon use of an erroneous program construct or erroneous data, for which this International Standard imposes no requirements 3. Undefined behavior may also be expected when this International Standard omits the description of any explicit definition of behavior. 3 : permissible undefined behavior ranges from ignoring the situation completely with unpredictable results, to behaving during translation or program execution in a documented manner characteristic of the environment (with or with- out the issuance of a diagnostic message), to terminating a translation or execution (with the issuance of a diagnostic message). What is the relation between Undefined Behaviour and Sequence Points? Before I get into that you must know the difference(s) between Undefined Behaviour, Unspecified Behaviour and Implementation Defined Behaviour. You must also know that 
```
the order of evaluation of operands of individual operators and subexpressions of individual expressions, and the order in which side effects take place, is unspecified
```
. For example: 
```
int x = 5, y = 6;

int z = x++ + y++; //it is unspecified whether x++ or y++ will be evaluated first.

```
 Another example here. Now the Standard in 
```
§5/4
```
 says Between the previous and next sequence point a scalar object shall have its stored value modified at most once by the evaluation of an expression. What does it mean? Informally it means that between two sequence points a variable must not be modified more than once. In an expression statement, the 
```
next sequence point
```
 is usually at the terminating semicolon, and the 
```
previous sequence point
```
 is at the end of the previous statement. An expression may also contain intermediate 
```
sequence points
```
. From the above sentence the following expressions invoke Undefined Behaviour: 
```
i++ * ++i;   // UB, i is modified more than once btw two SPs
i = ++i;     // UB, same as above
++i = 2;     // UB, same as above
i = ++i + 1; // UB, same as above
++++++i;     // UB, parsed as (++(++(++i)))

i = (i, ++i, ++i); // UB, there's no SP between `++i` (right most) and assignment to `i` (`i` is modified more than once btw two SPs)

```
 But the following expressions are fine: 
```
i = (i, ++i, 1) + 1; // well defined (AFAIK)
i = (++i, i++, i);   // well defined 
int j = i;
j = (++i, i++, j*i); // well defined

```
 Furthermore, the prior value shall be accessed only to determine the value to be stored. What does it mean? It means if an object is written to within a full expression, any and all accesses to it within the same expression must be directly involved in the computation of the value to be written. For example in 
```
i = i + 1
```
 all the access of 
```
i
```
 (in L.H.S and in R.H.S) are directly involved in computation of the value to be written. So it is fine. This rule effectively constrains legal expressions to those in which the accesses demonstrably precede the modification. Example 1: 
```
std::printf(""%d %d"", i,++i); // invokes Undefined Behaviour because of Rule no 2

```
 Example 2: 
```
a[i] = i++ // or a[++i] = i or a[i++] = ++i etc

```
 is disallowed because one of the accesses of 
```
i
```
 (the one in 
```
a[i]
```
) has nothing to do with the value which ends up being stored in i (which happens over in 
```
i++
```
), and so there's no good way to define--either for our understanding or the compiler's--whether the access should take place before or after the incremented value is stored. So the behaviour is undefined. Example 3 : 
```
int x = i + i++ ;// Similar to above

```
 Follow up answer for C++11 here."
228783,What are the rules about using an underscore in a C++ identifier?,https://stackoverflow.com/questions/228783/what-are-the-rules-about-using-an-underscore-in-a-c-identifier,6,969.0,"['The rules (which did not change in C++11): Reserved in any scope, including for use as implementation macros: identifiers beginning with an underscore followed immediately by an uppercase letter identifiers containing adjacent underscores (or ""double underscore"") Reserved in the global namespace: identifiers beginning with an underscore Also, everything in the \n```\nstd\n```\n namespace is reserved. (You are allowed to add template specializations, though.) From the 2003 C++ Standard: 17.4.3.1.2 Global names [lib.global.names] Certain sets of names and function signatures are always reserved to the implementation: Each name that contains a double underscore (\n```\n__\n```\n) or begins with an underscore followed by an uppercase letter (2.11) is reserved to the implementation for any use. Each name that begins with an underscore is reserved to the implementation for use as a name in the global namespace.165 165) Such names are also reserved in namespace \n```\n::std\n```', ""(17.4.3.1). The C++ language is based on the C language (1.1/2, C++03), and C99 is a normative reference (1.2/1, C++03), so it's useful to know the restrictions from the 1999 C Standard (although they do not apply to C++ directly): 7.1.3 Reserved identifiers Each header declares or defines all identifiers listed in its associated subclause, and optionally declares or defines identifiers listed in its associated future library directions subclause and identifiers which are always reserved either for any use or for use as file scope identifiers. All identifiers that begin with an underscore and either an uppercase letter or another underscore are always reserved for any use. All identifiers that begin with an underscore are always reserved for use as identifiers with file scope in both the ordinary and tag name spaces. Each macro name in any of the following subclauses (including the future library directions) is reserved for use as specified if any of its associated headers is"", 'the ordinary and tag name spaces. Each macro name in any of the following subclauses (including the future library directions) is reserved for use as specified if any of its associated headers is included; unless explicitly stated otherwise (see 7.1.4). All identifiers with external linkage in any of the following subclauses (including the future library directions) are always reserved for use as identifiers with external linkage.154 Each identifier with file scope listed in any of the following subclauses (including the future library directions) is reserved for use as a macro name and as an identifier with file scope in the same name space if any of its associated headers is included. No other identifiers are reserved. If the program declares or defines an identifier in a context in which it is reserved (other than as allowed by 7.1.4), or defines a reserved identifier as a macro name, the behavior is undefined. If the program removes (with', '```\n#undef\n```\n) any macro definition of an identifier in the first group listed above, the behavior is undefined. 154) The list of reserved identifiers with external linkage includes \n```\nerrno\n```\n, \n```\nmath_errhandling\n```\n, \n```\nsetjmp\n```\n, and \n```\nva_end\n```\n. Other restrictions might apply. For example, the POSIX standard reserves a lot of identifiers that are likely to show up in normal code: Names beginning with a capital \n```\nE\n```\n followed a digit or uppercase letter: may be used for additional error code names. Names that begin with either \n```\nis\n```\n or \n```\nto\n```\n followed by a lowercase letter: may be used for additional character testing and conversion functions. Names that begin with \n```\nLC_\n```\n followed by an uppercase letter: may be used for additional macros specifying locale attributes. Names of all existing mathematics functions suffixed with \n```\nf\n```\n or \n```\nl\n```', '```\nLC_\n```\n followed by an uppercase letter: may be used for additional macros specifying locale attributes. Names of all existing mathematics functions suffixed with \n```\nf\n```\n or \n```\nl\n```\n are reserved: for corresponding functions that operate on float and long double arguments, respectively. Names that begin with \n```\nSIG\n```\n followed by an uppercase letter are reserved: for additional signal names. Names that begin with \n```\nSIG_\n```\n followed by an uppercase letter are reserved: for additional signal actions. Names beginning with \n```\nstr\n```\n, \n```\nmem\n```\n, or \n```\nwcs\n```\n followed by a lowercase letter are reserved: for additional string and array functions. Names beginning with \n```\nPRI\n```\n or \n```\nSCN\n```\n followed by any lowercase letter or \n```\nX\n```\n are reserved: for additional format specifier macros Names that end with \n```\n_t\n```', ""```\nPRI\n```\n or \n```\nSCN\n```\n followed by any lowercase letter or \n```\nX\n```\n are reserved: for additional format specifier macros Names that end with \n```\n_t\n```\n are reserved: for additional type names. While using these names for your own purposes right now might not cause a problem, they do raise the possibility of conflict with future versions of that standard. Personally I just don't start identifiers with underscores. New addition to my rule: Don't use double underscores anywhere, which is easy as I rarely use underscore. After doing research on this article I no longer end my identifiers with \n```\n_t\n```\n as this is reserved by the POSIX standard. The rule about any identifier ending with \n```\n_t\n```"", ""```\n_t\n```\n as this is reserved by the POSIX standard. The rule about any identifier ending with \n```\n_t\n```\n surprised me a lot. I think that is a POSIX standard (not sure yet) looking for clarification and official chapter and verse. This is from the GNU libtool manual, listing reserved names. CesarB provided the following link to the POSIX 2004 reserved symbols and notes 'that many other reserved prefixes and suffixes ... can be found there'. The POSIX 2008 reserved symbols are defined here. The restrictions are somewhat more nuanced than those above.""]","The rules (which did not change in C++11): Reserved in any scope, including for use as implementation macros: identifiers beginning with an underscore followed immediately by an uppercase letter identifiers containing adjacent underscores (or ""double underscore"") Reserved in the global namespace: identifiers beginning with an underscore Also, everything in the 
```
std
```
 namespace is reserved. (You are allowed to add template specializations, though.) From the 2003 C++ Standard: 17.4.3.1.2 Global names [lib.global.names] Certain sets of names and function signatures are always reserved to the implementation: Each name that contains a double underscore (
```
__
```
) or begins with an underscore followed by an uppercase letter (2.11) is reserved to the implementation for any use. Each name that begins with an underscore is reserved to the implementation for use as a name in the global namespace.165 165) Such names are also reserved in namespace 
```
::std
```
 (17.4.3.1). The C++ language is based on the C language (1.1/2, C++03), and C99 is a normative reference (1.2/1, C++03), so it's useful to know the restrictions from the 1999 C Standard (although they do not apply to C++ directly): 7.1.3 Reserved identifiers Each header declares or defines all identifiers listed in its associated subclause, and optionally declares or defines identifiers listed in its associated future library directions subclause and identifiers which are always reserved either for any use or for use as file scope identifiers. All identifiers that begin with an underscore and either an uppercase letter or another underscore are always reserved for any use. All identifiers that begin with an underscore are always reserved for use as identifiers with file scope in both the ordinary and tag name spaces. Each macro name in any of the following subclauses (including the future library directions) is reserved for use as specified if any of its associated headers is included; unless explicitly stated otherwise (see 7.1.4). All identifiers with external linkage in any of the following subclauses (including the future library directions) are always reserved for use as identifiers with external linkage.154 Each identifier with file scope listed in any of the following subclauses (including the future library directions) is reserved for use as a macro name and as an identifier with file scope in the same name space if any of its associated headers is included. No other identifiers are reserved. If the program declares or defines an identifier in a context in which it is reserved (other than as allowed by 7.1.4), or defines a reserved identifier as a macro name, the behavior is undefined. If the program removes (with 
```
#undef
```
) any macro definition of an identifier in the first group listed above, the behavior is undefined. 154) The list of reserved identifiers with external linkage includes 
```
errno
```
, 
```
math_errhandling
```
, 
```
setjmp
```
, and 
```
va_end
```
. Other restrictions might apply. For example, the POSIX standard reserves a lot of identifiers that are likely to show up in normal code: Names beginning with a capital 
```
E
```
 followed a digit or uppercase letter: may be used for additional error code names. Names that begin with either 
```
is
```
 or 
```
to
```
 followed by a lowercase letter: may be used for additional character testing and conversion functions. Names that begin with 
```
LC_
```
 followed by an uppercase letter: may be used for additional macros specifying locale attributes. Names of all existing mathematics functions suffixed with 
```
f
```
 or 
```
l
```
 are reserved: for corresponding functions that operate on float and long double arguments, respectively. Names that begin with 
```
SIG
```
 followed by an uppercase letter are reserved: for additional signal names. Names that begin with 
```
SIG_
```
 followed by an uppercase letter are reserved: for additional signal actions. Names beginning with 
```
str
```
, 
```
mem
```
, or 
```
wcs
```
 followed by a lowercase letter are reserved: for additional string and array functions. Names beginning with 
```
PRI
```
 or 
```
SCN
```
 followed by any lowercase letter or 
```
X
```
 are reserved: for additional format specifier macros Names that end with 
```
_t
```
 are reserved: for additional type names. While using these names for your own purposes right now might not cause a problem, they do raise the possibility of conflict with future versions of that standard. Personally I just don't start identifiers with underscores. New addition to my rule: Don't use double underscores anywhere, which is easy as I rarely use underscore. After doing research on this article I no longer end my identifiers with 
```
_t
```
 as this is reserved by the POSIX standard. The rule about any identifier ending with 
```
_t
```
 surprised me a lot. I think that is a POSIX standard (not sure yet) looking for clarification and official chapter and verse. This is from the GNU libtool manual, listing reserved names. CesarB provided the following link to the POSIX 2004 reserved symbols and notes 'that many other reserved prefixes and suffixes ... can be found there'. The POSIX 2008 reserved symbols are defined here. The restrictions are somewhat more nuanced than those above."
1410563,What is the difference between a definition and a declaration?,https://stackoverflow.com/questions/1410563/what-is-the-difference-between-a-definition-and-a-declaration,27,1062.0,"[""A declaration introduces an identifier and describes its type, be it a type, object, or function. A declaration is what the compiler needs to accept references to that identifier. These are declarations: \n```\nextern int bar;\nextern int g(int, int);\ndouble f(int, double); // extern can be omitted for function declarations\nclass foo; // no extern allowed for type declarations\n\n```\n A definition actually instantiates/implements this identifier. It's what the linker needs in order to link references to those entities. These are definitions corresponding to the above declarations: \n```\nint bar;\nint g(int lhs, int rhs) {return lhs*rhs;}\ndouble f(int i, double d) {return i+d;}\nclass foo {};\n\n```\n A definition can be used in the place of a declaration. An identifier can be declared as often as you want. Thus, the following is legal in C and C++: \n```\ndouble f(int, double);\ndouble f(int, double);\nextern double f(int, double); // the same as the two above\nextern double f(int, double);"", ""```\n However, it must be defined exactly once. If you forget to define something that's been declared and referenced somewhere, then the linker doesn't know what to link references to and complains about a missing symbols. If you define something more than once, then the linker doesn't know which of the definitions to link references to and complains about duplicated symbols. Since the debate what is a class declaration vs. a class definition in C++ keeps coming up (in answers and comments to other questions) , I'll paste a quote from the C++ standard here. At 3.1/2, C++03 says: A declaration is a definition unless it [...] is a class name declaration [...]. 3.1/3 then gives a few examples. Amongst them: [Example: [...] struct S { int a; int b; }; // defines S, S::a, and S::b [...] struct S; // declares S —end example To sum it up: The C++ standard considers \n```\nstruct x;\n```\n to be a declaration and \n```\nstruct x {};\n```"", '```\nstruct x;\n```\n to be a declaration and \n```\nstruct x {};\n```\n a definition. (In other words, ""forward declaration"" a misnomer, since there are no other forms of class declarations in C++.) Thanks to litb (Johannes Schaub) who dug out the actual chapter and verse in one of his answers.']","A declaration introduces an identifier and describes its type, be it a type, object, or function. A declaration is what the compiler needs to accept references to that identifier. These are declarations: 
```
extern int bar;
extern int g(int, int);
double f(int, double); // extern can be omitted for function declarations
class foo; // no extern allowed for type declarations

```
 A definition actually instantiates/implements this identifier. It's what the linker needs in order to link references to those entities. These are definitions corresponding to the above declarations: 
```
int bar;
int g(int lhs, int rhs) {return lhs*rhs;}
double f(int i, double d) {return i+d;}
class foo {};

```
 A definition can be used in the place of a declaration. An identifier can be declared as often as you want. Thus, the following is legal in C and C++: 
```
double f(int, double);
double f(int, double);
extern double f(int, double); // the same as the two above
extern double f(int, double);

```
 However, it must be defined exactly once. If you forget to define something that's been declared and referenced somewhere, then the linker doesn't know what to link references to and complains about a missing symbols. If you define something more than once, then the linker doesn't know which of the definitions to link references to and complains about duplicated symbols. Since the debate what is a class declaration vs. a class definition in C++ keeps coming up (in answers and comments to other questions) , I'll paste a quote from the C++ standard here. At 3.1/2, C++03 says: A declaration is a definition unless it [...] is a class name declaration [...]. 3.1/3 then gives a few examples. Amongst them: [Example: [...] struct S { int a; int b; }; // defines S, S::a, and S::b [...] struct S; // declares S —end example To sum it up: The C++ standard considers 
```
struct x;
```
 to be a declaration and 
```
struct x {};
```
 a definition. (In other words, ""forward declaration"" a misnomer, since there are no other forms of class declarations in C++.) Thanks to litb (Johannes Schaub) who dug out the actual chapter and verse in one of his answers."
313970,How to convert an instance of std::string to lower case,https://stackoverflow.com/questions/313970/how-to-convert-an-instance-of-stdstring-to-lower-case,30,1136.0,"['Adapted from Not So Frequently Asked Questions: \n```\n#include <algorithm>\n#include <cctype>\n#include <string>\n\nstd::string data = ""Abc"";\nstd::transform(data.begin(), data.end(), data.begin(),\n    [](unsigned char c){ return std::tolower(c); });\n\n```\n You\'re really not going to get away without iterating through each character. There\'s no way to know whether the character is lowercase or uppercase otherwise. If you really hate \n```\ntolower()\n```\n, here\'s a specialized ASCII-only alternative that I don\'t recommend you use: \n```\nchar asciitolower(char in) {\n    if (in <= \'Z\' && in >= \'A\')\n        return in - (\'Z\' - \'z\');\n    return in;\n}\n\nstd::transform(data.begin(), data.end(), data.begin(), asciitolower);\n\n```\n Be aware that \n```\ntolower()\n```\n can only do a per-single-byte-character substitution, which is ill-fitting for many scripts, especially if using a multi-byte-encoding like UTF-8.']","Adapted from Not So Frequently Asked Questions: 
```
#include <algorithm>
#include <cctype>
#include <string>

std::string data = ""Abc"";
std::transform(data.begin(), data.end(), data.begin(),
    [](unsigned char c){ return std::tolower(c); });

```
 You're really not going to get away without iterating through each character. There's no way to know whether the character is lowercase or uppercase otherwise. If you really hate 
```
tolower()
```
, here's a specialized ASCII-only alternative that I don't recommend you use: 
```
char asciitolower(char in) {
    if (in <= 'Z' && in >= 'A')
        return in - ('Z' - 'z');
    return in;
}

std::transform(data.begin(), data.end(), data.begin(), asciitolower);

```
 Be aware that 
```
tolower()
```
 can only do a per-single-byte-character substitution, which is ill-fitting for many scripts, especially if using a multi-byte-encoding like UTF-8."
216823,How to trim a std::string?,https://stackoverflow.com/questions/216823/how-to-trim-a-stdstring,51,,[],
201718,Concatenating two std::vectors,https://stackoverflow.com/questions/201718/concatenating-two-stdvectors,29,,[],
98650,What is the strict aliasing rule?,https://stackoverflow.com/questions/98650/what-is-the-strict-aliasing-rule,11,707.0,"[""A typical situation where you encounter strict aliasing problems is when overlaying a struct (like a device/network msg) onto a buffer of the word size of your system (like a pointer to \n```\nuint32_t\n```\ns or \n```\nuint16_t\n```\ns). When you overlay a struct onto such a buffer, or a buffer onto such a struct through pointer casting you can easily violate strict aliasing rules. So in this kind of setup, if I want to send a message to something I'd have to have two incompatible pointers pointing to the same chunk of memory. I might then naively code something like this: \n```\ntypedef struct Msg\n{\n    unsigned int a;\n    unsigned int b;\n} Msg;\n\nvoid SendWord(uint32_t);"", 'void SendWord(uint32_t);\n\nint main(void)\n{\n    // Get a 32-bit buffer from the system\n    uint32_t* buff = malloc(sizeof(Msg));\n    \n    // Alias that buffer through message\n    Msg* msg = (Msg*)(buff);\n    \n    // Send a bunch of messages    \n    for (int i = 0; i < 10; ++i)\n    {\n        msg->a = i;\n        msg->b = i+1;\n        SendWord(buff[0]);\n        SendWord(buff[1]);   \n    }\n}', ""```\n The strict aliasing rule makes this setup illegal: dereferencing a pointer that aliases an object that is not of a compatible type or one of the other types allowed by C 2011 6.5 paragraph 71 is undefined behavior. Unfortunately, you can still code this way, maybe get some warnings, have it compile fine, only to have weird unexpected behavior when you run the code. (GCC appears somewhat inconsistent in its ability to give aliasing warnings, sometimes giving us a friendly warning and sometimes not.) To see why this behavior is undefined, we have to think about what the strict aliasing rule buys the compiler. Basically, with this rule, it doesn't have to think about inserting instructions to refresh the contents of \n```\nbuff\n```\n every run of the loop. Instead, when optimizing, with some annoyingly unenforced assumptions about aliasing, it can omit those instructions, load \n```\nbuff[0]\n```\n and \n```\nbuff[1]\n```"", ""```\nbuff\n```\n every run of the loop. Instead, when optimizing, with some annoyingly unenforced assumptions about aliasing, it can omit those instructions, load \n```\nbuff[0]\n```\n and \n```\nbuff[1]\n```\n into CPU registers once before the loop is run, and speed up the body of the loop. Before strict aliasing was introduced, the compiler had to live in a state of paranoia that the contents of \n```\nbuff\n```\n could change by any preceding memory stores. So to get an extra performance edge, and assuming most people don't type-pun pointers, the strict aliasing rule was introduced. Keep in mind, if you think the example is contrived, this might even happen if you're passing a buffer to another function doing the sending for you, if instead you have. \n```\nvoid SendMessage(uint32_t* buff, size_t size32)\n{\n    for (int i = 0; i < size32; ++i) \n    {\n        SendWord(buff[i]);\n    }\n}"", '```\n And rewrote our earlier loop to take advantage of this convenient function \n```\nfor (int i = 0; i < 10; ++i)\n{\n    msg->a = i;\n    msg->b = i+1;\n    SendMessage(buff, 2);\n}', ""```\n The compiler may or may not be able to or smart enough to try to inline SendMessage and it may or may not decide to load or not load buff again. If \n```\nSendMessage\n```\n is part of another API that's compiled separately, it probably has instructions to load buff's contents. Then again, maybe you're in C++ and this is some templated header only implementation that the compiler thinks it can inline. Or maybe it's just something you wrote in your .c file for your own convenience. Anyway undefined behavior might still ensue. Even when we know some of what's happening under the hood, it's still a violation of the rule so no well defined behavior is guaranteed. So just by wrapping in a function that takes our word delimited buffer doesn't necessarily help. So how do I get around this? Use a union. Most compilers support this without complaining about strict aliasing. This is allowed in C99 and explicitly allowed in C11. \n```\n  union {\n      Msg msg;"", '```\n  union {\n      Msg msg;\n      unsigned int asBuffer[sizeof(Msg)/sizeof(unsigned int)];\n  };', ""```\n You can disable strict aliasing in your compiler (f[no-]strict-aliasing in gcc)) You can use \n```\nchar*\n```\n for aliasing instead of your system's word. The rules allow an exception for \n```\nchar*\n```\n (including \n```\nsigned char\n```\n and \n```\nunsigned char\n```\n). It's always assumed that \n```\nchar*\n```"", ""). It's always assumed that \n```\nchar*\n```\n aliases other types. However this won't work the other way: there's no assumption that your struct aliases a buffer of chars. Beginner beware This is only one potential minefield when overlaying two types onto each other. You should also learn about endianness, word alignment, and how to deal with alignment issues through packing structs correctly. Footnote 1 The types that C 2011 6.5 7 allows an lvalue to access are: a type compatible with the effective type of the object, a qualified version of a type compatible with the effective type of the object, a type that is the signed or unsigned type corresponding to the effective type of the object, a type that is the signed or unsigned type corresponding to a qualified version of the effective type of the object, an aggregate or union type that includes one of the aforementioned types among its members (including, recursively, a member of a subaggregate or contained union), or a character type.""]","A typical situation where you encounter strict aliasing problems is when overlaying a struct (like a device/network msg) onto a buffer of the word size of your system (like a pointer to 
```
uint32_t
```
s or 
```
uint16_t
```
s). When you overlay a struct onto such a buffer, or a buffer onto such a struct through pointer casting you can easily violate strict aliasing rules. So in this kind of setup, if I want to send a message to something I'd have to have two incompatible pointers pointing to the same chunk of memory. I might then naively code something like this: 
```
typedef struct Msg
{
    unsigned int a;
    unsigned int b;
} Msg;

void SendWord(uint32_t);

int main(void)
{
    // Get a 32-bit buffer from the system
    uint32_t* buff = malloc(sizeof(Msg));
    
    // Alias that buffer through message
    Msg* msg = (Msg*)(buff);
    
    // Send a bunch of messages    
    for (int i = 0; i < 10; ++i)
    {
        msg->a = i;
        msg->b = i+1;
        SendWord(buff[0]);
        SendWord(buff[1]);   
    }
}

```
 The strict aliasing rule makes this setup illegal: dereferencing a pointer that aliases an object that is not of a compatible type or one of the other types allowed by C 2011 6.5 paragraph 71 is undefined behavior. Unfortunately, you can still code this way, maybe get some warnings, have it compile fine, only to have weird unexpected behavior when you run the code. (GCC appears somewhat inconsistent in its ability to give aliasing warnings, sometimes giving us a friendly warning and sometimes not.) To see why this behavior is undefined, we have to think about what the strict aliasing rule buys the compiler. Basically, with this rule, it doesn't have to think about inserting instructions to refresh the contents of 
```
buff
```
 every run of the loop. Instead, when optimizing, with some annoyingly unenforced assumptions about aliasing, it can omit those instructions, load 
```
buff[0]
```
 and 
```
buff[1]
```
 into CPU registers once before the loop is run, and speed up the body of the loop. Before strict aliasing was introduced, the compiler had to live in a state of paranoia that the contents of 
```
buff
```
 could change by any preceding memory stores. So to get an extra performance edge, and assuming most people don't type-pun pointers, the strict aliasing rule was introduced. Keep in mind, if you think the example is contrived, this might even happen if you're passing a buffer to another function doing the sending for you, if instead you have. 
```
void SendMessage(uint32_t* buff, size_t size32)
{
    for (int i = 0; i < size32; ++i) 
    {
        SendWord(buff[i]);
    }
}

```
 And rewrote our earlier loop to take advantage of this convenient function 
```
for (int i = 0; i < 10; ++i)
{
    msg->a = i;
    msg->b = i+1;
    SendMessage(buff, 2);
}

```
 The compiler may or may not be able to or smart enough to try to inline SendMessage and it may or may not decide to load or not load buff again. If 
```
SendMessage
```
 is part of another API that's compiled separately, it probably has instructions to load buff's contents. Then again, maybe you're in C++ and this is some templated header only implementation that the compiler thinks it can inline. Or maybe it's just something you wrote in your .c file for your own convenience. Anyway undefined behavior might still ensue. Even when we know some of what's happening under the hood, it's still a violation of the rule so no well defined behavior is guaranteed. So just by wrapping in a function that takes our word delimited buffer doesn't necessarily help. So how do I get around this? Use a union. Most compilers support this without complaining about strict aliasing. This is allowed in C99 and explicitly allowed in C11. 
```
  union {
      Msg msg;
      unsigned int asBuffer[sizeof(Msg)/sizeof(unsigned int)];
  };

```
 You can disable strict aliasing in your compiler (f[no-]strict-aliasing in gcc)) You can use 
```
char*
```
 for aliasing instead of your system's word. The rules allow an exception for 
```
char*
```
 (including 
```
signed char
```
 and 
```
unsigned char
```
). It's always assumed that 
```
char*
```
 aliases other types. However this won't work the other way: there's no assumption that your struct aliases a buffer of chars. Beginner beware This is only one potential minefield when overlaying two types onto each other. You should also learn about endianness, word alignment, and how to deal with alignment issues through packing structs correctly. Footnote 1 The types that C 2011 6.5 7 allows an lvalue to access are: a type compatible with the effective type of the object, a qualified version of a type compatible with the effective type of the object, a type that is the signed or unsigned type corresponding to the effective type of the object, a type that is the signed or unsigned type corresponding to a qualified version of the effective type of the object, an aggregate or union type that includes one of the aforementioned types among its members (including, recursively, a member of a subaggregate or contained union), or a character type."
6500313,Why should C++ programmers minimize use of 'new'?,https://stackoverflow.com/questions/6500313/why-should-c-programmers-minimize-use-of-new,20,1164.0,"['There are two widely-used memory allocation techniques: automatic allocation and dynamic allocation. Commonly, there is a corresponding region of memory for each: the stack and the heap. Stack The stack always allocates memory in a sequential fashion. It can do so because it requires you to release the memory in the reverse order (First-In, Last-Out: FILO). This is the memory allocation technique for local variables in many programming languages. It is very, very fast because it requires minimal bookkeeping and the next address to allocate is implicit. In C++, this is called automatic storage because the storage is claimed automatically at the end of scope. As soon as execution of current code block (delimited using \n```\n{}\n```', '```\n{}\n```\n) is completed, memory for all variables in that block is automatically collected. This is also the moment where destructors are invoked to clean up resources. Heap The heap allows for a more flexible memory allocation mode. Bookkeeping is more complex and allocation is slower. Because there is no implicit release point, you must release the memory manually, using \n```\ndelete\n```\n or \n```\ndelete[]\n```\n (\n```\nfree\n```', ""```\ndelete\n```\n or \n```\ndelete[]\n```\n (\n```\nfree\n```\n in C). However, the absence of an implicit release point is the key to the heap's flexibility. Reasons to use dynamic allocation Even if using the heap is slower and potentially leads to memory leaks or memory fragmentation, there are perfectly good use cases for dynamic allocation, as it's less limited. Two key reasons to use dynamic allocation: You don't know how much memory you need at compile time. For instance, when reading a text file into a string, you usually don't know what size the file has, so you can't decide how much memory to allocate until you run the program. You want to allocate memory which will persist after leaving the current block. For instance, you may want to write a function \n```\nstring readfile(string path)\n```"", '```\nstring readfile(string path)\n```\n that returns the contents of a file. In this case, even if the stack could hold the entire file contents, you could not return from a function and keep the allocated memory block. Why dynamic allocation is often unnecessary In C++ there\'s a neat construct called a destructor. This mechanism allows you to manage resources by aligning the lifetime of the resource with the lifetime of a variable. This technique is called RAII and is the distinguishing point of C++. It ""wraps"" resources into objects. \n```\nstd::string\n```\n is a perfect example. This snippet: \n```\nint main ( int argc, char* argv[] )\n{\n    std::string program(argv[0]);\n}', '```\n actually allocates a variable amount of memory. The \n```\nstd::string\n```\n object allocates memory using the heap and releases it in its destructor. In this case, you did not need to manually manage any resources and still got the benefits of dynamic memory allocation. In particular, it implies that in this snippet: \n```\nint main ( int argc, char* argv[] )\n{\n    std::string * program = new std::string(argv[0]);  // Bad!\n    delete program;\n}', '```\n there is unneeded dynamic memory allocation. The program requires more typing (!) and introduces the risk of forgetting to deallocate the memory. It does this with no apparent benefit. Why you should use automatic storage as often as possible Basically, the last paragraph sums it up. Using automatic storage as often as possible makes your programs: faster to type; faster when run; less prone to memory/resource leaks. Bonus points In the referenced question, there are additional concerns. In particular, the following class: \n```\nclass Line {\npublic:\n    Line();\n    ~Line();\n    std::string* mString;\n};\n\nLine::Line() {\n    mString = new std::string(""foo_bar"");\n}\n\nLine::~Line() {\n    delete mString;\n}\n\n```\n Is actually a lot more risky to use than the following one: \n```\nclass Line {\npublic:\n    Line();\n    std::string mString;\n};\n\nLine::Line() {\n    mString = ""foo_bar"";\n    // note: there is a cleaner way to write this.\n}', 'Line::Line() {\n    mString = ""foo_bar"";\n    // note: there is a cleaner way to write this.\n}\n\n```\n The reason is that \n```\nstd::string\n```\n properly defines a copy constructor. Consider the following program: \n```\nint main ()\n{\n    Line l1;\n    Line l2 = l1;\n}\n\n```\n Using the original version, this program will likely crash, as it uses \n```\ndelete\n```\n on the same string twice. Using the modified version, each \n```\nLine\n```\n instance will own its own string instance, each with its own memory and both will be released at the end of the program. Other notes Extensive use of RAII is considered a best practice in C++ because of all the reasons above. However, there is an additional benefit which is not immediately obvious. Basically, it\'s better than the sum of its parts. The whole mechanism composes. It scales. If you use the \n```\nLine\n```\n class as a building block: \n```\n class Table\n {\n      Line borders[4];\n };\n\n```\n Then \n```\n int main ()\n {\n     Table table;\n }', ""```\n Then \n```\n int main ()\n {\n     Table table;\n }\n\n```\n allocates four \n```\nstd::string\n```\n instances, four \n```\nLine\n```\n instances, one \n```\nTable\n```\n instance and all the string's contents and everything is freed automagically.""]","There are two widely-used memory allocation techniques: automatic allocation and dynamic allocation. Commonly, there is a corresponding region of memory for each: the stack and the heap. Stack The stack always allocates memory in a sequential fashion. It can do so because it requires you to release the memory in the reverse order (First-In, Last-Out: FILO). This is the memory allocation technique for local variables in many programming languages. It is very, very fast because it requires minimal bookkeeping and the next address to allocate is implicit. In C++, this is called automatic storage because the storage is claimed automatically at the end of scope. As soon as execution of current code block (delimited using 
```
{}
```
) is completed, memory for all variables in that block is automatically collected. This is also the moment where destructors are invoked to clean up resources. Heap The heap allows for a more flexible memory allocation mode. Bookkeeping is more complex and allocation is slower. Because there is no implicit release point, you must release the memory manually, using 
```
delete
```
 or 
```
delete[]
```
 (
```
free
```
 in C). However, the absence of an implicit release point is the key to the heap's flexibility. Reasons to use dynamic allocation Even if using the heap is slower and potentially leads to memory leaks or memory fragmentation, there are perfectly good use cases for dynamic allocation, as it's less limited. Two key reasons to use dynamic allocation: You don't know how much memory you need at compile time. For instance, when reading a text file into a string, you usually don't know what size the file has, so you can't decide how much memory to allocate until you run the program. You want to allocate memory which will persist after leaving the current block. For instance, you may want to write a function 
```
string readfile(string path)
```
 that returns the contents of a file. In this case, even if the stack could hold the entire file contents, you could not return from a function and keep the allocated memory block. Why dynamic allocation is often unnecessary In C++ there's a neat construct called a destructor. This mechanism allows you to manage resources by aligning the lifetime of the resource with the lifetime of a variable. This technique is called RAII and is the distinguishing point of C++. It ""wraps"" resources into objects. 
```
std::string
```
 is a perfect example. This snippet: 
```
int main ( int argc, char* argv[] )
{
    std::string program(argv[0]);
}

```
 actually allocates a variable amount of memory. The 
```
std::string
```
 object allocates memory using the heap and releases it in its destructor. In this case, you did not need to manually manage any resources and still got the benefits of dynamic memory allocation. In particular, it implies that in this snippet: 
```
int main ( int argc, char* argv[] )
{
    std::string * program = new std::string(argv[0]);  // Bad!
    delete program;
}

```
 there is unneeded dynamic memory allocation. The program requires more typing (!) and introduces the risk of forgetting to deallocate the memory. It does this with no apparent benefit. Why you should use automatic storage as often as possible Basically, the last paragraph sums it up. Using automatic storage as often as possible makes your programs: faster to type; faster when run; less prone to memory/resource leaks. Bonus points In the referenced question, there are additional concerns. In particular, the following class: 
```
class Line {
public:
    Line();
    ~Line();
    std::string* mString;
};

Line::Line() {
    mString = new std::string(""foo_bar"");
}

Line::~Line() {
    delete mString;
}

```
 Is actually a lot more risky to use than the following one: 
```
class Line {
public:
    Line();
    std::string mString;
};

Line::Line() {
    mString = ""foo_bar"";
    // note: there is a cleaner way to write this.
}

```
 The reason is that 
```
std::string
```
 properly defines a copy constructor. Consider the following program: 
```
int main ()
{
    Line l1;
    Line l2 = l1;
}

```
 Using the original version, this program will likely crash, as it uses 
```
delete
```
 on the same string twice. Using the modified version, each 
```
Line
```
 instance will own its own string instance, each with its own memory and both will be released at the end of the program. Other notes Extensive use of RAII is considered a best practice in C++ because of all the reasons above. However, there is an additional benefit which is not immediately obvious. Basically, it's better than the sum of its parts. The whole mechanism composes. It scales. If you use the 
```
Line
```
 class as a building block: 
```
 class Table
 {
      Line borders[4];
 };

```
 Then 
```
 int main ()
 {
     Table table;
 }

```
 allocates four 
```
std::string
```
 instances, four 
```
Line
```
 instances, one 
```
Table
```
 instance and all the string's contents and everything is freed automagically."
38060436,What are the new features in C++17?,https://stackoverflow.com/questions/38060436/what-are-the-new-features-in-c17,1,1330.0,"['Language features: Templates and Generic Code Template argument deduction for class templates Like how functions deduce template arguments, now constructors can deduce the template arguments of the class http://wg21.link/p0433r2 http://wg21.link/p0620r0 http://wg21.link/p0512r0 \n```\ntemplate <auto>\n```\n Represents a value of any (non-type template argument) type. Non-type template arguments fixes \n```\ntemplate<template<class...>typename bob> struct foo {}\n```\n ( Folding + ... + expressions ) and Revisions \n```\nauto x{8};\n```\n is an \n```\nint\n```\n modernizing \n```\nusing\n```\n with \n```\n...\n```\n and lists Lambda constexpr lambdas Lambdas are implicitly constexpr if they qualify Capturing \n```\n*this\n```\n in lambdas \n```\n[*this]{ std::cout << could << "" be "" << useful << \'\\n\'; }\n```\n Attributes \n```\n[[fallthrough]]\n```\n, \n```\n[[nodiscard]]\n```\n, \n```\n[[maybe_unused]]\n```\n attributes \n```\n[[attributes]]\n```\n on \n```\nnamespace\n```\ns and \n```\nenum { erator[[s]] }\n```\n \n```\nusing\n```', '```\n[[fallthrough]]\n```\n, \n```\n[[nodiscard]]\n```\n, \n```\n[[maybe_unused]]\n```\n attributes \n```\n[[attributes]]\n```\n on \n```\nnamespace\n```\ns and \n```\nenum { erator[[s]] }\n```\n \n```\nusing\n```\n in attributes to avoid having to repeat an attribute namespace. Compilers are now required to ignore non-standard attributes they don\'t recognize. The C++14 wording allowed compilers to reject unknown scoped attributes. Syntax cleanup Inline variables Like inline functions Compiler picks where the instance is instantiated Deprecate static constexpr redeclaration, now implicitly inline. \n```\nnamespace A::B\n```\n Simple \n```\nstatic_assert(expression);\n```\n with no string no \n```\nthrow\n```\n unless \n```\nthrow()\n```\n, and \n```\nthrow()\n```\n is \n```\nnoexcept(true)\n```\n. Cleaner multi-return and flow control Structured bindings Basically, first-class \n```\nstd::tie\n```\n with \n```\nauto\n```\n Example: \n```\nconst auto [it, inserted] = map.insert( {""foo"", bar} );\n```\n Creates variables \n```\nit\n```\n and \n```', '```\nstd::tie\n```\n with \n```\nauto\n```\n Example: \n```\nconst auto [it, inserted] = map.insert( {""foo"", bar} );\n```\n Creates variables \n```\nit\n```\n and \n```\ninserted\n```\n with deduced type from the \n```\npair\n```\n that \n```\nmap::insert\n```\n returns. Works with tuple/pair-likes & \n```\nstd::array\n```\ns and relatively flat structs Actually named structured bindings in standard \n```\nif (init; condition)\n```\n and \n```\nswitch (init; condition)\n```\n \n```\nif (const auto [it, inserted] = map.insert( {""foo"", bar} ); inserted)\n```\n Extends the \n```\nif(decl)\n```\n to cases where \n```\ndecl\n```', '```\n and \n```\nswitch (init; condition)\n```\n \n```\nif (const auto [it, inserted] = map.insert( {""foo"", bar} ); inserted)\n```\n Extends the \n```\nif(decl)\n```\n to cases where \n```\ndecl\n```\n isn\'t convertible-to-bool sensibly. Generalizing range-based for loops Appears to be mostly support for sentinels, or end iterators that are not the same type as begin iterators, which helps with null-terminated loops and the like. if constexpr Much requested feature to simplify almost-generic code. Misc Hexadecimal float point literals Dynamic memory allocation for over-aligned data Guaranteed copy elision Finally! Not in all cases, but distinguishes syntax where you are ""just creating something"" that was called elision, from ""genuine elision"". Fixed order-of-evaluation for (some) expressions with some modifications Not including function arguments, but function argument evaluation interleaving now banned Makes a bunch of broken code work mostly, and makes \n```\n.then\n```', '```\n.then\n```\n on future work. Direct list-initialization of enums Forward progress guarantees (FPG) (also, FPGs for parallel algorithms) I think this is saying ""the implementation may not stall threads forever""? \n```\nu8\'U\', u8\'T\', u8\'F\', u8\'8\'\n```\n character literals (string already existed) ""noexcept"" in the type system \n```\n__has_include\n```\n Test if a header file include would be an error makes migrating from experimental to std almost seamless Arrays of pointer conversion fixes inherited constructors fixes to some corner cases (see P0136R0 for examples of behavior changes) aggregate initialization with inheritance. \n```\nstd::launder\n```\n, type punning, etc Library additions: Data types \n```\nstd::variant<Ts...>\n```\n Almost-always non-empty last I checked? Tagged union type {awesome|useful} \n```\nstd::optional\n```\n Maybe holds one of something Ridiculously useful \n```\nstd::any\n```\n Holds one of anything (that is copyable) \n```\nstd::string_view\n```\n \n```\nstd::string\n```', '```\nstd::optional\n```\n Maybe holds one of something Ridiculously useful \n```\nstd::any\n```\n Holds one of anything (that is copyable) \n```\nstd::string_view\n```\n \n```\nstd::string\n```\n like reference-to-character-array or substring Never take a \n```\nstring const&\n```\n again. Also can make parsing a bajillion times faster. \n```\n""hello world""sv\n```\n constexpr \n```\nchar_traits\n```\n \n```\nstd::byte\n```\n off more than they could chew. Neither an integer nor a character, just data Invoke stuff \n```\nstd::invoke\n```\n Call any callable (function pointer, function, member pointer) with one syntax. From the standard INVOKE concept. \n```\nstd::apply\n```\n Takes a function-like and a tuple, and unpacks the tuple into the call. \n```\nstd::make_from_tuple\n```\n, \n```\nstd::apply\n```\n applied to object construction \n```\nis_invocable\n```\n, \n```\nis_invocable_r\n```\n, \n```\ninvoke_result\n```', '```\nstd::make_from_tuple\n```\n, \n```\nstd::apply\n```\n applied to object construction \n```\nis_invocable\n```\n, \n```\nis_invocable_r\n```\n, \n```\ninvoke_result\n```\n http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0077r2.html http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0604r0.html Deprecates \n```\nresult_of\n```\n \n```\nis_invocable<Foo(Args...), R>\n```\n is ""can you call \n```\nFoo\n```\n with \n```\nArgs...\n```\n and get something compatible with \n```\nR\n```\n"", where \n```\nR=void\n```\n is default. \n```\ninvoke_result<Foo, Args...>\n```\n is \n```\nstd::result_of_t<Foo(Args...)>\n```\n but apparently less confusing? File System TS v1 \n```\n[class.path]\n```\n \n```\n[class.filesystem.error]\n```\n \n```\n[class.file_status]\n```\n \n```\n[class.directory_entry]\n```\n \n```\n[class.directory_iterator]\n```\n and \n```\n[class.recursive_directory_iterator]\n```\n \n```\n[fs.ops.funcs]\n```\n \n```\nfstream\n```\ns can be opened with \n```\npath\n```\ns, as well as with \n```\nconst path::value_type*\n```\n strings. New algorithms', ""[class.recursive_directory_iterator]\n```\n \n```\n[fs.ops.funcs]\n```\n \n```\nfstream\n```\ns can be opened with \n```\npath\n```\ns, as well as with \n```\nconst path::value_type*\n```\n strings. New algorithms \n```\nfor_each_n\n```\n \n```\nreduce\n```\n \n```\ntransform_reduce\n```\n \n```\nexclusive_scan\n```\n \n```\ninclusive_scan\n```\n \n```\ntransform_exclusive_scan\n```\n \n```\ntransform_inclusive_scan\n```\n Added for threading purposes, exposed even if you aren't using them threaded Threading \n```\nstd::shared_mutex\n```\n Untimed, which can be more efficient if you don't need it. \n```\natomic<T>\n```"", '```\n::is_always_lockfree\n```\n \n```\nscoped_lock<Mutexes...>\n```\n Saves some \n```\nstd::lock\n```\n pain when locking more than one mutex at a time. Parallelism TS v1 The linked paper from 2014, may be out of date Parallel versions of \n```\nstd\n```\n algorithms, and related machinery hardware_*_interference_size (parts of) Library Fundamentals TS v1 not covered above or below \n```\n[func.searchers]\n```\n and \n```\n[alg.search]\n```\n A searching algorithm and techniques \n```\n[pmr]\n```\n Polymorphic allocator, like \n```\nstd::function\n```\n for allocators And some standard memory resources to go with it. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0358r1.html \n```\nstd::sample\n```\n, sampling from a range? Container Improvements \n```\ntry_emplace\n```\n and \n```\ninsert_or_assign\n```\n gives better guarantees in some cases where spurious move/copy would be bad Splicing for \n```\nmap<>\n```\n, \n```\nunordered_map<>\n```\n, \n```\nset<>\n```\n, and \n```\nunordered_set<>\n```', '```\n gives better guarantees in some cases where spurious move/copy would be bad Splicing for \n```\nmap<>\n```\n, \n```\nunordered_map<>\n```\n, \n```\nset<>\n```\n, and \n```\nunordered_set<>\n```\n Move nodes between containers cheaply. Merge whole containers cheaply. non-const \n```\n.data()\n```\n for string. non-member \n```\nstd::size\n```\n, \n```\nstd::empty\n```\n, \n```\nstd::data\n```\n like \n```\nstd::begin\n```\n/\n```\nend\n```\n Minimal incomplete type support in containers Contiguous iterator ""concept"" \n```\nconstexpr\n```\n iterators The \n```\nemplace\n```\n family of functions now returns a reference to the created object. Smart pointer changes \n```\nunique_ptr<T[]>\n```\n fixes and other \n```\nunique_ptr\n```\n tweaks. \n```\nweak_from_this\n```\n and some fixed to shared from this Other \n```\nstd\n```\n datatype improvements: \n```\n{}\n```\n construction of \n```\nstd::tuple\n```\n and other improvements TriviallyCopyable reference_wrapper, can be performance boost Misc C++17 library is based on C11 instead of C99 Reserved \n```', '```\n{}\n```\n construction of \n```\nstd::tuple\n```\n and other improvements TriviallyCopyable reference_wrapper, can be performance boost Misc C++17 library is based on C11 instead of C99 Reserved \n```\nstd[0-9]+\n```\n for future standard libraries \n```\ndestroy(_at|_n)\n```\n, \n```\nuninitialized_move(_n)\n```\n, \n```\nuninitialized_value_construct(_n)\n```\n, \n```\nuninitialized_default_construct(_n)\n```\n utility code already in most \n```\nstd\n```\n implementations exposed Special math functions scientists may like them \n```\nstd::clamp()\n```\n \n```\nstd::clamp( a, b, c ) == std::max( b, std::min( a, c ) )\n```\n roughly \n```\ngcd\n```\n and \n```\nlcm\n```\n \n```\nstd::uncaught_exceptions\n```\n Required if you want to only throw if safe from destructors \n```\nstd::as_const\n```\n \n```\nstd::bool_constant\n```\n A whole bunch of \n```\n_v\n```\n template variables \n```\nstd::void_t<T>\n```\n Surprisingly useful when writing templates \n```\nstd::owner_less<void>\n```\n like \n```\nstd::less<void>\n```', '```\n A whole bunch of \n```\n_v\n```\n template variables \n```\nstd::void_t<T>\n```\n Surprisingly useful when writing templates \n```\nstd::owner_less<void>\n```\n like \n```\nstd::less<void>\n```\n, but for smart pointers to sort based on contents \n```\nstd::chrono\n```\n polish \n```\nstd::conjunction\n```\n, \n```\nstd::disjunction\n```\n, \n```\nstd::negation\n```\n exposed \n```\nstd::not_fn\n```\n http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0358r1.html Rules for noexcept within \n```\nstd\n```\n std::is_contiguous_layout, useful for efficient hashing std::to_chars/std::from_chars, high performance, locale agnostic number conversion; finally a way to serialize/deserialize to human readable formats (JSON & co) std::default_order, indirection over \n```\nstd::less\n```\n. (breaks ABI of some compilers due to name mangling, removed.) \n```\nmemory_order_consume\n```\n, added language to prefer use of \n```\nmemory_order_acquire\n```', '```\nstd::less\n```\n. (breaks ABI of some compilers due to name mangling, removed.) \n```\nmemory_order_consume\n```\n, added language to prefer use of \n```\nmemory_order_acquire\n```\n Traits swap is_aggregate has_unique_object_representations Deprecated Some C libraries, \n```\n<codecvt>\n```\n \n```\nresult_of\n```\n, replaced with \n```\ninvoke_result\n```\n \n```\nshared_ptr::unique\n```', '<codecvt>\n```\n \n```\nresult_of\n```\n, replaced with \n```\ninvoke_result\n```\n \n```\nshared_ptr::unique\n```\n, it isn\'t very threadsafe Isocpp.org has has an independent list of changes since C++14; it has been partly pillaged. Naturally TS work continues in parallel, so there are some TS that are not-quite-ripe that will have to wait for the next iteration. The target for the next iteration is C++20 as previously planned, not C++19 as some rumors implied. C++1O has been avoided. Initial list taken from this reddit post and this reddit post, with links added via googling or from the above isocpp.org page. Additional entries pillaged from SD-6 feature-test list. clang\'s feature list and library feature list are next to be pillaged. This doesn\'t seem to be reliable, as it is C++1z, not C++17. these slides had some features missing elsewhere. While ""what was removed"" was not asked, here is a short list of a few things ((mostly?) previous deprecated) that are removed in C++17 from C++: Removed:', '```\nregister\n```\n, keyword reserved for future use \n```\nbool b; ++b;\n```\n trigraphs if you still need them, they are now part of your source file encoding, not part of language ios aliases auto_ptr, old \n```\n<functional>\n```\n stuff, \n```\nrandom_shuffle\n```\n allocators in \n```\nstd::function\n```\n There were rewordings. I am unsure if these have any impact on code, or if they are just cleanups in the standard: Papers not yet integrated into above: P0505R0 (constexpr chrono) P0418R2 (atomic tweaks) P0512R0 (template argument deduction tweaks) P0490R0 (structured binding tweaks) P0513R0 (changes to \n```\nstd::hash\n```', '```\nstd::hash\n```\n) P0502R0 (parallel exceptions) P0509R1 (updating restrictions on exception handling) P0012R1 (make exception specifications be part of the type system) P0510R0 (restrictions on variants) P0504R0 (tags for optional/variant/any) P0497R0 (shared ptr tweaks) P0508R0 (structured bindings node handles) P0521R0 (shared pointer use count and unique changes?) Spec changes: exception specs and throw expressions Further reference: papers grouped by year; not all accepted https://isocpp.org/files/papers/p0636r0.html Should be updated to ""Modifications to existing features"" here.']","Language features: Templates and Generic Code Template argument deduction for class templates Like how functions deduce template arguments, now constructors can deduce the template arguments of the class http://wg21.link/p0433r2 http://wg21.link/p0620r0 http://wg21.link/p0512r0 
```
template <auto>
```
 Represents a value of any (non-type template argument) type. Non-type template arguments fixes 
```
template<template<class...>typename bob> struct foo {}
```
 ( Folding + ... + expressions ) and Revisions 
```
auto x{8};
```
 is an 
```
int
```
 modernizing 
```
using
```
 with 
```
...
```
 and lists Lambda constexpr lambdas Lambdas are implicitly constexpr if they qualify Capturing 
```
*this
```
 in lambdas 
```
[*this]{ std::cout << could << "" be "" << useful << '\n'; }
```
 Attributes 
```
[[fallthrough]]
```
, 
```
[[nodiscard]]
```
, 
```
[[maybe_unused]]
```
 attributes 
```
[[attributes]]
```
 on 
```
namespace
```
s and 
```
enum { erator[[s]] }
```
 
```
using
```
 in attributes to avoid having to repeat an attribute namespace. Compilers are now required to ignore non-standard attributes they don't recognize. The C++14 wording allowed compilers to reject unknown scoped attributes. Syntax cleanup Inline variables Like inline functions Compiler picks where the instance is instantiated Deprecate static constexpr redeclaration, now implicitly inline. 
```
namespace A::B
```
 Simple 
```
static_assert(expression);
```
 with no string no 
```
throw
```
 unless 
```
throw()
```
, and 
```
throw()
```
 is 
```
noexcept(true)
```
. Cleaner multi-return and flow control Structured bindings Basically, first-class 
```
std::tie
```
 with 
```
auto
```
 Example: 
```
const auto [it, inserted] = map.insert( {""foo"", bar} );
```
 Creates variables 
```
it
```
 and 
```
inserted
```
 with deduced type from the 
```
pair
```
 that 
```
map::insert
```
 returns. Works with tuple/pair-likes & 
```
std::array
```
s and relatively flat structs Actually named structured bindings in standard 
```
if (init; condition)
```
 and 
```
switch (init; condition)
```
 
```
if (const auto [it, inserted] = map.insert( {""foo"", bar} ); inserted)
```
 Extends the 
```
if(decl)
```
 to cases where 
```
decl
```
 isn't convertible-to-bool sensibly. Generalizing range-based for loops Appears to be mostly support for sentinels, or end iterators that are not the same type as begin iterators, which helps with null-terminated loops and the like. if constexpr Much requested feature to simplify almost-generic code. Misc Hexadecimal float point literals Dynamic memory allocation for over-aligned data Guaranteed copy elision Finally! Not in all cases, but distinguishes syntax where you are ""just creating something"" that was called elision, from ""genuine elision"". Fixed order-of-evaluation for (some) expressions with some modifications Not including function arguments, but function argument evaluation interleaving now banned Makes a bunch of broken code work mostly, and makes 
```
.then
```
 on future work. Direct list-initialization of enums Forward progress guarantees (FPG) (also, FPGs for parallel algorithms) I think this is saying ""the implementation may not stall threads forever""? 
```
u8'U', u8'T', u8'F', u8'8'
```
 character literals (string already existed) ""noexcept"" in the type system 
```
__has_include
```
 Test if a header file include would be an error makes migrating from experimental to std almost seamless Arrays of pointer conversion fixes inherited constructors fixes to some corner cases (see P0136R0 for examples of behavior changes) aggregate initialization with inheritance. 
```
std::launder
```
, type punning, etc Library additions: Data types 
```
std::variant<Ts...>
```
 Almost-always non-empty last I checked? Tagged union type {awesome|useful} 
```
std::optional
```
 Maybe holds one of something Ridiculously useful 
```
std::any
```
 Holds one of anything (that is copyable) 
```
std::string_view
```
 
```
std::string
```
 like reference-to-character-array or substring Never take a 
```
string const&
```
 again. Also can make parsing a bajillion times faster. 
```
""hello world""sv
```
 constexpr 
```
char_traits
```
 
```
std::byte
```
 off more than they could chew. Neither an integer nor a character, just data Invoke stuff 
```
std::invoke
```
 Call any callable (function pointer, function, member pointer) with one syntax. From the standard INVOKE concept. 
```
std::apply
```
 Takes a function-like and a tuple, and unpacks the tuple into the call. 
```
std::make_from_tuple
```
, 
```
std::apply
```
 applied to object construction 
```
is_invocable
```
, 
```
is_invocable_r
```
, 
```
invoke_result
```
 http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0077r2.html http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0604r0.html Deprecates 
```
result_of
```
 
```
is_invocable<Foo(Args...), R>
```
 is ""can you call 
```
Foo
```
 with 
```
Args...
```
 and get something compatible with 
```
R
```
"", where 
```
R=void
```
 is default. 
```
invoke_result<Foo, Args...>
```
 is 
```
std::result_of_t<Foo(Args...)>
```
 but apparently less confusing? File System TS v1 
```
[class.path]
```
 
```
[class.filesystem.error]
```
 
```
[class.file_status]
```
 
```
[class.directory_entry]
```
 
```
[class.directory_iterator]
```
 and 
```
[class.recursive_directory_iterator]
```
 
```
[fs.ops.funcs]
```
 
```
fstream
```
s can be opened with 
```
path
```
s, as well as with 
```
const path::value_type*
```
 strings. New algorithms 
```
for_each_n
```
 
```
reduce
```
 
```
transform_reduce
```
 
```
exclusive_scan
```
 
```
inclusive_scan
```
 
```
transform_exclusive_scan
```
 
```
transform_inclusive_scan
```
 Added for threading purposes, exposed even if you aren't using them threaded Threading 
```
std::shared_mutex
```
 Untimed, which can be more efficient if you don't need it. 
```
atomic<T>
```

```
::is_always_lockfree
```
 
```
scoped_lock<Mutexes...>
```
 Saves some 
```
std::lock
```
 pain when locking more than one mutex at a time. Parallelism TS v1 The linked paper from 2014, may be out of date Parallel versions of 
```
std
```
 algorithms, and related machinery hardware_*_interference_size (parts of) Library Fundamentals TS v1 not covered above or below 
```
[func.searchers]
```
 and 
```
[alg.search]
```
 A searching algorithm and techniques 
```
[pmr]
```
 Polymorphic allocator, like 
```
std::function
```
 for allocators And some standard memory resources to go with it. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0358r1.html 
```
std::sample
```
, sampling from a range? Container Improvements 
```
try_emplace
```
 and 
```
insert_or_assign
```
 gives better guarantees in some cases where spurious move/copy would be bad Splicing for 
```
map<>
```
, 
```
unordered_map<>
```
, 
```
set<>
```
, and 
```
unordered_set<>
```
 Move nodes between containers cheaply. Merge whole containers cheaply. non-const 
```
.data()
```
 for string. non-member 
```
std::size
```
, 
```
std::empty
```
, 
```
std::data
```
 like 
```
std::begin
```
/
```
end
```
 Minimal incomplete type support in containers Contiguous iterator ""concept"" 
```
constexpr
```
 iterators The 
```
emplace
```
 family of functions now returns a reference to the created object. Smart pointer changes 
```
unique_ptr<T[]>
```
 fixes and other 
```
unique_ptr
```
 tweaks. 
```
weak_from_this
```
 and some fixed to shared from this Other 
```
std
```
 datatype improvements: 
```
{}
```
 construction of 
```
std::tuple
```
 and other improvements TriviallyCopyable reference_wrapper, can be performance boost Misc C++17 library is based on C11 instead of C99 Reserved 
```
std[0-9]+
```
 for future standard libraries 
```
destroy(_at|_n)
```
, 
```
uninitialized_move(_n)
```
, 
```
uninitialized_value_construct(_n)
```
, 
```
uninitialized_default_construct(_n)
```
 utility code already in most 
```
std
```
 implementations exposed Special math functions scientists may like them 
```
std::clamp()
```
 
```
std::clamp( a, b, c ) == std::max( b, std::min( a, c ) )
```
 roughly 
```
gcd
```
 and 
```
lcm
```
 
```
std::uncaught_exceptions
```
 Required if you want to only throw if safe from destructors 
```
std::as_const
```
 
```
std::bool_constant
```
 A whole bunch of 
```
_v
```
 template variables 
```
std::void_t<T>
```
 Surprisingly useful when writing templates 
```
std::owner_less<void>
```
 like 
```
std::less<void>
```
, but for smart pointers to sort based on contents 
```
std::chrono
```
 polish 
```
std::conjunction
```
, 
```
std::disjunction
```
, 
```
std::negation
```
 exposed 
```
std::not_fn
```
 http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0358r1.html Rules for noexcept within 
```
std
```
 std::is_contiguous_layout, useful for efficient hashing std::to_chars/std::from_chars, high performance, locale agnostic number conversion; finally a way to serialize/deserialize to human readable formats (JSON & co) std::default_order, indirection over 
```
std::less
```
. (breaks ABI of some compilers due to name mangling, removed.) 
```
memory_order_consume
```
, added language to prefer use of 
```
memory_order_acquire
```
 Traits swap is_aggregate has_unique_object_representations Deprecated Some C libraries, 
```
<codecvt>
```
 
```
result_of
```
, replaced with 
```
invoke_result
```
 
```
shared_ptr::unique
```
, it isn't very threadsafe Isocpp.org has has an independent list of changes since C++14; it has been partly pillaged. Naturally TS work continues in parallel, so there are some TS that are not-quite-ripe that will have to wait for the next iteration. The target for the next iteration is C++20 as previously planned, not C++19 as some rumors implied. C++1O has been avoided. Initial list taken from this reddit post and this reddit post, with links added via googling or from the above isocpp.org page. Additional entries pillaged from SD-6 feature-test list. clang's feature list and library feature list are next to be pillaged. This doesn't seem to be reliable, as it is C++1z, not C++17. these slides had some features missing elsewhere. While ""what was removed"" was not asked, here is a short list of a few things ((mostly?) previous deprecated) that are removed in C++17 from C++: Removed: 
```
register
```
, keyword reserved for future use 
```
bool b; ++b;
```
 trigraphs if you still need them, they are now part of your source file encoding, not part of language ios aliases auto_ptr, old 
```
<functional>
```
 stuff, 
```
random_shuffle
```
 allocators in 
```
std::function
```
 There were rewordings. I am unsure if these have any impact on code, or if they are just cleanups in the standard: Papers not yet integrated into above: P0505R0 (constexpr chrono) P0418R2 (atomic tweaks) P0512R0 (template argument deduction tweaks) P0490R0 (structured binding tweaks) P0513R0 (changes to 
```
std::hash
```
) P0502R0 (parallel exceptions) P0509R1 (updating restrictions on exception handling) P0012R1 (make exception specifications be part of the type system) P0510R0 (restrictions on variants) P0504R0 (tags for optional/variant/any) P0497R0 (shared ptr tweaks) P0508R0 (structured bindings node handles) P0521R0 (shared pointer use count and unique changes?) Spec changes: exception specs and throw expressions Further reference: papers grouped by year; not all accepted https://isocpp.org/files/papers/p0636r0.html Should be updated to ""Modifications to existing features"" here."
612328,Difference between 'struct' and 'typedef struct' in C++?,https://stackoverflow.com/questions/612328/difference-between-struct-and-typedef-struct-in-c,8,1396.0,"[""In C++, there is only a subtle difference. It's a holdover from C, in which it makes a difference. The C language standard (C89 §3.1.2.3, C99 §6.2.3, and C11 §6.2.3) mandates separate namespaces for different categories of identifiers, including tag identifiers (for \n```\nstruct\n```\n/\n```\nunion\n```\n/\n```\nenum\n```\n) and ordinary identifiers (for \n```\ntypedef\n```\n and other identifiers). If you just said: \n```\nstruct Foo { ... };\nFoo x;\n\n```\n you would get a compiler error, because \n```\nFoo\n```\n is only defined in the tag namespace. You'd have to declare it as: \n```\nstruct Foo x;\n\n```\n Any time you want to refer to a \n```\nFoo\n```\n, you'd always have to call it a \n```\nstruct Foo\n```\n. This gets annoying fast, so you can add a \n```\ntypedef\n```\n: \n```\nstruct Foo { ... };\ntypedef struct Foo Foo;"", '```\n Now \n```\nstruct Foo\n```\n (in the tag namespace) and just plain \n```\nFoo\n```\n (in the ordinary identifier namespace) both refer to the same thing, and you can freely declare objects of type \n```\nFoo\n```\n without the \n```\nstruct\n```\n keyword. The construct: \n```\ntypedef struct Foo { ... } Foo;\n\n```\n is just an abbreviation for the declaration and \n```\ntypedef\n```\n. Finally, \n```\ntypedef struct { ... } Foo;', ""```\n is just an abbreviation for the declaration and \n```\ntypedef\n```\n. Finally, \n```\ntypedef struct { ... } Foo;\n\n```\n declares an anonymous structure and creates a \n```\ntypedef\n```\n for it. Thus, with this construct, it doesn't have a name in the tag namespace, only a name in the typedef namespace. This means it also cannot be forward-declared. If you want to make a forward declaration, you have to give it a name in the tag namespace. In C++, all \n```\nstruct\n```\n/\n```\nunion\n```\n/\n```\nenum\n```\n/\n```\nclass\n```\n declarations act like they are implicitly \n```\ntypedef\n```\n'ed, as long as the name is not hidden by another declaration with the same name. See Michael Burr's answer for the full details.""]","In C++, there is only a subtle difference. It's a holdover from C, in which it makes a difference. The C language standard (C89 §3.1.2.3, C99 §6.2.3, and C11 §6.2.3) mandates separate namespaces for different categories of identifiers, including tag identifiers (for 
```
struct
```
/
```
union
```
/
```
enum
```
) and ordinary identifiers (for 
```
typedef
```
 and other identifiers). If you just said: 
```
struct Foo { ... };
Foo x;

```
 you would get a compiler error, because 
```
Foo
```
 is only defined in the tag namespace. You'd have to declare it as: 
```
struct Foo x;

```
 Any time you want to refer to a 
```
Foo
```
, you'd always have to call it a 
```
struct Foo
```
. This gets annoying fast, so you can add a 
```
typedef
```
: 
```
struct Foo { ... };
typedef struct Foo Foo;

```
 Now 
```
struct Foo
```
 (in the tag namespace) and just plain 
```
Foo
```
 (in the ordinary identifier namespace) both refer to the same thing, and you can freely declare objects of type 
```
Foo
```
 without the 
```
struct
```
 keyword. The construct: 
```
typedef struct Foo { ... } Foo;

```
 is just an abbreviation for the declaration and 
```
typedef
```
. Finally, 
```
typedef struct { ... } Foo;

```
 declares an anonymous structure and creates a 
```
typedef
```
 for it. Thus, with this construct, it doesn't have a name in the tag namespace, only a name in the typedef namespace. This means it also cannot be forward-declared. If you want to make a forward declaration, you have to give it a name in the tag namespace. In C++, all 
```
struct
```
/
```
union
```
/
```
enum
```
/
```
class
```
 declarations act like they are implicitly 
```
typedef
```
'ed, as long as the name is not hidden by another declaration with the same name. See Michael Burr's answer for the full details."
154136,Why use apparently meaningless do-while and if-else statements in macros?,https://stackoverflow.com/questions/154136/why-use-apparently-meaningless-do-while-and-if-else-statements-in-macros,9,995.0,"[""The \n```\ndo ... while\n```\n and \n```\nif ... else\n```\n are there to make it so that a semicolon after your macro always means the same thing. Let's say you had something like your second macro. \n```\n#define BAR(X) f(x); g(x)\n\n```\n Now if you were to use \n```\nBAR(X);\n```\n in an \n```\nif ... else\n```\n statement, where the bodies of the if statement were not wrapped in curly brackets, you'd get a bad surprise. \n```\nif (corge)\n  BAR(corge);\nelse\n  gralt();\n\n```\n The above code would expand into \n```\nif (corge)\n  f(corge); g(corge);\nelse\n  gralt();\n\n```\n which is syntactically incorrect, as the else is no longer associated with the if. It doesn't help to wrap things in curly braces within the macro, because a semicolon after the braces is syntactically incorrect. \n```\nif (corge)\n  {f(corge); g(corge);};\nelse\n  gralt();"", ""```\n There are two ways of fixing the problem. The first is to use a comma to sequence statements within the macro without robbing it of its ability to act like an expression. \n```\n#define BAR(X) f(X), g(X)\n\n```\n The above version of bar \n```\nBAR\n```\n expands the above code into what follows, which is syntactically correct. \n```\nif (corge)\n  f(corge), g(corge);\nelse\n  gralt();\n\n```\n This doesn't work if instead of \n```\nf(X)\n```\n you have a more complicated body of code that needs to go in its own block, say for example to declare local variables. In the most general case the solution is to use something like \n```\ndo ... while\n```\n to cause the macro to be a single statement that takes a semicolon without confusion. \n```\n#define BAR(X) do { \\\n  int i = f(X); \\\n  if (i > 4) g(i); \\\n} while (0)"", '```\n You don\'t have to use \n```\ndo ... while\n```\n, you could cook up something with \n```\nif ... else\n```\n as well, although when \n```\nif ... else\n```\n expands inside of an \n```\nif ... else\n```\n it leads to a ""dangling else"", which could make an existing dangling else problem even harder to find, as in the following code. \n```\nif (corge)\n  if (1) { f(corge); g(corge); } else;\nelse\n  gralt();\n\n```\n The point is to use up the semicolon in contexts where a dangling semicolon is erroneous. Of course, it could (and probably should) be argued at this point that it would be better to declare \n```\nBAR\n```\n as an actual function, not a macro. In summary, the \n```\ndo ... while\n```\n is there to work around the shortcomings of the C preprocessor. When those C style guides tell you to lay off the C preprocessor, this is the kind of thing they\'re worried about.']","The 
```
do ... while
```
 and 
```
if ... else
```
 are there to make it so that a semicolon after your macro always means the same thing. Let's say you had something like your second macro. 
```
#define BAR(X) f(x); g(x)

```
 Now if you were to use 
```
BAR(X);
```
 in an 
```
if ... else
```
 statement, where the bodies of the if statement were not wrapped in curly brackets, you'd get a bad surprise. 
```
if (corge)
  BAR(corge);
else
  gralt();

```
 The above code would expand into 
```
if (corge)
  f(corge); g(corge);
else
  gralt();

```
 which is syntactically incorrect, as the else is no longer associated with the if. It doesn't help to wrap things in curly braces within the macro, because a semicolon after the braces is syntactically incorrect. 
```
if (corge)
  {f(corge); g(corge);};
else
  gralt();

```
 There are two ways of fixing the problem. The first is to use a comma to sequence statements within the macro without robbing it of its ability to act like an expression. 
```
#define BAR(X) f(X), g(X)

```
 The above version of bar 
```
BAR
```
 expands the above code into what follows, which is syntactically correct. 
```
if (corge)
  f(corge), g(corge);
else
  gralt();

```
 This doesn't work if instead of 
```
f(X)
```
 you have a more complicated body of code that needs to go in its own block, say for example to declare local variables. In the most general case the solution is to use something like 
```
do ... while
```
 to cause the macro to be a single statement that takes a semicolon without confusion. 
```
#define BAR(X) do { \
  int i = f(X); \
  if (i > 4) g(i); \
} while (0)

```
 You don't have to use 
```
do ... while
```
, you could cook up something with 
```
if ... else
```
 as well, although when 
```
if ... else
```
 expands inside of an 
```
if ... else
```
 it leads to a ""dangling else"", which could make an existing dangling else problem even harder to find, as in the following code. 
```
if (corge)
  if (1) { f(corge); g(corge); } else;
else
  gralt();

```
 The point is to use up the semicolon in contexts where a dangling semicolon is erroneous. Of course, it could (and probably should) be argued at this point that it would be better to declare 
```
BAR
```
 as an actual function, not a macro. In summary, the 
```
do ... while
```
 is there to work around the shortcomings of the C preprocessor. When those C style guides tell you to lay off the C preprocessor, this is the kind of thing they're worried about."
40354978,Why does C++ code for testing the Collatz conjecture run faster than hand-written assembly?,https://stackoverflow.com/questions/40354978/why-does-c-code-for-testing-the-collatz-conjecture-run-faster-than-hand-writte,11,2134.0,"[""If you think a 64-bit DIV instruction is a good way to divide by two, then no wonder the compiler's asm output beat your hand-written code, even with \n```\n-O0\n```"", ""```\n-O0\n```\n (compile fast, no extra optimization, and store/reload to memory after/before every C statement so a debugger can modify variables). See Agner Fog's Optimizing Assembly guide to learn how to write efficient asm. He also has instruction tables and a microarch guide for specific details for specific CPUs. See also the x86 tag wiki for more perf links. See also this more general question about beating the compiler with hand-written asm: Is inline assembly language slower than native C++ code?. TL:DR: yes if you do it wrong (like this question). Usually you're fine letting the compiler do its thing, especially if you try to write C++ that can compile efficiently. Also see is assembly faster than compiled languages?. One of the answers links to these neat slides showing how various C compilers optimize some really simple functions with cool tricks. Matt Godbolt's CppCon2017 talk “What Has My Compiler Done for Me Lately? Unbolting the Compiler's Lid” is in a similar vein. \n```"", '```\neven:\n    mov rbx, 2\n    xor rdx, rdx\n    div rbx', ""```\n On Intel Haswell, \n```\ndiv r64\n```\n is 36 uops, with a latency of 32-96 cycles, and a throughput of one per 21-74 cycles. (Plus the 2 uops to set up RBX and zero RDX, but out-of-order execution can run those early). High-uop-count instructions like DIV are microcoded, which can also cause front-end bottlenecks. In this case, latency is the most relevant factor because it's part of a loop-carried dependency chain. \n```\nshr rax, 1\n```\n does the same unsigned division: It's 1 uop, with 1c latency, and can run 2 per clock cycle. For comparison, 32-bit division is faster, but still horrible vs. shifts. \n```\nidiv r32\n```\n is 9 uops, 22-29c latency, and one per 8-11c throughput on Haswell. As you can see from looking at gcc's \n```\n-O0\n```\n asm output (Godbolt compiler explorer), it only uses shifts instructions. clang \n```\n-O0\n```"", '```\n-O0\n```\n asm output (Godbolt compiler explorer), it only uses shifts instructions. clang \n```\n-O0\n```\n does compile naively like you thought, even using 64-bit IDIV twice. (When optimizing, compilers do use both outputs of IDIV when the source does a division and modulus with the same operands, if they use IDIV at all) GCC doesn\'t have a totally-naive mode; it always transforms through GIMPLE, which means some ""optimizations"" can\'t be disabled. This includes recognizing division-by-constant and using shifts (power of 2) or a fixed-point multiplicative inverse (non power of 2) to avoid IDIV (see \n```\ndiv_by_13\n```\n in the above godbolt link). \n```\ngcc -Os\n```\n (optimize for size) does use IDIV for non-power-of-2 division, unfortunately even in cases where the multiplicative inverse code is only slightly larger but much faster. Helping the compiler (summary for this case: use \n```\nuint64_t n\n```\n) First of all, it\'s only interesting to look at optimized compiler output. (\n```\n-O3', ""```\nuint64_t n\n```\n) First of all, it's only interesting to look at optimized compiler output. (\n```\n-O3\n```\n). \n```\n-O0\n```"", 'speed is basically meaningless. Look at your asm output (on Godbolt, or see How to remove ""noise"" from GCC/clang assembly output?). When the compiler doesn\'t make optimal code in the first place: Writing your C/C++ source in a way that guides the compiler into making better code is usually the best approach. You have to know asm, and know what\'s efficient, but you apply this knowledge indirectly. Compilers are also a good source of ideas: sometimes clang will do something cool, and you can hand-hold gcc into doing the same thing: see this answer and what I did with the non-unrolled loop in @Veedrac\'s code below.) This approach is portable, and in 20 years some future compiler can compile it to whatever is efficient on future hardware (x86 or not), maybe using new ISA extension or auto-vectorizing. Hand-written x86-64 asm from 15 years ago would usually not be optimally tuned for Skylake. e.g. compare&branch macro-fusion didn\'t exist back then. What\'s optimal now for hand-crafted asm', ""Hand-written x86-64 asm from 15 years ago would usually not be optimally tuned for Skylake. e.g. compare&branch macro-fusion didn't exist back then. What's optimal now for hand-crafted asm for one microarchitecture might not be optimal for other current and future CPUs. Comments on @johnfound's answer discuss major differences between AMD Bulldozer and Intel Haswell, which have a big effect on this code. But in theory,"", '```\ng++ -O3 -march=bdver3\n```\n and \n```\ng++ -O3 -march=skylake\n```\n will do the right thing. (Or \n```\n-march=native\n```\n.) Or \n```\n-mtune=...\n```', ""```\n.) Or \n```\n-mtune=...\n```\n to just tune, without using instructions that other CPUs might not support. My feeling is that guiding the compiler to asm that's good for a current CPU you care about shouldn't be a problem for future compilers. They're hopefully better than current compilers at finding ways to transform code, and can find a way that works for future CPUs. Regardless, future x86 probably won't be terrible at anything that's good on current x86, and the future compiler will avoid any asm-specific pitfalls while implementing something like the data movement from your C source, if it doesn't see something better. Hand-written asm is a black-box for the optimizer, so constant-propagation doesn't work when inlining makes an input a compile-time constant. Other optimizations are also affected. Read https://gcc.gnu.org/wiki/DontUseInlineAsm before using asm. (And avoid MSVC-style inline asm: inputs/outputs have to go through memory which adds overhead.) In this case: your \n```"", '```\nn\n```\n has a signed type, and gcc uses the SAR/SHR/ADD sequence that gives the correct rounding. (IDIV and arithmetic-shift ""round"" differently for negative inputs, see the SAR insn set ref manual entry). (IDK if gcc tried and failed to prove that \n```\nn\n```\n can\'t be negative, or what. Signed-overflow is undefined behaviour, so it should have been able to.) You should have used \n```\nuint64_t n\n```\n, so it can just SHR. And so it\'s portable to systems where \n```\nlong\n```\n is only 32-bit (e.g. x86-64 Windows). BTW, gcc\'s optimized asm output looks pretty good (using \n```\nunsigned long n\n```\n): the inner loop it inlines into \n```\nmain()\n```\n does this: \n```\n# from gcc5.4 -O3  plus my comments\n# edx= count=1\n# rax= uint64_t n', '.L9:              # do{\n    lea    rcx, [rax+1+rax*2]   # rcx = 3*n + 1\n    mov    rdi, rax\n    shr    rdi        # rdi = n>>1;\n    test   al, 1      # set flags based on n%2 (aka n&1)\n    mov    rax, rcx\n    cmove  rax, rdi   # n= (n%2) ? 3*n+1 : n/2;\n    add    edx, 1     # ++count;\n    cmp    rax, 1\n    jne   .L9      #}while(n!=1)\n\n  cmp/branch to update max and maxi, and then do the next n', ""```\n The inner loop is branchless, and the critical path of the loop-carried dependency chain is: 3-component LEA (3 cycles on Intel before Ice Lake) cmov (2 cycles on Haswell, 1c on Broadwell or later). Total: 5 cycle per iteration, latency bottleneck. Out-of-order execution takes care of everything else in parallel with this (in theory: I haven't tested with perf counters to see if it really runs at 5c/iter). The FLAGS input of \n```\ncmov\n```"", ""```\ncmov\n```\n (produced by TEST) is faster to produce than the RAX input (from LEA->MOV), so it's not on the critical path. Similarly, the MOV->SHR that produces CMOV's RDI input is off the critical path, because it's also faster than the LEA. MOV on IvyBridge and later has zero latency (handled at register-rename time). (It still takes a uop, and a slot in the pipeline, so it's not free, just zero latency). The extra MOV in the LEA dep chain is part of the bottleneck on other CPUs. The cmp/jne is also not part of the critical path: it's not loop-carried, because control dependencies are handled with branch prediction + speculative execution, unlike data dependencies on the critical path. Beating the compiler GCC did a pretty good job here. It could save one code byte by using \n```\ninc edx\n```\n instead of \n```\nadd edx, 1\n```"", '```\ninc edx\n```\n instead of \n```\nadd edx, 1\n```\n, because nobody cares about P4 and its false-dependencies for partial-flag-modifying instructions. It could also save all the MOV instructions, and the TEST: SHR sets CF= the bit shifted out, so we can use \n```\ncmovc\n```\n instead of \n```\ntest\n```\n / \n```\ncmovz\n```\n. \n```\n ### Hand-optimized version of what gcc does\n.L9:                  #do{\n  lea     rcx, [rax+1+rax*2] # rcx = 3*n + 1\n  shr     rax, 1       # n>>=1;    CF = n&1 = n%2\n  cmovc   rax, rcx     # n= (n&1) ? 3*n+1 : n/2;\n  inc     edx          # ++count;\n  cmp     rax, 1\n  jne     .L9         #}while(n!=1)', '```', 'See @johnfound\'s answer for another clever trick: remove the CMP by branching on SHR\'s flag result as well as using it for CMOV: zero only if n was 1 (or 0) to start with. (SHR with count != 1 on Nehalem or earlier causes a stall if you read the flag results. That\'s how they made it single-uop. The shift-by-1 encoding is fine, though.) Avoiding MOV doesn\'t help with the latency at all on Haswell (Can x86\'s MOV really be ""free""? Why can\'t I reproduce this at all?). It does help significantly on CPUs like Intel pre-IvB, and AMD Bulldozer-family, where MOV is not zero-latency (and Ice Lake with updated microcode). The compiler\'s wasted MOV instructions do affect the critical path. BD\'s complex-LEA and CMOV are both lower latency (2c and 1c respectively), so it\'s a bigger fraction of the latency. Also, throughput bottlenecks become an issue on BD because it only has two integer ALU pipes. See @johnfound\'s answer, where he has timing results from an AMD CPU. Even on Haswell, this version', ""Also, throughput bottlenecks become an issue on BD because it only has two integer ALU pipes. See @johnfound's answer, where he has timing results from an AMD CPU. Even on Haswell, this version may help a bit by avoiding some occasional delays where a non-critical uop steals an execution port from one on the critical path, delaying execution by 1 cycle. (This is called a resource conflict). It also saves a register, which may help when doing multiple"", ""```\nn\n```\n values in parallel in an interleaved loop (see below). LEA's latency depends on the addressing mode, on Intel SnB-family CPUs before Ice Lake. 3c for 3 components (\n```\n[base+idx+const]\n```\n, which takes two separate adds), but only 1c with 2 or fewer components (one add). Some CPUs (like Core2) do even a 3-component LEA in a single cycle. Worse, SnB-family standardizes latencies: no 2c uops, otherwise 3-component LEA would be only 2c like Bulldozer. (3-component LEA is slower on AMD too, just not by as much). Ice Lake improved the LEA execution units to be 1c latency for all addressing modes, and 4/clock throughput except with a scaled index (then 2/clock). Alder Lake / Sapphire Rapids has 2c latency for shifted-index. (https://uops.info/). Zen 3 and later run 3-component LEAs as 2 uops. So \n```\nlea  rcx, [rax + rax*2]\n```\n / \n```\ninc rcx\n```\n is only 2c latency, faster than \n```\nlea  rcx, [rax + rax*2 + 1]\n```"", ""on Intel before Ice Lake. Break-even on BD and Alder Lake, and worse on Core2 and Ice Lake. It costs an extra uop which often isn't worth it to save 1c latency, but latency is the major bottleneck here and HSW has a wide pipeline. Neither GCC, ICC, nor Clang (on godbolt) used SHR's CF output, always using an AND or TEST. Silly compilers. :P They're great pieces of complex machinery, but a clever human can often beat them on small-scale problems. (Given thousands to millions of times longer to think about it, of course! Compilers don't use exhaustive algorithms to search for every possible way to do things; that would take too long when optimizing a lot of inlined code, which is what they do best. They also don't model the pipeline in the target uarch, not in the same detail as IACA or especially https://uica.uops.info/; they just use some heuristics.) Simple loop unrolling won't help; this loop bottlenecks on the latency of a loop-carried dependency chain, not on loop overhead /"", ""especially https://uica.uops.info/; they just use some heuristics.) Simple loop unrolling won't help; this loop bottlenecks on the latency of a loop-carried dependency chain, not on loop overhead / throughput. This means it would do well with hyperthreading (or any other kind of SMT), since the CPU has lots of time to interleave instructions from two threads. This would mean parallelizing the loop in"", ""```\nmain\n```\n, but that's fine because each thread can just check a range of \n```\nn\n```\n values and produce a pair of integers as a result. Interleaving by hand within a single thread might be viable, too. Maybe compute the sequence for a pair of numbers in parallel, since each one only takes a couple registers, and they can all update the same \n```\nmax\n```\n / \n```\nmaxi\n```\n. This creates more instruction-level parallelism. The trick is deciding whether to wait until all the \n```\nn\n```\n values have reached \n```\n1\n```\n before getting another pair of starting \n```\nn\n```\n values, or whether to break out and get a new start point for just one that reached the end condition, without touching the registers for the other sequence. Probably it's best to keep each chain working on useful data, otherwise you'd have to conditionally increment its counter. You could maybe even do this with SSE packed-compare stuff to conditionally increment the counter for vector elements where \n```\nn\n```"", '```\nn\n```\n hadn\'t reached \n```\n1\n```\n yet. And then to hide the even longer latency of a SIMD conditional-increment implementation, you\'d need to keep more vectors of \n```\nn\n```\n values up in the air. Maybe only worth with 256b vector (4x \n```\nuint64_t\n```\n). I think the best strategy to make detection of a \n```\n1\n```\n ""sticky"" is to mask the vector of all-ones that you add to increment the counter. So after you\'ve seen a \n```\n1\n```\n in an element, the increment-vector will have a zero, and +=0 is a no-op. Untested idea for manual vectorization \n```\n# starting with YMM0 = [ n_d, n_c, n_b, n_a ]  (64-bit elements)\n# ymm4 = _mm256_set1_epi64x(1):  increment vector\n# ymm5 = all-zeros:  count vector', "".inner_loop:\n  vpaddq    ymm1, ymm0, xmm0\n  vpaddq    ymm1, ymm1, xmm0\n  vpaddq    ymm1, ymm1, set1_epi64(1)     # ymm1= 3*n + 1.  Maybe could do this more efficiently?\n\n  vpsllq    ymm3, ymm0, 63                # shift bit 1 to the sign bit\n\n  vpsrlq    ymm0, ymm0, 1                 # n /= 2\n\n  # FP blend between integer insns may cost extra bypass latency, but integer blends don't have 1 bit controlling a whole qword.\n  vpblendvpd ymm0, ymm0, ymm1, ymm3       # variable blend controlled by the sign bit of each 64-bit element.  I might have the source operands backwards, I always have to look this up.\n\n  # ymm0 = updated n  in each element.\n\n  vpcmpeqq ymm1, ymm0, set1_epi64(1)\n  vpandn   ymm4, ymm1, ymm4         # zero out elements of ymm4 where the compare was true\n\n  vpaddq   ymm5, ymm5, ymm4         # count++ in elements where n has never been == 1"", 'vpaddq   ymm5, ymm5, ymm4         # count++ in elements where n has never been == 1\n\n  vptest   ymm4, ymm4\n  jnz  .inner_loop\n  # Fall through when all the n values have reached 1 at some point, and our increment vector is all-zero\n\n  vextracti128 ymm0, ymm5, 1\n  vpmaxuq .... oops, requires AVX-512\n  # delay doing a horizontal max until the very end.  But you need some way to record max and maxi.', ""```\n You can and should implement this with intrinsics, not hand-written asm. Algorithmic / implementation improvement: Besides just implementing the same logic with more efficient asm, look for ways to simplify the logic, or avoid redundant work. e.g. memoize to detect common endings to sequences. Or even better, look at 8 trailing bits at once (gnasher's answer) @EOF points out that \n```\ntzcnt\n```\n (or \n```\nbsf\n```\n) could be used to do multiple \n```\nn/=2\n```\n iterations in one step. To vectorize that efficiently, we probably need AVX-512 \n```\nvplzcntq\n```\n after isolating the lowest set bit with \n```\nv & (v-1)\n```\n). Or just do multiple scalar \n```\nn\n```\ns in parallel in different integer regs. The loop might look like this: \n```\ngoto loop_entry;  // C++ structured like the asm, for illustration only\ndo {\n   n = n*3 + 1;\n  loop_entry:\n   shift = _tzcnt_u64(n);\n   n >>= shift;\n   count += shift;\n} while(n != 1);"", '```\n This may do significantly fewer iterations, but variable-count shifts are slow on Intel SnB-family CPUs without BMI2. 3 uops, 2c latency for FLAGS, although only 1c for the actual data. (count=0 means the flags are unmodified. They handle this as a data dependency, and take multiple uops because a uop can only have 2 inputs (pre-HSW/BDW anyway)). This is the kind of thing that people complaining about x86\'s crazy-CISC design are referring to. It makes x86 CPUs slower than they would be if the ISA was designed from scratch today, even in a mostly-similar way. (i.e. this is part of the ""x86 tax"" of speed / power cost.) BMI2 SHRX/SHLX/SARX are 1 uop / 1c latency. It also puts tzcnt (3c on Haswell and later) on the critical path, so it significantly lengthens the total latency of the loop-carried dependency chain. It does remove any need for a CMOV, or for preparing a register holding \n```\nn>>1\n```', ""```\nn>>1\n```\n, though. @Veedrac's answer overcomes all this by deferring the tzcnt/shift for multiple iterations, which is highly effective (see below). We can safely use BSF or TZCNT interchangeably, because \n```\nn\n```\n can never be zero at that point. TZCNT's machine-code decodes as BSF on CPUs that don't support BMI1. (Meaningless prefixes are ignored, so REP BSF runs as BSF). TZCNT performs much better than BSF on AMD CPUs that support it, so it can be a good idea to use \n```\nREP BSF\n```\n, even if you don't care about setting ZF if the input is zero rather than the output. Some compilers do this when you use \n```\n__builtin_ctzll\n```\n even with \n```\n-mno-bmi\n```"", "". They perform the same on Intel CPUs, so just save the byte if that's all that matters. TZCNT on Intel (pre-Skylake) still has a false-dependency on the supposedly write-only output operand, just like BSF, to support the undocumented behaviour that BSF with input = 0 leaves its destination unmodified. So you need to work around that unless optimizing only for Skylake, so there's nothing to gain from the extra REP byte. (Intel often goes above and beyond what the x86 ISA manual requires, to avoid breaking widely-used code that depends on something it shouldn't, or that is retroactively disallowed. e.g. Windows 9x's assumes no speculative prefetching of TLB entries, which was safe when the code was written, before Intel updated the TLB management rules.) Anyway, LZCNT/TZCNT on Haswell have the same false dep as POPCNT: see this Q&A. This is why in gcc's asm output for @Veedrac's code, you see it breaking the dep chain with xor-zeroing on the register it's about to use as TZCNT's"", 'have the same false dep as POPCNT: see this Q&A. This is why in gcc\'s asm output for @Veedrac\'s code, you see it breaking the dep chain with xor-zeroing on the register it\'s about to use as TZCNT\'s destination when it doesn\'t use dst=src. Since TZCNT/LZCNT/POPCNT never leave their destination undefined or unmodified, this false dependency on the output on Intel CPUs is a performance bug / limitation. Presumably it\'s worth some transistors / power to have them behave like other uops that go to the same execution unit. The only perf upside is interaction with another uarch limitation: they can micro-fuse a memory operand with an indexed addressing mode on Haswell, but on Skylake where Intel removed the false dep for LZCNT/TZCNT they ""un-laminate"" indexed addressing modes while POPCNT can still micro-fuse any addr mode. Improvements to ideas / code from other answers: @hidefromkgb\'s answer has a nice observation that you\'re guaranteed to be able to do one right shift after a 3n+1. You', ""still micro-fuse any addr mode. Improvements to ideas / code from other answers: @hidefromkgb's answer has a nice observation that you're guaranteed to be able to do one right shift after a 3n+1. You can compute this more even more efficiently than just leaving out the checks between steps. The asm implementation in that answer is broken, though (it depends on OF, which is undefined after SHRD with a count > 1), and slow:"", ""```\nROR rdi,2\n```\n is faster than \n```\nSHRD rdi,rdi,2\n```\n, and using two CMOV instructions on the critical path is slower than an extra TEST that can run in parallel. I put tidied / improved C (which guides the compiler to produce better asm), and tested+working faster asm (in comments below the C) up on Godbolt: see the link in @hidefromkgb's answer. (This answer hit the 30k char limit from the large Godbolt URLs, but shortlinks can rot and were too long for goo.gl anyway.) Also improved the output-printing to convert to a string and make one \n```\nwrite()\n```\n instead of writing one char at a time. This minimizes impact on timing the whole program with \n```\nperf stat ./collatz\n```"", ""```\nwrite()\n```\n instead of writing one char at a time. This minimizes impact on timing the whole program with \n```\nperf stat ./collatz\n```\n (to record performance counters), and I de-obfuscated some of the non-critical asm. @Veedrac's code I got a minor speedup from right-shifting as much as we know needs doing, and checking to continue the loop. From 7.5s for limit=1e8 down to 7.275s, on Core2Duo (Merom), with an unroll factor of 16. code + comments on Godbolt. Don't use this version with clang; it does something silly with the defer-loop. Using a tmp counter \n```\nk\n```\n and then adding it to \n```\ncount\n```\n later changes what clang does, but that slightly hurts gcc. See discussion in comments: Veedrac's code is excellent on CPUs with BMI1 (i.e. not Celeron/Pentium)""]","If you think a 64-bit DIV instruction is a good way to divide by two, then no wonder the compiler's asm output beat your hand-written code, even with 
```
-O0
```
 (compile fast, no extra optimization, and store/reload to memory after/before every C statement so a debugger can modify variables). See Agner Fog's Optimizing Assembly guide to learn how to write efficient asm. He also has instruction tables and a microarch guide for specific details for specific CPUs. See also the x86 tag wiki for more perf links. See also this more general question about beating the compiler with hand-written asm: Is inline assembly language slower than native C++ code?. TL:DR: yes if you do it wrong (like this question). Usually you're fine letting the compiler do its thing, especially if you try to write C++ that can compile efficiently. Also see is assembly faster than compiled languages?. One of the answers links to these neat slides showing how various C compilers optimize some really simple functions with cool tricks. Matt Godbolt's CppCon2017 talk “What Has My Compiler Done for Me Lately? Unbolting the Compiler's Lid” is in a similar vein. 
```
even:
    mov rbx, 2
    xor rdx, rdx
    div rbx

```
 On Intel Haswell, 
```
div r64
```
 is 36 uops, with a latency of 32-96 cycles, and a throughput of one per 21-74 cycles. (Plus the 2 uops to set up RBX and zero RDX, but out-of-order execution can run those early). High-uop-count instructions like DIV are microcoded, which can also cause front-end bottlenecks. In this case, latency is the most relevant factor because it's part of a loop-carried dependency chain. 
```
shr rax, 1
```
 does the same unsigned division: It's 1 uop, with 1c latency, and can run 2 per clock cycle. For comparison, 32-bit division is faster, but still horrible vs. shifts. 
```
idiv r32
```
 is 9 uops, 22-29c latency, and one per 8-11c throughput on Haswell. As you can see from looking at gcc's 
```
-O0
```
 asm output (Godbolt compiler explorer), it only uses shifts instructions. clang 
```
-O0
```
 does compile naively like you thought, even using 64-bit IDIV twice. (When optimizing, compilers do use both outputs of IDIV when the source does a division and modulus with the same operands, if they use IDIV at all) GCC doesn't have a totally-naive mode; it always transforms through GIMPLE, which means some ""optimizations"" can't be disabled. This includes recognizing division-by-constant and using shifts (power of 2) or a fixed-point multiplicative inverse (non power of 2) to avoid IDIV (see 
```
div_by_13
```
 in the above godbolt link). 
```
gcc -Os
```
 (optimize for size) does use IDIV for non-power-of-2 division, unfortunately even in cases where the multiplicative inverse code is only slightly larger but much faster. Helping the compiler (summary for this case: use 
```
uint64_t n
```
) First of all, it's only interesting to look at optimized compiler output. (
```
-O3
```
). 
```
-O0
```
 speed is basically meaningless. Look at your asm output (on Godbolt, or see How to remove ""noise"" from GCC/clang assembly output?). When the compiler doesn't make optimal code in the first place: Writing your C/C++ source in a way that guides the compiler into making better code is usually the best approach. You have to know asm, and know what's efficient, but you apply this knowledge indirectly. Compilers are also a good source of ideas: sometimes clang will do something cool, and you can hand-hold gcc into doing the same thing: see this answer and what I did with the non-unrolled loop in @Veedrac's code below.) This approach is portable, and in 20 years some future compiler can compile it to whatever is efficient on future hardware (x86 or not), maybe using new ISA extension or auto-vectorizing. Hand-written x86-64 asm from 15 years ago would usually not be optimally tuned for Skylake. e.g. compare&branch macro-fusion didn't exist back then. What's optimal now for hand-crafted asm for one microarchitecture might not be optimal for other current and future CPUs. Comments on @johnfound's answer discuss major differences between AMD Bulldozer and Intel Haswell, which have a big effect on this code. But in theory, 
```
g++ -O3 -march=bdver3
```
 and 
```
g++ -O3 -march=skylake
```
 will do the right thing. (Or 
```
-march=native
```
.) Or 
```
-mtune=...
```
 to just tune, without using instructions that other CPUs might not support. My feeling is that guiding the compiler to asm that's good for a current CPU you care about shouldn't be a problem for future compilers. They're hopefully better than current compilers at finding ways to transform code, and can find a way that works for future CPUs. Regardless, future x86 probably won't be terrible at anything that's good on current x86, and the future compiler will avoid any asm-specific pitfalls while implementing something like the data movement from your C source, if it doesn't see something better. Hand-written asm is a black-box for the optimizer, so constant-propagation doesn't work when inlining makes an input a compile-time constant. Other optimizations are also affected. Read https://gcc.gnu.org/wiki/DontUseInlineAsm before using asm. (And avoid MSVC-style inline asm: inputs/outputs have to go through memory which adds overhead.) In this case: your 
```
n
```
 has a signed type, and gcc uses the SAR/SHR/ADD sequence that gives the correct rounding. (IDIV and arithmetic-shift ""round"" differently for negative inputs, see the SAR insn set ref manual entry). (IDK if gcc tried and failed to prove that 
```
n
```
 can't be negative, or what. Signed-overflow is undefined behaviour, so it should have been able to.) You should have used 
```
uint64_t n
```
, so it can just SHR. And so it's portable to systems where 
```
long
```
 is only 32-bit (e.g. x86-64 Windows). BTW, gcc's optimized asm output looks pretty good (using 
```
unsigned long n
```
): the inner loop it inlines into 
```
main()
```
 does this: 
```
# from gcc5.4 -O3  plus my comments
# edx= count=1
# rax= uint64_t n

.L9:              # do{
    lea    rcx, [rax+1+rax*2]   # rcx = 3*n + 1
    mov    rdi, rax
    shr    rdi        # rdi = n>>1;
    test   al, 1      # set flags based on n%2 (aka n&1)
    mov    rax, rcx
    cmove  rax, rdi   # n= (n%2) ? 3*n+1 : n/2;
    add    edx, 1     # ++count;
    cmp    rax, 1
    jne   .L9      #}while(n!=1)

  cmp/branch to update max and maxi, and then do the next n

```
 The inner loop is branchless, and the critical path of the loop-carried dependency chain is: 3-component LEA (3 cycles on Intel before Ice Lake) cmov (2 cycles on Haswell, 1c on Broadwell or later). Total: 5 cycle per iteration, latency bottleneck. Out-of-order execution takes care of everything else in parallel with this (in theory: I haven't tested with perf counters to see if it really runs at 5c/iter). The FLAGS input of 
```
cmov
```
 (produced by TEST) is faster to produce than the RAX input (from LEA->MOV), so it's not on the critical path. Similarly, the MOV->SHR that produces CMOV's RDI input is off the critical path, because it's also faster than the LEA. MOV on IvyBridge and later has zero latency (handled at register-rename time). (It still takes a uop, and a slot in the pipeline, so it's not free, just zero latency). The extra MOV in the LEA dep chain is part of the bottleneck on other CPUs. The cmp/jne is also not part of the critical path: it's not loop-carried, because control dependencies are handled with branch prediction + speculative execution, unlike data dependencies on the critical path. Beating the compiler GCC did a pretty good job here. It could save one code byte by using 
```
inc edx
```
 instead of 
```
add edx, 1
```
, because nobody cares about P4 and its false-dependencies for partial-flag-modifying instructions. It could also save all the MOV instructions, and the TEST: SHR sets CF= the bit shifted out, so we can use 
```
cmovc
```
 instead of 
```
test
```
 / 
```
cmovz
```
. 
```
 ### Hand-optimized version of what gcc does
.L9:                  #do{
  lea     rcx, [rax+1+rax*2] # rcx = 3*n + 1
  shr     rax, 1       # n>>=1;    CF = n&1 = n%2
  cmovc   rax, rcx     # n= (n&1) ? 3*n+1 : n/2;
  inc     edx          # ++count;
  cmp     rax, 1
  jne     .L9         #}while(n!=1)

```
 See @johnfound's answer for another clever trick: remove the CMP by branching on SHR's flag result as well as using it for CMOV: zero only if n was 1 (or 0) to start with. (SHR with count != 1 on Nehalem or earlier causes a stall if you read the flag results. That's how they made it single-uop. The shift-by-1 encoding is fine, though.) Avoiding MOV doesn't help with the latency at all on Haswell (Can x86's MOV really be ""free""? Why can't I reproduce this at all?). It does help significantly on CPUs like Intel pre-IvB, and AMD Bulldozer-family, where MOV is not zero-latency (and Ice Lake with updated microcode). The compiler's wasted MOV instructions do affect the critical path. BD's complex-LEA and CMOV are both lower latency (2c and 1c respectively), so it's a bigger fraction of the latency. Also, throughput bottlenecks become an issue on BD because it only has two integer ALU pipes. See @johnfound's answer, where he has timing results from an AMD CPU. Even on Haswell, this version may help a bit by avoiding some occasional delays where a non-critical uop steals an execution port from one on the critical path, delaying execution by 1 cycle. (This is called a resource conflict). It also saves a register, which may help when doing multiple 
```
n
```
 values in parallel in an interleaved loop (see below). LEA's latency depends on the addressing mode, on Intel SnB-family CPUs before Ice Lake. 3c for 3 components (
```
[base+idx+const]
```
, which takes two separate adds), but only 1c with 2 or fewer components (one add). Some CPUs (like Core2) do even a 3-component LEA in a single cycle. Worse, SnB-family standardizes latencies: no 2c uops, otherwise 3-component LEA would be only 2c like Bulldozer. (3-component LEA is slower on AMD too, just not by as much). Ice Lake improved the LEA execution units to be 1c latency for all addressing modes, and 4/clock throughput except with a scaled index (then 2/clock). Alder Lake / Sapphire Rapids has 2c latency for shifted-index. (https://uops.info/). Zen 3 and later run 3-component LEAs as 2 uops. So 
```
lea  rcx, [rax + rax*2]
```
 / 
```
inc rcx
```
 is only 2c latency, faster than 
```
lea  rcx, [rax + rax*2 + 1]
```
 on Intel before Ice Lake. Break-even on BD and Alder Lake, and worse on Core2 and Ice Lake. It costs an extra uop which often isn't worth it to save 1c latency, but latency is the major bottleneck here and HSW has a wide pipeline. Neither GCC, ICC, nor Clang (on godbolt) used SHR's CF output, always using an AND or TEST. Silly compilers. :P They're great pieces of complex machinery, but a clever human can often beat them on small-scale problems. (Given thousands to millions of times longer to think about it, of course! Compilers don't use exhaustive algorithms to search for every possible way to do things; that would take too long when optimizing a lot of inlined code, which is what they do best. They also don't model the pipeline in the target uarch, not in the same detail as IACA or especially https://uica.uops.info/; they just use some heuristics.) Simple loop unrolling won't help; this loop bottlenecks on the latency of a loop-carried dependency chain, not on loop overhead / throughput. This means it would do well with hyperthreading (or any other kind of SMT), since the CPU has lots of time to interleave instructions from two threads. This would mean parallelizing the loop in 
```
main
```
, but that's fine because each thread can just check a range of 
```
n
```
 values and produce a pair of integers as a result. Interleaving by hand within a single thread might be viable, too. Maybe compute the sequence for a pair of numbers in parallel, since each one only takes a couple registers, and they can all update the same 
```
max
```
 / 
```
maxi
```
. This creates more instruction-level parallelism. The trick is deciding whether to wait until all the 
```
n
```
 values have reached 
```
1
```
 before getting another pair of starting 
```
n
```
 values, or whether to break out and get a new start point for just one that reached the end condition, without touching the registers for the other sequence. Probably it's best to keep each chain working on useful data, otherwise you'd have to conditionally increment its counter. You could maybe even do this with SSE packed-compare stuff to conditionally increment the counter for vector elements where 
```
n
```
 hadn't reached 
```
1
```
 yet. And then to hide the even longer latency of a SIMD conditional-increment implementation, you'd need to keep more vectors of 
```
n
```
 values up in the air. Maybe only worth with 256b vector (4x 
```
uint64_t
```
). I think the best strategy to make detection of a 
```
1
```
 ""sticky"" is to mask the vector of all-ones that you add to increment the counter. So after you've seen a 
```
1
```
 in an element, the increment-vector will have a zero, and +=0 is a no-op. Untested idea for manual vectorization 
```
# starting with YMM0 = [ n_d, n_c, n_b, n_a ]  (64-bit elements)
# ymm4 = _mm256_set1_epi64x(1):  increment vector
# ymm5 = all-zeros:  count vector

.inner_loop:
  vpaddq    ymm1, ymm0, xmm0
  vpaddq    ymm1, ymm1, xmm0
  vpaddq    ymm1, ymm1, set1_epi64(1)     # ymm1= 3*n + 1.  Maybe could do this more efficiently?

  vpsllq    ymm3, ymm0, 63                # shift bit 1 to the sign bit

  vpsrlq    ymm0, ymm0, 1                 # n /= 2

  # FP blend between integer insns may cost extra bypass latency, but integer blends don't have 1 bit controlling a whole qword.
  vpblendvpd ymm0, ymm0, ymm1, ymm3       # variable blend controlled by the sign bit of each 64-bit element.  I might have the source operands backwards, I always have to look this up.

  # ymm0 = updated n  in each element.

  vpcmpeqq ymm1, ymm0, set1_epi64(1)
  vpandn   ymm4, ymm1, ymm4         # zero out elements of ymm4 where the compare was true

  vpaddq   ymm5, ymm5, ymm4         # count++ in elements where n has never been == 1

  vptest   ymm4, ymm4
  jnz  .inner_loop
  # Fall through when all the n values have reached 1 at some point, and our increment vector is all-zero

  vextracti128 ymm0, ymm5, 1
  vpmaxuq .... oops, requires AVX-512
  # delay doing a horizontal max until the very end.  But you need some way to record max and maxi.

```
 You can and should implement this with intrinsics, not hand-written asm. Algorithmic / implementation improvement: Besides just implementing the same logic with more efficient asm, look for ways to simplify the logic, or avoid redundant work. e.g. memoize to detect common endings to sequences. Or even better, look at 8 trailing bits at once (gnasher's answer) @EOF points out that 
```
tzcnt
```
 (or 
```
bsf
```
) could be used to do multiple 
```
n/=2
```
 iterations in one step. To vectorize that efficiently, we probably need AVX-512 
```
vplzcntq
```
 after isolating the lowest set bit with 
```
v & (v-1)
```
). Or just do multiple scalar 
```
n
```
s in parallel in different integer regs. The loop might look like this: 
```
goto loop_entry;  // C++ structured like the asm, for illustration only
do {
   n = n*3 + 1;
  loop_entry:
   shift = _tzcnt_u64(n);
   n >>= shift;
   count += shift;
} while(n != 1);

```
 This may do significantly fewer iterations, but variable-count shifts are slow on Intel SnB-family CPUs without BMI2. 3 uops, 2c latency for FLAGS, although only 1c for the actual data. (count=0 means the flags are unmodified. They handle this as a data dependency, and take multiple uops because a uop can only have 2 inputs (pre-HSW/BDW anyway)). This is the kind of thing that people complaining about x86's crazy-CISC design are referring to. It makes x86 CPUs slower than they would be if the ISA was designed from scratch today, even in a mostly-similar way. (i.e. this is part of the ""x86 tax"" of speed / power cost.) BMI2 SHRX/SHLX/SARX are 1 uop / 1c latency. It also puts tzcnt (3c on Haswell and later) on the critical path, so it significantly lengthens the total latency of the loop-carried dependency chain. It does remove any need for a CMOV, or for preparing a register holding 
```
n>>1
```
, though. @Veedrac's answer overcomes all this by deferring the tzcnt/shift for multiple iterations, which is highly effective (see below). We can safely use BSF or TZCNT interchangeably, because 
```
n
```
 can never be zero at that point. TZCNT's machine-code decodes as BSF on CPUs that don't support BMI1. (Meaningless prefixes are ignored, so REP BSF runs as BSF). TZCNT performs much better than BSF on AMD CPUs that support it, so it can be a good idea to use 
```
REP BSF
```
, even if you don't care about setting ZF if the input is zero rather than the output. Some compilers do this when you use 
```
__builtin_ctzll
```
 even with 
```
-mno-bmi
```
. They perform the same on Intel CPUs, so just save the byte if that's all that matters. TZCNT on Intel (pre-Skylake) still has a false-dependency on the supposedly write-only output operand, just like BSF, to support the undocumented behaviour that BSF with input = 0 leaves its destination unmodified. So you need to work around that unless optimizing only for Skylake, so there's nothing to gain from the extra REP byte. (Intel often goes above and beyond what the x86 ISA manual requires, to avoid breaking widely-used code that depends on something it shouldn't, or that is retroactively disallowed. e.g. Windows 9x's assumes no speculative prefetching of TLB entries, which was safe when the code was written, before Intel updated the TLB management rules.) Anyway, LZCNT/TZCNT on Haswell have the same false dep as POPCNT: see this Q&A. This is why in gcc's asm output for @Veedrac's code, you see it breaking the dep chain with xor-zeroing on the register it's about to use as TZCNT's destination when it doesn't use dst=src. Since TZCNT/LZCNT/POPCNT never leave their destination undefined or unmodified, this false dependency on the output on Intel CPUs is a performance bug / limitation. Presumably it's worth some transistors / power to have them behave like other uops that go to the same execution unit. The only perf upside is interaction with another uarch limitation: they can micro-fuse a memory operand with an indexed addressing mode on Haswell, but on Skylake where Intel removed the false dep for LZCNT/TZCNT they ""un-laminate"" indexed addressing modes while POPCNT can still micro-fuse any addr mode. Improvements to ideas / code from other answers: @hidefromkgb's answer has a nice observation that you're guaranteed to be able to do one right shift after a 3n+1. You can compute this more even more efficiently than just leaving out the checks between steps. The asm implementation in that answer is broken, though (it depends on OF, which is undefined after SHRD with a count > 1), and slow: 
```
ROR rdi,2
```
 is faster than 
```
SHRD rdi,rdi,2
```
, and using two CMOV instructions on the critical path is slower than an extra TEST that can run in parallel. I put tidied / improved C (which guides the compiler to produce better asm), and tested+working faster asm (in comments below the C) up on Godbolt: see the link in @hidefromkgb's answer. (This answer hit the 30k char limit from the large Godbolt URLs, but shortlinks can rot and were too long for goo.gl anyway.) Also improved the output-printing to convert to a string and make one 
```
write()
```
 instead of writing one char at a time. This minimizes impact on timing the whole program with 
```
perf stat ./collatz
```
 (to record performance counters), and I de-obfuscated some of the non-critical asm. @Veedrac's code I got a minor speedup from right-shifting as much as we know needs doing, and checking to continue the loop. From 7.5s for limit=1e8 down to 7.275s, on Core2Duo (Merom), with an unroll factor of 16. code + comments on Godbolt. Don't use this version with clang; it does something silly with the defer-loop. Using a tmp counter 
```
k
```
 and then adding it to 
```
count
```
 later changes what clang does, but that slightly hurts gcc. See discussion in comments: Veedrac's code is excellent on CPUs with BMI1 (i.e. not Celeron/Pentium)"
274626,What is object slicing?,https://stackoverflow.com/questions/274626/what-is-object-slicing,17,,[],
402283,std::wstring VS std::string,https://stackoverflow.com/questions/402283/stdwstring-vs-stdstring,14,,[],
1008019,How do you implement the Singleton design pattern?,https://stackoverflow.com/questions/1008019/how-do-you-implement-the-singleton-design-pattern,24,1413.0,"['In 2008 I provided a C++98 implementation of the Singleton design pattern that is lazy-evaluated, guaranteed-destruction, not-technically-thread-safe: Can any one provide me a sample of Singleton in c++? Here is an updated C++11 implementation of the Singleton design pattern that is lazy-evaluated, correctly-destroyed, and thread-safe. \n```\nclass S\n{\n    public:\n        static S& getInstance()\n        {\n            static S    instance; // Guaranteed to be destroyed.\n                                  // Instantiated on first use.\n            return instance;\n        }\n    private:\n        S() {}                    // Constructor? (the {} brackets) are needed here.', ""// C++ 03\n        // ========\n        // Don't forget to declare these two. You want to make sure they\n        // are inaccessible(especially from outside), otherwise, you may accidentally get copies of\n        // your singleton appearing.\n        S(S const&);              // Don't Implement\n        void operator=(S const&); // Don't implement\n\n        // C++ 11\n        // =======\n        // We can use the better technique of deleting the methods\n        // we don't want.\n    public:\n        S(S const&)               = delete;\n        void operator=(S const&)  = delete;\n\n        // Note: Scott Meyers mentions in his Effective Modern\n        //       C++ book, that deleted functions should generally\n        //       be public as it results in better error messages\n        //       due to the compilers behavior to check accessibility\n        //       before deleted status\n};"", '```\n See this article about when to use a singleton: (not often) Singleton: How should it be used See this two article about initialization order and how to cope: Static variables initialisation order Finding C++ static initialization order problems See this article describing lifetimes: What is the lifetime of a static variable in a C++ function? See this article that discusses some threading implications to singletons: Singleton instance declared as static variable of GetInstance method, is it thread-safe? See this article that explains why double checked locking will not work on C++: What are all the common undefined behaviours that a C++ programmer should know about? Dr Dobbs: C++ and The Perils of Double-Checked Locking: Part I']","In 2008 I provided a C++98 implementation of the Singleton design pattern that is lazy-evaluated, guaranteed-destruction, not-technically-thread-safe: Can any one provide me a sample of Singleton in c++? Here is an updated C++11 implementation of the Singleton design pattern that is lazy-evaluated, correctly-destroyed, and thread-safe. 
```
class S
{
    public:
        static S& getInstance()
        {
            static S    instance; // Guaranteed to be destroyed.
                                  // Instantiated on first use.
            return instance;
        }
    private:
        S() {}                    // Constructor? (the {} brackets) are needed here.

        // C++ 03
        // ========
        // Don't forget to declare these two. You want to make sure they
        // are inaccessible(especially from outside), otherwise, you may accidentally get copies of
        // your singleton appearing.
        S(S const&);              // Don't Implement
        void operator=(S const&); // Don't implement

        // C++ 11
        // =======
        // We can use the better technique of deleting the methods
        // we don't want.
    public:
        S(S const&)               = delete;
        void operator=(S const&)  = delete;

        // Note: Scott Meyers mentions in his Effective Modern
        //       C++ book, that deleted functions should generally
        //       be public as it results in better error messages
        //       due to the compilers behavior to check accessibility
        //       before deleted status
};

```
 See this article about when to use a singleton: (not often) Singleton: How should it be used See this two article about initialization order and how to cope: Static variables initialisation order Finding C++ static initialization order problems See this article describing lifetimes: What is the lifetime of a static variable in a C++ function? See this article that discusses some threading implications to singletons: Singleton instance declared as static variable of GetInstance method, is it thread-safe? See this article that explains why double checked locking will not work on C++: What are all the common undefined behaviours that a C++ programmer should know about? Dr Dobbs: C++ and The Perils of Double-Checked Locking: Part I"
318064,How do you declare an interface in C++?,https://stackoverflow.com/questions/318064/how-do-you-declare-an-interface-in-c,17,747.0,"[""To expand on the answer by bradtgmurray, you may want to make one exception to the pure virtual method list of your interface by adding a virtual destructor. This allows you to pass pointer ownership to another party without exposing the concrete derived class. The destructor doesn't have to do anything, because the interface doesn't have any concrete members. It might seem contradictory to define a function as both virtual and inline, but trust me - it isn't. \n```\nclass IDemo\n{\n    public:\n        virtual ~IDemo() {}\n        virtual void OverrideMe() = 0;\n};\n\nclass Parent\n{\n    public:\n        virtual ~Parent();\n};\n\nclass Child : public Parent, public IDemo\n{\n    public:\n        virtual void OverrideMe()\n        {\n            //do stuff\n        }\n};\n\n```\n You don't have to include a body for the virtual destructor - it turns out some compilers have trouble optimizing an empty destructor and you're better off using the default.""]","To expand on the answer by bradtgmurray, you may want to make one exception to the pure virtual method list of your interface by adding a virtual destructor. This allows you to pass pointer ownership to another party without exposing the concrete derived class. The destructor doesn't have to do anything, because the interface doesn't have any concrete members. It might seem contradictory to define a function as both virtual and inline, but trust me - it isn't. 
```
class IDemo
{
    public:
        virtual ~IDemo() {}
        virtual void OverrideMe() = 0;
};

class Parent
{
    public:
        virtual ~Parent();
};

class Child : public Parent, public IDemo
{
    public:
        virtual void OverrideMe()
        {
            //do stuff
        }
};

```
 You don't have to include a body for the virtual destructor - it turns out some compilers have trouble optimizing an empty destructor and you're better off using the default."
14116003,What's the difference between constexpr and const?,https://stackoverflow.com/questions/14116003/whats-the-difference-between-constexpr-and-const,10,820.0,"[""Basic meaning and syntax Both keywords can be used in the declaration of objects as well as functions. The basic difference when applied to objects is this: \n```\nconst\n```\n declares an object as constant. This implies a guarantee that once initialized, the value of that object won't change, and the compiler can make use of this fact for optimizations. It also helps prevent the programmer from writing code that modifies objects that were not meant to be modified after initialization. \n```\nconstexpr\n```\n declares an object as fit for use in what the Standard calls constant expressions. But note that \n```\nconstexpr\n```\n is not the only way to do this. When applied to functions the basic difference is this: \n```\nconst\n```\n can only be used for non-static member functions, not functions in general. It gives a guarantee that the member function does not modify any of the non-static data members (except for mutable data members, which can be modified anyway). \n```\nconstexpr\n```"", '```\nconstexpr\n```\n can be used with both member and non-member functions, as well as constructors. It declares the function fit for use in constant expressions. The compiler will only accept it if the function meets certain criteria (7.1.5/3,4), most importantly (†): The function body must be non-virtual and extremely simple: Apart from typedefs and static asserts, only a single \n```\nreturn\n```\n statement is allowed. In the case of a constructor, only an initialization list, typedefs, and static assert are allowed. (\n```\n= default\n```\n and \n```\n= delete\n```\n are allowed, too, though.) As of C++14, the rules are more relaxed, what is allowed since then inside a constexpr function: \n```\nasm\n```\n declaration, a \n```\ngoto\n```\n statement, a statement with a label other than \n```\ncase\n```\n and \n```\ndefault\n```', '```\nasm\n```\n declaration, a \n```\ngoto\n```\n statement, a statement with a label other than \n```\ncase\n```\n and \n```\ndefault\n```\n, try-block, the definition of a variable of non-literal type, definition of a variable of static or thread storage duration, the definition of a variable for which no initialization is performed. The arguments and the return type must be literal types (i.e., generally speaking, very simple types, typically scalars or aggregates) Constant expressions As said above, \n```\nconstexpr\n```\n declares both objects as well as functions as fit for use in constant expressions. A constant expression is more than merely constant: It can be used in places that require compile-time evaluation, for example, template parameters and array-size specifiers: \n```\ntemplate<int N>\nclass fixed_size_list\n{ /*...*/ };', 'fixed_size_list<X> mylist;  // X must be an integer constant expression\n\nint numbers[X];  // X must be an integer constant expression\n\n```\n But note: Declaring something as \n```\nconstexpr\n```\n does not necessarily guarantee that it will be evaluated at compile time. It can be used for such, but it can be used in other places that are evaluated at run-time, as well. An object may be fit for use in constant expressions without being declared \n```\nconstexpr\n```\n. Example: \n```\nint main()\n{\n  const int N = 3;\n  int numbers[N] = {1, 2, 3};  // N is constant expression\n}', '```\n This is possible because \n```\nN\n```\n, being constant and initialized at declaration time with a literal, satisfies the criteria for a constant expression, even if it isn\'t declared \n```\nconstexpr\n```\n. So when do I actually have to use \n```\nconstexpr\n```\n? An object like \n```\nN\n```\n above can be used as constant expression without being declared \n```\nconstexpr\n```\n. This is true for all objects that are: \n```\nconst\n```\n and of integral or enumeration type and initialized at declaration time with an expression that is itself a constant expression. [This is due to §5.19/2: A constant expression must not include a subexpression that involves ""an lvalue-to-rvalue modification unless […] a glvalue of integral or enumeration type […]"" Thanks to Richard Smith for correcting my earlier claim that this was true for all literal types.] For a function to be fit for use in constant expressions, it must be explicitly declared \n```\nconstexpr\n```', '```\nconstexpr\n```\n; it is not sufficient for it merely to satisfy the criteria for constant-expression functions. Example: \n```\ntemplate<int N>\nclass list\n{ };', 'constexpr int sqr1(int arg)\n{ return arg * arg; }\n\nint sqr2(int arg)\n{ return arg * arg; }\n\nint main()\n{\n  const int X = 2;\n  list<sqr1(X)> mylist1;  // OK: sqr1 is constexpr\n  list<sqr2(X)> mylist2;  // wrong: sqr2 is not constexpr\n}\n\n```\n When can I / should I use both, \n```\nconst\n```\n and \n```\nconstexpr\n```\n together? A. In object declarations. This is never necessary when both keywords refer to the same object to be declared. \n```\nconstexpr\n```\n implies \n```\nconst\n```\n. \n```\nconstexpr const int N = 5;\n\n```\n is the same as \n```\nconstexpr int N = 5;\n\n```\n However, note that there may be situations when the keywords each refer to different parts of the declaration: \n```\nstatic constexpr int N = 3;\n\nint main()\n{\n  constexpr const int *NP = &N;\n}', 'int main()\n{\n  constexpr const int *NP = &N;\n}\n\n```\n Here, \n```\nNP\n```\n is declared as an address constant-expression, i.e. a pointer that is itself a constant expression. (This is possible when the address is generated by applying the address operator to a static/global constant expression.) Here, both \n```\nconstexpr\n```\n and \n```\nconst\n```\n are required: \n```\nconstexpr\n```\n always refers to the expression being declared (here \n```\nNP\n```\n), while \n```\nconst\n```\n refers to \n```\nint\n```\n (it declares a pointer-to-const). Removing the \n```\nconst\n```\n would render the expression illegal (because (a) a pointer to a non-const object cannot be a constant expression, and (b) \n```\n&N\n```\n is in-fact a pointer-to-constant). B. In member function declarations. In C++11, \n```\nconstexpr\n```\n implies \n```\nconst\n```\n, while in C++14 and C++17 that is not the case. A member function declared under C++11 as \n```\nconstexpr void f();\n\n```\n needs to be declared as \n```\nconstexpr void f() const;', '```\n needs to be declared as \n```\nconstexpr void f() const;\n\n```\n under C++14 in order to still be usable as a \n```\nconst\n```\n function.']","Basic meaning and syntax Both keywords can be used in the declaration of objects as well as functions. The basic difference when applied to objects is this: 
```
const
```
 declares an object as constant. This implies a guarantee that once initialized, the value of that object won't change, and the compiler can make use of this fact for optimizations. It also helps prevent the programmer from writing code that modifies objects that were not meant to be modified after initialization. 
```
constexpr
```
 declares an object as fit for use in what the Standard calls constant expressions. But note that 
```
constexpr
```
 is not the only way to do this. When applied to functions the basic difference is this: 
```
const
```
 can only be used for non-static member functions, not functions in general. It gives a guarantee that the member function does not modify any of the non-static data members (except for mutable data members, which can be modified anyway). 
```
constexpr
```
 can be used with both member and non-member functions, as well as constructors. It declares the function fit for use in constant expressions. The compiler will only accept it if the function meets certain criteria (7.1.5/3,4), most importantly (†): The function body must be non-virtual and extremely simple: Apart from typedefs and static asserts, only a single 
```
return
```
 statement is allowed. In the case of a constructor, only an initialization list, typedefs, and static assert are allowed. (
```
= default
```
 and 
```
= delete
```
 are allowed, too, though.) As of C++14, the rules are more relaxed, what is allowed since then inside a constexpr function: 
```
asm
```
 declaration, a 
```
goto
```
 statement, a statement with a label other than 
```
case
```
 and 
```
default
```
, try-block, the definition of a variable of non-literal type, definition of a variable of static or thread storage duration, the definition of a variable for which no initialization is performed. The arguments and the return type must be literal types (i.e., generally speaking, very simple types, typically scalars or aggregates) Constant expressions As said above, 
```
constexpr
```
 declares both objects as well as functions as fit for use in constant expressions. A constant expression is more than merely constant: It can be used in places that require compile-time evaluation, for example, template parameters and array-size specifiers: 
```
template<int N>
class fixed_size_list
{ /*...*/ };

fixed_size_list<X> mylist;  // X must be an integer constant expression

int numbers[X];  // X must be an integer constant expression

```
 But note: Declaring something as 
```
constexpr
```
 does not necessarily guarantee that it will be evaluated at compile time. It can be used for such, but it can be used in other places that are evaluated at run-time, as well. An object may be fit for use in constant expressions without being declared 
```
constexpr
```
. Example: 
```
int main()
{
  const int N = 3;
  int numbers[N] = {1, 2, 3};  // N is constant expression
}

```
 This is possible because 
```
N
```
, being constant and initialized at declaration time with a literal, satisfies the criteria for a constant expression, even if it isn't declared 
```
constexpr
```
. So when do I actually have to use 
```
constexpr
```
? An object like 
```
N
```
 above can be used as constant expression without being declared 
```
constexpr
```
. This is true for all objects that are: 
```
const
```
 and of integral or enumeration type and initialized at declaration time with an expression that is itself a constant expression. [This is due to §5.19/2: A constant expression must not include a subexpression that involves ""an lvalue-to-rvalue modification unless […] a glvalue of integral or enumeration type […]"" Thanks to Richard Smith for correcting my earlier claim that this was true for all literal types.] For a function to be fit for use in constant expressions, it must be explicitly declared 
```
constexpr
```
; it is not sufficient for it merely to satisfy the criteria for constant-expression functions. Example: 
```
template<int N>
class list
{ };

constexpr int sqr1(int arg)
{ return arg * arg; }

int sqr2(int arg)
{ return arg * arg; }

int main()
{
  const int X = 2;
  list<sqr1(X)> mylist1;  // OK: sqr1 is constexpr
  list<sqr2(X)> mylist2;  // wrong: sqr2 is not constexpr
}

```
 When can I / should I use both, 
```
const
```
 and 
```
constexpr
```
 together? A. In object declarations. This is never necessary when both keywords refer to the same object to be declared. 
```
constexpr
```
 implies 
```
const
```
. 
```
constexpr const int N = 5;

```
 is the same as 
```
constexpr int N = 5;

```
 However, note that there may be situations when the keywords each refer to different parts of the declaration: 
```
static constexpr int N = 3;

int main()
{
  constexpr const int *NP = &N;
}

```
 Here, 
```
NP
```
 is declared as an address constant-expression, i.e. a pointer that is itself a constant expression. (This is possible when the address is generated by applying the address operator to a static/global constant expression.) Here, both 
```
constexpr
```
 and 
```
const
```
 are required: 
```
constexpr
```
 always refers to the expression being declared (here 
```
NP
```
), while 
```
const
```
 refers to 
```
int
```
 (it declares a pointer-to-const). Removing the 
```
const
```
 would render the expression illegal (because (a) a pointer to a non-const object cannot be a constant expression, and (b) 
```
&N
```
 is in-fact a pointer-to-constant). B. In member function declarations. In C++11, 
```
constexpr
```
 implies 
```
const
```
, while in C++14 and C++17 that is not the case. A member function declared under C++11 as 
```
constexpr void f();

```
 needs to be declared as 
```
constexpr void f() const;

```
 under C++14 in order to still be usable as a 
```
const
```
 function."
16699247,"What is a ""cache-friendly"" code?",https://stackoverflow.com/questions/16699247/what-is-a-cache-friendly-code,10,1159.0,"['Preliminaries On modern computers, only the lowest level memory structures (the registers) can move data around in single clock cycles. However, registers are very expensive and most computer cores have less than a few dozen registers. At the other end of the memory spectrum (DRAM), the memory is very cheap (i.e. literally millions of times cheaper) but takes hundreds of cycles after a request to receive the data. To bridge this gap between super fast and expensive and super slow and cheap are the cache memories, named L1, L2, L3 in decreasing speed and cost. The idea is that most of the executing code will be hitting a small set of variables often, and the rest (a much larger set of variables) infrequently. If the processor can\'t find the data in L1 cache, then it looks in L2 cache. If not there, then L3 cache, and if not there, main memory. Each of these ""misses"" is expensive in time. (The analogy is cache memory is to system memory, as system memory is to hard disk storage. Hard', 'not there, then L3 cache, and if not there, main memory. Each of these ""misses"" is expensive in time. (The analogy is cache memory is to system memory, as system memory is to hard disk storage. Hard disk storage is super cheap but very slow). Caching is one of the main methods to reduce the impact of latency. To paraphrase Herb Sutter (cfr. links below): increasing bandwidth is easy, but we can\'t buy our way out of latency. Data is always retrieved through the memory hierarchy (smallest == fastest to slowest). A cache hit/miss usually refers to a hit/miss in the highest level of cache in the CPU -- by highest level I mean the largest == slowest. The cache hit rate is crucial for performance since every cache miss results in fetching data from RAM (or worse ...) which takes a lot of time (hundreds of cycles for RAM, tens of millions of cycles for HDD). In comparison, reading data from the (highest level) cache typically takes only a handful of cycles. In modern computer architectures,', ""of cycles for RAM, tens of millions of cycles for HDD). In comparison, reading data from the (highest level) cache typically takes only a handful of cycles. In modern computer architectures, the performance bottleneck is leaving the CPU die (e.g. accessing RAM or higher). This will only get worse over time. The increase in processor frequency is currently no longer relevant to increase performance. The problem is memory access. Hardware design efforts in CPUs therefore currently focus heavily on optimizing caches, prefetching, pipelines and concurrency. For instance, modern CPUs spend around 85% of die on caches and up to 99% for storing/moving data! There is quite a lot to be said on the subject. Here are a few great references about caches, memory hierarchies and proper programming: Agner Fog's page. In his excellent documents, you can find detailed examples covering languages ranging from assembly to C++. If you are into videos, I strongly recommend to have a look at Herb Sutter's"", 'Fog\'s page. In his excellent documents, you can find detailed examples covering languages ranging from assembly to C++. If you are into videos, I strongly recommend to have a look at Herb Sutter\'s talk on machine architecture (youtube) (specifically check 12:00 and onwards!). Slides about memory optimization by Christer Ericson (director of technology @ Sony) LWN.net\'s article ""What every programmer should know about memory"" Main concepts for cache-friendly code A very important aspect of cache-friendly code is all about the principle of locality, the goal of which is to place related data close in memory to allow efficient caching. In terms of the CPU cache, it\'s important to be aware of cache lines to understand how this works: How do cache lines work? The following particular aspects are of high importance to optimize caching: Temporal locality: when a given memory location was accessed, it is likely that the same location is accessed again in the near future. Ideally, this', ""are of high importance to optimize caching: Temporal locality: when a given memory location was accessed, it is likely that the same location is accessed again in the near future. Ideally, this information will still be cached at that point. Spatial locality: this refers to placing related data close to each other. Caching happens on many levels, not just in the CPU. For example, when you read from RAM, typically a larger chunk of memory is fetched than what was specifically asked for because very often the program will require that data soon. HDD caches follow the same line of thought. Specifically for CPU caches, the notion of cache lines is important. Use appropriate c++ containers A simple example of cache-friendly versus cache-unfriendly is c++'s"", '```\nstd::vector\n```\n versus \n```\nstd::list\n```\n. Elements of a \n```\nstd::vector\n```\n are stored in contiguous memory, and as such accessing them is much more cache-friendly than accessing elements in a \n```\nstd::list\n```', ""```\nstd::vector\n```\n are stored in contiguous memory, and as such accessing them is much more cache-friendly than accessing elements in a \n```\nstd::list\n```\n, which stores its content all over the place. This is due to spatial locality. A very nice illustration of this is given by Bjarne Stroustrup in this youtube clip (thanks to @Mohammad Ali Baydoun for the link!). Don't neglect the cache in data structure and algorithm design Whenever possible, try to adapt your data structures and order of computations in a way that allows maximum use of the cache. A common technique in this regard is cache blocking (Archive.org version), which is of extreme importance in high-performance computing (cfr. for example ATLAS). Know and exploit the implicit structure of data Another simple example, which many people in the field sometimes forget is column-major (ex. fortran,matlab) vs. row-major ordering (ex. c,c++) for storing two dimensional arrays. For example, consider the following matrix: \n```"", '```\n1 2\n3 4', '```\n In row-major ordering, this is stored in memory as \n```\n1 2 3 4\n```\n; in column-major ordering, this would be stored as \n```\n1 3 2 4\n```\n. It is easy to see that implementations which do not exploit this ordering will quickly run into (easily avoidable!) cache issues. Unfortunately, I see stuff like this very often in my domain (machine learning). @MatteoItalia showed this example in more detail in his answer. When fetching a certain element of a matrix from memory, elements near it will be fetched as well and stored in a cache line. If the ordering is exploited, this will result in fewer memory accesses (because the next few values which are needed for subsequent computations are already in a cache line). For simplicity, assume the cache comprises a single cache line which can contain 2 matrix elements and that when a given element is fetched from memory, the next one is too. Say we want to take the sum over all elements in the example 2x2 matrix above (lets call it \n```\nM\n```', '```\nM\n```\n): Exploiting the ordering (e.g. changing column index first in c++): \n```\nM[0][0] (memory) + M[0][1] (cached) + M[1][0] (memory) + M[1][1] (cached)\n= 1 + 2 + 3 + 4\n--> 2 cache hits, 2 memory accesses', '```\n Not exploiting the ordering (e.g. changing row index first in c++): \n```\nM[0][0] (memory) + M[1][0] (memory) + M[0][1] (memory) + M[1][1] (memory)\n= 1 + 3 + 2 + 4\n--> 0 cache hits, 4 memory accesses', '```\n In this simple example, exploiting the ordering approximately doubles execution speed (since memory access requires much more cycles than computing the sums). In practice, the performance difference can be much larger. Avoid unpredictable branches Modern architectures feature pipelines and compilers are becoming very good at reordering code to minimize delays due to memory access. When your critical code contains (unpredictable) branches, it is hard or impossible to prefetch data. This will indirectly lead to more cache misses. This is explained very well here (thanks to @0x90 for the link): Why is processing a sorted array faster than processing an unsorted array? Avoid virtual functions In the context of c++, \n```\nvirtual\n```', 'methods represent a controversial issue with regard to cache misses (a general consensus exists that they should be avoided when possible in terms of performance). Virtual functions can induce cache misses during look up, but this only happens if the specific function is not called often (otherwise it would likely be cached), so this is regarded as a non-issue by some. For reference about this issue, check out: What is the performance cost of having a virtual method in a C++ class? Common problems A common problem in modern architectures with multiprocessor caches is called false sharing. This occurs when each individual processor is attempting to use data in another memory region and attempts to store it in the same cache line. This causes the cache line -- which contains data another processor can use -- to be overwritten again and again. Effectively, different threads make each other wait by inducing cache misses in this situation. See also (thanks to @Matt for the link): How and', 'can use -- to be overwritten again and again. Effectively, different threads make each other wait by inducing cache misses in this situation. See also (thanks to @Matt for the link): How and when to align to cache line size? An extreme symptom of poor caching in RAM memory (which is probably not what you mean in this context) is so-called thrashing. This occurs when the process continuously generates page faults (e.g. accesses memory which is not in the current page) which require disk access.']","Preliminaries On modern computers, only the lowest level memory structures (the registers) can move data around in single clock cycles. However, registers are very expensive and most computer cores have less than a few dozen registers. At the other end of the memory spectrum (DRAM), the memory is very cheap (i.e. literally millions of times cheaper) but takes hundreds of cycles after a request to receive the data. To bridge this gap between super fast and expensive and super slow and cheap are the cache memories, named L1, L2, L3 in decreasing speed and cost. The idea is that most of the executing code will be hitting a small set of variables often, and the rest (a much larger set of variables) infrequently. If the processor can't find the data in L1 cache, then it looks in L2 cache. If not there, then L3 cache, and if not there, main memory. Each of these ""misses"" is expensive in time. (The analogy is cache memory is to system memory, as system memory is to hard disk storage. Hard disk storage is super cheap but very slow). Caching is one of the main methods to reduce the impact of latency. To paraphrase Herb Sutter (cfr. links below): increasing bandwidth is easy, but we can't buy our way out of latency. Data is always retrieved through the memory hierarchy (smallest == fastest to slowest). A cache hit/miss usually refers to a hit/miss in the highest level of cache in the CPU -- by highest level I mean the largest == slowest. The cache hit rate is crucial for performance since every cache miss results in fetching data from RAM (or worse ...) which takes a lot of time (hundreds of cycles for RAM, tens of millions of cycles for HDD). In comparison, reading data from the (highest level) cache typically takes only a handful of cycles. In modern computer architectures, the performance bottleneck is leaving the CPU die (e.g. accessing RAM or higher). This will only get worse over time. The increase in processor frequency is currently no longer relevant to increase performance. The problem is memory access. Hardware design efforts in CPUs therefore currently focus heavily on optimizing caches, prefetching, pipelines and concurrency. For instance, modern CPUs spend around 85% of die on caches and up to 99% for storing/moving data! There is quite a lot to be said on the subject. Here are a few great references about caches, memory hierarchies and proper programming: Agner Fog's page. In his excellent documents, you can find detailed examples covering languages ranging from assembly to C++. If you are into videos, I strongly recommend to have a look at Herb Sutter's talk on machine architecture (youtube) (specifically check 12:00 and onwards!). Slides about memory optimization by Christer Ericson (director of technology @ Sony) LWN.net's article ""What every programmer should know about memory"" Main concepts for cache-friendly code A very important aspect of cache-friendly code is all about the principle of locality, the goal of which is to place related data close in memory to allow efficient caching. In terms of the CPU cache, it's important to be aware of cache lines to understand how this works: How do cache lines work? The following particular aspects are of high importance to optimize caching: Temporal locality: when a given memory location was accessed, it is likely that the same location is accessed again in the near future. Ideally, this information will still be cached at that point. Spatial locality: this refers to placing related data close to each other. Caching happens on many levels, not just in the CPU. For example, when you read from RAM, typically a larger chunk of memory is fetched than what was specifically asked for because very often the program will require that data soon. HDD caches follow the same line of thought. Specifically for CPU caches, the notion of cache lines is important. Use appropriate c++ containers A simple example of cache-friendly versus cache-unfriendly is c++'s 
```
std::vector
```
 versus 
```
std::list
```
. Elements of a 
```
std::vector
```
 are stored in contiguous memory, and as such accessing them is much more cache-friendly than accessing elements in a 
```
std::list
```
, which stores its content all over the place. This is due to spatial locality. A very nice illustration of this is given by Bjarne Stroustrup in this youtube clip (thanks to @Mohammad Ali Baydoun for the link!). Don't neglect the cache in data structure and algorithm design Whenever possible, try to adapt your data structures and order of computations in a way that allows maximum use of the cache. A common technique in this regard is cache blocking (Archive.org version), which is of extreme importance in high-performance computing (cfr. for example ATLAS). Know and exploit the implicit structure of data Another simple example, which many people in the field sometimes forget is column-major (ex. fortran,matlab) vs. row-major ordering (ex. c,c++) for storing two dimensional arrays. For example, consider the following matrix: 
```
1 2
3 4

```
 In row-major ordering, this is stored in memory as 
```
1 2 3 4
```
; in column-major ordering, this would be stored as 
```
1 3 2 4
```
. It is easy to see that implementations which do not exploit this ordering will quickly run into (easily avoidable!) cache issues. Unfortunately, I see stuff like this very often in my domain (machine learning). @MatteoItalia showed this example in more detail in his answer. When fetching a certain element of a matrix from memory, elements near it will be fetched as well and stored in a cache line. If the ordering is exploited, this will result in fewer memory accesses (because the next few values which are needed for subsequent computations are already in a cache line). For simplicity, assume the cache comprises a single cache line which can contain 2 matrix elements and that when a given element is fetched from memory, the next one is too. Say we want to take the sum over all elements in the example 2x2 matrix above (lets call it 
```
M
```
): Exploiting the ordering (e.g. changing column index first in c++): 
```
M[0][0] (memory) + M[0][1] (cached) + M[1][0] (memory) + M[1][1] (cached)
= 1 + 2 + 3 + 4
--> 2 cache hits, 2 memory accesses

```
 Not exploiting the ordering (e.g. changing row index first in c++): 
```
M[0][0] (memory) + M[1][0] (memory) + M[0][1] (memory) + M[1][1] (memory)
= 1 + 3 + 2 + 4
--> 0 cache hits, 4 memory accesses

```
 In this simple example, exploiting the ordering approximately doubles execution speed (since memory access requires much more cycles than computing the sums). In practice, the performance difference can be much larger. Avoid unpredictable branches Modern architectures feature pipelines and compilers are becoming very good at reordering code to minimize delays due to memory access. When your critical code contains (unpredictable) branches, it is hard or impossible to prefetch data. This will indirectly lead to more cache misses. This is explained very well here (thanks to @0x90 for the link): Why is processing a sorted array faster than processing an unsorted array? Avoid virtual functions In the context of c++, 
```
virtual
```
 methods represent a controversial issue with regard to cache misses (a general consensus exists that they should be avoided when possible in terms of performance). Virtual functions can induce cache misses during look up, but this only happens if the specific function is not called often (otherwise it would likely be cached), so this is regarded as a non-issue by some. For reference about this issue, check out: What is the performance cost of having a virtual method in a C++ class? Common problems A common problem in modern architectures with multiprocessor caches is called false sharing. This occurs when each individual processor is attempting to use data in another memory region and attempts to store it in the same cache line. This causes the cache line -- which contains data another processor can use -- to be overwritten again and again. Effectively, different threads make each other wait by inducing cache misses in this situation. See also (thanks to @Matt for the link): How and when to align to cache line size? An extreme symptom of poor caching in RAM memory (which is probably not what you mean in this context) is so-called thrashing. This occurs when the process continuously generates page faults (e.g. accesses memory which is not in the current page) which require disk access."
2346806,What is a segmentation fault?,https://stackoverflow.com/questions/2346806/what-is-a-segmentation-fault,17,977.0,"['Segmentation fault is a specific kind of error caused by accessing memory that “does not belong to you.” It’s a helper mechanism that keeps you from corrupting the memory and introducing hard-to-debug memory bugs. Whenever you get a segfault you know you are doing something wrong with memory – accessing a variable that has already been freed, writing to a read-only portion of the memory, etc. Segmentation fault is essentially the same in most languages that let you mess with memory management, there is no principal difference between segfaults in C and C++. There are many ways to get a segfault, at least in the lower-level languages such as C(++). A common way to get a segfault is to dereference a null pointer: \n```\nint *p = NULL;\n*p = 1;\n\n```\n Another segfault happens when you try to write to a portion of memory that was marked as read-only: \n```\nchar *str = ""Foo""; // Compiler marks the constant string as read-only\n*str = \'b\'; // Which means this is illegal and results in a segfault', ""```\n Dangling pointer points to a thing that does not exist anymore, like here: \n```\nchar *p = NULL;\n{\n    char c;\n    p = &c;\n}\n// Now p is dangling\n\n```\n The pointer \n```\np\n```\n dangles because it points to the character variable \n```\nc\n```\n that ceased to exist after the block ended. And when you try to dereference dangling pointer (like \n```\n*p='A'\n```\n), you would probably get a segfault.""]","Segmentation fault is a specific kind of error caused by accessing memory that “does not belong to you.” It’s a helper mechanism that keeps you from corrupting the memory and introducing hard-to-debug memory bugs. Whenever you get a segfault you know you are doing something wrong with memory – accessing a variable that has already been freed, writing to a read-only portion of the memory, etc. Segmentation fault is essentially the same in most languages that let you mess with memory management, there is no principal difference between segfaults in C and C++. There are many ways to get a segfault, at least in the lower-level languages such as C(++). A common way to get a segfault is to dereference a null pointer: 
```
int *p = NULL;
*p = 1;

```
 Another segfault happens when you try to write to a portion of memory that was marked as read-only: 
```
char *str = ""Foo""; // Compiler marks the constant string as read-only
*str = 'b'; // Which means this is illegal and results in a segfault

```
 Dangling pointer points to a thing that does not exist anymore, like here: 
```
char *p = NULL;
{
    char c;
    p = &c;
}
// Now p is dangling

```
 The pointer 
```
p
```
 dangles because it points to the character variable 
```
c
```
 that ceased to exist after the block ended. And when you try to dereference dangling pointer (like 
```
*p='A'
```
), you would probably get a segfault."
751681,What is the meaning of 'const' at the end of a member function declaration?,https://stackoverflow.com/questions/751681/what-is-the-meaning-of-const-at-the-end-of-a-member-function-declaration,12,,[],
120876,What are the rules for calling the base class constructor?,https://stackoverflow.com/questions/120876/what-are-the-rules-for-calling-the-base-class-constructor,10,1174.0,"['Base class constructors are automatically called for you if they have no argument. If you want to call a superclass constructor with an argument, you must use the subclass\'s constructor initialization list. Unlike Java, C++ supports multiple inheritance (for better or worse), so the base class must be referred to by name, rather than ""super()"". \n```\nclass SuperClass\n{\n    public:\n\n        SuperClass(int foo)\n        {\n            // do something with foo\n        }\n};\n\nclass SubClass : public SuperClass\n{\n    public:\n\n        SubClass(int foo, int bar)\n        : SuperClass(foo)    // Call the superclass constructor in the subclass\' initialization list.\n        {\n            // do something with bar\n        }\n};\n\n```\n More info on the constructor\'s initialization list here and here.']","Base class constructors are automatically called for you if they have no argument. If you want to call a superclass constructor with an argument, you must use the subclass's constructor initialization list. Unlike Java, C++ supports multiple inheritance (for better or worse), so the base class must be referred to by name, rather than ""super()"". 
```
class SuperClass
{
    public:

        SuperClass(int foo)
        {
            // do something with foo
        }
};

class SubClass : public SuperClass
{
    public:

        SubClass(int foo, int bar)
        : SuperClass(foo)    // Call the superclass constructor in the subclass' initialization list.
        {
            // do something with bar
        }
};

```
 More info on the constructor's initialization list here and here."
4184468,Sleep for milliseconds,https://stackoverflow.com/questions/4184468/sleep-for-milliseconds,18,531.0,"['Note that there is no standard C API for milliseconds, so (on Unix) you will have to settle for \n```\nusleep\n```\n, which accepts microseconds: \n```\n#include <unistd.h>\n\nunsigned int microseconds;\n...\nusleep(microseconds);\n\n```']","Note that there is no standard C API for milliseconds, so (on Unix) you will have to settle for 
```
usleep
```
, which accepts microseconds: 
```
#include <unistd.h>

unsigned int microseconds;
...
usleep(microseconds);

```
"
119123,Why isn't sizeof for a struct equal to the sum of sizeof of each member?,https://stackoverflow.com/questions/119123/why-isnt-sizeof-for-a-struct-equal-to-the-sum-of-sizeof-of-each-member,13,799.0,"[""This is because of padding added to satisfy alignment constraints. Data structure alignment impacts both performance and correctness of programs: Mis-aligned access might be a hard error (often \n```\nSIGBUS\n```\n). Mis-aligned access might be a soft error. Either corrected in hardware, for a modest performance-degradation. Or corrected by emulation in software, for a severe performance-degradation. In addition, atomicity and other concurrency-guarantees might be broken, leading to subtle errors. Here's an example using typical settings for an x86 processor (all used 32 and 64 bit modes): \n```\nstruct X\n{\n    short s; /* 2 bytes */\n             /* 2 padding bytes */\n    int   i; /* 4 bytes */\n    char  c; /* 1 byte */\n             /* 3 padding bytes */\n};\n\nstruct Y\n{\n    int   i; /* 4 bytes */\n    char  c; /* 1 byte */\n             /* 1 padding byte */\n    short s; /* 2 bytes */\n};"", 'struct Y\n{\n    int   i; /* 4 bytes */\n    char  c; /* 1 byte */\n             /* 1 padding byte */\n    short s; /* 2 bytes */\n};\n\nstruct Z\n{\n    int   i; /* 4 bytes */\n    short s; /* 2 bytes */\n    char  c; /* 1 byte */\n             /* 1 padding byte */\n};\n\nconst int sizeX = sizeof(struct X); /* = 12 */\nconst int sizeY = sizeof(struct Y); /* = 8 */\nconst int sizeZ = sizeof(struct Z); /* = 8 */', 'const int sizeX = sizeof(struct X); /* = 12 */\nconst int sizeY = sizeof(struct Y); /* = 8 */\nconst int sizeZ = sizeof(struct Z); /* = 8 */\n\n```\n One can minimize the size of structures by sorting members by alignment (sorting by size suffices for that in basic types) (like structure \n```\nZ\n```\n in the example above). IMPORTANT NOTE: Both the C and C++ standards state that structure alignment is implementation-defined. Therefore each compiler may choose to align data differently, resulting in different and incompatible data layouts. For this reason, when dealing with libraries that will be used by different compilers, it is important to understand how the compilers align data. Some compilers have command-line settings and/or special \n```\n#pragma\n```\n statements to change the structure alignment settings.']","This is because of padding added to satisfy alignment constraints. Data structure alignment impacts both performance and correctness of programs: Mis-aligned access might be a hard error (often 
```
SIGBUS
```
). Mis-aligned access might be a soft error. Either corrected in hardware, for a modest performance-degradation. Or corrected by emulation in software, for a severe performance-degradation. In addition, atomicity and other concurrency-guarantees might be broken, leading to subtle errors. Here's an example using typical settings for an x86 processor (all used 32 and 64 bit modes): 
```
struct X
{
    short s; /* 2 bytes */
             /* 2 padding bytes */
    int   i; /* 4 bytes */
    char  c; /* 1 byte */
             /* 3 padding bytes */
};

struct Y
{
    int   i; /* 4 bytes */
    char  c; /* 1 byte */
             /* 1 padding byte */
    short s; /* 2 bytes */
};

struct Z
{
    int   i; /* 4 bytes */
    short s; /* 2 bytes */
    char  c; /* 1 byte */
             /* 1 padding byte */
};

const int sizeX = sizeof(struct X); /* = 12 */
const int sizeY = sizeof(struct Y); /* = 8 */
const int sizeZ = sizeof(struct Z); /* = 8 */

```
 One can minimize the size of structures by sorting members by alignment (sorting by size suffices for that in basic types) (like structure 
```
Z
```
 in the example above). IMPORTANT NOTE: Both the C and C++ standards state that structure alignment is implementation-defined. Therefore each compiler may choose to align data differently, resulting in different and incompatible data layouts. For this reason, when dealing with libraries that will be used by different compilers, it is important to understand how the compilers align data. Some compilers have command-line settings and/or special 
```
#pragma
```
 statements to change the structure alignment settings."
2551775,Appending a vector to a vector,https://stackoverflow.com/questions/2551775/appending-a-vector-to-a-vector,4,,[],
204476,What should main() return in C and C++?,https://stackoverflow.com/questions/204476/what-should-main-return-in-c-and-c,19,666.0,"['The return value for \n```\nmain\n```\n indicates how the program exited. Normal exit is represented by a 0 return value from \n```\nmain\n```\n. Abnormal exit is signaled by a non-zero return, but there is no standard for how non-zero codes are interpreted. As noted by others, \n```\nvoid main()\n```\n is prohibited by the C++ standard and should not be used. The valid C++ \n```\nmain\n```\n signatures are: \n```\nint main(void)\n\n```\n and \n```\nint main(int argc, char **argv)\n\n```\n which is equivalent to \n```\nint main(int argc, char *argv[])', ""```\n and \n```\nint main(int argc, char **argv)\n\n```\n which is equivalent to \n```\nint main(int argc, char *argv[])\n\n```\n It is also worth noting that in C++, \n```\nint main()\n```\n can be left without a return-statement, at which point it defaults to returning 0. This is also true with a C99 program. Whether \n```\nreturn 0;\n```\n should be omitted or not is open to debate. The range of valid C program main signatures is much greater. Efficiency is not an issue with the \n```\nmain\n```\n function. It can only be entered and left once (marking the program's start and termination) according to the C++ standard. For C, re-entering \n```\nmain()\n```\n is allowed, but should be avoided.""]","The return value for 
```
main
```
 indicates how the program exited. Normal exit is represented by a 0 return value from 
```
main
```
. Abnormal exit is signaled by a non-zero return, but there is no standard for how non-zero codes are interpreted. As noted by others, 
```
void main()
```
 is prohibited by the C++ standard and should not be used. The valid C++ 
```
main
```
 signatures are: 
```
int main(void)

```
 and 
```
int main(int argc, char **argv)

```
 which is equivalent to 
```
int main(int argc, char *argv[])

```
 It is also worth noting that in C++, 
```
int main()
```
 can be left without a return-statement, at which point it defaults to returning 0. This is also true with a C99 program. Whether 
```
return 0;
```
 should be omitted or not is open to debate. The range of valid C program main signatures is much greater. Efficiency is not an issue with the 
```
main
```
 function. It can only be entered and left once (marking the program's start and termination) according to the C++ standard. For C, re-entering 
```
main()
```
 is allowed, but should be avoided."
103512,Why use static_cast<T>(x) instead of (T)x?,https://stackoverflow.com/questions/103512/why-use-static-casttx-instead-of-tx,9,756.0,"['The main reason is that classic C casts make no distinction between what we call \n```\nstatic_cast<>()\n```\n, \n```\nreinterpret_cast<>()\n```\n, \n```\nconst_cast<>()\n```\n, and \n```\ndynamic_cast<>()\n```\n. These four things are completely different. A \n```\nstatic_cast<>()\n```\n is usually safe. There is a valid conversion in the language, or an appropriate constructor that makes it possible. The only time it\'s a bit risky is when you cast down to an inherited class; you must make sure that the object is actually the descendant that you claim it is, by means external to the language (like a flag in the object). A \n```\ndynamic_cast<>()\n```\n is safe as long as the result is checked (pointer) or a possible exception is taken into account (reference). A \n```\nreinterpret_cast<>()\n```\n (or a \n```\nconst_cast<>()\n```\n) on the other hand is always dangerous. You tell the compiler: ""trust me: I know this doesn\'t look like a \n```\nfoo\n```', '```\nreinterpret_cast<>()\n```\n (or a \n```\nconst_cast<>()\n```\n) on the other hand is always dangerous. You tell the compiler: ""trust me: I know this doesn\'t look like a \n```\nfoo\n```\n (this looks as if it isn\'t mutable), but it is"". The first problem is that it\'s almost impossible to tell which one will occur in a C-style cast without looking at large and disperse pieces of code and knowing all the rules. Let\'s assume these: \n```\nclass CDerivedClass : public CMyBase {...};\nclass CMyOtherStuff {...} ;', ""CMyBase  *pSomething; // filled somewhere\n\n```\n Now, these two are compiled the same way: \n```\nCDerivedClass *pMyObject;\npMyObject = static_cast<CDerivedClass*>(pSomething); // Safe; as long as we checked\n\npMyObject = (CDerivedClass*)(pSomething); // Same as static_cast<>\n                                     // Safe; as long as we checked\n                                     // but harder to read\n\n```\n However, let's see this almost identical code: \n```\nCMyOtherStuff *pOther;\npOther = static_cast<CMyOtherStuff*>(pSomething); // Compiler error: Can't convert\n\npOther = (CMyOtherStuff*)(pSomething);            // No compiler error.\n                                                  // Same as reinterpret_cast<>\n                                                  // and it's wrong!!!"", '```\n As you can see, there is no easy way to distinguish between the two situations without knowing a lot about all the classes involved. The second problem is that the C-style casts are too hard to locate. In complex expressions it can be very hard to see C-style casts. It is virtually impossible to write an automated tool that needs to locate C-style casts (for example a search tool) without a full blown C++ compiler front-end. On the other hand, it\'s easy to search for ""static_cast<"" or ""reinterpret_cast<"". \n```\npOther = reinterpret_cast<CMyOtherStuff*>(pSomething);\n      // No compiler error.\n      // but the presence of a reinterpret_cast<> is \n      // like a Siren with Red Flashing Lights in your code.\n      // The mere typing of it should cause you to feel VERY uncomfortable.\n\n```\n That means that, not only are C-style casts more dangerous, but it\'s a lot harder to find them all to make sure that they are correct.']","The main reason is that classic C casts make no distinction between what we call 
```
static_cast<>()
```
, 
```
reinterpret_cast<>()
```
, 
```
const_cast<>()
```
, and 
```
dynamic_cast<>()
```
. These four things are completely different. A 
```
static_cast<>()
```
 is usually safe. There is a valid conversion in the language, or an appropriate constructor that makes it possible. The only time it's a bit risky is when you cast down to an inherited class; you must make sure that the object is actually the descendant that you claim it is, by means external to the language (like a flag in the object). A 
```
dynamic_cast<>()
```
 is safe as long as the result is checked (pointer) or a possible exception is taken into account (reference). A 
```
reinterpret_cast<>()
```
 (or a 
```
const_cast<>()
```
) on the other hand is always dangerous. You tell the compiler: ""trust me: I know this doesn't look like a 
```
foo
```
 (this looks as if it isn't mutable), but it is"". The first problem is that it's almost impossible to tell which one will occur in a C-style cast without looking at large and disperse pieces of code and knowing all the rules. Let's assume these: 
```
class CDerivedClass : public CMyBase {...};
class CMyOtherStuff {...} ;

CMyBase  *pSomething; // filled somewhere

```
 Now, these two are compiled the same way: 
```
CDerivedClass *pMyObject;
pMyObject = static_cast<CDerivedClass*>(pSomething); // Safe; as long as we checked

pMyObject = (CDerivedClass*)(pSomething); // Same as static_cast<>
                                     // Safe; as long as we checked
                                     // but harder to read

```
 However, let's see this almost identical code: 
```
CMyOtherStuff *pOther;
pOther = static_cast<CMyOtherStuff*>(pSomething); // Compiler error: Can't convert

pOther = (CMyOtherStuff*)(pSomething);            // No compiler error.
                                                  // Same as reinterpret_cast<>
                                                  // and it's wrong!!!

```
 As you can see, there is no easy way to distinguish between the two situations without knowing a lot about all the classes involved. The second problem is that the C-style casts are too hard to locate. In complex expressions it can be very hard to see C-style casts. It is virtually impossible to write an automated tool that needs to locate C-style casts (for example a search tool) without a full blown C++ compiler front-end. On the other hand, it's easy to search for ""static_cast<"" or ""reinterpret_cast<"". 
```
pOther = reinterpret_cast<CMyOtherStuff*>(pSomething);
      // No compiler error.
      // but the presence of a reinterpret_cast<> is 
      // like a Siren with Red Flashing Lights in your code.
      // The mere typing of it should cause you to feel VERY uncomfortable.

```
 That means that, not only are C-style casts more dangerous, but it's a lot harder to find them all to make sure that they are correct."
571394,How to find out if an item is present in a std::vector?,https://stackoverflow.com/questions/571394/how-to-find-out-if-an-item-is-present-in-a-stdvector,21,1226.0,"['You can use \n```\nstd::find\n```\n from \n```\n<algorithm>\n```\n: \n```\n#include <algorithm>\n#include <vector>\nvector<int> vec; \n//can have other data types instead of int but must same datatype as item \nstd::find(vec.begin(), vec.end(), item) != vec.end()\n\n```\n This returns an iterator to the first element found. If not present, it returns an iterator to one-past-the-last. With your example: \n```\n#include <algorithm>\n#include <vector>\n\nif ( std::find(vec.begin(), vec.end(), item) != vec.end() )\n   do_this();\nelse\n   do_that();\n\n```']","You can use 
```
std::find
```
 from 
```
<algorithm>
```
: 
```
#include <algorithm>
#include <vector>
vector<int> vec; 
//can have other data types instead of int but must same datatype as item 
std::find(vec.begin(), vec.end(), item) != vec.end()

```
 This returns an iterator to the first element found. If not present, it returns an iterator to one-past-the-last. With your example: 
```
#include <algorithm>
#include <vector>

if ( std::find(vec.begin(), vec.end(), item) != vec.end() )
   do_this();
else
   do_that();

```
"
612097,How can I get the list of files in a directory using C or C++?,https://stackoverflow.com/questions/612097/how-can-i-get-the-list-of-files-in-a-directory-using-c-or-c,33,1115.0,"['UPDATE 2017: In C++17 there is now an official way to list files of your file system: \n```\nstd::filesystem\n```\n. There is an excellent answer from Shreevardhan below with this source code: \n```\n#include <string>\n#include <iostream>\n#include <filesystem>\nnamespace fs = std::filesystem;\n\nint main()\n{\n    std::string path = ""/path/to/directory"";\n    for (const auto & entry : fs::directory_iterator(path))\n        std::cout << entry.path() << std::endl;\n}\n\n```\n Old Answer: In small and simple tasks I do not use boost, I use \n```\ndirent.h\n```\n. It is available as a standard header in UNIX, and also available for Windows via a compatibility layer created by Toni Rönkkö. \n```\nDIR *dir;\nstruct dirent *ent;\nif ((dir = opendir (""c:\\\\src\\\\"")) != NULL) {\n  /* print all the files and directories within directory */\n  while ((ent = readdir (dir)) != NULL) {\n    printf (""%s\\n"", ent->d_name);\n  }\n  closedir (dir);\n} else {\n  /* could not open directory */\n  perror ("""");\n  return EXIT_FAILURE;\n}', '```\n It is just a small header file and does most of the simple stuff you need without using a big template-based approach like boost (no offence, I like boost!).']","UPDATE 2017: In C++17 there is now an official way to list files of your file system: 
```
std::filesystem
```
. There is an excellent answer from Shreevardhan below with this source code: 
```
#include <string>
#include <iostream>
#include <filesystem>
namespace fs = std::filesystem;

int main()
{
    std::string path = ""/path/to/directory"";
    for (const auto & entry : fs::directory_iterator(path))
        std::cout << entry.path() << std::endl;
}

```
 Old Answer: In small and simple tasks I do not use boost, I use 
```
dirent.h
```
. It is available as a standard header in UNIX, and also available for Windows via a compatibility layer created by Toni Rönkkö. 
```
DIR *dir;
struct dirent *ent;
if ((dir = opendir (""c:\\src\\"")) != NULL) {
  /* print all the files and directories within directory */
  while ((ent = readdir (dir)) != NULL) {
    printf (""%s\n"", ent->d_name);
  }
  closedir (dir);
} else {
  /* could not open directory */
  perror ("""");
  return EXIT_FAILURE;
}

```
 It is just a small header file and does most of the simple stuff you need without using a big template-based approach like boost (no offence, I like boost!)."
7663709,How can I convert a std::string to int?,https://stackoverflow.com/questions/7663709/how-can-i-convert-a-stdstring-to-int,26,1151.0,"['In C++11 there are some nice new convert functions from \n```\nstd::string\n```\n to a number type. So instead of \n```\natoi( str.c_str() )\n\n```\n you can use \n```\nstd::stoi( str )\n\n```\n where \n```\nstr\n```\n is your number as \n```\nstd::string\n```\n. There are version for all flavours of numbers: \n```\nlong stol(string)\n```\n, \n```\nfloat stof(string)\n```\n, \n```\ndouble stod(string)\n```\n,... see http://en.cppreference.com/w/cpp/string/basic_string/stol']","In C++11 there are some nice new convert functions from 
```
std::string
```
 to a number type. So instead of 
```
atoi( str.c_str() )

```
 you can use 
```
std::stoi( str )

```
 where 
```
str
```
 is your number as 
```
std::string
```
. There are version for all flavours of numbers: 
```
long stol(string)
```
, 
```
float stof(string)
```
, 
```
double stod(string)
```
,... see http://en.cppreference.com/w/cpp/string/basic_string/stol"
7868936,Read file line by line using ifstream in C++,https://stackoverflow.com/questions/7868936/read-file-line-by-line-using-ifstream-in-c,8,1169.0,"['First, make an \n```\nifstream\n```\n: \n```\n#include <fstream>\nstd::ifstream infile(""thefile.txt"");\n\n```\n The two standard methods are: Assume that every line consists of two numbers and read token by token: \n```\nint a, b;\nwhile (infile >> a >> b)\n{\n    // process pair (a,b)\n}\n\n```\n Line-based parsing, using string streams: \n```\n#include <sstream>\n#include <string>\n\nstd::string line;\nwhile (std::getline(infile, line))\n{\n    std::istringstream iss(line);\n    int a, b;\n    if (!(iss >> a >> b)) { break; } // error\n\n    // process pair (a,b)\n}\n\n```\n You shouldn\'t mix (1) and (2), since the token-based parsing doesn\'t gobble up newlines, so you may end up with spurious empty lines if you use \n```\ngetline()\n```\n after token-based extraction got you to the end of a line already.']","First, make an 
```
ifstream
```
: 
```
#include <fstream>
std::ifstream infile(""thefile.txt"");

```
 The two standard methods are: Assume that every line consists of two numbers and read token by token: 
```
int a, b;
while (infile >> a >> b)
{
    // process pair (a,b)
}

```
 Line-based parsing, using string streams: 
```
#include <sstream>
#include <string>

std::string line;
while (std::getline(infile, line))
{
    std::istringstream iss(line);
    int a, b;
    if (!(iss >> a >> b)) { break; } // error

    // process pair (a,b)
}

```
 You shouldn't mix (1) and (2), since the token-based parsing doesn't gobble up newlines, so you may end up with spurious empty lines if you use 
```
getline()
```
 after token-based extraction got you to the end of a line already."
357307,How to call a parent class function from derived class function?,https://stackoverflow.com/questions/357307/how-to-call-a-parent-class-function-from-derived-class-function,9,1009.0,"['I\'ll take the risk of stating the obvious: You call the function, if it\'s defined in the base class it\'s automatically available in the derived class (unless it\'s \n```\nprivate\n```\n). If there is a function with the same signature in the derived class you can disambiguate it by adding the base class\'s name followed by two colons \n```\nbase_class::foo(...)\n```\n. You should note that unlike Java and C#, C++ does not have a keyword for ""the base class"" (\n```\nsuper\n```\n or \n```\nbase\n```\n) since C++ supports multiple inheritance which may lead to ambiguity. \n```\nclass left {\npublic:\n    void foo();\n};\n\nclass right {\npublic:\n    void foo();\n};\n\nclass bottom : public left, public right {\npublic:\n    void foo()\n    {\n        //base::foo();// ambiguous\n        left::foo();\n        right::foo();\n\n        // and when foo() is not called for \'this\':\n        bottom b;\n        b.left::foo();  // calls b.foo() from \'left\'\n        b.right::foo();  // call b.foo() from \'right\'\n    }\n};', ""// and when foo() is not called for 'this':\n        bottom b;\n        b.left::foo();  // calls b.foo() from 'left'\n        b.right::foo();  // call b.foo() from 'right'\n    }\n};\n\n```\n Incidentally, you can't derive directly from the same class twice since there will be no way to refer to one of the base classes over the other. \n```\nclass bottom : public left, public left { // Illegal\n};\n\n```""]","I'll take the risk of stating the obvious: You call the function, if it's defined in the base class it's automatically available in the derived class (unless it's 
```
private
```
). If there is a function with the same signature in the derived class you can disambiguate it by adding the base class's name followed by two colons 
```
base_class::foo(...)
```
. You should note that unlike Java and C#, C++ does not have a keyword for ""the base class"" (
```
super
```
 or 
```
base
```
) since C++ supports multiple inheritance which may lead to ambiguity. 
```
class left {
public:
    void foo();
};

class right {
public:
    void foo();
};

class bottom : public left, public right {
public:
    void foo()
    {
        //base::foo();// ambiguous
        left::foo();
        right::foo();

        // and when foo() is not called for 'this':
        bottom b;
        b.left::foo();  // calls b.foo() from 'left'
        b.right::foo();  // call b.foo() from 'right'
    }
};

```
 Incidentally, you can't derive directly from the same class twice since there will be no way to refer to one of the base classes over the other. 
```
class bottom : public left, public left { // Illegal
};

```
"
12264970,Why is my program slow when looping over exactly 8192 elements?,https://stackoverflow.com/questions/12264970/why-is-my-program-slow-when-looping-over-exactly-8192-elements,2,1008.0,"[""The difference is caused by the same super-alignment issue from the following related questions: Why is transposing a matrix of 512x512 much slower than transposing a matrix of 513x513? Matrix multiplication: Small difference in matrix size, large difference in timings But that's only because there's one other problem with the code. Starting from the original loop: \n```\nfor(i=1;i<SIZE-1;i++) \n    for(j=1;j<SIZE-1;j++) {\n        res[j][i]=0;\n        for(k=-1;k<2;k++) \n            for(l=-1;l<2;l++) \n                res[j][i] += img[j+l][i+k];\n        res[j][i] /= 9;\n}"", '```\n First notice that the two inner loops are trivial. They can be unrolled as follows: \n```\nfor(i=1;i<SIZE-1;i++) {\n    for(j=1;j<SIZE-1;j++) {\n        res[j][i]=0;\n        res[j][i] += img[j-1][i-1];\n        res[j][i] += img[j  ][i-1];\n        res[j][i] += img[j+1][i-1];\n        res[j][i] += img[j-1][i  ];\n        res[j][i] += img[j  ][i  ];\n        res[j][i] += img[j+1][i  ];\n        res[j][i] += img[j-1][i+1];\n        res[j][i] += img[j  ][i+1];\n        res[j][i] += img[j+1][i+1];\n        res[j][i] /= 9;\n    }\n}', ""```\n So that leaves the two outer-loops that we're interested in. Now we can see the problem is the same in this question: Why does the order of the loops affect performance when iterating over a 2D array? You are iterating the matrix column-wise instead of row-wise. To solve this problem, you should interchange the two loops. \n```\nfor(j=1;j<SIZE-1;j++) {\n    for(i=1;i<SIZE-1;i++) {\n        res[j][i]=0;\n        res[j][i] += img[j-1][i-1];\n        res[j][i] += img[j  ][i-1];\n        res[j][i] += img[j+1][i-1];\n        res[j][i] += img[j-1][i  ];\n        res[j][i] += img[j  ][i  ];\n        res[j][i] += img[j+1][i  ];\n        res[j][i] += img[j-1][i+1];\n        res[j][i] += img[j  ][i+1];\n        res[j][i] += img[j+1][i+1];\n        res[j][i] /= 9;\n    }\n}\n\n```\n This eliminates all the non-sequential access completely so you no longer get random slow-downs on large powers-of-two. Core i7 920 @ 3.5 GHz Original code: \n```\n8191: 1.499 seconds\n8192: 2.122 seconds\n8193: 1.582 seconds"", '```\n Interchanged Outer-Loops: \n```\n8191: 0.376 seconds\n8192: 0.357 seconds\n8193: 0.351 seconds\n\n```']","The difference is caused by the same super-alignment issue from the following related questions: Why is transposing a matrix of 512x512 much slower than transposing a matrix of 513x513? Matrix multiplication: Small difference in matrix size, large difference in timings But that's only because there's one other problem with the code. Starting from the original loop: 
```
for(i=1;i<SIZE-1;i++) 
    for(j=1;j<SIZE-1;j++) {
        res[j][i]=0;
        for(k=-1;k<2;k++) 
            for(l=-1;l<2;l++) 
                res[j][i] += img[j+l][i+k];
        res[j][i] /= 9;
}

```
 First notice that the two inner loops are trivial. They can be unrolled as follows: 
```
for(i=1;i<SIZE-1;i++) {
    for(j=1;j<SIZE-1;j++) {
        res[j][i]=0;
        res[j][i] += img[j-1][i-1];
        res[j][i] += img[j  ][i-1];
        res[j][i] += img[j+1][i-1];
        res[j][i] += img[j-1][i  ];
        res[j][i] += img[j  ][i  ];
        res[j][i] += img[j+1][i  ];
        res[j][i] += img[j-1][i+1];
        res[j][i] += img[j  ][i+1];
        res[j][i] += img[j+1][i+1];
        res[j][i] /= 9;
    }
}

```
 So that leaves the two outer-loops that we're interested in. Now we can see the problem is the same in this question: Why does the order of the loops affect performance when iterating over a 2D array? You are iterating the matrix column-wise instead of row-wise. To solve this problem, you should interchange the two loops. 
```
for(j=1;j<SIZE-1;j++) {
    for(i=1;i<SIZE-1;i++) {
        res[j][i]=0;
        res[j][i] += img[j-1][i-1];
        res[j][i] += img[j  ][i-1];
        res[j][i] += img[j+1][i-1];
        res[j][i] += img[j-1][i  ];
        res[j][i] += img[j  ][i  ];
        res[j][i] += img[j+1][i  ];
        res[j][i] += img[j-1][i+1];
        res[j][i] += img[j  ][i+1];
        res[j][i] += img[j+1][i+1];
        res[j][i] /= 9;
    }
}

```
 This eliminates all the non-sequential access completely so you no longer get random slow-downs on large powers-of-two. Core i7 920 @ 3.5 GHz Original code: 
```
8191: 1.499 seconds
8192: 2.122 seconds
8193: 1.582 seconds

```
 Interchanged Outer-Loops: 
```
8191: 0.376 seconds
8192: 0.357 seconds
8193: 0.351 seconds

```
"
2023977,"What is the difference between ""typename"" and ""class"" template parameters?",https://stackoverflow.com/questions/2023977/what-is-the-difference-between-typename-and-class-template-parameters,6,620.0,"['```\ntypename\n```\n and \n```\nclass\n```\n are interchangeable in the basic case of specifying a template: \n```\ntemplate<class T>\nclass Foo\n{\n};\n\n```\n and \n```\ntemplate<typename T>\nclass Foo\n{\n};\n\n```\n are equivalent. Having said that, there are specific cases where there is a difference between \n```\ntypename\n```\n and \n```\nclass\n```\n. The first one is in the case of dependent types. \n```\ntypename\n```\n is used to declare when you are referencing a nested type that depends on another template parameter, such as the \n```\ntypedef\n```\n in this example: \n```\ntemplate<typename param_t>\nclass Foo\n{\n    typedef typename param_t::baz sub_t;\n};\n\n```\n The second one you actually show in your question, though you might not realize it: \n```\ntemplate < template < typename, typename > class Container, typename Type >', ""```\n The second one you actually show in your question, though you might not realize it: \n```\ntemplate < template < typename, typename > class Container, typename Type >\n\n```\n When specifying a template template, the \n```\nclass\n```\n keyword MUST be used as above -- it is not interchangeable with \n```\ntypename\n```\n in this case (note: since C++17 both keywords are allowed in this case). You also must use \n```\nclass\n```\n when explicitly instantiating a template: \n```\ntemplate class Foo<int>;\n\n```\n I'm sure that there are other cases that I've missed, but the bottom line is: these two keywords are not equivalent, and these are some common cases where you need to use one or the other.""]","
```
typename
```
 and 
```
class
```
 are interchangeable in the basic case of specifying a template: 
```
template<class T>
class Foo
{
};

```
 and 
```
template<typename T>
class Foo
{
};

```
 are equivalent. Having said that, there are specific cases where there is a difference between 
```
typename
```
 and 
```
class
```
. The first one is in the case of dependent types. 
```
typename
```
 is used to declare when you are referencing a nested type that depends on another template parameter, such as the 
```
typedef
```
 in this example: 
```
template<typename param_t>
class Foo
{
    typedef typename param_t::baz sub_t;
};

```
 The second one you actually show in your question, though you might not realize it: 
```
template < template < typename, typename > class Container, typename Type >

```
 When specifying a template template, the 
```
class
```
 keyword MUST be used as above -- it is not interchangeable with 
```
typename
```
 in this case (note: since C++17 both keywords are allowed in this case). You also must use 
```
class
```
 when explicitly instantiating a template: 
```
template class Foo<int>;

```
 I'm sure that there are other cases that I've missed, but the bottom line is: these two keywords are not equivalent, and these are some common cases where you need to use one or the other."
191757,How to concatenate a std::string and an int,https://stackoverflow.com/questions/191757/how-to-concatenate-a-stdstring-and-an-int,25,,[],
3141087,"What is meant with ""const"" at end of function declaration?",https://stackoverflow.com/questions/3141087/what-is-meant-with-const-at-end-of-function-declaration,6,1278.0,"['A ""const function"", denoted with the keyword \n```\nconst\n```\n after a function declaration, makes it a compiler error for this class function to change a data member of the class. However, reading of a class variables is okay inside of the function, but writing inside of this function will generate a compiler error. Another way of thinking about such ""const function"" is by viewing a class function as a normal function taking an implicit \n```\nthis\n```\n pointer. So a method \n```\nint Foo::Bar(int random_arg)\n```\n (without the const at the end) results in a function like \n```\nint Foo_Bar(Foo* this, int random_arg)\n```\n, and a call such as \n```\nFoo f; f.Bar(4)\n```\n will internally correspond to something like \n```\nFoo f; Foo_Bar(&f, 4)\n```\n. Now adding the const at the end (\n```\nint Foo::Bar(int random_arg) const\n```\n) can then be understood as a declaration with a const this pointer: \n```\nint Foo_Bar(const Foo* this, int random_arg)\n```\n. Since the type of \n```\nthis\n```', '```\nint Foo::Bar(int random_arg) const\n```\n) can then be understood as a declaration with a const this pointer: \n```\nint Foo_Bar(const Foo* this, int random_arg)\n```\n. Since the type of \n```\nthis\n```\n in such case is const, no modifications of data members are possible. It is possible to loosen the ""const function"" restriction of not allowing the function to write to any variable of a class. To allow some of the variables to be writable even when the function is marked as a ""const function"", these class variables are marked with the keyword \n```\nmutable\n```\n. Thus, if a class variable is marked as mutable, and a ""const function"" writes to this variable then the code will compile cleanly and the variable is possible to change. (C++11) As usual when dealing with the \n```\nconst\n```\n keyword, changing the location of the const key word in a C++ statement has entirely different meanings. The above usage of \n```\nconst\n```\n only applies when adding \n```\nconst\n```', ""```\nconst\n```\n keyword, changing the location of the const key word in a C++ statement has entirely different meanings. The above usage of \n```\nconst\n```\n only applies when adding \n```\nconst\n```\n to the end of the function declaration after the parenthesis. \n```\nconst\n```\n is a highly overused qualifier in C++: the syntax and ordering is often not straightforward in combination with pointers. Some readings about \n```\nconst\n```\n correctness and the \n```\nconst\n```\n keyword: Const correctness The C++ 'const' Declaration: Why & How""]","A ""const function"", denoted with the keyword 
```
const
```
 after a function declaration, makes it a compiler error for this class function to change a data member of the class. However, reading of a class variables is okay inside of the function, but writing inside of this function will generate a compiler error. Another way of thinking about such ""const function"" is by viewing a class function as a normal function taking an implicit 
```
this
```
 pointer. So a method 
```
int Foo::Bar(int random_arg)
```
 (without the const at the end) results in a function like 
```
int Foo_Bar(Foo* this, int random_arg)
```
, and a call such as 
```
Foo f; f.Bar(4)
```
 will internally correspond to something like 
```
Foo f; Foo_Bar(&f, 4)
```
. Now adding the const at the end (
```
int Foo::Bar(int random_arg) const
```
) can then be understood as a declaration with a const this pointer: 
```
int Foo_Bar(const Foo* this, int random_arg)
```
. Since the type of 
```
this
```
 in such case is const, no modifications of data members are possible. It is possible to loosen the ""const function"" restriction of not allowing the function to write to any variable of a class. To allow some of the variables to be writable even when the function is marked as a ""const function"", these class variables are marked with the keyword 
```
mutable
```
. Thus, if a class variable is marked as mutable, and a ""const function"" writes to this variable then the code will compile cleanly and the variable is possible to change. (C++11) As usual when dealing with the 
```
const
```
 keyword, changing the location of the const key word in a C++ statement has entirely different meanings. The above usage of 
```
const
```
 only applies when adding 
```
const
```
 to the end of the function declaration after the parenthesis. 
```
const
```
 is a highly overused qualifier in C++: the syntax and ordering is often not straightforward in combination with pointers. Some readings about 
```
const
```
 correctness and the 
```
const
```
 keyword: Const correctness The C++ 'const' Declaration: Why & How"
152555,*.h or *.hpp for your class definitions,https://stackoverflow.com/questions/152555/h-or-hpp-for-your-class-definitions,22,740.0,"[""Here are a couple of reasons for having different naming of C vs C++ headers: Automatic code formatting, you might have different guidelines for formatting C and C++ code. If the headers are separated by extension you can set your editor to apply the appropriate formatting automatically Naming, I've been on projects where there were libraries written in C and then wrappers had been implemented in C++. Since the headers usually had similar names, i.e. Feature.h vs Feature.hpp, they were easy to tell apart. Inclusion, maybe your project has more appropriate versions available written in C++ but you are using the C version (see above point). If headers are named after the language they are implemented in you can easily spot all the C-headers and check for C++ versions. Remember, C is not C++ and it can be very dangerous to mix and match unless you know what you are doing. Naming your sources appropriately helps you tell the languages apart.""]","Here are a couple of reasons for having different naming of C vs C++ headers: Automatic code formatting, you might have different guidelines for formatting C and C++ code. If the headers are separated by extension you can set your editor to apply the appropriate formatting automatically Naming, I've been on projects where there were libraries written in C and then wrappers had been implemented in C++. Since the headers usually had similar names, i.e. Feature.h vs Feature.hpp, they were easy to tell apart. Inclusion, maybe your project has more appropriate versions available written in C++ but you are using the C version (see above point). If headers are named after the language they are implemented in you can easily spot all the C-headers and check for C++ versions. Remember, C is not C++ and it can be very dangerous to mix and match unless you know what you are doing. Naming your sources appropriately helps you tell the languages apart."
63166,How to determine CPU and memory consumption from inside a process,https://stackoverflow.com/questions/63166/how-to-determine-cpu-and-memory-consumption-from-inside-a-process,10,,[],
1759300,When should I write the keyword 'inline' for a function/method?,https://stackoverflow.com/questions/1759300/when-should-i-write-the-keyword-inline-for-a-function-method,16,1205.0,"[""Oh man, one of my pet peeves. \n```\ninline\n```\n is more like \n```\nstatic\n```\n or \n```\nextern\n```\n than a directive telling the compiler to inline your functions. \n```\nextern\n```\n, \n```\nstatic\n```\n, \n```\ninline\n```\n are linkage directives, used almost exclusively by the linker, not the compiler. It is said that \n```\ninline\n```\n hints to the compiler that you think the function should be inlined. That may have been true in 1998, but a decade later the compiler needs no such hints. Not to mention humans are usually wrong when it comes to optimizing code, so most compilers flat out ignore the 'hint'. \n```\nstatic\n```\n - the variable/function name cannot be used in other translation units. Linker needs to make sure it doesn't accidentally use a statically defined variable/function from another translation unit. \n```\nextern\n```"", ""```\nextern\n```\n - use this variable/function name in this translation unit but don't complain if it isn't defined. The linker will sort it out and make sure all the code that tried to use some extern symbol has its address. \n```\ninline\n```\n - this function will be defined in multiple translation units, don't worry about it. The linker needs to make sure all translation units use a single instance of the variable/function. Note: Generally, declaring templates \n```\ninline\n```\n is pointless, as they have the linkage semantics of \n```\ninline\n```\n already. However, explicit specialization and instantiation of templates require \n```\ninline\n```"", ""```\ninline\n```\n to be used. Specific answers to your questions: When should I write the keyword 'inline' for a function/method in C++? Only when you want the function to be defined in a header. More exactly only when the function's definition can show up in multiple translation units. It's a good idea to define small (as in one liner) functions in the header file as it gives the compiler more information to work with while optimizing your code. It also increases compilation time. When should I not write the keyword 'inline' for a function/method in C++? Don't add inline just because you think your code will run faster if the compiler inlines it. When will the compiler not know when to make a function/method 'inline'? Generally, the compiler will be able to do this better than you. However, the compiler doesn't have the option to inline code if it doesn't have the function definition. In maximally optimized code usually all \n```\nprivate\n```"", ""```\nprivate\n```\n methods are inlined whether you ask for it or not. As an aside to prevent inlining in GCC, use \n```\n__attribute__(( noinline ))\n```\n, and in Visual Studio, use \n```\n__declspec(noinline)\n```\n. Does it matter if an application is multithreaded when one writes 'inline' for a function/method? Multithreading doesn't affect inlining in any way.""]","Oh man, one of my pet peeves. 
```
inline
```
 is more like 
```
static
```
 or 
```
extern
```
 than a directive telling the compiler to inline your functions. 
```
extern
```
, 
```
static
```
, 
```
inline
```
 are linkage directives, used almost exclusively by the linker, not the compiler. It is said that 
```
inline
```
 hints to the compiler that you think the function should be inlined. That may have been true in 1998, but a decade later the compiler needs no such hints. Not to mention humans are usually wrong when it comes to optimizing code, so most compilers flat out ignore the 'hint'. 
```
static
```
 - the variable/function name cannot be used in other translation units. Linker needs to make sure it doesn't accidentally use a statically defined variable/function from another translation unit. 
```
extern
```
 - use this variable/function name in this translation unit but don't complain if it isn't defined. The linker will sort it out and make sure all the code that tried to use some extern symbol has its address. 
```
inline
```
 - this function will be defined in multiple translation units, don't worry about it. The linker needs to make sure all translation units use a single instance of the variable/function. Note: Generally, declaring templates 
```
inline
```
 is pointless, as they have the linkage semantics of 
```
inline
```
 already. However, explicit specialization and instantiation of templates require 
```
inline
```
 to be used. Specific answers to your questions: When should I write the keyword 'inline' for a function/method in C++? Only when you want the function to be defined in a header. More exactly only when the function's definition can show up in multiple translation units. It's a good idea to define small (as in one liner) functions in the header file as it gives the compiler more information to work with while optimizing your code. It also increases compilation time. When should I not write the keyword 'inline' for a function/method in C++? Don't add inline just because you think your code will run faster if the compiler inlines it. When will the compiler not know when to make a function/method 'inline'? Generally, the compiler will be able to do this better than you. However, the compiler doesn't have the option to inline code if it doesn't have the function definition. In maximally optimized code usually all 
```
private
```
 methods are inlined whether you ask for it or not. As an aside to prevent inlining in GCC, use 
```
__attribute__(( noinline ))
```
, and in Visual Studio, use 
```
__declspec(noinline)
```
. Does it matter if an application is multithreaded when one writes 'inline' for a function/method? Multithreading doesn't affect inlining in any way."
2340281,Check if a string contains a string in C++,https://stackoverflow.com/questions/2340281/check-if-a-string-contains-a-string-in-c,16,1152.0,"['Use \n```\nstd::string::find\n```\n as follows: \n```\nif (s1.find(s2) != std::string::npos) {\n    std::cout << ""found!"" << \'\\n\';\n}\n\n```\n Note: ""found!"" will be printed if \n```\ns2\n```\n is a substring of \n```\ns1\n```\n, both \n```\ns1\n```\n and \n```\ns2\n```\n are of type \n```\nstd::string\n```\n.']","Use 
```
std::string::find
```
 as follows: 
```
if (s1.find(s2) != std::string::npos) {
    std::cout << ""found!"" << '\n';
}

```
 Note: ""found!"" will be printed if 
```
s2
```
 is a substring of 
```
s1
```
, both 
```
s1
```
 and 
```
s2
```
 are of type 
```
std::string
```
."
1545080,C++ code file extension? What is the difference between .cc and .cpp,https://stackoverflow.com/questions/1545080/c-code-file-extension-what-is-the-difference-between-cc-and-cpp,17,923.0,"[""At the end of the day it doesn't matter because C++ compilers can deal with the files in either format. If it's a real issue within your team, flip a coin and move on to the actual work.""]","At the end of the day it doesn't matter because C++ compilers can deal with the files in either format. If it's a real issue within your team, flip a coin and move on to the actual work."
589575,"What does the C++ standard say about the size of int, long?",https://stackoverflow.com/questions/589575/what-does-the-c-standard-say-about-the-size-of-int-long,24,,[],
18335861,Why is enum class considered safer to use than plain enum?,https://stackoverflow.com/questions/18335861/why-is-enum-class-considered-safer-to-use-than-plain-enum,9,837.0,"['C++ has two kinds of \n```\nenum\n```\n: \n```\nenum class\n```\nes Plain \n```\nenum\n```\ns Here are a couple of examples on how to declare them: \n```\n enum class Color { red, green, blue }; // enum class\n enum Animal { dog, cat, bird, human }; // plain enum \n\n```\n What is the difference between the two? \n```\nenum class\n```\nes - enumerator names are local to the enum and their values do not implicitly convert to other types (like another \n```\nenum\n```\n or \n```\nint\n```\n) Plain \n```\nenum\n```\ns - where enumerator names are in the same scope as the enum and their values implicitly convert to integers and other types Example: \n```\nenum Color { red, green, blue };                    // plain enum \nenum Card { red_card, green_card, yellow_card };    // another plain enum \nenum class Animal { dog, deer, cat, bird, human };  // enum class\nenum class Mammal { kangaroo, deer, human };        // another enum class\n\nvoid fun() {', 'void fun() {\n\n    // examples of bad use of plain enums:\n    Color color = Color::red;\n    Card card = Card::green_card;\n\n    int num = color;    // no problem\n\n    if (color == Card::red_card) // no problem (bad)\n        cout << ""bad"" << endl;\n\n    if (card == Color::green)   // no problem (bad)\n        cout << ""bad"" << endl;\n\n    // examples of good use of enum classes (safe)\n    Animal a = Animal::deer;\n    Mammal m = Mammal::deer;\n\n    int num2 = a;   // error\n    if (m == a)         // error (good)\n        cout << ""bad"" << endl;\n\n    if (a == Mammal::deer) // error (good)\n        cout << ""bad"" << endl;\n\n}\n\n```\n Conclusion: \n```\nenum class\n```\nes should be preferred because they cause fewer surprises that could potentially lead to bugs.']","C++ has two kinds of 
```
enum
```
: 
```
enum class
```
es Plain 
```
enum
```
s Here are a couple of examples on how to declare them: 
```
 enum class Color { red, green, blue }; // enum class
 enum Animal { dog, cat, bird, human }; // plain enum 

```
 What is the difference between the two? 
```
enum class
```
es - enumerator names are local to the enum and their values do not implicitly convert to other types (like another 
```
enum
```
 or 
```
int
```
) Plain 
```
enum
```
s - where enumerator names are in the same scope as the enum and their values implicitly convert to integers and other types Example: 
```
enum Color { red, green, blue };                    // plain enum 
enum Card { red_card, green_card, yellow_card };    // another plain enum 
enum class Animal { dog, deer, cat, bird, human };  // enum class
enum class Mammal { kangaroo, deer, human };        // another enum class

void fun() {

    // examples of bad use of plain enums:
    Color color = Color::red;
    Card card = Card::green_card;

    int num = color;    // no problem

    if (color == Card::red_card) // no problem (bad)
        cout << ""bad"" << endl;

    if (card == Color::green)   // no problem (bad)
        cout << ""bad"" << endl;

    // examples of good use of enum classes (safe)
    Animal a = Animal::deer;
    Mammal m = Mammal::deer;

    int num2 = a;   // error
    if (m == a)         // error (good)
        cout << ""bad"" << endl;

    if (a == Mammal::deer) // error (good)
        cout << ""bad"" << endl;

}

```
 Conclusion: 
```
enum class
```
es should be preferred because they cause fewer surprises that could potentially lead to bugs."
199333,How do I detect unsigned integer overflow?,https://stackoverflow.com/questions/199333/how-do-i-detect-unsigned-integer-overflow,30,,[],
875103,How do I erase an element from std::vector<> by index?,https://stackoverflow.com/questions/875103/how-do-i-erase-an-element-from-stdvector-by-index,16,869.0,"['To delete a single element, you could do: \n```\nstd::vector<int> vec;\n\nvec.push_back(6);\nvec.push_back(-17);\nvec.push_back(12);\n\n// Deletes the second element (vec[1])\nvec.erase(std::next(vec.begin()));\n\n```\n Or, to delete more than one element at once: \n```\n// Deletes the second through third elements (vec[1], vec[2])\nvec.erase(std::next(vec.begin(), 1), std::next(vec.begin(), 3));\n\n```']","To delete a single element, you could do: 
```
std::vector<int> vec;

vec.push_back(6);
vec.push_back(-17);
vec.push_back(12);

// Deletes the second element (vec[1])
vec.erase(std::next(vec.begin()));

```
 Or, to delete more than one element at once: 
```
// Deletes the second through third elements (vec[1], vec[2])
vec.erase(std::next(vec.begin(), 1), std::next(vec.begin(), 3));

```
"
10787766,When should I really use noexcept?,https://stackoverflow.com/questions/10787766/when-should-i-really-use-noexcept,10,253.0,"['I think it is too early to give a ""best practices"" answer for this as there hasn\'t been enough time to use it in practice. If this was asked about throw specifiers right after they came out then the answers would be very different to now. Having to think about whether or not I need to append \n```\nnoexcept\n```\n after every function declaration would greatly reduce programmer productivity (and frankly, would be a pain). Well, then use it when it\'s obvious that the function will never throw. When can I realistically expect to observe a performance improvement after using \n```\nnoexcept\n```\n? [...] Personally, I care about \n```\nnoexcept\n```\n because of the increased freedom provided to the compiler to safely apply certain kinds of optimizations. It seems like the biggest optimization gains are from user optimizations, not compiler ones due to the possibility of checking \n```\nnoexcept\n```', ""```\nnoexcept\n```\n and overloading on it. Most compilers follow a no-penalty-if-you-don't-throw exception handling method, so I doubt it would change much (or anything) on the machine code level of your code, although perhaps reduce the binary size by removing the handling code. Using \n```\nnoexcept\n```\n in the big four (constructors, assignment, not destructors as they're already \n```\nnoexcept\n```\n) will likely cause the best improvements as \n```\nnoexcept\n```\n checks are 'common' in template code such as in \n```\nstd\n```\n containers. For instance, \n```\nstd::vector\n```\n won't use your class's move unless it's marked \n```\nnoexcept\n```\n (or the compiler can deduce it otherwise).""]","I think it is too early to give a ""best practices"" answer for this as there hasn't been enough time to use it in practice. If this was asked about throw specifiers right after they came out then the answers would be very different to now. Having to think about whether or not I need to append 
```
noexcept
```
 after every function declaration would greatly reduce programmer productivity (and frankly, would be a pain). Well, then use it when it's obvious that the function will never throw. When can I realistically expect to observe a performance improvement after using 
```
noexcept
```
? [...] Personally, I care about 
```
noexcept
```
 because of the increased freedom provided to the compiler to safely apply certain kinds of optimizations. It seems like the biggest optimization gains are from user optimizations, not compiler ones due to the possibility of checking 
```
noexcept
```
 and overloading on it. Most compilers follow a no-penalty-if-you-don't-throw exception handling method, so I doubt it would change much (or anything) on the machine code level of your code, although perhaps reduce the binary size by removing the handling code. Using 
```
noexcept
```
 in the big four (constructors, assignment, not destructors as they're already 
```
noexcept
```
) will likely cause the best improvements as 
```
noexcept
```
 checks are 'common' in template code such as in 
```
std
```
 containers. For instance, 
```
std::vector
```
 won't use your class's move unless it's marked 
```
noexcept
```
 (or the compiler can deduce it otherwise)."
2602013,Read whole ASCII file into C++ std::string,https://stackoverflow.com/questions/2602013/read-whole-ascii-file-into-c-stdstring,9,616.0,"['Update: Turns out that this method, while following STL idioms well, is actually surprisingly inefficient! Don\'t do this with large files. (See: http://insanecoding.blogspot.com/2011/11/how-to-read-in-file-in-c.html) You can make a streambuf iterator out of the file and initialize the string with it: \n```\n#include <string>\n#include <fstream>\n#include <streambuf>\n\nstd::ifstream t(""file.txt"");\nstd::string str((std::istreambuf_iterator<char>(t)),\n                 std::istreambuf_iterator<char>());', 'std::ifstream t(""file.txt"");\nstd::string str((std::istreambuf_iterator<char>(t)),\n                 std::istreambuf_iterator<char>());\n\n```\n Not sure where you\'re getting the \n```\nt.open(""file.txt"", ""r"")\n```\n syntax from. As far as I know that\'s not a method that \n```\nstd::ifstream\n```\n has. It looks like you\'ve confused it with C\'s \n```\nfopen\n```\n. Edit: Also note the extra parentheses around the first argument to the string constructor. These are essential. They prevent the problem known as the ""most vexing parse"", which in this case won\'t actually give you a compile error like it usually does, but will give you interesting (read: wrong) results. Following KeithB\'s point in the comments, here\'s a way to do it that allocates all the memory up front (rather than relying on the string class\'s automatic reallocation): \n```\n#include <string>\n#include <fstream>\n#include <streambuf>\n\nstd::ifstream t(""file.txt"");\nstd::string str;', 'std::ifstream t(""file.txt"");\nstd::string str;\n\nt.seekg(0, std::ios::end);   \nstr.reserve(t.tellg());\nt.seekg(0, std::ios::beg);\n\nstr.assign((std::istreambuf_iterator<char>(t)),\n            std::istreambuf_iterator<char>());\n\n```']","Update: Turns out that this method, while following STL idioms well, is actually surprisingly inefficient! Don't do this with large files. (See: http://insanecoding.blogspot.com/2011/11/how-to-read-in-file-in-c.html) You can make a streambuf iterator out of the file and initialize the string with it: 
```
#include <string>
#include <fstream>
#include <streambuf>

std::ifstream t(""file.txt"");
std::string str((std::istreambuf_iterator<char>(t)),
                 std::istreambuf_iterator<char>());

```
 Not sure where you're getting the 
```
t.open(""file.txt"", ""r"")
```
 syntax from. As far as I know that's not a method that 
```
std::ifstream
```
 has. It looks like you've confused it with C's 
```
fopen
```
. Edit: Also note the extra parentheses around the first argument to the string constructor. These are essential. They prevent the problem known as the ""most vexing parse"", which in this case won't actually give you a compile error like it usually does, but will give you interesting (read: wrong) results. Following KeithB's point in the comments, here's a way to do it that allocates all the memory up front (rather than relying on the string class's automatic reallocation): 
```
#include <string>
#include <fstream>
#include <streambuf>

std::ifstream t(""file.txt"");
std::string str;

t.seekg(0, std::ios::end);   
str.reserve(t.tellg());
t.seekg(0, std::ios::beg);

str.assign((std::istreambuf_iterator<char>(t)),
            std::istreambuf_iterator<char>());

```
"
1653958,Why are #ifndef and #define used in C++ header files?,https://stackoverflow.com/questions/1653958/why-are-ifndef-and-define-used-in-c-header-files,5,739.0,"[""Those are called #include guards. Once the header is included, it checks if a unique value (in this case \n```\nHEADERFILE_H\n```\n) is defined. Then if it's not defined, it defines it and continues to the rest of the page. When the code is included again, the first \n```\nifndef\n```\n fails, resulting in a blank file. That prevents double declaration of any identifiers such as types, enums and static variables.""]","Those are called #include guards. Once the header is included, it checks if a unique value (in this case 
```
HEADERFILE_H
```
) is defined. Then if it's not defined, it defines it and continues to the rest of the page. When the code is included again, the first 
```
ifndef
```
 fails, resulting in a blank file. That prevents double declaration of any identifiers such as types, enums and static variables."
115703,Storing C++ template function definitions in a .CPP file,https://stackoverflow.com/questions/115703/storing-c-template-function-definitions-in-a-cpp-file,14,320.0,"['The problem you describe can be solved by defining the template in the header, or via the approach you describe above. I recommend reading the following points from the C++ FAQ Lite: Why can’t I separate the definition of my templates class from its declaration and put it inside a .cpp file? How can I avoid linker errors with my template functions? How does the C++ keyword export help with template linker errors? They go into a lot of detail about these (and other) template issues.']","The problem you describe can be solved by defining the template in the header, or via the approach you describe above. I recommend reading the following points from the C++ FAQ Lite: Why can’t I separate the definition of my templates class from its declaration and put it inside a .cpp file? How can I avoid linker errors with my template functions? How does the C++ keyword export help with template linker errors? They go into a lot of detail about these (and other) template issues."
2236197,What is the easiest way to initialize a std::vector with hardcoded elements?,https://stackoverflow.com/questions/2236197/what-is-the-easiest-way-to-initialize-a-stdvector-with-hardcoded-elements,29,588.0,"['One method would be to use the array to initialize the vector \n```\nstatic const int arr[] = {16,2,77,29};\nvector<int> vec (arr, arr + sizeof(arr) / sizeof(arr[0]) );\n\n```']","One method would be to use the array to initialize the vector 
```
static const int arr[] = {16,2,77,29};
vector<int> vec (arr, arr + sizeof(arr) / sizeof(arr[0]) );

```
"
213907,"""std::endl"" vs ""\n""",https://stackoverflow.com/questions/213907/stdendl-vs-n,12,581.0,"[""The varying line-ending characters don't matter, assuming the file is open in text mode, which is what you get unless you ask for binary. The compiled program will write out the correct thing for the system compiled for. The only difference is that \n```\nstd::endl\n```\n flushes the output buffer, and \n```\n'\\n'\n```\n doesn't. If you don't want the buffer flushed frequently, use \n```\n'\\n'\n```\n. If you do (for example, if you want to get all the output, and the program is unstable), use \n```\nstd::endl\n```\n.""]","The varying line-ending characters don't matter, assuming the file is open in text mode, which is what you get unless you ask for binary. The compiled program will write out the correct thing for the system compiled for. The only difference is that 
```
std::endl
```
 flushes the output buffer, and 
```
'\n'
```
 doesn't. If you don't want the buffer flushed frequently, use 
```
'\n'
```
. If you do (for example, if you want to get all the output, and the program is unstable), use 
```
std::endl
```
."
12887700,Can code that is valid in both C and C++ produce different behavior when compiled in each language?,https://stackoverflow.com/questions/12887700/can-code-that-is-valid-in-both-c-and-c-produce-different-behavior-when-compile,19,419.0,"['The following, valid in C and C++, is going to (most likely) result in different values in \n```\ni\n```\n in C and C++: \n```\nint i = sizeof(\'a\');\n\n```\n See Size of character (\'a\') in C/C++ for an explanation of the difference. Another one from this article: \n```\n#include <stdio.h>\n\nint  sz = 80;\n\nint main(void)\n{\n    struct sz { char c; };\n\n    int val = sizeof(sz);      // sizeof(int) in C,\n                               // sizeof(struct sz) in C++\n    printf(""%d\\n"", val);\n    return 0;\n}\n\n```']","The following, valid in C and C++, is going to (most likely) result in different values in 
```
i
```
 in C and C++: 
```
int i = sizeof('a');

```
 See Size of character ('a') in C/C++ for an explanation of the difference. Another one from this article: 
```
#include <stdio.h>

int  sz = 80;

int main(void)
{
    struct sz { char c; };

    int val = sizeof(sz);      // sizeof(int) in C,
                               // sizeof(struct sz) in C++
    printf(""%d\n"", val);
    return 0;
}

```
"
3024197,"What does int argc, char *argv[] mean?",https://stackoverflow.com/questions/3024197/what-does-int-argc-char-argv-mean,11,890.0,"['```\nargv\n```\n and \n```\nargc\n```\n are how command line arguments are passed to \n```\nmain()\n```\n in C and C++. \n```\nargc\n```\n will be the number of strings pointed to by \n```\nargv\n```\n. This will (in practice) be 1 plus the number of arguments, as virtually all implementations will prepend the name of the program to the array. The variables are named \n```\nargc\n```\n (argument count) and \n```\nargv\n```\n (argument vector) by convention, but they can be given any valid identifier: \n```\nint main(int num_args, char** arg_strings)\n```\n is equally valid. They can also be omitted entirely, yielding \n```\nint main()\n```\n, if you do not intend to process command line arguments. Try the following program: \n```\n#include <iostream>\n\nint main(int argc, char** argv) {\n    std::cout << ""Have "" << argc << "" arguments:\\n"";\n    for (int i = 0; i < argc; ++i) {\n        std::cout << argv[i] << ""\\n"";\n    }\n}\n\n```\n Running it with \n```\n./test a1 b2 c3\n```\n will output \n```\nHave 4 arguments:\n./test\na1\nb2\nc3\n\n```']","
```
argv
```
 and 
```
argc
```
 are how command line arguments are passed to 
```
main()
```
 in C and C++. 
```
argc
```
 will be the number of strings pointed to by 
```
argv
```
. This will (in practice) be 1 plus the number of arguments, as virtually all implementations will prepend the name of the program to the array. The variables are named 
```
argc
```
 (argument count) and 
```
argv
```
 (argument vector) by convention, but they can be given any valid identifier: 
```
int main(int num_args, char** arg_strings)
```
 is equally valid. They can also be omitted entirely, yielding 
```
int main()
```
, if you do not intend to process command line arguments. Try the following program: 
```
#include <iostream>

int main(int argc, char** argv) {
    std::cout << ""Have "" << argc << "" arguments:\n"";
    for (int i = 0; i < argc; ++i) {
        std::cout << argv[i] << ""\n"";
    }
}

```
 Running it with 
```
./test a1 b2 c3
```
 will output 
```
Have 4 arguments:
./test
a1
b2
c3

```
"
4178175,"What are aggregates and trivial types/PODs, and how/why are they special?",https://stackoverflow.com/questions/4178175/what-are-aggregates-and-trivial-types-pods-and-how-why-are-they-special,6,,[],
77005,How to automatically generate a stacktrace when my program crashes,https://stackoverflow.com/questions/77005/how-to-automatically-generate-a-stacktrace-when-my-program-crashes,31,602.0,"['For Linux and I believe Mac OS X, if you\'re using gcc, or any compiler that uses glibc, you can use the backtrace() functions in \n```\nexecinfo.h\n```\n to print a stacktrace and exit gracefully when you get a segmentation fault. Documentation can be found in the libc manual. Here\'s an example program that installs a \n```\nSIGSEGV\n```\n handler and prints a stacktrace to \n```\nstderr\n```\n when it segfaults. The \n```\nbaz()\n```\n function here causes the segfault that triggers the handler: \n```\n#include <stdio.h>\n#include <execinfo.h>\n#include <signal.h>\n#include <stdlib.h>\n#include <unistd.h>\n\n\nvoid handler(int sig) {\n  void *array[10];\n  size_t size;\n\n  // get void*\'s for all entries on the stack\n  size = backtrace(array, 10);\n\n  // print out all the frames to stderr\n  fprintf(stderr, ""Error: signal %d:\\n"", sig);\n  backtrace_symbols_fd(array, size, STDERR_FILENO);\n  exit(1);\n}\n\nvoid baz() {\n int *foo = (int*)-1; // make a bad pointer\n  printf(""%d\\n"", *foo);       // causes segfault\n}', 'void baz() {\n int *foo = (int*)-1; // make a bad pointer\n  printf(""%d\\n"", *foo);       // causes segfault\n}\n\nvoid bar() { baz(); }\nvoid foo() { bar(); }\n\n\nint main(int argc, char **argv) {\n  signal(SIGSEGV, handler);   // install our handler\n  foo(); // this will call foo, bar, and baz.  baz segfaults.\n}\n\n```\n Compiling with \n```\n-g -rdynamic\n```\n gets you symbol info in your output, which glibc can use to make a nice stacktrace: \n```\n$ gcc -g -rdynamic ./test.c -o test\n\n```\n Executing this gets you this output: \n```\n$ ./test\nError: signal 11:\n./test(handler+0x19)[0x400911]\n/lib64/tls/libc.so.6[0x3a9b92e380]\n./test(baz+0x14)[0x400962]\n./test(bar+0xe)[0x400983]\n./test(foo+0xe)[0x400993]\n./test(main+0x28)[0x4009bd]\n/lib64/tls/libc.so.6(__libc_start_main+0xdb)[0x3a9b91c4bb]\n./test[0x40086a]', '```\n This shows the load module, offset, and function that each frame in the stack came from. Here you can see the signal handler on top of the stack, and the libc functions before \n```\nmain\n```\n in addition to \n```\nmain\n```\n, \n```\nfoo\n```\n, \n```\nbar\n```\n, and \n```\nbaz\n```\n.']","For Linux and I believe Mac OS X, if you're using gcc, or any compiler that uses glibc, you can use the backtrace() functions in 
```
execinfo.h
```
 to print a stacktrace and exit gracefully when you get a segmentation fault. Documentation can be found in the libc manual. Here's an example program that installs a 
```
SIGSEGV
```
 handler and prints a stacktrace to 
```
stderr
```
 when it segfaults. The 
```
baz()
```
 function here causes the segfault that triggers the handler: 
```
#include <stdio.h>
#include <execinfo.h>
#include <signal.h>
#include <stdlib.h>
#include <unistd.h>


void handler(int sig) {
  void *array[10];
  size_t size;

  // get void*'s for all entries on the stack
  size = backtrace(array, 10);

  // print out all the frames to stderr
  fprintf(stderr, ""Error: signal %d:\n"", sig);
  backtrace_symbols_fd(array, size, STDERR_FILENO);
  exit(1);
}

void baz() {
 int *foo = (int*)-1; // make a bad pointer
  printf(""%d\n"", *foo);       // causes segfault
}

void bar() { baz(); }
void foo() { bar(); }


int main(int argc, char **argv) {
  signal(SIGSEGV, handler);   // install our handler
  foo(); // this will call foo, bar, and baz.  baz segfaults.
}

```
 Compiling with 
```
-g -rdynamic
```
 gets you symbol info in your output, which glibc can use to make a nice stacktrace: 
```
$ gcc -g -rdynamic ./test.c -o test

```
 Executing this gets you this output: 
```
$ ./test
Error: signal 11:
./test(handler+0x19)[0x400911]
/lib64/tls/libc.so.6[0x3a9b92e380]
./test(baz+0x14)[0x400962]
./test(bar+0xe)[0x400983]
./test(foo+0xe)[0x400993]
./test(main+0x28)[0x4009bd]
/lib64/tls/libc.so.6(__libc_start_main+0xdb)[0x3a9b91c4bb]
./test[0x40086a]

```
 This shows the load module, offset, and function that each frame in the stack came from. Here you can see the signal handler on top of the stack, and the libc functions before 
```
main
```
 in addition to 
```
main
```
, 
```
foo
```
, 
```
bar
```
, and 
```
baz
```
."
4955198,What does 'dereferencing' a pointer mean in C/C++?,https://stackoverflow.com/questions/4955198/what-does-dereferencing-a-pointer-mean-in-c-c,6,909.0,"['Reviewing the basic terminology It\'s usually good enough - unless you\'re programming assembly - to envisage a pointer containing a numeric memory address, with 1 referring to the second byte in the process\'s memory, 2 the third, 3 the fourth and so on.... What happened to 0 and the first byte? Well, we\'ll get to that later - see null pointers below. For a more accurate definition of what pointers store, and how memory and addresses relate, see ""More about memory addresses, and why you probably don\'t need to know"" at the end of this answer. When you want to access the data/value in the memory that the pointer points to - the contents of the address with that numerical index - then you dereference the pointer. Different computer languages have different notations to tell the compiler or interpreter that you\'re now interested in the pointed-to object\'s (current) value - I focus below on C and C++. A pointer scenario Consider in C, given a pointer such as \n```\np\n```\n below... \n```', '```\np\n```\n below... \n```\nconst char* p = ""abc"";', ""```\n ...four bytes with the numerical values used to encode the letters 'a', 'b', 'c', and a 0 byte to denote the end of the textual data, are stored somewhere in memory and the numerical address of that data is stored in \n```\np\n```\n. This way C encodes text in memory is known as ASCIIZ. For example, if the string literal happened to be at address 0x1000 and \n```\np\n```\n a 32-bit pointer at 0x2000, the memory content would be: \n```\nMemory Address (hex)    Variable name    Contents\n1000                                     'a' == 97 (ASCII)\n1001                                     'b' == 98\n1002                                     'c' == 99\n1003                                     0\n...\n2000-2003               p                1000 hex"", ""```\n Note that there is no variable name/identifier for address 0x1000, but we can indirectly refer to the string literal using a pointer storing its address: \n```\np\n```\n. Dereferencing the pointer To refer to the characters \n```\np\n```\n points to, we dereference \n```\np\n```\n using one of these notations (again, for C): \n```\nassert(*p == 'a');  // The first character at address p will be 'a'\nassert(p[1] == 'b'); // p[1] actually dereferences a pointer created by adding\n                     // p and 1 times the size of the things to which p points:\n                     // In this case they're char which are 1 byte in C...\nassert(*(p + 1) == 'b');  // Another notation for p[1]\n\n```\n You can also move pointers through the pointed-to data, dereferencing them as you go: \n```\n++p;  // Increment p so it's now 0x1001\nassert(*p == 'b');  // p == 0x1001 which is where the 'b' is..."", '```\n If you have some data that can be written to, then you can do things like this: \n```\nint x = 2;\nint* p_x = &x;  // Put the address of the x variable into the pointer p_x\n*p_x = 4;       // Change the memory at the address in p_x to be 4\nassert(x == 4); // Check x is now 4\n\n```\n Above, you must have known at compile time that you would need a variable called \n```\nx\n```\n, and the code asks the compiler to arrange where it should be stored, ensuring the address will be available via \n```\n&x\n```\n. Dereferencing and accessing a structure data member In C, if you have a variable that is a pointer to a structure with data members, you can access those members using the \n```\n->\n```\n dereferencing operator: \n```\ntypedef struct X { int i_; double d_; } X;\nX x;\nX* p = &x;\np->d_ = 3.14159;  // Dereference and access data member x.d_\n(*p).d_ *= -1;    // Another equivalent notation for accessing x.d_', '```\n Multi-byte data types To use a pointer, a computer program also needs some insight into the type of data that is being pointed at - if that data type needs more than one byte to represent, then the pointer normally points to the lowest-numbered byte in the data. So, looking at a slightly more complex example: \n```\ndouble sizes[] = { 10.3, 13.4, 11.2, 19.4 };\ndouble* p = sizes;\nassert(p[0] == 10.3);  // Knows to look at all the bytes in the first double value\nassert(p[1] == 13.4);  // Actually looks at bytes from address p + 1 * sizeof(double)\n                       // (sizeof(double) is almost always eight bytes)\n++p;                   // Advance p by sizeof(double)\nassert(*p == 13.4);    // The double at memory beginning at address p has value 13.4\n*(p + 2) = 29.8;       // Change sizes[3] from 19.4 to 29.8\n                       // Note earlier ++p and + 2 here => sizes[3]', ""```\n Pointers to dynamically allocated memory Sometimes you don't know how much memory you'll need until your program is running and sees what data is thrown at it... then you can dynamically allocate memory using \n```\nmalloc\n```\n. It is common practice to store the address in a pointer... \n```\nint* p = (int*)malloc(sizeof(int)); // Get some memory somewhere...\n*p = 10;            // Dereference the pointer to the memory, then write a value in\nfn(*p);             // Call a function, passing it the value at address p\n(*p) += 3;          // Change the value, adding 3 to it\nfree(p);            // Release the memory back to the heap allocation library\n\n```\n In C++, memory allocation is normally done with the \n```\nnew\n```\n operator, and deallocation with \n```\ndelete\n```\n: \n```\nint* p = new int(10); // Memory for one int with initial value 10\ndelete p;\n\np = new int[10];      // Memory for ten ints with unspecified initial value\ndelete[] p;"", 'p = new int[10];      // Memory for ten ints with unspecified initial value\ndelete[] p;\n\np = new int[10]();    // Memory for ten ints that are value initialised (to 0)\ndelete[] p;\n\n```\n See also C++ smart pointers below. Losing and leaking addresses Often a pointer may be the only indication of where some data or buffer exists in memory. If ongoing use of that data/buffer is needed, or the ability to call \n```\nfree()\n```\n or \n```\ndelete\n```\n to avoid leaking the memory, then the programmer must operate on a copy of the pointer... \n```\nconst char* p = asprintf(""name: %s"", name);  // Common but non-Standard printf-on-heap\n\n// Replace non-printable characters with underscores....\nfor (const char* q = p; *q; ++q)\n    if (!isprint(*q))\n        *q = \'_\';\n\nprintf(""%s\\n"", p); // Only q was modified\nfree(p);\n\n```\n ...or carefully orchestrate reversal of any changes... \n```\nconst size_t n = ...;\np += n;\n...\np -= n;  // Restore earlier value...\nfree(p);', 'printf(""%s\\n"", p); // Only q was modified\nfree(p);\n\n```\n ...or carefully orchestrate reversal of any changes... \n```\nconst size_t n = ...;\np += n;\n...\np -= n;  // Restore earlier value...\nfree(p);\n\n```\n C++ smart pointers In C++, it\'s best practice to use smart pointer objects to store and manage the pointers, automatically deallocating them when the smart pointers\' destructors run. Since C++11 the Standard Library provides two, \n```\nunique_ptr\n```\n for when there\'s a single owner for an allocated object... \n```\n{\n    std::unique_ptr<T> p{new T(42, ""meaning"")};\n    call_a_function(p);\n    // The function above might throw, so delete here is unreliable, but...\n} // p\'s destructor\'s guaranteed to run ""here"", calling delete', '```\n ...and \n```\nshared_ptr\n```\n for share ownership (using reference counting)... \n```\n{\n    auto p = std::make_shared<T>(3.14, ""pi"");\n    number_storage1.may_add(p); // Might copy p into its container\n    number_storage2.may_add(p); // Might copy p into its container    } // p\'s destructor will only delete the T if neither may_add copied it\n\n```\n Null pointers In C, \n```\nNULL\n```\n and \n```\n0\n```\n - and additionally in C++ \n```\nnullptr\n```\n - can be used to indicate that a pointer doesn\'t currently hold the memory address of a variable, and shouldn\'t be dereferenced or used in pointer arithmetic. For example: \n```\nconst char* p_filename = NULL; // Or ""= 0"", or ""= nullptr"" in C++\nint c;\nwhile ((c = getopt(argc, argv, ""f:"")) != -1)\n    switch (c) {\n      case f: p_filename = optarg; break;\n    }\nif (p_filename)  // Only NULL converts to false\n    ...   // Only get here if -f flag specified', '```\n In C and C++, just as inbuilt numeric types don\'t necessarily default to \n```\n0\n```\n, nor \n```\nbools\n```\n to \n```\nfalse\n```\n, pointers are not always set to \n```\nNULL\n```\n. All these are set to 0/false/NULL when they\'re \n```\nstatic\n```\n variables or (C++ only) direct or indirect member variables of static objects or their bases, or undergo zero initialisation (e.g. \n```\nnew T();\n```\n and \n```\nnew T(x, y, z);\n```\n perform zero-initialisation on T\'s members including pointers, whereas \n```\nnew T;\n```\n does not). Further, when you assign \n```\n0\n```\n, \n```\nNULL\n```\n and \n```\nnullptr\n```\n to a pointer the bits in the pointer are not necessarily all reset: the pointer may not contain ""0"" at the hardware level, or refer to address 0 in your virtual address space. The compiler is allowed to store something else there if it has reason to, but whatever it does - if you come along and compare the pointer to \n```\n0\n```\n, \n```\nNULL\n```\n, \n```\nnullptr\n```', '```\n0\n```\n, \n```\nNULL\n```\n, \n```\nnullptr\n```\n or another pointer that was assigned any of those, the comparison must work as expected. So, below the source code at the compiler level, ""NULL"" is potentially a bit ""magical"" in the C and C++ languages... More about memory addresses, and why you probably don\'t need to know More strictly, initialised pointers store a bit-pattern identifying either \n```\nNULL\n```\n or a (often virtual) memory address. The simple case is where this is a numeric offset into the process\'s entire virtual address space; in more complex cases the pointer may be relative to some specific memory area, which the CPU may select based on CPU ""segment"" registers or some manner of segment id encoded in the bit-pattern, and/or looking in different places depending on the machine code instructions using the address. For example, an \n```\nint*\n```\n properly initialised to point to an \n```\nint\n```\n variable might - after casting to a \n```\nfloat*\n```', '```\nint*\n```\n properly initialised to point to an \n```\nint\n```\n variable might - after casting to a \n```\nfloat*\n```\n - access memory in ""GPU"" memory quite distinct from the memory where the \n```\nint\n```\n variable is, then once cast to and used as a function pointer it might point into further distinct memory holding machine opcodes for the program (with the numeric value of the \n```\nint*\n```', 'effectively a random, invalid pointer within these other memory regions). 3GL programming languages like C and C++ tend to hide this complexity, such that: If the compiler gives you a pointer to a variable or function, you can dereference it freely (as long as the variable\'s not destructed/deallocated meanwhile) and it\'s the compiler\'s problem whether e.g. a particular CPU segment register needs to be restored beforehand, or a distinct machine code instruction used If you get a pointer to an element in an array, you can use pointer arithmetic to move anywhere else in the array, or even to form an address one-past-the-end of the array that\'s legal to compare with other pointers to elements in the array (or that have similarly been moved by pointer arithmetic to the same one-past-the-end value); again in C and C++, it\'s up to the compiler to ensure this ""just works"" Specific OS functions, e.g. shared memory mapping, may give you pointers, and they\'ll ""just work"" within the range of', 'value); again in C and C++, it\'s up to the compiler to ensure this ""just works"" Specific OS functions, e.g. shared memory mapping, may give you pointers, and they\'ll ""just work"" within the range of addresses that makes sense for them Attempts to move legal pointers beyond these boundaries, or to cast arbitrary numbers to pointers, or use pointers cast to unrelated types, typically have undefined behaviour, so should be avoided in higher level libraries and applications, but code for OSes, device drivers, etc. may need to rely on behaviour left undefined by the C or C++ Standard, that is nevertheless well defined by their specific implementation or hardware.']","Reviewing the basic terminology It's usually good enough - unless you're programming assembly - to envisage a pointer containing a numeric memory address, with 1 referring to the second byte in the process's memory, 2 the third, 3 the fourth and so on.... What happened to 0 and the first byte? Well, we'll get to that later - see null pointers below. For a more accurate definition of what pointers store, and how memory and addresses relate, see ""More about memory addresses, and why you probably don't need to know"" at the end of this answer. When you want to access the data/value in the memory that the pointer points to - the contents of the address with that numerical index - then you dereference the pointer. Different computer languages have different notations to tell the compiler or interpreter that you're now interested in the pointed-to object's (current) value - I focus below on C and C++. A pointer scenario Consider in C, given a pointer such as 
```
p
```
 below... 
```
const char* p = ""abc"";

```
 ...four bytes with the numerical values used to encode the letters 'a', 'b', 'c', and a 0 byte to denote the end of the textual data, are stored somewhere in memory and the numerical address of that data is stored in 
```
p
```
. This way C encodes text in memory is known as ASCIIZ. For example, if the string literal happened to be at address 0x1000 and 
```
p
```
 a 32-bit pointer at 0x2000, the memory content would be: 
```
Memory Address (hex)    Variable name    Contents
1000                                     'a' == 97 (ASCII)
1001                                     'b' == 98
1002                                     'c' == 99
1003                                     0
...
2000-2003               p                1000 hex

```
 Note that there is no variable name/identifier for address 0x1000, but we can indirectly refer to the string literal using a pointer storing its address: 
```
p
```
. Dereferencing the pointer To refer to the characters 
```
p
```
 points to, we dereference 
```
p
```
 using one of these notations (again, for C): 
```
assert(*p == 'a');  // The first character at address p will be 'a'
assert(p[1] == 'b'); // p[1] actually dereferences a pointer created by adding
                     // p and 1 times the size of the things to which p points:
                     // In this case they're char which are 1 byte in C...
assert(*(p + 1) == 'b');  // Another notation for p[1]

```
 You can also move pointers through the pointed-to data, dereferencing them as you go: 
```
++p;  // Increment p so it's now 0x1001
assert(*p == 'b');  // p == 0x1001 which is where the 'b' is...

```
 If you have some data that can be written to, then you can do things like this: 
```
int x = 2;
int* p_x = &x;  // Put the address of the x variable into the pointer p_x
*p_x = 4;       // Change the memory at the address in p_x to be 4
assert(x == 4); // Check x is now 4

```
 Above, you must have known at compile time that you would need a variable called 
```
x
```
, and the code asks the compiler to arrange where it should be stored, ensuring the address will be available via 
```
&x
```
. Dereferencing and accessing a structure data member In C, if you have a variable that is a pointer to a structure with data members, you can access those members using the 
```
->
```
 dereferencing operator: 
```
typedef struct X { int i_; double d_; } X;
X x;
X* p = &x;
p->d_ = 3.14159;  // Dereference and access data member x.d_
(*p).d_ *= -1;    // Another equivalent notation for accessing x.d_

```
 Multi-byte data types To use a pointer, a computer program also needs some insight into the type of data that is being pointed at - if that data type needs more than one byte to represent, then the pointer normally points to the lowest-numbered byte in the data. So, looking at a slightly more complex example: 
```
double sizes[] = { 10.3, 13.4, 11.2, 19.4 };
double* p = sizes;
assert(p[0] == 10.3);  // Knows to look at all the bytes in the first double value
assert(p[1] == 13.4);  // Actually looks at bytes from address p + 1 * sizeof(double)
                       // (sizeof(double) is almost always eight bytes)
++p;                   // Advance p by sizeof(double)
assert(*p == 13.4);    // The double at memory beginning at address p has value 13.4
*(p + 2) = 29.8;       // Change sizes[3] from 19.4 to 29.8
                       // Note earlier ++p and + 2 here => sizes[3]

```
 Pointers to dynamically allocated memory Sometimes you don't know how much memory you'll need until your program is running and sees what data is thrown at it... then you can dynamically allocate memory using 
```
malloc
```
. It is common practice to store the address in a pointer... 
```
int* p = (int*)malloc(sizeof(int)); // Get some memory somewhere...
*p = 10;            // Dereference the pointer to the memory, then write a value in
fn(*p);             // Call a function, passing it the value at address p
(*p) += 3;          // Change the value, adding 3 to it
free(p);            // Release the memory back to the heap allocation library

```
 In C++, memory allocation is normally done with the 
```
new
```
 operator, and deallocation with 
```
delete
```
: 
```
int* p = new int(10); // Memory for one int with initial value 10
delete p;

p = new int[10];      // Memory for ten ints with unspecified initial value
delete[] p;

p = new int[10]();    // Memory for ten ints that are value initialised (to 0)
delete[] p;

```
 See also C++ smart pointers below. Losing and leaking addresses Often a pointer may be the only indication of where some data or buffer exists in memory. If ongoing use of that data/buffer is needed, or the ability to call 
```
free()
```
 or 
```
delete
```
 to avoid leaking the memory, then the programmer must operate on a copy of the pointer... 
```
const char* p = asprintf(""name: %s"", name);  // Common but non-Standard printf-on-heap

// Replace non-printable characters with underscores....
for (const char* q = p; *q; ++q)
    if (!isprint(*q))
        *q = '_';

printf(""%s\n"", p); // Only q was modified
free(p);

```
 ...or carefully orchestrate reversal of any changes... 
```
const size_t n = ...;
p += n;
...
p -= n;  // Restore earlier value...
free(p);

```
 C++ smart pointers In C++, it's best practice to use smart pointer objects to store and manage the pointers, automatically deallocating them when the smart pointers' destructors run. Since C++11 the Standard Library provides two, 
```
unique_ptr
```
 for when there's a single owner for an allocated object... 
```
{
    std::unique_ptr<T> p{new T(42, ""meaning"")};
    call_a_function(p);
    // The function above might throw, so delete here is unreliable, but...
} // p's destructor's guaranteed to run ""here"", calling delete

```
 ...and 
```
shared_ptr
```
 for share ownership (using reference counting)... 
```
{
    auto p = std::make_shared<T>(3.14, ""pi"");
    number_storage1.may_add(p); // Might copy p into its container
    number_storage2.may_add(p); // Might copy p into its container    } // p's destructor will only delete the T if neither may_add copied it

```
 Null pointers In C, 
```
NULL
```
 and 
```
0
```
 - and additionally in C++ 
```
nullptr
```
 - can be used to indicate that a pointer doesn't currently hold the memory address of a variable, and shouldn't be dereferenced or used in pointer arithmetic. For example: 
```
const char* p_filename = NULL; // Or ""= 0"", or ""= nullptr"" in C++
int c;
while ((c = getopt(argc, argv, ""f:"")) != -1)
    switch (c) {
      case f: p_filename = optarg; break;
    }
if (p_filename)  // Only NULL converts to false
    ...   // Only get here if -f flag specified

```
 In C and C++, just as inbuilt numeric types don't necessarily default to 
```
0
```
, nor 
```
bools
```
 to 
```
false
```
, pointers are not always set to 
```
NULL
```
. All these are set to 0/false/NULL when they're 
```
static
```
 variables or (C++ only) direct or indirect member variables of static objects or their bases, or undergo zero initialisation (e.g. 
```
new T();
```
 and 
```
new T(x, y, z);
```
 perform zero-initialisation on T's members including pointers, whereas 
```
new T;
```
 does not). Further, when you assign 
```
0
```
, 
```
NULL
```
 and 
```
nullptr
```
 to a pointer the bits in the pointer are not necessarily all reset: the pointer may not contain ""0"" at the hardware level, or refer to address 0 in your virtual address space. The compiler is allowed to store something else there if it has reason to, but whatever it does - if you come along and compare the pointer to 
```
0
```
, 
```
NULL
```
, 
```
nullptr
```
 or another pointer that was assigned any of those, the comparison must work as expected. So, below the source code at the compiler level, ""NULL"" is potentially a bit ""magical"" in the C and C++ languages... More about memory addresses, and why you probably don't need to know More strictly, initialised pointers store a bit-pattern identifying either 
```
NULL
```
 or a (often virtual) memory address. The simple case is where this is a numeric offset into the process's entire virtual address space; in more complex cases the pointer may be relative to some specific memory area, which the CPU may select based on CPU ""segment"" registers or some manner of segment id encoded in the bit-pattern, and/or looking in different places depending on the machine code instructions using the address. For example, an 
```
int*
```
 properly initialised to point to an 
```
int
```
 variable might - after casting to a 
```
float*
```
 - access memory in ""GPU"" memory quite distinct from the memory where the 
```
int
```
 variable is, then once cast to and used as a function pointer it might point into further distinct memory holding machine opcodes for the program (with the numeric value of the 
```
int*
```
 effectively a random, invalid pointer within these other memory regions). 3GL programming languages like C and C++ tend to hide this complexity, such that: If the compiler gives you a pointer to a variable or function, you can dereference it freely (as long as the variable's not destructed/deallocated meanwhile) and it's the compiler's problem whether e.g. a particular CPU segment register needs to be restored beforehand, or a distinct machine code instruction used If you get a pointer to an element in an array, you can use pointer arithmetic to move anywhere else in the array, or even to form an address one-past-the-end of the array that's legal to compare with other pointers to elements in the array (or that have similarly been moved by pointer arithmetic to the same one-past-the-end value); again in C and C++, it's up to the compiler to ensure this ""just works"" Specific OS functions, e.g. shared memory mapping, may give you pointers, and they'll ""just work"" within the range of addresses that makes sense for them Attempts to move legal pointers beyond these boundaries, or to cast arbitrary numbers to pointers, or use pointers cast to unrelated types, typically have undefined behaviour, so should be avoided in higher level libraries and applications, but code for OSes, device drivers, etc. may need to rely on behaviour left undefined by the C or C++ Standard, that is nevertheless well defined by their specific implementation or hardware."
8389648,How do I achieve the theoretical maximum of 4 FLOPs per cycle?,https://stackoverflow.com/questions/8389648/how-do-i-achieve-the-theoretical-maximum-of-4-flops-per-cycle,4,563.0,"[""I've done this exact task before. But it was mainly to measure power consumption and CPU temperatures. The following code (which is fairly long) achieves close to optimal on my Core i7 2600K. The key thing to note here is the massive amount of manual loop-unrolling as well as interleaving of multiplies and adds... The full project can be found on my GitHub: https://github.com/Mysticial/Flops Warning: If you decide to compile and run this, pay attention to your CPU temperatures!!!Make sure you don't overheat it. And make sure CPU-throttling doesn't affect your results! Furthermore, I take no responsibility for whatever damage that may result from running this code. Notes: This code is optimized for x64. x86 doesn't have enough registers for this to compile well. This code has been tested to work well on Visual Studio 2010/2012 and GCC 4.6.ICC 11 (Intel Compiler 11) surprisingly has trouble compiling it well. These are for pre-FMA processors. In order to achieve peak FLOPS on Intel"", 'to work well on Visual Studio 2010/2012 and GCC 4.6.ICC 11 (Intel Compiler 11) surprisingly has trouble compiling it well. These are for pre-FMA processors. In order to achieve peak FLOPS on Intel Haswell and AMD Bulldozer processors (and later), FMA (Fused Multiply Add) instructions will be needed. These are beyond the scope of this benchmark.', '```\n#include <emmintrin.h>\n#include <omp.h>\n#include <iostream>\nusing namespace std;', 'typedef unsigned long long uint64;\n\ndouble test_dp_mac_SSE(double x,double y,uint64 iterations){\n    register __m128d r0,r1,r2,r3,r4,r5,r6,r7,r8,r9,rA,rB,rC,rD,rE,rF;\n\n    //  Generate starting data.\n    r0 = _mm_set1_pd(x);\n    r1 = _mm_set1_pd(y);\n\n    r8 = _mm_set1_pd(-0.0);\n\n    r2 = _mm_xor_pd(r0,r8);\n    r3 = _mm_or_pd(r0,r8);\n    r4 = _mm_andnot_pd(r8,r0);\n    r5 = _mm_mul_pd(r1,_mm_set1_pd(0.37796447300922722721));\n    r6 = _mm_mul_pd(r1,_mm_set1_pd(0.24253562503633297352));\n    r7 = _mm_mul_pd(r1,_mm_set1_pd(4.1231056256176605498));\n    r8 = _mm_add_pd(r0,_mm_set1_pd(0.37796447300922722721));\n    r9 = _mm_add_pd(r1,_mm_set1_pd(0.24253562503633297352));\n    rA = _mm_sub_pd(r0,_mm_set1_pd(4.1231056256176605498));\n    rB = _mm_sub_pd(r1,_mm_set1_pd(4.1231056256176605498));\n\n    rC = _mm_set1_pd(1.4142135623730950488);\n    rD = _mm_set1_pd(1.7320508075688772935);\n    rE = _mm_set1_pd(0.57735026918962576451);\n    rF = _mm_set1_pd(0.70710678118654752440);', ""rC = _mm_set1_pd(1.4142135623730950488);\n    rD = _mm_set1_pd(1.7320508075688772935);\n    rE = _mm_set1_pd(0.57735026918962576451);\n    rF = _mm_set1_pd(0.70710678118654752440);\n\n    uint64 iMASK = 0x800fffffffffffffull;\n    __m128d MASK = _mm_set1_pd(*(double*)&iMASK);\n    __m128d vONE = _mm_set1_pd(1.0);\n\n    uint64 c = 0;\n    while (c < iterations){\n        size_t i = 0;\n        while (i < 1000){\n            //  Here's the meat - the part that really matters.\n\n            r0 = _mm_mul_pd(r0,rC);\n            r1 = _mm_add_pd(r1,rD);\n            r2 = _mm_mul_pd(r2,rE);\n            r3 = _mm_sub_pd(r3,rF);\n            r4 = _mm_mul_pd(r4,rC);\n            r5 = _mm_add_pd(r5,rD);\n            r6 = _mm_mul_pd(r6,rE);\n            r7 = _mm_sub_pd(r7,rF);\n            r8 = _mm_mul_pd(r8,rC);\n            r9 = _mm_add_pd(r9,rD);\n            rA = _mm_mul_pd(rA,rE);\n            rB = _mm_sub_pd(rB,rF);"", 'r0 = _mm_add_pd(r0,rF);\n            r1 = _mm_mul_pd(r1,rE);\n            r2 = _mm_sub_pd(r2,rD);\n            r3 = _mm_mul_pd(r3,rC);\n            r4 = _mm_add_pd(r4,rF);\n            r5 = _mm_mul_pd(r5,rE);\n            r6 = _mm_sub_pd(r6,rD);\n            r7 = _mm_mul_pd(r7,rC);\n            r8 = _mm_add_pd(r8,rF);\n            r9 = _mm_mul_pd(r9,rE);\n            rA = _mm_sub_pd(rA,rD);\n            rB = _mm_mul_pd(rB,rC);\n\n            r0 = _mm_mul_pd(r0,rC);\n            r1 = _mm_add_pd(r1,rD);\n            r2 = _mm_mul_pd(r2,rE);\n            r3 = _mm_sub_pd(r3,rF);\n            r4 = _mm_mul_pd(r4,rC);\n            r5 = _mm_add_pd(r5,rD);\n            r6 = _mm_mul_pd(r6,rE);\n            r7 = _mm_sub_pd(r7,rF);\n            r8 = _mm_mul_pd(r8,rC);\n            r9 = _mm_add_pd(r9,rD);\n            rA = _mm_mul_pd(rA,rE);\n            rB = _mm_sub_pd(rB,rF);', 'r0 = _mm_add_pd(r0,rF);\n            r1 = _mm_mul_pd(r1,rE);\n            r2 = _mm_sub_pd(r2,rD);\n            r3 = _mm_mul_pd(r3,rC);\n            r4 = _mm_add_pd(r4,rF);\n            r5 = _mm_mul_pd(r5,rE);\n            r6 = _mm_sub_pd(r6,rD);\n            r7 = _mm_mul_pd(r7,rC);\n            r8 = _mm_add_pd(r8,rF);\n            r9 = _mm_mul_pd(r9,rE);\n            rA = _mm_sub_pd(rA,rD);\n            rB = _mm_mul_pd(rB,rC);\n\n            i++;\n        }', 'i++;\n        }\n\n        //  Need to renormalize to prevent denormal/overflow.\n        r0 = _mm_and_pd(r0,MASK);\n        r1 = _mm_and_pd(r1,MASK);\n        r2 = _mm_and_pd(r2,MASK);\n        r3 = _mm_and_pd(r3,MASK);\n        r4 = _mm_and_pd(r4,MASK);\n        r5 = _mm_and_pd(r5,MASK);\n        r6 = _mm_and_pd(r6,MASK);\n        r7 = _mm_and_pd(r7,MASK);\n        r8 = _mm_and_pd(r8,MASK);\n        r9 = _mm_and_pd(r9,MASK);\n        rA = _mm_and_pd(rA,MASK);\n        rB = _mm_and_pd(rB,MASK);\n        r0 = _mm_or_pd(r0,vONE);\n        r1 = _mm_or_pd(r1,vONE);\n        r2 = _mm_or_pd(r2,vONE);\n        r3 = _mm_or_pd(r3,vONE);\n        r4 = _mm_or_pd(r4,vONE);\n        r5 = _mm_or_pd(r5,vONE);\n        r6 = _mm_or_pd(r6,vONE);\n        r7 = _mm_or_pd(r7,vONE);\n        r8 = _mm_or_pd(r8,vONE);\n        r9 = _mm_or_pd(r9,vONE);\n        rA = _mm_or_pd(rA,vONE);\n        rB = _mm_or_pd(rB,vONE);\n\n        c++;\n    }', 'c++;\n    }\n\n    r0 = _mm_add_pd(r0,r1);\n    r2 = _mm_add_pd(r2,r3);\n    r4 = _mm_add_pd(r4,r5);\n    r6 = _mm_add_pd(r6,r7);\n    r8 = _mm_add_pd(r8,r9);\n    rA = _mm_add_pd(rA,rB);\n\n    r0 = _mm_add_pd(r0,r2);\n    r4 = _mm_add_pd(r4,r6);\n    r8 = _mm_add_pd(r8,rA);\n\n    r0 = _mm_add_pd(r0,r4);\n    r0 = _mm_add_pd(r0,r8);\n\n\n    //  Prevent Dead Code Elimination\n    double out = 0;\n    __m128d temp = r0;\n    out += ((double*)&temp)[0];\n    out += ((double*)&temp)[1];\n\n    return out;\n}\n\nvoid test_dp_mac_SSE(int tds,uint64 iterations){\n\n    double *sum = (double*)malloc(tds * sizeof(double));\n    double start = omp_get_wtime();\n\n#pragma omp parallel num_threads(tds)\n    {\n        double ret = test_dp_mac_SSE(1.1,2.1,iterations);\n        sum[omp_get_thread_num()] = ret;\n    }', '#pragma omp parallel num_threads(tds)\n    {\n        double ret = test_dp_mac_SSE(1.1,2.1,iterations);\n        sum[omp_get_thread_num()] = ret;\n    }\n\n    double secs = omp_get_wtime() - start;\n    uint64 ops = 48 * 1000 * iterations * tds * 2;\n    cout << ""Seconds = "" << secs << endl;\n    cout << ""FP Ops  = "" << ops << endl;\n    cout << ""FLOPs   = "" << ops / secs << endl;\n\n    double out = 0;\n    int c = 0;\n    while (c < tds){\n        out += sum[c++];\n    }\n\n    cout << ""sum = "" << out << endl;\n    cout << endl;\n\n    free(sum);\n}\n\nint main(){\n    //  (threads, iterations)\n    test_dp_mac_SSE(8,10000000);\n\n    system(""pause"");\n}\n\n```\n Output (1 thread, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release: \n```\nSeconds = 55.5104\nFP Ops  = 960000000000\nFLOPs   = 1.7294e+010\nsum = 2.22652', ""```\n Output (1 thread, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release: \n```\nSeconds = 55.5104\nFP Ops  = 960000000000\nFLOPs   = 1.7294e+010\nsum = 2.22652\n\n```\n The machine is a Core i7 2600K @ 4.4 GHz. Theoretical SSE peak is 4 flops * 4.4 GHz = 17.6 GFlops. This code achieves 17.3 GFlops - not bad. Output (8 threads, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release: \n```\nSeconds = 117.202\nFP Ops  = 7680000000000\nFLOPs   = 6.55279e+010\nsum = 17.8122\n\n```\n Theoretical SSE peak is 4 flops * 4 cores * 4.4 GHz = 70.4 GFlops. Actual is 65.5 GFlops. Let's take this one step further. AVX... \n```\n#include <immintrin.h>\n#include <omp.h>\n#include <iostream>\nusing namespace std;\n\ntypedef unsigned long long uint64;\n\ndouble test_dp_mac_AVX(double x,double y,uint64 iterations){\n    register __m256d r0,r1,r2,r3,r4,r5,r6,r7,r8,r9,rA,rB,rC,rD,rE,rF;\n\n    //  Generate starting data.\n    r0 = _mm256_set1_pd(x);\n    r1 = _mm256_set1_pd(y);"", '//  Generate starting data.\n    r0 = _mm256_set1_pd(x);\n    r1 = _mm256_set1_pd(y);\n\n    r8 = _mm256_set1_pd(-0.0);\n\n    r2 = _mm256_xor_pd(r0,r8);\n    r3 = _mm256_or_pd(r0,r8);\n    r4 = _mm256_andnot_pd(r8,r0);\n    r5 = _mm256_mul_pd(r1,_mm256_set1_pd(0.37796447300922722721));\n    r6 = _mm256_mul_pd(r1,_mm256_set1_pd(0.24253562503633297352));\n    r7 = _mm256_mul_pd(r1,_mm256_set1_pd(4.1231056256176605498));\n    r8 = _mm256_add_pd(r0,_mm256_set1_pd(0.37796447300922722721));\n    r9 = _mm256_add_pd(r1,_mm256_set1_pd(0.24253562503633297352));\n    rA = _mm256_sub_pd(r0,_mm256_set1_pd(4.1231056256176605498));\n    rB = _mm256_sub_pd(r1,_mm256_set1_pd(4.1231056256176605498));\n\n    rC = _mm256_set1_pd(1.4142135623730950488);\n    rD = _mm256_set1_pd(1.7320508075688772935);\n    rE = _mm256_set1_pd(0.57735026918962576451);\n    rF = _mm256_set1_pd(0.70710678118654752440);', ""rC = _mm256_set1_pd(1.4142135623730950488);\n    rD = _mm256_set1_pd(1.7320508075688772935);\n    rE = _mm256_set1_pd(0.57735026918962576451);\n    rF = _mm256_set1_pd(0.70710678118654752440);\n\n    uint64 iMASK = 0x800fffffffffffffull;\n    __m256d MASK = _mm256_set1_pd(*(double*)&iMASK);\n    __m256d vONE = _mm256_set1_pd(1.0);\n\n    uint64 c = 0;\n    while (c < iterations){\n        size_t i = 0;\n        while (i < 1000){\n            //  Here's the meat - the part that really matters.\n\n            r0 = _mm256_mul_pd(r0,rC);\n            r1 = _mm256_add_pd(r1,rD);\n            r2 = _mm256_mul_pd(r2,rE);\n            r3 = _mm256_sub_pd(r3,rF);\n            r4 = _mm256_mul_pd(r4,rC);\n            r5 = _mm256_add_pd(r5,rD);\n            r6 = _mm256_mul_pd(r6,rE);\n            r7 = _mm256_sub_pd(r7,rF);\n            r8 = _mm256_mul_pd(r8,rC);\n            r9 = _mm256_add_pd(r9,rD);\n            rA = _mm256_mul_pd(rA,rE);\n            rB = _mm256_sub_pd(rB,rF);"", 'r0 = _mm256_add_pd(r0,rF);\n            r1 = _mm256_mul_pd(r1,rE);\n            r2 = _mm256_sub_pd(r2,rD);\n            r3 = _mm256_mul_pd(r3,rC);\n            r4 = _mm256_add_pd(r4,rF);\n            r5 = _mm256_mul_pd(r5,rE);\n            r6 = _mm256_sub_pd(r6,rD);\n            r7 = _mm256_mul_pd(r7,rC);\n            r8 = _mm256_add_pd(r8,rF);\n            r9 = _mm256_mul_pd(r9,rE);\n            rA = _mm256_sub_pd(rA,rD);\n            rB = _mm256_mul_pd(rB,rC);\n\n            r0 = _mm256_mul_pd(r0,rC);\n            r1 = _mm256_add_pd(r1,rD);\n            r2 = _mm256_mul_pd(r2,rE);\n            r3 = _mm256_sub_pd(r3,rF);\n            r4 = _mm256_mul_pd(r4,rC);\n            r5 = _mm256_add_pd(r5,rD);\n            r6 = _mm256_mul_pd(r6,rE);\n            r7 = _mm256_sub_pd(r7,rF);\n            r8 = _mm256_mul_pd(r8,rC);\n            r9 = _mm256_add_pd(r9,rD);\n            rA = _mm256_mul_pd(rA,rE);\n            rB = _mm256_sub_pd(rB,rF);', 'r0 = _mm256_add_pd(r0,rF);\n            r1 = _mm256_mul_pd(r1,rE);\n            r2 = _mm256_sub_pd(r2,rD);\n            r3 = _mm256_mul_pd(r3,rC);\n            r4 = _mm256_add_pd(r4,rF);\n            r5 = _mm256_mul_pd(r5,rE);\n            r6 = _mm256_sub_pd(r6,rD);\n            r7 = _mm256_mul_pd(r7,rC);\n            r8 = _mm256_add_pd(r8,rF);\n            r9 = _mm256_mul_pd(r9,rE);\n            rA = _mm256_sub_pd(rA,rD);\n            rB = _mm256_mul_pd(rB,rC);\n\n            i++;\n        }', 'i++;\n        }\n\n        //  Need to renormalize to prevent denormal/overflow.\n        r0 = _mm256_and_pd(r0,MASK);\n        r1 = _mm256_and_pd(r1,MASK);\n        r2 = _mm256_and_pd(r2,MASK);\n        r3 = _mm256_and_pd(r3,MASK);\n        r4 = _mm256_and_pd(r4,MASK);\n        r5 = _mm256_and_pd(r5,MASK);\n        r6 = _mm256_and_pd(r6,MASK);\n        r7 = _mm256_and_pd(r7,MASK);\n        r8 = _mm256_and_pd(r8,MASK);\n        r9 = _mm256_and_pd(r9,MASK);\n        rA = _mm256_and_pd(rA,MASK);\n        rB = _mm256_and_pd(rB,MASK);\n        r0 = _mm256_or_pd(r0,vONE);\n        r1 = _mm256_or_pd(r1,vONE);\n        r2 = _mm256_or_pd(r2,vONE);\n        r3 = _mm256_or_pd(r3,vONE);\n        r4 = _mm256_or_pd(r4,vONE);\n        r5 = _mm256_or_pd(r5,vONE);\n        r6 = _mm256_or_pd(r6,vONE);\n        r7 = _mm256_or_pd(r7,vONE);\n        r8 = _mm256_or_pd(r8,vONE);\n        r9 = _mm256_or_pd(r9,vONE);\n        rA = _mm256_or_pd(rA,vONE);\n        rB = _mm256_or_pd(rB,vONE);\n\n        c++;\n    }', 'c++;\n    }\n\n    r0 = _mm256_add_pd(r0,r1);\n    r2 = _mm256_add_pd(r2,r3);\n    r4 = _mm256_add_pd(r4,r5);\n    r6 = _mm256_add_pd(r6,r7);\n    r8 = _mm256_add_pd(r8,r9);\n    rA = _mm256_add_pd(rA,rB);\n\n    r0 = _mm256_add_pd(r0,r2);\n    r4 = _mm256_add_pd(r4,r6);\n    r8 = _mm256_add_pd(r8,rA);\n\n    r0 = _mm256_add_pd(r0,r4);\n    r0 = _mm256_add_pd(r0,r8);\n\n    //  Prevent Dead Code Elimination\n    double out = 0;\n    __m256d temp = r0;\n    out += ((double*)&temp)[0];\n    out += ((double*)&temp)[1];\n    out += ((double*)&temp)[2];\n    out += ((double*)&temp)[3];\n\n    return out;\n}\n\nvoid test_dp_mac_AVX(int tds,uint64 iterations){\n\n    double *sum = (double*)malloc(tds * sizeof(double));\n    double start = omp_get_wtime();\n\n#pragma omp parallel num_threads(tds)\n    {\n        double ret = test_dp_mac_AVX(1.1,2.1,iterations);\n        sum[omp_get_thread_num()] = ret;\n    }', '#pragma omp parallel num_threads(tds)\n    {\n        double ret = test_dp_mac_AVX(1.1,2.1,iterations);\n        sum[omp_get_thread_num()] = ret;\n    }\n\n    double secs = omp_get_wtime() - start;\n    uint64 ops = 48 * 1000 * iterations * tds * 4;\n    cout << ""Seconds = "" << secs << endl;\n    cout << ""FP Ops  = "" << ops << endl;\n    cout << ""FLOPs   = "" << ops / secs << endl;\n\n    double out = 0;\n    int c = 0;\n    while (c < tds){\n        out += sum[c++];\n    }\n\n    cout << ""sum = "" << out << endl;\n    cout << endl;\n\n    free(sum);\n}\n\nint main(){\n    //  (threads, iterations)\n    test_dp_mac_AVX(8,10000000);\n\n    system(""pause"");\n}\n\n```\n Output (1 thread, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release: \n```\nSeconds = 57.4679\nFP Ops  = 1920000000000\nFLOPs   = 3.34099e+010\nsum = 4.45305', '```\n Output (1 thread, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release: \n```\nSeconds = 57.4679\nFP Ops  = 1920000000000\nFLOPs   = 3.34099e+010\nsum = 4.45305\n\n```\n Theoretical AVX peak is 8 flops * 4.4 GHz = 35.2 GFlops. Actual is 33.4 GFlops. Output (8 threads, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release: \n```\nSeconds = 111.119\nFP Ops  = 15360000000000\nFLOPs   = 1.3823e+011\nsum = 35.6244', '```', 'Theoretical AVX peak is 8 flops * 4 cores * 4.4 GHz = 140.8 GFlops. Actual is 138.2 GFlops. Now for some explanations: The performance critical part is obviously the 48 instructions inside the inner loop. You\'ll notice that it\'s broken into 4 blocks of 12 instructions each. Each of these 12 instructions blocks are completely independent from each other - and take on average 6 cycles to execute. So there\'s 12 instructions and 6 cycles between issue-to-use. The latency of multiplication is 5 cycles, so it\'s just enough to avoid latency stalls. The normalization step is needed to keep the data from over/underflowing. This is needed since the do-nothing code will slowly increase/decrease the magnitude of the data. So it\'s actually possible to do better than this if you just use all zeros and get rid of the normalization step. However, since I wrote the benchmark to measure power consumption and temperature, I had to make sure the flops were on ""real"" data, rather than zeros - as the', 'and get rid of the normalization step. However, since I wrote the benchmark to measure power consumption and temperature, I had to make sure the flops were on ""real"" data, rather than zeros - as the execution units may very well have special case-handling for zeros that use less power and produce less heat. More Results: Intel Core i7 920 @ 3.5 GHz Windows 7 Ultimate x64 Visual Studio 2010 SP1 - x64 Release Threads: 1', '```\nSeconds = 72.1116\nFP Ops  = 960000000000\nFLOPs   = 1.33127e+010\nsum = 2.22652', ""```\n Theoretical SSE Peak: 4 flops * 3.5 GHz = 14.0 GFlops. Actual is 13.3 GFlops. Threads: 8 \n```\nSeconds = 149.576\nFP Ops  = 7680000000000\nFLOPs   = 5.13452e+010\nsum = 17.8122\n\n```\n Theoretical SSE Peak: 4 flops * 4 cores * 3.5 GHz = 56.0 GFlops. Actual is 51.3 GFlops. My processor temps hit 76C on the multi-threaded run! If you runs these, be sure the results aren't affected by CPU throttling. 2 x Intel Xeon X5482 Harpertown @ 3.2 GHz Ubuntu Linux 10 x64 GCC 4.5.2 x64 - (-O2 -msse3 -fopenmp) Threads: 1 \n```\nSeconds = 78.3357\nFP Ops  = 960000000000\nFLOPs   = 1.22549e+10\nsum = 2.22652\n\n```\n Theoretical SSE Peak: 4 flops * 3.2 GHz = 12.8 GFlops. Actual is 12.3 GFlops. Threads: 8 \n```\nSeconds = 78.4733\nFP Ops  = 7680000000000\nFLOPs   = 9.78676e+10\nsum = 17.8122\n\n```\n Theoretical SSE Peak: 4 flops * 8 cores * 3.2 GHz = 102.4 GFlops. Actual is 97.9 GFlops.""]","I've done this exact task before. But it was mainly to measure power consumption and CPU temperatures. The following code (which is fairly long) achieves close to optimal on my Core i7 2600K. The key thing to note here is the massive amount of manual loop-unrolling as well as interleaving of multiplies and adds... The full project can be found on my GitHub: https://github.com/Mysticial/Flops Warning: If you decide to compile and run this, pay attention to your CPU temperatures!!!Make sure you don't overheat it. And make sure CPU-throttling doesn't affect your results! Furthermore, I take no responsibility for whatever damage that may result from running this code. Notes: This code is optimized for x64. x86 doesn't have enough registers for this to compile well. This code has been tested to work well on Visual Studio 2010/2012 and GCC 4.6.ICC 11 (Intel Compiler 11) surprisingly has trouble compiling it well. These are for pre-FMA processors. In order to achieve peak FLOPS on Intel Haswell and AMD Bulldozer processors (and later), FMA (Fused Multiply Add) instructions will be needed. These are beyond the scope of this benchmark. 
```
#include <emmintrin.h>
#include <omp.h>
#include <iostream>
using namespace std;

typedef unsigned long long uint64;

double test_dp_mac_SSE(double x,double y,uint64 iterations){
    register __m128d r0,r1,r2,r3,r4,r5,r6,r7,r8,r9,rA,rB,rC,rD,rE,rF;

    //  Generate starting data.
    r0 = _mm_set1_pd(x);
    r1 = _mm_set1_pd(y);

    r8 = _mm_set1_pd(-0.0);

    r2 = _mm_xor_pd(r0,r8);
    r3 = _mm_or_pd(r0,r8);
    r4 = _mm_andnot_pd(r8,r0);
    r5 = _mm_mul_pd(r1,_mm_set1_pd(0.37796447300922722721));
    r6 = _mm_mul_pd(r1,_mm_set1_pd(0.24253562503633297352));
    r7 = _mm_mul_pd(r1,_mm_set1_pd(4.1231056256176605498));
    r8 = _mm_add_pd(r0,_mm_set1_pd(0.37796447300922722721));
    r9 = _mm_add_pd(r1,_mm_set1_pd(0.24253562503633297352));
    rA = _mm_sub_pd(r0,_mm_set1_pd(4.1231056256176605498));
    rB = _mm_sub_pd(r1,_mm_set1_pd(4.1231056256176605498));

    rC = _mm_set1_pd(1.4142135623730950488);
    rD = _mm_set1_pd(1.7320508075688772935);
    rE = _mm_set1_pd(0.57735026918962576451);
    rF = _mm_set1_pd(0.70710678118654752440);

    uint64 iMASK = 0x800fffffffffffffull;
    __m128d MASK = _mm_set1_pd(*(double*)&iMASK);
    __m128d vONE = _mm_set1_pd(1.0);

    uint64 c = 0;
    while (c < iterations){
        size_t i = 0;
        while (i < 1000){
            //  Here's the meat - the part that really matters.

            r0 = _mm_mul_pd(r0,rC);
            r1 = _mm_add_pd(r1,rD);
            r2 = _mm_mul_pd(r2,rE);
            r3 = _mm_sub_pd(r3,rF);
            r4 = _mm_mul_pd(r4,rC);
            r5 = _mm_add_pd(r5,rD);
            r6 = _mm_mul_pd(r6,rE);
            r7 = _mm_sub_pd(r7,rF);
            r8 = _mm_mul_pd(r8,rC);
            r9 = _mm_add_pd(r9,rD);
            rA = _mm_mul_pd(rA,rE);
            rB = _mm_sub_pd(rB,rF);

            r0 = _mm_add_pd(r0,rF);
            r1 = _mm_mul_pd(r1,rE);
            r2 = _mm_sub_pd(r2,rD);
            r3 = _mm_mul_pd(r3,rC);
            r4 = _mm_add_pd(r4,rF);
            r5 = _mm_mul_pd(r5,rE);
            r6 = _mm_sub_pd(r6,rD);
            r7 = _mm_mul_pd(r7,rC);
            r8 = _mm_add_pd(r8,rF);
            r9 = _mm_mul_pd(r9,rE);
            rA = _mm_sub_pd(rA,rD);
            rB = _mm_mul_pd(rB,rC);

            r0 = _mm_mul_pd(r0,rC);
            r1 = _mm_add_pd(r1,rD);
            r2 = _mm_mul_pd(r2,rE);
            r3 = _mm_sub_pd(r3,rF);
            r4 = _mm_mul_pd(r4,rC);
            r5 = _mm_add_pd(r5,rD);
            r6 = _mm_mul_pd(r6,rE);
            r7 = _mm_sub_pd(r7,rF);
            r8 = _mm_mul_pd(r8,rC);
            r9 = _mm_add_pd(r9,rD);
            rA = _mm_mul_pd(rA,rE);
            rB = _mm_sub_pd(rB,rF);

            r0 = _mm_add_pd(r0,rF);
            r1 = _mm_mul_pd(r1,rE);
            r2 = _mm_sub_pd(r2,rD);
            r3 = _mm_mul_pd(r3,rC);
            r4 = _mm_add_pd(r4,rF);
            r5 = _mm_mul_pd(r5,rE);
            r6 = _mm_sub_pd(r6,rD);
            r7 = _mm_mul_pd(r7,rC);
            r8 = _mm_add_pd(r8,rF);
            r9 = _mm_mul_pd(r9,rE);
            rA = _mm_sub_pd(rA,rD);
            rB = _mm_mul_pd(rB,rC);

            i++;
        }

        //  Need to renormalize to prevent denormal/overflow.
        r0 = _mm_and_pd(r0,MASK);
        r1 = _mm_and_pd(r1,MASK);
        r2 = _mm_and_pd(r2,MASK);
        r3 = _mm_and_pd(r3,MASK);
        r4 = _mm_and_pd(r4,MASK);
        r5 = _mm_and_pd(r5,MASK);
        r6 = _mm_and_pd(r6,MASK);
        r7 = _mm_and_pd(r7,MASK);
        r8 = _mm_and_pd(r8,MASK);
        r9 = _mm_and_pd(r9,MASK);
        rA = _mm_and_pd(rA,MASK);
        rB = _mm_and_pd(rB,MASK);
        r0 = _mm_or_pd(r0,vONE);
        r1 = _mm_or_pd(r1,vONE);
        r2 = _mm_or_pd(r2,vONE);
        r3 = _mm_or_pd(r3,vONE);
        r4 = _mm_or_pd(r4,vONE);
        r5 = _mm_or_pd(r5,vONE);
        r6 = _mm_or_pd(r6,vONE);
        r7 = _mm_or_pd(r7,vONE);
        r8 = _mm_or_pd(r8,vONE);
        r9 = _mm_or_pd(r9,vONE);
        rA = _mm_or_pd(rA,vONE);
        rB = _mm_or_pd(rB,vONE);

        c++;
    }

    r0 = _mm_add_pd(r0,r1);
    r2 = _mm_add_pd(r2,r3);
    r4 = _mm_add_pd(r4,r5);
    r6 = _mm_add_pd(r6,r7);
    r8 = _mm_add_pd(r8,r9);
    rA = _mm_add_pd(rA,rB);

    r0 = _mm_add_pd(r0,r2);
    r4 = _mm_add_pd(r4,r6);
    r8 = _mm_add_pd(r8,rA);

    r0 = _mm_add_pd(r0,r4);
    r0 = _mm_add_pd(r0,r8);


    //  Prevent Dead Code Elimination
    double out = 0;
    __m128d temp = r0;
    out += ((double*)&temp)[0];
    out += ((double*)&temp)[1];

    return out;
}

void test_dp_mac_SSE(int tds,uint64 iterations){

    double *sum = (double*)malloc(tds * sizeof(double));
    double start = omp_get_wtime();

#pragma omp parallel num_threads(tds)
    {
        double ret = test_dp_mac_SSE(1.1,2.1,iterations);
        sum[omp_get_thread_num()] = ret;
    }

    double secs = omp_get_wtime() - start;
    uint64 ops = 48 * 1000 * iterations * tds * 2;
    cout << ""Seconds = "" << secs << endl;
    cout << ""FP Ops  = "" << ops << endl;
    cout << ""FLOPs   = "" << ops / secs << endl;

    double out = 0;
    int c = 0;
    while (c < tds){
        out += sum[c++];
    }

    cout << ""sum = "" << out << endl;
    cout << endl;

    free(sum);
}

int main(){
    //  (threads, iterations)
    test_dp_mac_SSE(8,10000000);

    system(""pause"");
}

```
 Output (1 thread, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release: 
```
Seconds = 55.5104
FP Ops  = 960000000000
FLOPs   = 1.7294e+010
sum = 2.22652

```
 The machine is a Core i7 2600K @ 4.4 GHz. Theoretical SSE peak is 4 flops * 4.4 GHz = 17.6 GFlops. This code achieves 17.3 GFlops - not bad. Output (8 threads, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release: 
```
Seconds = 117.202
FP Ops  = 7680000000000
FLOPs   = 6.55279e+010
sum = 17.8122

```
 Theoretical SSE peak is 4 flops * 4 cores * 4.4 GHz = 70.4 GFlops. Actual is 65.5 GFlops. Let's take this one step further. AVX... 
```
#include <immintrin.h>
#include <omp.h>
#include <iostream>
using namespace std;

typedef unsigned long long uint64;

double test_dp_mac_AVX(double x,double y,uint64 iterations){
    register __m256d r0,r1,r2,r3,r4,r5,r6,r7,r8,r9,rA,rB,rC,rD,rE,rF;

    //  Generate starting data.
    r0 = _mm256_set1_pd(x);
    r1 = _mm256_set1_pd(y);

    r8 = _mm256_set1_pd(-0.0);

    r2 = _mm256_xor_pd(r0,r8);
    r3 = _mm256_or_pd(r0,r8);
    r4 = _mm256_andnot_pd(r8,r0);
    r5 = _mm256_mul_pd(r1,_mm256_set1_pd(0.37796447300922722721));
    r6 = _mm256_mul_pd(r1,_mm256_set1_pd(0.24253562503633297352));
    r7 = _mm256_mul_pd(r1,_mm256_set1_pd(4.1231056256176605498));
    r8 = _mm256_add_pd(r0,_mm256_set1_pd(0.37796447300922722721));
    r9 = _mm256_add_pd(r1,_mm256_set1_pd(0.24253562503633297352));
    rA = _mm256_sub_pd(r0,_mm256_set1_pd(4.1231056256176605498));
    rB = _mm256_sub_pd(r1,_mm256_set1_pd(4.1231056256176605498));

    rC = _mm256_set1_pd(1.4142135623730950488);
    rD = _mm256_set1_pd(1.7320508075688772935);
    rE = _mm256_set1_pd(0.57735026918962576451);
    rF = _mm256_set1_pd(0.70710678118654752440);

    uint64 iMASK = 0x800fffffffffffffull;
    __m256d MASK = _mm256_set1_pd(*(double*)&iMASK);
    __m256d vONE = _mm256_set1_pd(1.0);

    uint64 c = 0;
    while (c < iterations){
        size_t i = 0;
        while (i < 1000){
            //  Here's the meat - the part that really matters.

            r0 = _mm256_mul_pd(r0,rC);
            r1 = _mm256_add_pd(r1,rD);
            r2 = _mm256_mul_pd(r2,rE);
            r3 = _mm256_sub_pd(r3,rF);
            r4 = _mm256_mul_pd(r4,rC);
            r5 = _mm256_add_pd(r5,rD);
            r6 = _mm256_mul_pd(r6,rE);
            r7 = _mm256_sub_pd(r7,rF);
            r8 = _mm256_mul_pd(r8,rC);
            r9 = _mm256_add_pd(r9,rD);
            rA = _mm256_mul_pd(rA,rE);
            rB = _mm256_sub_pd(rB,rF);

            r0 = _mm256_add_pd(r0,rF);
            r1 = _mm256_mul_pd(r1,rE);
            r2 = _mm256_sub_pd(r2,rD);
            r3 = _mm256_mul_pd(r3,rC);
            r4 = _mm256_add_pd(r4,rF);
            r5 = _mm256_mul_pd(r5,rE);
            r6 = _mm256_sub_pd(r6,rD);
            r7 = _mm256_mul_pd(r7,rC);
            r8 = _mm256_add_pd(r8,rF);
            r9 = _mm256_mul_pd(r9,rE);
            rA = _mm256_sub_pd(rA,rD);
            rB = _mm256_mul_pd(rB,rC);

            r0 = _mm256_mul_pd(r0,rC);
            r1 = _mm256_add_pd(r1,rD);
            r2 = _mm256_mul_pd(r2,rE);
            r3 = _mm256_sub_pd(r3,rF);
            r4 = _mm256_mul_pd(r4,rC);
            r5 = _mm256_add_pd(r5,rD);
            r6 = _mm256_mul_pd(r6,rE);
            r7 = _mm256_sub_pd(r7,rF);
            r8 = _mm256_mul_pd(r8,rC);
            r9 = _mm256_add_pd(r9,rD);
            rA = _mm256_mul_pd(rA,rE);
            rB = _mm256_sub_pd(rB,rF);

            r0 = _mm256_add_pd(r0,rF);
            r1 = _mm256_mul_pd(r1,rE);
            r2 = _mm256_sub_pd(r2,rD);
            r3 = _mm256_mul_pd(r3,rC);
            r4 = _mm256_add_pd(r4,rF);
            r5 = _mm256_mul_pd(r5,rE);
            r6 = _mm256_sub_pd(r6,rD);
            r7 = _mm256_mul_pd(r7,rC);
            r8 = _mm256_add_pd(r8,rF);
            r9 = _mm256_mul_pd(r9,rE);
            rA = _mm256_sub_pd(rA,rD);
            rB = _mm256_mul_pd(rB,rC);

            i++;
        }

        //  Need to renormalize to prevent denormal/overflow.
        r0 = _mm256_and_pd(r0,MASK);
        r1 = _mm256_and_pd(r1,MASK);
        r2 = _mm256_and_pd(r2,MASK);
        r3 = _mm256_and_pd(r3,MASK);
        r4 = _mm256_and_pd(r4,MASK);
        r5 = _mm256_and_pd(r5,MASK);
        r6 = _mm256_and_pd(r6,MASK);
        r7 = _mm256_and_pd(r7,MASK);
        r8 = _mm256_and_pd(r8,MASK);
        r9 = _mm256_and_pd(r9,MASK);
        rA = _mm256_and_pd(rA,MASK);
        rB = _mm256_and_pd(rB,MASK);
        r0 = _mm256_or_pd(r0,vONE);
        r1 = _mm256_or_pd(r1,vONE);
        r2 = _mm256_or_pd(r2,vONE);
        r3 = _mm256_or_pd(r3,vONE);
        r4 = _mm256_or_pd(r4,vONE);
        r5 = _mm256_or_pd(r5,vONE);
        r6 = _mm256_or_pd(r6,vONE);
        r7 = _mm256_or_pd(r7,vONE);
        r8 = _mm256_or_pd(r8,vONE);
        r9 = _mm256_or_pd(r9,vONE);
        rA = _mm256_or_pd(rA,vONE);
        rB = _mm256_or_pd(rB,vONE);

        c++;
    }

    r0 = _mm256_add_pd(r0,r1);
    r2 = _mm256_add_pd(r2,r3);
    r4 = _mm256_add_pd(r4,r5);
    r6 = _mm256_add_pd(r6,r7);
    r8 = _mm256_add_pd(r8,r9);
    rA = _mm256_add_pd(rA,rB);

    r0 = _mm256_add_pd(r0,r2);
    r4 = _mm256_add_pd(r4,r6);
    r8 = _mm256_add_pd(r8,rA);

    r0 = _mm256_add_pd(r0,r4);
    r0 = _mm256_add_pd(r0,r8);

    //  Prevent Dead Code Elimination
    double out = 0;
    __m256d temp = r0;
    out += ((double*)&temp)[0];
    out += ((double*)&temp)[1];
    out += ((double*)&temp)[2];
    out += ((double*)&temp)[3];

    return out;
}

void test_dp_mac_AVX(int tds,uint64 iterations){

    double *sum = (double*)malloc(tds * sizeof(double));
    double start = omp_get_wtime();

#pragma omp parallel num_threads(tds)
    {
        double ret = test_dp_mac_AVX(1.1,2.1,iterations);
        sum[omp_get_thread_num()] = ret;
    }

    double secs = omp_get_wtime() - start;
    uint64 ops = 48 * 1000 * iterations * tds * 4;
    cout << ""Seconds = "" << secs << endl;
    cout << ""FP Ops  = "" << ops << endl;
    cout << ""FLOPs   = "" << ops / secs << endl;

    double out = 0;
    int c = 0;
    while (c < tds){
        out += sum[c++];
    }

    cout << ""sum = "" << out << endl;
    cout << endl;

    free(sum);
}

int main(){
    //  (threads, iterations)
    test_dp_mac_AVX(8,10000000);

    system(""pause"");
}

```
 Output (1 thread, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release: 
```
Seconds = 57.4679
FP Ops  = 1920000000000
FLOPs   = 3.34099e+010
sum = 4.45305

```
 Theoretical AVX peak is 8 flops * 4.4 GHz = 35.2 GFlops. Actual is 33.4 GFlops. Output (8 threads, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release: 
```
Seconds = 111.119
FP Ops  = 15360000000000
FLOPs   = 1.3823e+011
sum = 35.6244

```
 Theoretical AVX peak is 8 flops * 4 cores * 4.4 GHz = 140.8 GFlops. Actual is 138.2 GFlops. Now for some explanations: The performance critical part is obviously the 48 instructions inside the inner loop. You'll notice that it's broken into 4 blocks of 12 instructions each. Each of these 12 instructions blocks are completely independent from each other - and take on average 6 cycles to execute. So there's 12 instructions and 6 cycles between issue-to-use. The latency of multiplication is 5 cycles, so it's just enough to avoid latency stalls. The normalization step is needed to keep the data from over/underflowing. This is needed since the do-nothing code will slowly increase/decrease the magnitude of the data. So it's actually possible to do better than this if you just use all zeros and get rid of the normalization step. However, since I wrote the benchmark to measure power consumption and temperature, I had to make sure the flops were on ""real"" data, rather than zeros - as the execution units may very well have special case-handling for zeros that use less power and produce less heat. More Results: Intel Core i7 920 @ 3.5 GHz Windows 7 Ultimate x64 Visual Studio 2010 SP1 - x64 Release Threads: 1 
```
Seconds = 72.1116
FP Ops  = 960000000000
FLOPs   = 1.33127e+010
sum = 2.22652

```
 Theoretical SSE Peak: 4 flops * 3.5 GHz = 14.0 GFlops. Actual is 13.3 GFlops. Threads: 8 
```
Seconds = 149.576
FP Ops  = 7680000000000
FLOPs   = 5.13452e+010
sum = 17.8122

```
 Theoretical SSE Peak: 4 flops * 4 cores * 3.5 GHz = 56.0 GFlops. Actual is 51.3 GFlops. My processor temps hit 76C on the multi-threaded run! If you runs these, be sure the results aren't affected by CPU throttling. 2 x Intel Xeon X5482 Harpertown @ 3.2 GHz Ubuntu Linux 10 x64 GCC 4.5.2 x64 - (-O2 -msse3 -fopenmp) Threads: 1 
```
Seconds = 78.3357
FP Ops  = 960000000000
FLOPs   = 1.22549e+10
sum = 2.22652

```
 Theoretical SSE Peak: 4 flops * 3.2 GHz = 12.8 GFlops. Actual is 12.3 GFlops. Threads: 8 
```
Seconds = 78.4733
FP Ops  = 7680000000000
FLOPs   = 9.78676e+10
sum = 17.8122

```
 Theoretical SSE Peak: 4 flops * 8 cores * 3.2 GHz = 102.4 GFlops. Actual is 97.9 GFlops."
14265581,Parse (split) a string in C++ using string delimiter (standard C++),https://stackoverflow.com/questions/14265581/parse-split-a-string-in-c-using-string-delimiter-standard-c,35,1003.0,"['You can use the \n```\nstd::string::find()\n```\n function to find the position of your string delimiter, then use \n```\nstd::string::substr()\n```\n to get a token. Example: \n```\nstd::string s = ""scott>=tiger"";\nstd::string delimiter = "">="";\nstd::string token = s.substr(0, s.find(delimiter)); // token is ""scott""\n\n```\n The \n```\nfind(const string& str, size_t pos = 0)\n```\n function returns the position of the first occurrence of \n```\nstr\n```\n in the string, or \n```\nnpos\n```\n if the string is not found. The \n```\nsubstr(size_t pos = 0, size_t n = npos)\n```\n function returns a substring of the object, starting at position \n```\npos\n```\n and of length \n```\nnpos\n```\n. If you have multiple delimiters, after you have extracted one token, you can remove it (delimiter included) to proceed with subsequent extractions (if you want to preserve the original string, just use \n```\ns = s.substr(pos + delimiter.length());\n```\n): \n```\ns.erase(0, s.find(delimiter) + delimiter.length());', '```\n This way you can easily loop to get each token. Complete Example \n```\nstd::vector<std::string> split(const std::string& s, const std::string& delimiter) {\n    std::vector<std::string> tokens;\n    size_t pos = 0;\n    std::string token;\n    while ((pos = s.find(delimiter)) != std::string::npos) {\n        token = s.substr(0, pos);\n        tokens.push_back(token);\n        s.erase(0, pos + delimiter.length());\n    }\n    tokens.push_back(s);\n\n    return tokens;\n}\n\nstd::string s = ""scott>=tiger>=mushroom"";\nstd::string delimiter = "">="";\n\nsplit(s, delimiter); // [""scott"", ""tiger"", ""mushroom""]\n\n```']","You can use the 
```
std::string::find()
```
 function to find the position of your string delimiter, then use 
```
std::string::substr()
```
 to get a token. Example: 
```
std::string s = ""scott>=tiger"";
std::string delimiter = "">="";
std::string token = s.substr(0, s.find(delimiter)); // token is ""scott""

```
 The 
```
find(const string& str, size_t pos = 0)
```
 function returns the position of the first occurrence of 
```
str
```
 in the string, or 
```
npos
```
 if the string is not found. The 
```
substr(size_t pos = 0, size_t n = npos)
```
 function returns a substring of the object, starting at position 
```
pos
```
 and of length 
```
npos
```
. If you have multiple delimiters, after you have extracted one token, you can remove it (delimiter included) to proceed with subsequent extractions (if you want to preserve the original string, just use 
```
s = s.substr(pos + delimiter.length());
```
): 
```
s.erase(0, s.find(delimiter) + delimiter.length());

```
 This way you can easily loop to get each token. Complete Example 
```
std::vector<std::string> split(const std::string& s, const std::string& delimiter) {
    std::vector<std::string> tokens;
    size_t pos = 0;
    std::string token;
    while ((pos = s.find(delimiter)) != std::string::npos) {
        token = s.substr(0, pos);
        tokens.push_back(token);
        s.erase(0, pos + delimiter.length());
    }
    tokens.push_back(s);

    return tokens;
}

std::string s = ""scott>=tiger>=mushroom"";
std::string delimiter = "">="";

split(s, delimiter); // [""scott"", ""tiger"", ""mushroom""]

```
"
2649334,Difference between static and shared libraries?,https://stackoverflow.com/questions/2649334/difference-between-static-and-shared-libraries,9,911.0,"['Shared libraries are .so (or in Windows .dll, or in OS X .dylib) files. All the code relating to the library is in this file, and it is referenced by programs using it at run-time. A program using a shared library only makes reference to the code that it uses in the shared library. Static libraries are .a (or in Windows .lib) files. All the code relating to the library is in this file, and it is directly linked into the program at compile time. A program using a static library takes copies of the code that it uses from the static library and makes it part of the program. [Windows also has .lib files which are used to reference .dll files, but they act the same way as the first one]. There are advantages and disadvantages in each method: Shared libraries reduce the amount of code that is duplicated in each program that makes use of the library, keeping the binaries small. It also allows you to replace the shared object with one that is functionally equivalent, but may have added', ""is duplicated in each program that makes use of the library, keeping the binaries small. It also allows you to replace the shared object with one that is functionally equivalent, but may have added performance benefits without needing to recompile the program that makes use of it. Shared libraries will, however have a small additional cost for the execution of the functions as well as a run-time loading cost as all the symbols in the library need to be connected to the things they use. Additionally, shared libraries can be loaded into an application at run-time, which is the general mechanism for implementing binary plug-in systems. Static libraries increase the overall size of the binary, but it means that you don't need to carry along a copy of the library that is being used. As the code is connected at compile time there are not any additional run-time loading costs. The code is simply there. Personally, I prefer shared libraries, but use static libraries when needing to ensure"", 'code is connected at compile time there are not any additional run-time loading costs. The code is simply there. Personally, I prefer shared libraries, but use static libraries when needing to ensure that the binary does not have many external dependencies that may be difficult to meet, such as specific versions of the C++ standard library or specific versions of the Boost C++ library.']","Shared libraries are .so (or in Windows .dll, or in OS X .dylib) files. All the code relating to the library is in this file, and it is referenced by programs using it at run-time. A program using a shared library only makes reference to the code that it uses in the shared library. Static libraries are .a (or in Windows .lib) files. All the code relating to the library is in this file, and it is directly linked into the program at compile time. A program using a static library takes copies of the code that it uses from the static library and makes it part of the program. [Windows also has .lib files which are used to reference .dll files, but they act the same way as the first one]. There are advantages and disadvantages in each method: Shared libraries reduce the amount of code that is duplicated in each program that makes use of the library, keeping the binaries small. It also allows you to replace the shared object with one that is functionally equivalent, but may have added performance benefits without needing to recompile the program that makes use of it. Shared libraries will, however have a small additional cost for the execution of the functions as well as a run-time loading cost as all the symbols in the library need to be connected to the things they use. Additionally, shared libraries can be loaded into an application at run-time, which is the general mechanism for implementing binary plug-in systems. Static libraries increase the overall size of the binary, but it means that you don't need to carry along a copy of the library that is being used. As the code is connected at compile time there are not any additional run-time loading costs. The code is simply there. Personally, I prefer shared libraries, but use static libraries when needing to ensure that the binary does not have many external dependencies that may be difficult to meet, such as specific versions of the C++ standard library or specific versions of the Boost C++ library."
553682,When can I use a forward declaration?,https://stackoverflow.com/questions/553682/when-can-i-use-a-forward-declaration,13,1109.0,"[""Put yourself in the compiler's position: when you forward declare a type, all the compiler knows is that this type exists; it knows nothing about its size, members, or methods. This is why it's called an incomplete type. Therefore, you cannot use the type to declare a member, or a base class, since the compiler would need to know the layout of the type. Assuming the following forward declaration. \n```\nclass X;\n\n```\n Here's what you can and cannot do. What you can do with an incomplete type: Declare a member to be a pointer or a reference to the incomplete type: \n```\nclass Foo {\n    X *p;\n    X &r;\n};\n\n```\n Declare functions or methods which accept/return incomplete types: \n```\nvoid f1(X);\nX    f2();\n\n```\n Define functions or methods which accept/return pointers/references to the incomplete type (but without using its members): \n```\nvoid f3(X*, X&) {}\nX&   f4()       {}\nX*   f5()       {}"", '```\n Define functions or methods which accept/return pointers/references to the incomplete type (but without using its members): \n```\nvoid f3(X*, X&) {}\nX&   f4()       {}\nX*   f5()       {}\n\n```\n What you cannot do with an incomplete type: Use it as a base class \n```\nclass Foo : X {} // compiler error!\n\n```\n Use it to declare a member: \n```\nclass Foo {\n    X m; // compiler error!\n};\n\n```\n Define functions or methods using this type \n```\nvoid f1(X x) {} // compiler error!\nX    f2()    {} // compiler error!\n\n```\n Use its methods or fields, in fact trying to dereference a variable with incomplete type \n```\nclass Foo {\n    X *m;            \n    void method()            \n    {\n        m->someMethod();      // compiler error!\n        int i = m->someField; // compiler error!\n    }\n};', '```\n When it comes to templates, there is no absolute rule: whether you can use an incomplete type as a template parameter is dependent on the way the type is used in the template. For instance, \n```\nstd::vector<T>\n```\n requires its parameter to be a complete type, while \n```\nboost::container::vector<T>\n```\n does not. Sometimes, a complete type is required only if you use certain member functions; this is the case for \n```\nstd::unique_ptr<T>\n```\n, for example. A well-documented template should indicate in its documentation all the requirements of its parameters, including whether they need to be complete types or not.']","Put yourself in the compiler's position: when you forward declare a type, all the compiler knows is that this type exists; it knows nothing about its size, members, or methods. This is why it's called an incomplete type. Therefore, you cannot use the type to declare a member, or a base class, since the compiler would need to know the layout of the type. Assuming the following forward declaration. 
```
class X;

```
 Here's what you can and cannot do. What you can do with an incomplete type: Declare a member to be a pointer or a reference to the incomplete type: 
```
class Foo {
    X *p;
    X &r;
};

```
 Declare functions or methods which accept/return incomplete types: 
```
void f1(X);
X    f2();

```
 Define functions or methods which accept/return pointers/references to the incomplete type (but without using its members): 
```
void f3(X*, X&) {}
X&   f4()       {}
X*   f5()       {}

```
 What you cannot do with an incomplete type: Use it as a base class 
```
class Foo : X {} // compiler error!

```
 Use it to declare a member: 
```
class Foo {
    X m; // compiler error!
};

```
 Define functions or methods using this type 
```
void f1(X x) {} // compiler error!
X    f2()    {} // compiler error!

```
 Use its methods or fields, in fact trying to dereference a variable with incomplete type 
```
class Foo {
    X *m;            
    void method()            
    {
        m->someMethod();      // compiler error!
        int i = m->someField; // compiler error!
    }
};

```
 When it comes to templates, there is no absolute rule: whether you can use an incomplete type as a template parameter is dependent on the way the type is used in the template. For instance, 
```
std::vector<T>
```
 requires its parameter to be a complete type, while 
```
boost::container::vector<T>
```
 does not. Sometimes, a complete type is required only if you use certain member functions; this is the case for 
```
std::unique_ptr<T>
```
, for example. A well-documented template should indicate in its documentation all the requirements of its parameters, including whether they need to be complete types or not."
154469,Why should you prefer unnamed namespaces over static functions?,https://stackoverflow.com/questions/154469/why-should-you-prefer-unnamed-namespaces-over-static-functions,11,442.0,"[""The C++ Standard reads in section 7.3.1.1 Unnamed namespaces, paragraph 2: The use of the static keyword is deprecated when declaring objects in a namespace scope, the unnamed-namespace provides a superior alternative. Static only applies to names of objects, functions, and anonymous unions, not to type declarations. Edit: The decision to deprecate this use of the \n```\nstatic\n```\n keyword (affecting visibility of a variable declaration in a translation unit) has been reversed (ref). In this case using a \n```\nstatic\n```\n or an unnamed \n```\nnamespace\n```\n are back to being essentially two ways of doing the exact same thing. For more discussion please see this SO question. Unnamed \n```\nnamespace\n```\n's still have the advantage of allowing you to define translation-unit-local types. Please see this SO question for more details. Credit goes to Mike Percy for bringing this to my attention.""]","The C++ Standard reads in section 7.3.1.1 Unnamed namespaces, paragraph 2: The use of the static keyword is deprecated when declaring objects in a namespace scope, the unnamed-namespace provides a superior alternative. Static only applies to names of objects, functions, and anonymous unions, not to type declarations. Edit: The decision to deprecate this use of the 
```
static
```
 keyword (affecting visibility of a variable declaration in a translation unit) has been reversed (ref). In this case using a 
```
static
```
 or an unnamed 
```
namespace
```
 are back to being essentially two ways of doing the exact same thing. For more discussion please see this SO question. Unnamed 
```
namespace
```
's still have the advantage of allowing you to define translation-unit-local types. Please see this SO question for more details. Credit goes to Mike Percy for bringing this to my attention."
10231349,Are the days of passing const std::string & as a parameter over?,https://stackoverflow.com/questions/10231349/are-the-days-of-passing-const-stdstring-as-a-parameter-over,13,444.0,"['The reason Herb said what he said is because of cases like this. Let\'s say I have function \n```\nA\n```\n which calls function \n```\nB\n```\n, which calls function \n```\nC\n```\n. And \n```\nA\n```\n passes a string through \n```\nB\n```\n and into \n```\nC\n```\n. \n```\nA\n```\n does not know or care about \n```\nC\n```\n; all \n```\nA\n```\n knows about is \n```\nB\n```\n. That is, \n```\nC\n```\n is an implementation detail of \n```\nB\n```\n. Let\'s say that A is defined as follows: \n```\nvoid A()\n{\n  B(""value"");\n}\n\n```\n If B and C take the string by \n```\nconst&\n```\n, then it looks something like this: \n```\nvoid B(const std::string &str)\n{\n  C(str);\n}\n\nvoid C(const std::string &str)\n{\n  //Do something with `str`. Does not store it.\n}', ""void C(const std::string &str)\n{\n  //Do something with `str`. Does not store it.\n}\n\n```\n All well and good. You're just passing pointers around, no copying, no moving, everyone's happy. \n```\nC\n```\n takes a \n```\nconst&\n```\n because it doesn't store the string. It simply uses it. Now, I want to make one simple change: \n```\nC\n```\n needs to store the string somewhere. \n```\nvoid C(const std::string &str)\n{\n  //Do something with `str`.\n  m_str = str;\n}"", ""```\n Hello, copy constructor and potential memory allocation (ignore the Short String Optimization (SSO)). C++11's move semantics are supposed to make it possible to remove needless copy-constructing, right? And \n```\nA\n```\n passes a temporary; there's no reason why \n```\nC\n```\n should have to copy the data. It should just abscond with what was given to it. Except it can't. Because it takes a \n```\nconst&\n```\n. If I change \n```\nC\n```\n to take its parameter by value, that just causes \n```\nB\n```\n to do the copy into that parameter; I gain nothing. So if I had just passed \n```\nstr\n```\n by value through all of the functions, relying on \n```\nstd::move\n```"", ""```\nB\n```\n to do the copy into that parameter; I gain nothing. So if I had just passed \n```\nstr\n```\n by value through all of the functions, relying on \n```\nstd::move\n```\n to shuffle the data around, we wouldn't have this problem. If someone wants to hold on to it, they can. If they don't, oh well. Is it more expensive? Yes; moving into a value is more expensive than using references. Is it less expensive than the copy? Not for small strings with SSO. Is it worth doing? It depends on your use case. How much do you hate memory allocations?""]","The reason Herb said what he said is because of cases like this. Let's say I have function 
```
A
```
 which calls function 
```
B
```
, which calls function 
```
C
```
. And 
```
A
```
 passes a string through 
```
B
```
 and into 
```
C
```
. 
```
A
```
 does not know or care about 
```
C
```
; all 
```
A
```
 knows about is 
```
B
```
. That is, 
```
C
```
 is an implementation detail of 
```
B
```
. Let's say that A is defined as follows: 
```
void A()
{
  B(""value"");
}

```
 If B and C take the string by 
```
const&
```
, then it looks something like this: 
```
void B(const std::string &str)
{
  C(str);
}

void C(const std::string &str)
{
  //Do something with `str`. Does not store it.
}

```
 All well and good. You're just passing pointers around, no copying, no moving, everyone's happy. 
```
C
```
 takes a 
```
const&
```
 because it doesn't store the string. It simply uses it. Now, I want to make one simple change: 
```
C
```
 needs to store the string somewhere. 
```
void C(const std::string &str)
{
  //Do something with `str`.
  m_str = str;
}

```
 Hello, copy constructor and potential memory allocation (ignore the Short String Optimization (SSO)). C++11's move semantics are supposed to make it possible to remove needless copy-constructing, right? And 
```
A
```
 passes a temporary; there's no reason why 
```
C
```
 should have to copy the data. It should just abscond with what was given to it. Except it can't. Because it takes a 
```
const&
```
. If I change 
```
C
```
 to take its parameter by value, that just causes 
```
B
```
 to do the copy into that parameter; I gain nothing. So if I had just passed 
```
str
```
 by value through all of the functions, relying on 
```
std::move
```
 to shuffle the data around, we wouldn't have this problem. If someone wants to hold on to it, they can. If they don't, oh well. Is it more expensive? Yes; moving into a value is more expensive than using references. Is it less expensive than the copy? Not for small strings with SSO. Is it worth doing? It depends on your use case. How much do you hate memory allocations?"
4108313,How do I find the length of an array?,https://stackoverflow.com/questions/4108313/how-do-i-find-the-length-of-an-array,31,652.0,"['If you mean a C-style array, then you can do something like: \n```\nint a[7];\nstd::cout << ""Length of array = "" << (sizeof(a)/sizeof(*a)) << std::endl;\n\n```\n This doesn\'t work on pointers (i.e. it won\'t work for either of the following): \n```\nint *p = new int[7];\nstd::cout << ""Length of array = "" << (sizeof(p)/sizeof(*p)) << std::endl;\n\n```\n or: \n```\nvoid func(int *p)\n{\n    std::cout << ""Length of array = "" << (sizeof(p)/sizeof(*p)) << std::endl;\n}\n\nint a[7];\nfunc(a);\n\n```\n In C++, if you want this kind of behavior, then you should be using a container class; probably \n```\nstd::vector\n```\n.']","If you mean a C-style array, then you can do something like: 
```
int a[7];
std::cout << ""Length of array = "" << (sizeof(a)/sizeof(*a)) << std::endl;

```
 This doesn't work on pointers (i.e. it won't work for either of the following): 
```
int *p = new int[7];
std::cout << ""Length of array = "" << (sizeof(p)/sizeof(*p)) << std::endl;

```
 or: 
```
void func(int *p)
{
    std::cout << ""Length of array = "" << (sizeof(p)/sizeof(*p)) << std::endl;
}

int a[7];
func(a);

```
 In C++, if you want this kind of behavior, then you should be using a container class; probably 
```
std::vector
```
."
5605125,Why is iostream::eof inside a loop condition (i.e. `while (!stream.eof())`) considered wrong?,https://stackoverflow.com/questions/5605125/why-is-iostreameof-inside-a-loop-condition-i-e-while-stream-eof-cons,5,619.0,"['Because \n```\niostream::eof\n```\n will only return \n```\ntrue\n```\n after reading the end of the stream. It does not indicate, that the next read will be the end of the stream. Consider this (and assume then next read will be at the end of the stream): \n```\nwhile(!inStream.eof()){\n  int data;\n  // yay, not end of stream yet, now read ...\n  inStream >> data;\n  // oh crap, now we read the end and *only* now the eof bit will be set (as well as the fail bit)\n  // do stuff with (now uninitialized) data\n}\n\n```\n Against this: \n```\nint data;\nwhile(inStream >> data){\n  // when we land here, we can be sure that the read was successful.\n  // if it wasn\'t, the returned stream from operator>> would be converted to false\n  // and the loop wouldn\'t even be entered\n  // do stuff with correctly initialized data (hopefully)\n}\n\n```\n And on your second question: Because \n```\nif(scanf(""..."",...)!=EOF)\n\n```\n is the same as \n```\nif(!(inStream >> data).eof())', '```\n And on your second question: Because \n```\nif(scanf(""..."",...)!=EOF)\n\n```\n is the same as \n```\nif(!(inStream >> data).eof())\n\n```\n and not the same as \n```\nif(!inStream.eof())\n    inFile >> data\n\n```']","Because 
```
iostream::eof
```
 will only return 
```
true
```
 after reading the end of the stream. It does not indicate, that the next read will be the end of the stream. Consider this (and assume then next read will be at the end of the stream): 
```
while(!inStream.eof()){
  int data;
  // yay, not end of stream yet, now read ...
  inStream >> data;
  // oh crap, now we read the end and *only* now the eof bit will be set (as well as the fail bit)
  // do stuff with (now uninitialized) data
}

```
 Against this: 
```
int data;
while(inStream >> data){
  // when we land here, we can be sure that the read was successful.
  // if it wasn't, the returned stream from operator>> would be converted to false
  // and the loop wouldn't even be entered
  // do stuff with correctly initialized data (hopefully)
}

```
 And on your second question: Because 
```
if(scanf(""..."",...)!=EOF)

```
 is the same as 
```
if(!(inStream >> data).eof())

```
 and not the same as 
```
if(!inStream.eof())
    inFile >> data

```
"
1282295,"What is the nullptr keyword, and why is it better than NULL?",https://stackoverflow.com/questions/1282295/what-is-the-nullptr-keyword-and-why-is-it-better-than-null,15,452.0,"[""How is it a keyword and an instance of a type? This isn't surprising. Both \n```\ntrue\n```\n and \n```\nfalse\n```\n are keywords and as literals they have a type ( \n```\nbool\n```\n ). \n```\nnullptr\n```\n is a pointer literal of type \n```\nstd::nullptr_t\n```\n, and it's a prvalue (you cannot take the address of it using \n```\n&\n```\n). \n```\n4.10\n```\n about pointer conversion says that a prvalue of type \n```\nstd::nullptr_t\n```\n is a null pointer constant, and that an integral null pointer constant can be converted to \n```\nstd::nullptr_t\n```\n. The opposite direction is not allowed. This allows overloading a function for both pointers and integers, and passing \n```\nnullptr\n```\n to select the pointer version. Passing \n```\nNULL\n```\n or \n```\n0\n```\n would confusingly select the \n```\nint\n```\n version. A cast of \n```\nnullptr_t\n```\n to an integral type needs a \n```\nreinterpret_cast\n```\n, and has the same semantics as a cast of \n```\n(void*)0\n```\n to an integral type (mapping implementation defined). A \n```"", '```\nnullptr_t\n```\n to an integral type needs a \n```\nreinterpret_cast\n```\n, and has the same semantics as a cast of \n```\n(void*)0\n```\n to an integral type (mapping implementation defined). A \n```\nreinterpret_cast\n```\n cannot convert \n```\nnullptr_t\n```\n to any pointer type. Rely on the implicit conversion if possible or use \n```\nstatic_cast\n```\n. The Standard requires that \n```\nsizeof(nullptr_t)\n```\n be \n```\nsizeof(void*)\n```\n.']","How is it a keyword and an instance of a type? This isn't surprising. Both 
```
true
```
 and 
```
false
```
 are keywords and as literals they have a type ( 
```
bool
```
 ). 
```
nullptr
```
 is a pointer literal of type 
```
std::nullptr_t
```
, and it's a prvalue (you cannot take the address of it using 
```
&
```
). 
```
4.10
```
 about pointer conversion says that a prvalue of type 
```
std::nullptr_t
```
 is a null pointer constant, and that an integral null pointer constant can be converted to 
```
std::nullptr_t
```
. The opposite direction is not allowed. This allows overloading a function for both pointers and integers, and passing 
```
nullptr
```
 to select the pointer version. Passing 
```
NULL
```
 or 
```
0
```
 would confusingly select the 
```
int
```
 version. A cast of 
```
nullptr_t
```
 to an integral type needs a 
```
reinterpret_cast
```
, and has the same semantics as a cast of 
```
(void*)0
```
 to an integral type (mapping implementation defined). A 
```
reinterpret_cast
```
 cannot convert 
```
nullptr_t
```
 to any pointer type. Rely on the implicit conversion if possible or use 
```
static_cast
```
. The Standard requires that 
```
sizeof(nullptr_t)
```
 be 
```
sizeof(void*)
```
."
17333,How do you compare float and double while accounting for precision loss?,https://stackoverflow.com/questions/17333/how-do-you-compare-float-and-double-while-accounting-for-precision-loss,32,,[],
2397984,"Undefined, unspecified and implementation-defined behavior",https://stackoverflow.com/questions/2397984/undefined-unspecified-and-implementation-defined-behavior,10,499.0,"['Undefined behavior is one of those aspects of the C and C++ language that can be surprising to programmers coming from other languages (other languages try to hide it better). Basically, it is possible to write C++ programs that do not behave in a predictable way, even though many C++ compilers will not report any errors in the program! Let\'s look at a classic example: \n```\n#include <iostream>\n    \nint main()\n{\n    char* p = ""hello!\\n"";   // yes I know, deprecated conversion\n    p[0] = \'y\';\n    p[5] = \'w\';\n    std::cout << p;\n}', '```\n The variable \n```\np\n```\n points to the string literal \n```\n""hello!\\n""\n```\n, and the two assignments below try to modify that string literal. What does this program do? According to the C++ standard, [lex.string] note 4, it invokes undefined behavior: The effect of attempting to modify a string literal is undefined. I can hear people screaming ""But wait, I can compile this no problem and get the output \n```\nyellow\n```', '```\nyellow\n```\n"" or ""What do you mean undefined, string literals are stored in read-only memory, so the first assignment attempt results in a core dump"". This is exactly the problem with undefined behavior. Basically, the standard allows anything to happen once you invoke undefined behavior (even nasal demons). If there is a ""correct"" behavior according to your mental model of the language, that model is simply wrong; The C++ standard has the only vote, period. Other examples of undefined behavior include accessing an array beyond its bounds, division by zero, dereferencing a null pointer, accessing objects after their lifetime ended, or writing allegedly clever expressions like \n```\ni++ + ++i\n```', "". [intro.defs] also defines undefined behavior's two less dangerous brothers, unspecified behavior and implementation-defined behavior: implementation-defined behavior [defns.impl.defined] behavior, for a well-formed program construct and correct data, that depends on the implementation and that each implementation documents unspecified behavior [defns.unspecified] behavior, for a well-formed program construct and correct data, that depends on the implementation [Note: The implementation is not required to document which behavior occurs. The range of possible behaviors is usually delineated by this document. — end note] undefined behavior [defns.undefined] behavior for which this document imposes no requirements [Note: Undefined behavior may be expected when this document omits any explicit definition of behavior or when a program uses an erroneous construct or erroneous data. Permissible undefined behavior ranges from ignoring the situation completely with unpredictable results, to"", ""definition of behavior or when a program uses an erroneous construct or erroneous data. Permissible undefined behavior ranges from ignoring the situation completely with unpredictable results, to behaving during translation or program execution in a documented manner characteristic of the environment (with or without the issuance of a diagnostic message), to terminating a translation or execution (with the issuance of a diagnostic message). [...] — end note] What can you do to avoid running into undefined behavior? Basically, you have to read good C++ books by authors who know what they're talking about. Avoid internet tutorials. Avoid bullschildt.""]","Undefined behavior is one of those aspects of the C and C++ language that can be surprising to programmers coming from other languages (other languages try to hide it better). Basically, it is possible to write C++ programs that do not behave in a predictable way, even though many C++ compilers will not report any errors in the program! Let's look at a classic example: 
```
#include <iostream>
    
int main()
{
    char* p = ""hello!\n"";   // yes I know, deprecated conversion
    p[0] = 'y';
    p[5] = 'w';
    std::cout << p;
}

```
 The variable 
```
p
```
 points to the string literal 
```
""hello!\n""
```
, and the two assignments below try to modify that string literal. What does this program do? According to the C++ standard, [lex.string] note 4, it invokes undefined behavior: The effect of attempting to modify a string literal is undefined. I can hear people screaming ""But wait, I can compile this no problem and get the output 
```
yellow
```
"" or ""What do you mean undefined, string literals are stored in read-only memory, so the first assignment attempt results in a core dump"". This is exactly the problem with undefined behavior. Basically, the standard allows anything to happen once you invoke undefined behavior (even nasal demons). If there is a ""correct"" behavior according to your mental model of the language, that model is simply wrong; The C++ standard has the only vote, period. Other examples of undefined behavior include accessing an array beyond its bounds, division by zero, dereferencing a null pointer, accessing objects after their lifetime ended, or writing allegedly clever expressions like 
```
i++ + ++i
```
. [intro.defs] also defines undefined behavior's two less dangerous brothers, unspecified behavior and implementation-defined behavior: implementation-defined behavior [defns.impl.defined] behavior, for a well-formed program construct and correct data, that depends on the implementation and that each implementation documents unspecified behavior [defns.unspecified] behavior, for a well-formed program construct and correct data, that depends on the implementation [Note: The implementation is not required to document which behavior occurs. The range of possible behaviors is usually delineated by this document. — end note] undefined behavior [defns.undefined] behavior for which this document imposes no requirements [Note: Undefined behavior may be expected when this document omits any explicit definition of behavior or when a program uses an erroneous construct or erroneous data. Permissible undefined behavior ranges from ignoring the situation completely with unpredictable results, to behaving during translation or program execution in a documented manner characteristic of the environment (with or without the issuance of a diagnostic message), to terminating a translation or execution (with the issuance of a diagnostic message). [...] — end note] What can you do to avoid running into undefined behavior? Basically, you have to read good C++ books by authors who know what they're talking about. Avoid internet tutorials. Avoid bullschildt."
1939953,How to find if a given key exists in a std::map,https://stackoverflow.com/questions/1939953/how-to-find-if-a-given-key-exists-in-a-stdmap,15,994.0,"['Use \n```\nmap::find\n```\n and \n```\nmap::end\n```\n: \n```\nif (m.find(""f"") == m.end()) {\n  // not found\n} else {\n  // found\n}\n\n```']","Use 
```
map::find
```
 and 
```
map::end
```
: 
```
if (m.find(""f"") == m.end()) {
  // not found
} else {
  // found
}

```
"
16710047,usr/bin/ld: cannot find -l<nameOfTheLibrary>,https://stackoverflow.com/questions/16710047/usr-bin-ld-cannot-find-lnameofthelibrary,16,254.0,['If your library name is say \n```\nlibxyz.so\n```\n and it is located on path say: \n```\n/home/user/myDir\n\n```\n then to link it to your program: \n```\ng++ -L/home/user/myDir -lxyz myprog.cpp -o myprog\n\n```'],"If your library name is say 
```
libxyz.so
```
 and it is located on path say: 
```
/home/user/myDir

```
 then to link it to your program: 
```
g++ -L/home/user/myDir -lxyz myprog.cpp -o myprog

```
"
997946,How to get current time and date in C++?,https://stackoverflow.com/questions/997946/how-to-get-current-time-and-date-in-c,27,921.0,"['Since C++ 11 you can use \n```\nstd::chrono::system_clock::now()\n```\n Example (copied from en.cppreference.com): \n```\n#include <iostream>\n#include <chrono>\n#include <ctime>    \n\nint main()\n{\n    auto start = std::chrono::system_clock::now();\n    // Some computation here\n    auto end = std::chrono::system_clock::now();\n \n    std::chrono::duration<double> elapsed_seconds = end-start;\n    std::time_t end_time = std::chrono::system_clock::to_time_t(end);\n \n    std::cout << ""finished computation at "" << std::ctime(&end_time)\n              << ""elapsed time: "" << elapsed_seconds.count() << ""s""\n              << std::endl;\n}\n\n```\n This should print something like this: \n```\nfinished computation at Mon Oct  2 00:59:08 2017\nelapsed time: 1.88232s\n\n```']","Since C++ 11 you can use 
```
std::chrono::system_clock::now()
```
 Example (copied from en.cppreference.com): 
```
#include <iostream>
#include <chrono>
#include <ctime>    

int main()
{
    auto start = std::chrono::system_clock::now();
    // Some computation here
    auto end = std::chrono::system_clock::now();
 
    std::chrono::duration<double> elapsed_seconds = end-start;
    std::time_t end_time = std::chrono::system_clock::to_time_t(end);
 
    std::cout << ""finished computation at "" << std::ctime(&end_time)
              << ""elapsed time: "" << elapsed_seconds.count() << ""s""
              << std::endl;
}

```
 This should print something like this: 
```
finished computation at Mon Oct  2 00:59:08 2017
elapsed time: 1.88232s

```
"
81870,Is it possible to print a variable's type in standard C++?,https://stackoverflow.com/questions/81870/is-it-possible-to-print-a-variables-type-in-standard-c,27,827.0,"['C++11 update to a very old question: Print variable type in C++. The accepted (and good) answer is to use \n```\ntypeid(a).name()\n```\n, where \n```\na\n```\n is a variable name. Now in C++11 we have \n```\ndecltype(x)\n```\n, which can turn an expression into a type. And \n```\ndecltype()\n```\n comes with its own set of very interesting rules. For example \n```\ndecltype(a)\n```\n and \n```\ndecltype((a))\n```\n will generally be different types (and for good and understandable reasons once those reasons are exposed). Will our trusty \n```\ntypeid(a).name()\n```\n help us explore this brave new world? No. But the tool that will is not that complicated. And it is that tool which I am using as an answer to this question. I will compare and contrast this new tool to \n```\ntypeid(a).name()\n```\n. And this new tool is actually built on top of \n```\ntypeid(a).name()\n```\n. The fundamental issue: \n```\ntypeid(a).name()', ""```\n throws away cv-qualifiers, references, and lvalue/rvalue-ness. For example: \n```\nconst int ci = 0;\nstd::cout << typeid(ci).name() << '\\n';\n\n```\n For me outputs: \n```\ni\n\n```\n and I'm guessing on MSVC outputs: \n```\nint\n\n```\n I.e. the \n```\nconst\n```\n is gone. This is not a QOI (Quality Of Implementation) issue. The standard mandates this behavior. What I'm recommending below is: \n```\ntemplate <typename T> std::string type_name();\n\n```\n which would be used like this: \n```\nconst int ci = 0;\nstd::cout << type_name<decltype(ci)>() << '\\n';\n\n```\n and for me outputs: \n```\nint const"", ""```\n which would be used like this: \n```\nconst int ci = 0;\nstd::cout << type_name<decltype(ci)>() << '\\n';\n\n```\n and for me outputs: \n```\nint const\n\n```\n \n```\n<disclaimer>\n```\n I have not tested this on MSVC. \n```\n</disclaimer>\n```\n But I welcome feedback from those who do. The C++11 Solution I am using \n```\n__cxa_demangle\n```\n for non-MSVC platforms as recommend by ipapadop in his answer to demangle types. But on MSVC I'm trusting \n```\ntypeid\n```\n to demangle names (untested). And this core is wrapped around some simple testing that detects, restores and reports cv-qualifiers and references to the input type. \n```\n#include <type_traits>\n#include <typeinfo>\n#ifndef _MSC_VER\n#   include <cxxabi.h>\n#endif\n#include <memory>\n#include <string>\n#include <cstdlib>"", 'template <class T>\nstd::string\ntype_name()\n{\n    typedef typename std::remove_reference<T>::type TR;\n    std::unique_ptr<char, void(*)(void*)> own\n           (\n#ifndef _MSC_VER\n                abi::__cxa_demangle(typeid(TR).name(), nullptr,\n                                           nullptr, nullptr),\n#else\n                nullptr,\n#endif\n                std::free\n           );\n    std::string r = own != nullptr ? own.get() : typeid(TR).name();\n    if (std::is_const<TR>::value)\n        r += "" const"";\n    if (std::is_volatile<TR>::value)\n        r += "" volatile"";\n    if (std::is_lvalue_reference<T>::value)\n        r += ""&"";\n    else if (std::is_rvalue_reference<T>::value)\n        r += ""&&"";\n    return r;\n}\n\n```\n The Results With this solution I can do this: \n```\nint& foo_lref();\nint&& foo_rref();\nint foo_value();', 'int\nmain()\n{\n    int i = 0;\n    const int ci = 0;\n    std::cout << ""decltype(i) is "" << type_name<decltype(i)>() << \'\\n\';\n    std::cout << ""decltype((i)) is "" << type_name<decltype((i))>() << \'\\n\';\n    std::cout << ""decltype(ci) is "" << type_name<decltype(ci)>() << \'\\n\';\n    std::cout << ""decltype((ci)) is "" << type_name<decltype((ci))>() << \'\\n\';\n    std::cout << ""decltype(static_cast<int&>(i)) is "" << type_name<decltype(static_cast<int&>(i))>() << \'\\n\';\n    std::cout << ""decltype(static_cast<int&&>(i)) is "" << type_name<decltype(static_cast<int&&>(i))>() << \'\\n\';\n    std::cout << ""decltype(static_cast<int>(i)) is "" << type_name<decltype(static_cast<int>(i))>() << \'\\n\';\n    std::cout << ""decltype(foo_lref()) is "" << type_name<decltype(foo_lref())>() << \'\\n\';\n    std::cout << ""decltype(foo_rref()) is "" << type_name<decltype(foo_rref())>() << \'\\n\';\n    std::cout << ""decltype(foo_value()) is "" << type_name<decltype(foo_value())>() << \'\\n\';\n}', '```\n and the output is: \n```\ndecltype(i) is int\ndecltype((i)) is int&\ndecltype(ci) is int const\ndecltype((ci)) is int const&\ndecltype(static_cast<int&>(i)) is int&\ndecltype(static_cast<int&&>(i)) is int&&\ndecltype(static_cast<int>(i)) is int\ndecltype(foo_lref()) is int&\ndecltype(foo_rref()) is int&&\ndecltype(foo_value()) is int', '```\n Note (for example) the difference between \n```\ndecltype(i)\n```\n and \n```\ndecltype((i))\n```\n. The former is the type of the declaration of \n```\ni\n```\n. The latter is the ""type"" of the expression \n```\ni\n```\n. (expressions never have reference type, but as a convention \n```\ndecltype\n```\n represents lvalue expressions with lvalue references). Thus this tool is an excellent vehicle just to learn about \n```\ndecltype\n```\n, in addition to exploring and debugging your own code. In contrast, if I were to build this just on \n```\ntypeid(a).name()\n```\n, without adding back lost cv-qualifiers or references, the output would be: \n```\ndecltype(i) is int\ndecltype((i)) is int\ndecltype(ci) is int\ndecltype((ci)) is int\ndecltype(static_cast<int&>(i)) is int\ndecltype(static_cast<int&&>(i)) is int\ndecltype(static_cast<int>(i)) is int\ndecltype(foo_lref()) is int\ndecltype(foo_rref()) is int\ndecltype(foo_value()) is int', ""```\n I.e. Every reference and cv-qualifier is stripped off. C++14 Update Just when you think you've got a solution to a problem nailed, someone always comes out of nowhere and shows you a much better way. :-) This answer from Jamboree shows how to get the type name in C++14 at compile time. It is a brilliant solution for a couple reasons: It's at compile time! You get the compiler itself to do the job instead of a library (even a std::lib). This means more accurate results for the latest language features (like lambdas). Jamboree's answer doesn't quite lay everything out for VS, and I'm tweaking his code a little bit. But since this answer gets a lot of views, take some time to go over there and upvote his answer, without which, this update would never have happened. \n```\n#include <cstddef>\n#include <stdexcept>\n#include <cstring>\n#include <ostream>"", '#ifndef _MSC_VER\n#  if __cplusplus < 201103\n#    define CONSTEXPR11_TN\n#    define CONSTEXPR14_TN\n#    define NOEXCEPT_TN\n#  elif __cplusplus < 201402\n#    define CONSTEXPR11_TN constexpr\n#    define CONSTEXPR14_TN\n#    define NOEXCEPT_TN noexcept\n#  else\n#    define CONSTEXPR11_TN constexpr\n#    define CONSTEXPR14_TN constexpr\n#    define NOEXCEPT_TN noexcept\n#  endif\n#else  // _MSC_VER\n#  if _MSC_VER < 1900\n#    define CONSTEXPR11_TN\n#    define CONSTEXPR14_TN\n#    define NOEXCEPT_TN\n#  elif _MSC_VER < 2000\n#    define CONSTEXPR11_TN constexpr\n#    define CONSTEXPR14_TN\n#    define NOEXCEPT_TN noexcept\n#  else\n#    define CONSTEXPR11_TN constexpr\n#    define CONSTEXPR14_TN constexpr\n#    define NOEXCEPT_TN noexcept\n#  endif\n#endif  // _MSC_VER\n\nclass static_string\n{\n    const char* const p_;\n    const std::size_t sz_;\n\npublic:\n    typedef const char* const_iterator;', 'class static_string\n{\n    const char* const p_;\n    const std::size_t sz_;\n\npublic:\n    typedef const char* const_iterator;\n\n    template <std::size_t N>\n    CONSTEXPR11_TN static_string(const char(&a)[N]) NOEXCEPT_TN\n        : p_(a)\n        , sz_(N-1)\n        {}\n\n    CONSTEXPR11_TN static_string(const char* p, std::size_t N) NOEXCEPT_TN\n        : p_(p)\n        , sz_(N)\n        {}\n\n    CONSTEXPR11_TN const char* data() const NOEXCEPT_TN {return p_;}\n    CONSTEXPR11_TN std::size_t size() const NOEXCEPT_TN {return sz_;}\n\n    CONSTEXPR11_TN const_iterator begin() const NOEXCEPT_TN {return p_;}\n    CONSTEXPR11_TN const_iterator end()   const NOEXCEPT_TN {return p_ + sz_;}\n\n    CONSTEXPR11_TN char operator[](std::size_t n) const\n    {\n        return n < sz_ ? p_[n] : throw std::out_of_range(""static_string"");\n    }\n};\n\ninline\nstd::ostream&\noperator<<(std::ostream& os, static_string const& s)\n{\n    return os.write(s.data(), s.size());\n}', 'inline\nstd::ostream&\noperator<<(std::ostream& os, static_string const& s)\n{\n    return os.write(s.data(), s.size());\n}\n\ntemplate <class T>\nCONSTEXPR14_TN\nstatic_string\ntype_name()\n{\n#ifdef __clang__\n    static_string p = __PRETTY_FUNCTION__;\n    return static_string(p.data() + 31, p.size() - 31 - 1);\n#elif defined(__GNUC__)\n    static_string p = __PRETTY_FUNCTION__;\n#  if __cplusplus < 201402\n    return static_string(p.data() + 36, p.size() - 36 - 1);\n#  else\n    return static_string(p.data() + 46, p.size() - 46 - 1);\n#  endif\n#elif defined(_MSC_VER)\n    static_string p = __FUNCSIG__;\n    return static_string(p.data() + 38, p.size() - 38 - 7);\n#endif\n}', ""```\n This code will auto-backoff on the \n```\nconstexpr\n```\n if you're still stuck in ancient C++11. And if you're painting on the cave wall with C++98/03, the \n```\nnoexcept\n```\n is sacrificed as well. C++17 Update In the comments below Lyberta points out that the new \n```\nstd::string_view\n```\n can replace \n```\nstatic_string\n```\n: \n```\ntemplate <class T>\nconstexpr\nstd::string_view\ntype_name()\n{\n    using namespace std;\n#ifdef __clang__\n    string_view p = __PRETTY_FUNCTION__;\n    return string_view(p.data() + 34, p.size() - 34 - 1);\n#elif defined(__GNUC__)\n    string_view p = __PRETTY_FUNCTION__;\n#  if __cplusplus < 201402\n    return string_view(p.data() + 36, p.size() - 36 - 1);\n#  else\n    return string_view(p.data() + 49, p.find(';', 49) - 49);\n#  endif\n#elif defined(_MSC_VER)\n    string_view p = __FUNCSIG__;\n    return string_view(p.data() + 84, p.size() - 84 - 7);\n#endif\n}"", ""```\n I've updated the constants for VS thanks to the very nice detective work by Jive Dadson in the comments below. Update: Be sure to check out this rewrite or this rewrite below which eliminate the unreadable magic numbers in my latest formulation.""]","C++11 update to a very old question: Print variable type in C++. The accepted (and good) answer is to use 
```
typeid(a).name()
```
, where 
```
a
```
 is a variable name. Now in C++11 we have 
```
decltype(x)
```
, which can turn an expression into a type. And 
```
decltype()
```
 comes with its own set of very interesting rules. For example 
```
decltype(a)
```
 and 
```
decltype((a))
```
 will generally be different types (and for good and understandable reasons once those reasons are exposed). Will our trusty 
```
typeid(a).name()
```
 help us explore this brave new world? No. But the tool that will is not that complicated. And it is that tool which I am using as an answer to this question. I will compare and contrast this new tool to 
```
typeid(a).name()
```
. And this new tool is actually built on top of 
```
typeid(a).name()
```
. The fundamental issue: 
```
typeid(a).name()

```
 throws away cv-qualifiers, references, and lvalue/rvalue-ness. For example: 
```
const int ci = 0;
std::cout << typeid(ci).name() << '\n';

```
 For me outputs: 
```
i

```
 and I'm guessing on MSVC outputs: 
```
int

```
 I.e. the 
```
const
```
 is gone. This is not a QOI (Quality Of Implementation) issue. The standard mandates this behavior. What I'm recommending below is: 
```
template <typename T> std::string type_name();

```
 which would be used like this: 
```
const int ci = 0;
std::cout << type_name<decltype(ci)>() << '\n';

```
 and for me outputs: 
```
int const

```
 
```
<disclaimer>
```
 I have not tested this on MSVC. 
```
</disclaimer>
```
 But I welcome feedback from those who do. The C++11 Solution I am using 
```
__cxa_demangle
```
 for non-MSVC platforms as recommend by ipapadop in his answer to demangle types. But on MSVC I'm trusting 
```
typeid
```
 to demangle names (untested). And this core is wrapped around some simple testing that detects, restores and reports cv-qualifiers and references to the input type. 
```
#include <type_traits>
#include <typeinfo>
#ifndef _MSC_VER
#   include <cxxabi.h>
#endif
#include <memory>
#include <string>
#include <cstdlib>

template <class T>
std::string
type_name()
{
    typedef typename std::remove_reference<T>::type TR;
    std::unique_ptr<char, void(*)(void*)> own
           (
#ifndef _MSC_VER
                abi::__cxa_demangle(typeid(TR).name(), nullptr,
                                           nullptr, nullptr),
#else
                nullptr,
#endif
                std::free
           );
    std::string r = own != nullptr ? own.get() : typeid(TR).name();
    if (std::is_const<TR>::value)
        r += "" const"";
    if (std::is_volatile<TR>::value)
        r += "" volatile"";
    if (std::is_lvalue_reference<T>::value)
        r += ""&"";
    else if (std::is_rvalue_reference<T>::value)
        r += ""&&"";
    return r;
}

```
 The Results With this solution I can do this: 
```
int& foo_lref();
int&& foo_rref();
int foo_value();

int
main()
{
    int i = 0;
    const int ci = 0;
    std::cout << ""decltype(i) is "" << type_name<decltype(i)>() << '\n';
    std::cout << ""decltype((i)) is "" << type_name<decltype((i))>() << '\n';
    std::cout << ""decltype(ci) is "" << type_name<decltype(ci)>() << '\n';
    std::cout << ""decltype((ci)) is "" << type_name<decltype((ci))>() << '\n';
    std::cout << ""decltype(static_cast<int&>(i)) is "" << type_name<decltype(static_cast<int&>(i))>() << '\n';
    std::cout << ""decltype(static_cast<int&&>(i)) is "" << type_name<decltype(static_cast<int&&>(i))>() << '\n';
    std::cout << ""decltype(static_cast<int>(i)) is "" << type_name<decltype(static_cast<int>(i))>() << '\n';
    std::cout << ""decltype(foo_lref()) is "" << type_name<decltype(foo_lref())>() << '\n';
    std::cout << ""decltype(foo_rref()) is "" << type_name<decltype(foo_rref())>() << '\n';
    std::cout << ""decltype(foo_value()) is "" << type_name<decltype(foo_value())>() << '\n';
}

```
 and the output is: 
```
decltype(i) is int
decltype((i)) is int&
decltype(ci) is int const
decltype((ci)) is int const&
decltype(static_cast<int&>(i)) is int&
decltype(static_cast<int&&>(i)) is int&&
decltype(static_cast<int>(i)) is int
decltype(foo_lref()) is int&
decltype(foo_rref()) is int&&
decltype(foo_value()) is int

```
 Note (for example) the difference between 
```
decltype(i)
```
 and 
```
decltype((i))
```
. The former is the type of the declaration of 
```
i
```
. The latter is the ""type"" of the expression 
```
i
```
. (expressions never have reference type, but as a convention 
```
decltype
```
 represents lvalue expressions with lvalue references). Thus this tool is an excellent vehicle just to learn about 
```
decltype
```
, in addition to exploring and debugging your own code. In contrast, if I were to build this just on 
```
typeid(a).name()
```
, without adding back lost cv-qualifiers or references, the output would be: 
```
decltype(i) is int
decltype((i)) is int
decltype(ci) is int
decltype((ci)) is int
decltype(static_cast<int&>(i)) is int
decltype(static_cast<int&&>(i)) is int
decltype(static_cast<int>(i)) is int
decltype(foo_lref()) is int
decltype(foo_rref()) is int
decltype(foo_value()) is int

```
 I.e. Every reference and cv-qualifier is stripped off. C++14 Update Just when you think you've got a solution to a problem nailed, someone always comes out of nowhere and shows you a much better way. :-) This answer from Jamboree shows how to get the type name in C++14 at compile time. It is a brilliant solution for a couple reasons: It's at compile time! You get the compiler itself to do the job instead of a library (even a std::lib). This means more accurate results for the latest language features (like lambdas). Jamboree's answer doesn't quite lay everything out for VS, and I'm tweaking his code a little bit. But since this answer gets a lot of views, take some time to go over there and upvote his answer, without which, this update would never have happened. 
```
#include <cstddef>
#include <stdexcept>
#include <cstring>
#include <ostream>

#ifndef _MSC_VER
#  if __cplusplus < 201103
#    define CONSTEXPR11_TN
#    define CONSTEXPR14_TN
#    define NOEXCEPT_TN
#  elif __cplusplus < 201402
#    define CONSTEXPR11_TN constexpr
#    define CONSTEXPR14_TN
#    define NOEXCEPT_TN noexcept
#  else
#    define CONSTEXPR11_TN constexpr
#    define CONSTEXPR14_TN constexpr
#    define NOEXCEPT_TN noexcept
#  endif
#else  // _MSC_VER
#  if _MSC_VER < 1900
#    define CONSTEXPR11_TN
#    define CONSTEXPR14_TN
#    define NOEXCEPT_TN
#  elif _MSC_VER < 2000
#    define CONSTEXPR11_TN constexpr
#    define CONSTEXPR14_TN
#    define NOEXCEPT_TN noexcept
#  else
#    define CONSTEXPR11_TN constexpr
#    define CONSTEXPR14_TN constexpr
#    define NOEXCEPT_TN noexcept
#  endif
#endif  // _MSC_VER

class static_string
{
    const char* const p_;
    const std::size_t sz_;

public:
    typedef const char* const_iterator;

    template <std::size_t N>
    CONSTEXPR11_TN static_string(const char(&a)[N]) NOEXCEPT_TN
        : p_(a)
        , sz_(N-1)
        {}

    CONSTEXPR11_TN static_string(const char* p, std::size_t N) NOEXCEPT_TN
        : p_(p)
        , sz_(N)
        {}

    CONSTEXPR11_TN const char* data() const NOEXCEPT_TN {return p_;}
    CONSTEXPR11_TN std::size_t size() const NOEXCEPT_TN {return sz_;}

    CONSTEXPR11_TN const_iterator begin() const NOEXCEPT_TN {return p_;}
    CONSTEXPR11_TN const_iterator end()   const NOEXCEPT_TN {return p_ + sz_;}

    CONSTEXPR11_TN char operator[](std::size_t n) const
    {
        return n < sz_ ? p_[n] : throw std::out_of_range(""static_string"");
    }
};

inline
std::ostream&
operator<<(std::ostream& os, static_string const& s)
{
    return os.write(s.data(), s.size());
}

template <class T>
CONSTEXPR14_TN
static_string
type_name()
{
#ifdef __clang__
    static_string p = __PRETTY_FUNCTION__;
    return static_string(p.data() + 31, p.size() - 31 - 1);
#elif defined(__GNUC__)
    static_string p = __PRETTY_FUNCTION__;
#  if __cplusplus < 201402
    return static_string(p.data() + 36, p.size() - 36 - 1);
#  else
    return static_string(p.data() + 46, p.size() - 46 - 1);
#  endif
#elif defined(_MSC_VER)
    static_string p = __FUNCSIG__;
    return static_string(p.data() + 38, p.size() - 38 - 7);
#endif
}

```
 This code will auto-backoff on the 
```
constexpr
```
 if you're still stuck in ancient C++11. And if you're painting on the cave wall with C++98/03, the 
```
noexcept
```
 is sacrificed as well. C++17 Update In the comments below Lyberta points out that the new 
```
std::string_view
```
 can replace 
```
static_string
```
: 
```
template <class T>
constexpr
std::string_view
type_name()
{
    using namespace std;
#ifdef __clang__
    string_view p = __PRETTY_FUNCTION__;
    return string_view(p.data() + 34, p.size() - 34 - 1);
#elif defined(__GNUC__)
    string_view p = __PRETTY_FUNCTION__;
#  if __cplusplus < 201402
    return string_view(p.data() + 36, p.size() - 36 - 1);
#  else
    return string_view(p.data() + 49, p.find(';', 49) - 49);
#  endif
#elif defined(_MSC_VER)
    string_view p = __FUNCSIG__;
    return string_view(p.data() + 84, p.size() - 84 - 7);
#endif
}

```
 I've updated the constants for VS thanks to the very nice detective work by Jive Dadson in the comments below. Update: Be sure to check out this rewrite or this rewrite below which eliminate the unreadable magic numbers in my latest formulation."
12774207,"Fastest way to check if a file exists using standard C++/C++11,14,17/C?",https://stackoverflow.com/questions/12774207/fastest-way-to-check-if-a-file-exists-using-standard-c-c11-14-17-c,23,1033.0,"['Well I threw together a test program that ran each of these methods 100,000 times, half on files that existed and half on files that didn\'t. \n```\n#include <sys/stat.h>\n#include <unistd.h>\n#include <string>\n#include <fstream>\n\ninline bool exists_test0 (const std::string& name) {\n    ifstream f(name.c_str());\n    return f.good();\n}\n\ninline bool exists_test1 (const std::string& name) {\n    if (FILE *file = fopen(name.c_str(), ""r"")) {\n        fclose(file);\n        return true;\n    } else {\n        return false;\n    }   \n}\n\ninline bool exists_test2 (const std::string& name) {\n    return ( access( name.c_str(), F_OK ) != -1 );\n}\n\ninline bool exists_test3 (const std::string& name) {\n  struct stat buffer;   \n  return (stat (name.c_str(), &buffer) == 0); \n}', 'inline bool exists_test3 (const std::string& name) {\n  struct stat buffer;   \n  return (stat (name.c_str(), &buffer) == 0); \n}\n\n```\n Results for total time to run the 100,000 calls averaged over 5 runs, Method Time \n```\nexists_test0\n```\n (ifstream) 0.485s \n```\nexists_test1\n```\n (FILE fopen) 0.302s \n```\nexists_test2\n```\n (posix access()) 0.202s \n```\nexists_test3\n```\n (posix stat()) 0.134s The \n```\nstat()\n```\n function provided the best performance on my system (Linux, compiled with \n```\ng++\n```\n), with a standard \n```\nfopen\n```\n call being your best bet if you for some reason refuse to use POSIX functions.']","Well I threw together a test program that ran each of these methods 100,000 times, half on files that existed and half on files that didn't. 
```
#include <sys/stat.h>
#include <unistd.h>
#include <string>
#include <fstream>

inline bool exists_test0 (const std::string& name) {
    ifstream f(name.c_str());
    return f.good();
}

inline bool exists_test1 (const std::string& name) {
    if (FILE *file = fopen(name.c_str(), ""r"")) {
        fclose(file);
        return true;
    } else {
        return false;
    }   
}

inline bool exists_test2 (const std::string& name) {
    return ( access( name.c_str(), F_OK ) != -1 );
}

inline bool exists_test3 (const std::string& name) {
  struct stat buffer;   
  return (stat (name.c_str(), &buffer) == 0); 
}

```
 Results for total time to run the 100,000 calls averaged over 5 runs, Method Time 
```
exists_test0
```
 (ifstream) 0.485s 
```
exists_test1
```
 (FILE fopen) 0.302s 
```
exists_test2
```
 (posix access()) 0.202s 
```
exists_test3
```
 (posix stat()) 0.134s The 
```
stat()
```
 function provided the best performance on my system (Linux, compiled with 
```
g++
```
), with a standard 
```
fopen
```
 call being your best bet if you for some reason refuse to use POSIX functions."
936687,How do I declare a 2d array in C++ using new?,https://stackoverflow.com/questions/936687/how-do-i-declare-a-2d-array-in-c-using-new,30,885.0,"[""If your row length is a compile time constant, C++11 allows \n```\nauto arr2d = new int [nrows][CONSTANT];\n\n```\n See this answer. Compilers like gcc that allow variable-length arrays as an extension to C++ can use \n```\nnew\n```\n as shown here to get fully runtime-variable array dimension functionality like C99 allows, but portable ISO C++ is limited to only the first dimension being variable. Another efficient option is to do the 2d indexing manually into a big 1d array, as another answer shows, allowing the same compiler optimizations as a real 2D array (e.g. proving or checking that arrays don't alias each other / overlap). Otherwise, you can use an array of pointers to arrays to allow 2D syntax like contiguous 2D arrays, even though it's not an efficient single large allocation. You can initialize it using a loop, like this: \n```\nint** a = new int*[rowCount];\nfor(int i = 0; i < rowCount; ++i)\n    a[i] = new int[colCount];"", ""```\n The above, for \n```\ncolCount= 5\n```\n and \n```\nrowCount = 4\n```\n, would produce the following: Don't forget to \n```\ndelete\n```\n each row separately with a loop, before deleting the array of pointers. Example in another answer.""]","If your row length is a compile time constant, C++11 allows 
```
auto arr2d = new int [nrows][CONSTANT];

```
 See this answer. Compilers like gcc that allow variable-length arrays as an extension to C++ can use 
```
new
```
 as shown here to get fully runtime-variable array dimension functionality like C99 allows, but portable ISO C++ is limited to only the first dimension being variable. Another efficient option is to do the 2d indexing manually into a big 1d array, as another answer shows, allowing the same compiler optimizations as a real 2D array (e.g. proving or checking that arrays don't alias each other / overlap). Otherwise, you can use an array of pointers to arrays to allow 2D syntax like contiguous 2D arrays, even though it's not an efficient single large allocation. You can initialize it using a loop, like this: 
```
int** a = new int*[rowCount];
for(int i = 0; i < rowCount; ++i)
    a[i] = new int[colCount];

```
 The above, for 
```
colCount= 5
```
 and 
```
rowCount = 4
```
, would produce the following: Don't forget to 
```
delete
```
 each row separately with a loop, before deleting the array of pointers. Example in another answer."
2342162,std::string formatting like sprintf,https://stackoverflow.com/questions/2342162/stdstring-formatting-like-sprintf,44,420.0,"['You can\'t do it directly, because you don\'t have write access to the underlying buffer (until C++11; see Dietrich Epp\'s comment). You\'ll have to do it first in a c-string, then copy it into a std::string: \n```\n  char buff[100];\n  snprintf(buff, sizeof(buff), ""%s"", ""Hello"");\n  std::string buffAsStdStr = buff;\n\n```\n But I\'m not sure why you wouldn\'t just use a string stream? I\'m assuming you have specific reasons to not just do this: \n```\n  std::ostringstream stringStream;\n  stringStream << ""Hello"";\n  std::string copyOfStr = stringStream.str();\n\n```']","You can't do it directly, because you don't have write access to the underlying buffer (until C++11; see Dietrich Epp's comment). You'll have to do it first in a c-string, then copy it into a std::string: 
```
  char buff[100];
  snprintf(buff, sizeof(buff), ""%s"", ""Hello"");
  std::string buffAsStdStr = buff;

```
 But I'm not sure why you wouldn't just use a string stream? I'm assuming you have specific reasons to not just do this: 
```
  std::ostringstream stringStream;
  stringStream << ""Hello"";
  std::string copyOfStr = stringStream.str();

```
"
105014,Does the 'mutable' keyword have any purpose other than allowing a data member to be modified by a const member function?,https://stackoverflow.com/questions/105014/does-the-mutable-keyword-have-any-purpose-other-than-allowing-a-data-member-to,18,451.0,"[""It allows the differentiation of bitwise const and logical const. Logical const is when an object doesn't change in a way that is visible through the public interface, like your locking example. Another example would be a class that computes a value the first time it is requested, and caches the result. Since c++11 \n```\nmutable\n```\n can be used on a lambda to denote that things captured by value are modifiable (they aren't by default): \n```\nint x = 0;\nauto f1 = [=]() mutable {x = 42;};  // OK\nauto f2 = [=]()         {x = 42;};  // Error: a by-value capture cannot be modified in a non-mutable lambda\n\n```""]","It allows the differentiation of bitwise const and logical const. Logical const is when an object doesn't change in a way that is visible through the public interface, like your locking example. Another example would be a class that computes a value the first time it is requested, and caches the result. Since c++11 
```
mutable
```
 can be used on a lambda to denote that things captured by value are modifiable (they aren't by default): 
```
int x = 0;
auto f1 = [=]() mutable {x = 42;};  // OK
auto f2 = [=]()         {x = 42;};  // Error: a by-value capture cannot be modified in a non-mutable lambda

```
"
2896600,How to replace all occurrences of a character in string?,https://stackoverflow.com/questions/2896600/how-to-replace-all-occurrences-of-a-character-in-string,19,978.0,"['```\nstd::string\n```\n doesn\'t contain such function but you could use stand-alone \n```\nreplace\n```\n function from \n```\nalgorithm\n```\n header. \n```\n#include <algorithm>\n#include <string>\n\nvoid some_func() {\n  std::string s = ""example string"";\n  std::replace( s.begin(), s.end(), \'x\', \'y\'); // replace all \'x\' to \'y\'\n}\n\n```']","
```
std::string
```
 doesn't contain such function but you could use stand-alone 
```
replace
```
 function from 
```
algorithm
```
 header. 
```
#include <algorithm>
#include <string>

void some_func() {
  std::string s = ""example string"";
  std::replace( s.begin(), s.end(), 'x', 'y'); // replace all 'x' to 'y'
}

```
"
1727881,How to use the PI constant in C++,https://stackoverflow.com/questions/1727881/how-to-use-the-pi-constant-in-c,25,704.0,"['On some (especially older) platforms (see the comments below) you might need to \n```\n#define _USE_MATH_DEFINES\n\n```\n and then include the necessary header file: \n```\n#include <math.h>\n\n```\n and the value of pi can be accessed via: \n```\nM_PI\n\n```\n In my \n```\nmath.h\n```\n (2014) it is defined as: \n```\n# define M_PI           3.14159265358979323846  /* pi */\n\n```\n but check your \n```\nmath.h\n```\n for more. An extract from the ""old"" \n```\nmath.h\n```\n (in 2009): \n```\n/* Define _USE_MATH_DEFINES before including math.h to expose these macro\n * definitions for common math constants.  These are placed under an #ifdef\n * since these commonly-defined names are not part of the C/C++ standards.\n */\n\n```\n However: on newer platforms (at least on my 64 bit Ubuntu 14.04) I do not need to define the \n```\n_USE_MATH_DEFINES\n```\n On (recent) Linux platforms there are \n```\nlong double\n```\n values too provided as a GNU Extension: \n```\n# define M_PIl          3.141592653589793238462643383279502884L /* pi */', '```']","On some (especially older) platforms (see the comments below) you might need to 
```
#define _USE_MATH_DEFINES

```
 and then include the necessary header file: 
```
#include <math.h>

```
 and the value of pi can be accessed via: 
```
M_PI

```
 In my 
```
math.h
```
 (2014) it is defined as: 
```
# define M_PI           3.14159265358979323846  /* pi */

```
 but check your 
```
math.h
```
 for more. An extract from the ""old"" 
```
math.h
```
 (in 2009): 
```
/* Define _USE_MATH_DEFINES before including math.h to expose these macro
 * definitions for common math constants.  These are placed under an #ifdef
 * since these commonly-defined names are not part of the C/C++ standards.
 */

```
 However: on newer platforms (at least on my 64 bit Ubuntu 14.04) I do not need to define the 
```
_USE_MATH_DEFINES
```
 On (recent) Linux platforms there are 
```
long double
```
 values too provided as a GNU Extension: 
```
# define M_PIl          3.141592653589793238462643383279502884L /* pi */

```
"
185844,How to initialize private static data members in a header file,https://stackoverflow.com/questions/185844/how-to-initialize-private-static-data-members-in-a-header-file,18,677.0,"['The class declaration should be in the header file, or in the source file, if the class is not used in other files. \n```\n// foo.h\nclass foo\n{\n    private:\n        static int i;\n};\n\n```\n However, the initialization should be in the source file. \n```\n// foo.cpp\nint foo::i = 0;', '```\n If the initialization is in the header file, then each file that includes the header file will have a definition of the static member. Thus during the link phase, you will get linker errors as the code to initialize the variable will be defined in multiple source files. The initialization of the \n```\nstatic int i\n```\n must be done outside of any function. Note: Matt Curtis: points out that C++ allows the simplification of the above if the static data member is of const integer type (\n```\nbool\n```\n, \n```\nchar\n```\n, \n```\nchar8_t\n```\n [since C++20], \n```\nchar16_t\n```\n, \n```\nchar32_t\n```\n, \n```\nwchar_t\n```\n, \n```\nshort\n```\n, \n```\nint\n```\n, \n```\nlong\n```\n, \n```\nlong long\n```\n, or any implementation-defined extended integer types, including any signed, unsigned, and cv-qualified variants.). You can then declare and initialize the data member directly inside the class declaration in the header file: \n```\nclass foo\n{\n    private:\n        static int const i = 42;\n};\n\n```']","The class declaration should be in the header file, or in the source file, if the class is not used in other files. 
```
// foo.h
class foo
{
    private:
        static int i;
};

```
 However, the initialization should be in the source file. 
```
// foo.cpp
int foo::i = 0;

```
 If the initialization is in the header file, then each file that includes the header file will have a definition of the static member. Thus during the link phase, you will get linker errors as the code to initialize the variable will be defined in multiple source files. The initialization of the 
```
static int i
```
 must be done outside of any function. Note: Matt Curtis: points out that C++ allows the simplification of the above if the static data member is of const integer type (
```
bool
```
, 
```
char
```
, 
```
char8_t
```
 [since C++20], 
```
char16_t
```
, 
```
char32_t
```
, 
```
wchar_t
```
, 
```
short
```
, 
```
int
```
, 
```
long
```
, 
```
long long
```
, or any implementation-defined extended integer types, including any signed, unsigned, and cv-qualified variants.). You can then declare and initialize the data member directly inside the class declaration in the header file: 
```
class foo
{
    private:
        static int const i = 42;
};

```
"
18222926,What are the advantages of list initialization (using curly braces)?,https://stackoverflow.com/questions/18222926/what-are-the-advantages-of-list-initialization-using-curly-braces,5,560.0,"['Basically copying and pasting from Bjarne Stroustrup\'s ""The C++ Programming Language 4th Edition"": List initialization does not allow narrowing (§iso.8.5.4). That is: An integer cannot be converted to another integer that cannot hold its value. For example, char to int is allowed, but not int to char. A floating-point value cannot be converted to another floating-point type that cannot hold its value. For example, float to double is allowed, but not double to float. A floating-point value cannot be converted to an integer type. An integer value cannot be converted to a floating-point type. Example: \n```\nvoid fun(double val, int val2) {\n\n    int x2 = val;    // if val == 7.9, x2 becomes 7 (bad)\n\n    char c2 = val2;  // if val2 == 1025, c2 becomes 1 (bad)\n\n    int x3 {val};    // error: possible truncation (good)\n\n    char c3 {val2};  // error: possible narrowing (good)\n\n    char c4 {24};    // OK: 24 can be represented exactly as a char (good)', 'int x3 {val};    // error: possible truncation (good)\n\n    char c3 {val2};  // error: possible narrowing (good)\n\n    char c4 {24};    // OK: 24 can be represented exactly as a char (good)\n\n    char c5 {264};   // error (assuming 8-bit chars): 264 cannot be \n                     // represented as a char (good)\n\n    int x4 {2.0};    // error: no double to int value conversion (good)\n\n}\n\n```\n The only situation where = is preferred over {} is when using \n```\nauto\n```\n keyword to get the type determined by the initializer. Example: \n```\nauto z1 {99};   // z1 is an int\nauto z2 = {99}; // z2 is std::initializer_list<int>\nauto z3 = 99;   // z3 is an int\n\n```\n Conclusion Prefer {} initialization over alternatives unless you have a strong reason not to.']","Basically copying and pasting from Bjarne Stroustrup's ""The C++ Programming Language 4th Edition"": List initialization does not allow narrowing (§iso.8.5.4). That is: An integer cannot be converted to another integer that cannot hold its value. For example, char to int is allowed, but not int to char. A floating-point value cannot be converted to another floating-point type that cannot hold its value. For example, float to double is allowed, but not double to float. A floating-point value cannot be converted to an integer type. An integer value cannot be converted to a floating-point type. Example: 
```
void fun(double val, int val2) {

    int x2 = val;    // if val == 7.9, x2 becomes 7 (bad)

    char c2 = val2;  // if val2 == 1025, c2 becomes 1 (bad)

    int x3 {val};    // error: possible truncation (good)

    char c3 {val2};  // error: possible narrowing (good)

    char c4 {24};    // OK: 24 can be represented exactly as a char (good)

    char c5 {264};   // error (assuming 8-bit chars): 264 cannot be 
                     // represented as a char (good)

    int x4 {2.0};    // error: no double to int value conversion (good)

}

```
 The only situation where = is preferred over {} is when using 
```
auto
```
 keyword to get the type determined by the initializer. Example: 
```
auto z1 {99};   // z1 is an int
auto z2 = {99}; // z2 is std::initializer_list<int>
auto z3 = 99;   // z3 is an int

```
 Conclusion Prefer {} initialization over alternatives unless you have a strong reason not to."
257288,How can you check whether a templated class has a member function?,https://stackoverflow.com/questions/257288/how-can-you-check-whether-a-templated-class-has-a-member-function,34,386.0,"[""Yes, with SFINAE you can check if a given class does provide a certain method. Here's the working code: \n```\n#include <iostream>\n\nstruct Hello\n{\n    int helloworld() { return 0; }\n};\n\nstruct Generic {};    \n\n// SFINAE test\ntemplate <typename T>\nclass has_helloworld\n{\n    typedef char one;\n    struct two { char x[2]; };\n\n    template <typename C> static one test( decltype(&C::helloworld) ) ;\n    template <typename C> static two test(...);    \n\npublic:\n    enum { value = sizeof(test<T>(0)) == sizeof(char) };\n};\n    \nint main(int argc, char *argv[])\n{\n    std::cout << has_helloworld<Hello>::value << std::endl;\n    std::cout << has_helloworld<Generic>::value << std::endl;\n    return 0;\n}\n\n```\n I've just tested it with Linux and gcc 4.1/4.3. I don't know if it's portable to other platforms running different compilers.""]","Yes, with SFINAE you can check if a given class does provide a certain method. Here's the working code: 
```
#include <iostream>

struct Hello
{
    int helloworld() { return 0; }
};

struct Generic {};    

// SFINAE test
template <typename T>
class has_helloworld
{
    typedef char one;
    struct two { char x[2]; };

    template <typename C> static one test( decltype(&C::helloworld) ) ;
    template <typename C> static two test(...);    

public:
    enum { value = sizeof(test<T>(0)) == sizeof(char) };
};
    
int main(int argc, char *argv[])
{
    std::cout << has_helloworld<Hello>::value << std::endl;
    std::cout << has_helloworld<Generic>::value << std::endl;
    return 0;
}

```
 I've just tested it with Linux and gcc 4.1/4.3. I don't know if it's portable to other platforms running different compilers."
573294,When to use reinterpret_cast?,https://stackoverflow.com/questions/573294/when-to-use-reinterpret-cast,11,580.0,"['The C++ standard guarantees the following: \n```\nstatic_cast\n```\ning a pointer to and from \n```\nvoid*\n```\n preserves the address. That is, in the following, \n```\na\n```\n, \n```\nb\n```\n and \n```\nc\n```\n all point to the same address: \n```\nint* a = new int();\nvoid* b = static_cast<void*>(a);\nint* c = static_cast<int*>(b);\n\n```\n \n```\nreinterpret_cast\n```\n only guarantees that if you cast a pointer to a different type, and then \n```\nreinterpret_cast\n```\n it back to the original type, you get the original value. So in the following: \n```\nint* a = new int();\nvoid* b = reinterpret_cast<void*>(a);\nint* c = reinterpret_cast<int*>(b);', ""```\n \n```\na\n```\n and \n```\nc\n```\n contain the same value, but the value of \n```\nb\n```\n is unspecified. (in practice it will typically contain the same address as \n```\na\n```\n and \n```\nc\n```\n, but that's not specified in the standard, and it may not be true on machines with more complex memory systems.) For casting to and from \n```\nvoid*\n```\n, \n```\nstatic_cast\n```\n should be preferred.""]","The C++ standard guarantees the following: 
```
static_cast
```
ing a pointer to and from 
```
void*
```
 preserves the address. That is, in the following, 
```
a
```
, 
```
b
```
 and 
```
c
```
 all point to the same address: 
```
int* a = new int();
void* b = static_cast<void*>(a);
int* c = static_cast<int*>(b);

```
 
```
reinterpret_cast
```
 only guarantees that if you cast a pointer to a different type, and then 
```
reinterpret_cast
```
 it back to the original type, you get the original value. So in the following: 
```
int* a = new int();
void* b = reinterpret_cast<void*>(a);
int* c = reinterpret_cast<int*>(b);

```
 
```
a
```
 and 
```
c
```
 contain the same value, but the value of 
```
b
```
 is unspecified. (in practice it will typically contain the same address as 
```
a
```
 and 
```
c
```
, but that's not specified in the standard, and it may not be true on machines with more complex memory systems.) For casting to and from 
```
void*
```
, 
```
static_cast
```
 should be preferred."
34732,How do I list the symbols in a .so file,https://stackoverflow.com/questions/34732/how-do-i-list-the-symbols-in-a-so-file,11,796.0,"['The standard tool for listing symbols is \n```\nnm\n```\n, you can use it simply like this: \n```\nnm -gD yourLib.so\n\n```\n If you want to see symbols of a C++ library, add the ""-C"" option which demangle the symbols (it\'s far more readable demangled). \n```\nnm -gDC yourLib.so\n\n```\n If your .so file is in elf format, you have two options: Either \n```\nobjdump\n```\n (\n```\n-C\n```\n is also useful for demangling C++): \n```\n$ objdump -TC libz.so\n\nlibz.so:     file format elf64-x86-64\n\nDYNAMIC SYMBOL TABLE:\n0000000000002010 l    d  .init  0000000000000000              .init\n0000000000000000      DF *UND*  0000000000000000  GLIBC_2.2.5 free\n0000000000000000      DF *UND*  0000000000000000  GLIBC_2.2.5 __errno_location\n0000000000000000  w   D  *UND*  0000000000000000              _ITM_deregisterTMCloneTable', ""```\n Or use \n```\nreadelf\n```\n: \n```\n$ readelf -Ws libz.so\nSymbol table '.dynsym' contains 112 entries:\n   Num:    Value          Size Type    Bind   Vis      Ndx Name\n     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND\n     1: 0000000000002010     0 SECTION LOCAL  DEFAULT   10\n     2: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND free@GLIBC_2.2.5 (14)\n     3: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND __errno_location@GLIBC_2.2.5 (14)\n     4: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_deregisterTMCloneTable\n\n```""]","The standard tool for listing symbols is 
```
nm
```
, you can use it simply like this: 
```
nm -gD yourLib.so

```
 If you want to see symbols of a C++ library, add the ""-C"" option which demangle the symbols (it's far more readable demangled). 
```
nm -gDC yourLib.so

```
 If your .so file is in elf format, you have two options: Either 
```
objdump
```
 (
```
-C
```
 is also useful for demangling C++): 
```
$ objdump -TC libz.so

libz.so:     file format elf64-x86-64

DYNAMIC SYMBOL TABLE:
0000000000002010 l    d  .init  0000000000000000              .init
0000000000000000      DF *UND*  0000000000000000  GLIBC_2.2.5 free
0000000000000000      DF *UND*  0000000000000000  GLIBC_2.2.5 __errno_location
0000000000000000  w   D  *UND*  0000000000000000              _ITM_deregisterTMCloneTable

```
 Or use 
```
readelf
```
: 
```
$ readelf -Ws libz.so
Symbol table '.dynsym' contains 112 entries:
   Num:    Value          Size Type    Bind   Vis      Ndx Name
     0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND
     1: 0000000000002010     0 SECTION LOCAL  DEFAULT   10
     2: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND free@GLIBC_2.2.5 (14)
     3: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND __errno_location@GLIBC_2.2.5 (14)
     4: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_deregisterTMCloneTable

```
"
318398,Why does C++ compilation take so long?,https://stackoverflow.com/questions/318398/why-does-c-compilation-take-so-long,15,883.0,"[""Several reasons Header files Every single compilation unit requires hundreds or even thousands of headers to be (1) loaded and (2) compiled. Every one of them typically has to be recompiled for every compilation unit, because the preprocessor ensures that the result of compiling a header might vary between every compilation unit. (A macro may be defined in one compilation unit which changes the content of the header). This is probably the main reason, as it requires huge amounts of code to be compiled for every compilation unit, and additionally, every header has to be compiled multiple times (once for every compilation unit that includes it). Linking Once compiled, all the object files have to be linked together. This is basically a monolithic process that can't very well be parallelized, and has to process your entire project. Parsing The syntax is extremely complicated to parse, depends heavily on context, and is very hard to disambiguate. This takes a lot of time. Templates In C#,"", '```\nList<T>\n```\n is the only type that is compiled, no matter how many instantiations of List you have in your program. In C++, \n```\nvector<int>\n```\n is a completely separate type from \n```\nvector<float>\n```', ', and each one will have to be compiled separately. Add to this that templates make up a full Turing-complete ""sub-language"" that the compiler has to interpret, and this can become ridiculously complicated. Even relatively simple template metaprogramming code can define recursive templates that create dozens and dozens of template instantiations. Templates may also result in extremely complex types, with ridiculously long names, adding a lot of extra work to the linker. (It has to compare a lot of symbol names, and if these names can grow into many thousand characters, that can become fairly expensive). And of course, they exacerbate the problems with header files, because templates generally have to be defined in headers, which means far more code has to be parsed and compiled for every compilation unit. In plain C code, a header typically only contains forward declarations, but very little actual code. In C++, it is not uncommon for almost all the code to reside in header files.', 'compilation unit. In plain C code, a header typically only contains forward declarations, but very little actual code. In C++, it is not uncommon for almost all the code to reside in header files. Optimization C++ allows for some very dramatic optimizations. C# or Java don\'t allow classes to be completely eliminated (they have to be there for reflection purposes), but even a simple C++ template metaprogram can easily generate dozens or hundreds of classes, all of which are inlined and eliminated again in the optimization phase. Moreover, a C++ program must be fully optimized by the compiler. A C# program can rely on the JIT compiler to perform additional optimizations at load-time, C++ doesn\'t get any such ""second chances"". What the compiler generates is as optimized as it\'s going to get. Machine C++ is compiled to machine code which may be somewhat more complicated than the bytecode Java or .NET use (especially in the case of x86). (This is mentioned out of completeness only because', ""Machine C++ is compiled to machine code which may be somewhat more complicated than the bytecode Java or .NET use (especially in the case of x86). (This is mentioned out of completeness only because it was mentioned in comments and such. In practice, this step is unlikely to take more than a tiny fraction of the total compilation time). Conclusion Most of these factors are shared by C code, which actually compiles fairly efficiently. The parsing step is a lot more complicated in C++, and can take up significantly more time, but the main offender is probably templates. They're useful, and make C++ a far more powerful language, but they also take their toll in terms of compilation speed.""]","Several reasons Header files Every single compilation unit requires hundreds or even thousands of headers to be (1) loaded and (2) compiled. Every one of them typically has to be recompiled for every compilation unit, because the preprocessor ensures that the result of compiling a header might vary between every compilation unit. (A macro may be defined in one compilation unit which changes the content of the header). This is probably the main reason, as it requires huge amounts of code to be compiled for every compilation unit, and additionally, every header has to be compiled multiple times (once for every compilation unit that includes it). Linking Once compiled, all the object files have to be linked together. This is basically a monolithic process that can't very well be parallelized, and has to process your entire project. Parsing The syntax is extremely complicated to parse, depends heavily on context, and is very hard to disambiguate. This takes a lot of time. Templates In C#, 
```
List<T>
```
 is the only type that is compiled, no matter how many instantiations of List you have in your program. In C++, 
```
vector<int>
```
 is a completely separate type from 
```
vector<float>
```
, and each one will have to be compiled separately. Add to this that templates make up a full Turing-complete ""sub-language"" that the compiler has to interpret, and this can become ridiculously complicated. Even relatively simple template metaprogramming code can define recursive templates that create dozens and dozens of template instantiations. Templates may also result in extremely complex types, with ridiculously long names, adding a lot of extra work to the linker. (It has to compare a lot of symbol names, and if these names can grow into many thousand characters, that can become fairly expensive). And of course, they exacerbate the problems with header files, because templates generally have to be defined in headers, which means far more code has to be parsed and compiled for every compilation unit. In plain C code, a header typically only contains forward declarations, but very little actual code. In C++, it is not uncommon for almost all the code to reside in header files. Optimization C++ allows for some very dramatic optimizations. C# or Java don't allow classes to be completely eliminated (they have to be there for reflection purposes), but even a simple C++ template metaprogram can easily generate dozens or hundreds of classes, all of which are inlined and eliminated again in the optimization phase. Moreover, a C++ program must be fully optimized by the compiler. A C# program can rely on the JIT compiler to perform additional optimizations at load-time, C++ doesn't get any such ""second chances"". What the compiler generates is as optimized as it's going to get. Machine C++ is compiled to machine code which may be somewhat more complicated than the bytecode Java or .NET use (especially in the case of x86). (This is mentioned out of completeness only because it was mentioned in comments and such. In practice, this step is unlikely to take more than a tiny fraction of the total compilation time). Conclusion Most of these factors are shared by C code, which actually compiles fairly efficiently. The parsing step is a lot more complicated in C++, and can take up significantly more time, but the main offender is probably templates. They're useful, and make C++ a far more powerful language, but they also take their toll in terms of compilation speed."
213121,Use 'class' or 'typename' for template parameters?,https://stackoverflow.com/questions/213121/use-class-or-typename-for-template-parameters,10,452.0,"['Stan Lippman talked about this here. I thought it was interesting. Summary: Stroustrup originally used \n```\nclass\n```\n to specify types in templates to avoid introducing a new keyword. Some in the committee worried that this overloading of the keyword led to confusion. Later, the committee introduced a new keyword \n```\ntypename\n```\n to resolve syntactic ambiguity, and decided to let it also be used to specify template types to reduce confusion, but for backward compatibility, \n```\nclass\n```\n kept its overloaded meaning.']","Stan Lippman talked about this here. I thought it was interesting. Summary: Stroustrup originally used 
```
class
```
 to specify types in templates to avoid introducing a new keyword. Some in the committee worried that this overloading of the keyword led to confusion. Later, the committee introduced a new keyword 
```
typename
```
 to resolve syntactic ambiguity, and decided to let it also be used to specify template types to reduce confusion, but for backward compatibility, 
```
class
```
 kept its overloaded meaning."
145270,Calling C/C++ from Python?,https://stackoverflow.com/questions/145270/calling-c-c-from-python,12,202.0,"[""You should have a look at Boost.Python. Here is the short introduction taken from their website: The Boost Python Library is a framework for interfacing Python and C++. It allows you to quickly and seamlessly expose C++ classes functions and objects to Python, and vice-versa, using no special tools -- just your C++ compiler. It is designed to wrap C++ interfaces non-intrusively, so that you should not have to change the C++ code at all in order to wrap it, making Boost.Python ideal for exposing 3rd-party libraries to Python. The library's use of advanced metaprogramming techniques simplifies its syntax for users, so that wrapping code takes on the look of a kind of declarative interface definition language (IDL).""]","You should have a look at Boost.Python. Here is the short introduction taken from their website: The Boost Python Library is a framework for interfacing Python and C++. It allows you to quickly and seamlessly expose C++ classes functions and objects to Python, and vice-versa, using no special tools -- just your C++ compiler. It is designed to wrap C++ interfaces non-intrusively, so that you should not have to change the C++ code at all in order to wrap it, making Boost.Python ideal for exposing 3rd-party libraries to Python. The library's use of advanced metaprogramming techniques simplifies its syntax for users, so that wrapping code takes on the look of a kind of declarative interface definition language (IDL)."
298708,Debugging with command-line parameters in Visual Studio,https://stackoverflow.com/questions/298708/debugging-with-command-line-parameters-in-visual-studio,15,900.0,"['Yes, it\'s in the Debug section of the properties page of the project. In Visual Studio since 2008: right-click on the project node, choose Properties, go to the Debugging section -- there is a box for ""Command Arguments"".']","Yes, it's in the Debug section of the properties page of the project. In Visual Studio since 2008: right-click on the project node, choose Properties, go to the Debugging section -- there is a box for ""Command Arguments""."
184537,In what cases do I use malloc and/or new?,https://stackoverflow.com/questions/184537/in-what-cases-do-i-use-malloc-and-or-new,20,,[],
478898,How do I execute a command and get the output of the command within C++ using POSIX?,https://stackoverflow.com/questions/478898/how-do-i-execute-a-command-and-get-the-output-of-the-command-within-c-using-po,14,799.0,"['```\n#include <cstdio>\n#include <iostream>\n#include <memory>\n#include <stdexcept>\n#include <string>\n#include <array>\n\nstd::string exec(const char* cmd) {\n    std::array<char, 128> buffer;\n    std::string result;\n    std::unique_ptr<FILE, decltype(&pclose)> pipe(popen(cmd, ""r""), pclose);\n    if (!pipe) {\n        throw std::runtime_error(""popen() failed!"");\n    }\n    while (fgets(buffer.data(), static_cast<int>(buffer.size()), pipe.get()) != nullptr) {\n        result += buffer.data();\n    }\n    return result;\n}\n\n```\n Pre-C++11 version: \n```\n#include <iostream>\n#include <stdexcept>\n#include <stdio.h>\n#include <string>', '```\n Pre-C++11 version: \n```\n#include <iostream>\n#include <stdexcept>\n#include <stdio.h>\n#include <string>\n\nstd::string exec(const char* cmd) {\n    char buffer[128];\n    std::string result = """";\n    FILE* pipe = popen(cmd, ""r"");\n    if (!pipe) throw std::runtime_error(""popen() failed!"");\n    try {\n        while (fgets(buffer, sizeof buffer, pipe) != NULL) {\n            result += buffer;\n        }\n    } catch (...) {\n        pclose(pipe);\n        throw;\n    }\n    pclose(pipe);\n    return result;\n}\n\n```\n Replace \n```\npopen\n```\n and \n```\npclose\n```\n with \n```\n_popen\n```\n and \n```\n_pclose\n```\n for Windows. 2024 Edit: With newer versions of gnu g++ such as the one in Ubuntu 24.04, the code above results in an error because the \n```\nstd::unique_ptr\n```\n deleter is ignoring the return value from \n```\npclose()\n```\n. \n```\nerror: ignoring attributes on template argument ‘int (*)(FILE*)’ [-Werror=ignored-attributes]', '```\n Had to modify the code to wrap \n```\npclose()\n```\n. Used a lambda for the wrapper. Now looks like this: \n```\nstd::unique_ptr<FILE, void(*)(FILE*)> pipe(popen(cmd.c_str(), ""r""),\n    [](FILE * f) -> void\n    {\n        // wrapper to ignore the return value from pclose() is needed with newer versions of gnu g++\n        std::ignore = pclose(f);\n    });\n\n```']","
```
#include <cstdio>
#include <iostream>
#include <memory>
#include <stdexcept>
#include <string>
#include <array>

std::string exec(const char* cmd) {
    std::array<char, 128> buffer;
    std::string result;
    std::unique_ptr<FILE, decltype(&pclose)> pipe(popen(cmd, ""r""), pclose);
    if (!pipe) {
        throw std::runtime_error(""popen() failed!"");
    }
    while (fgets(buffer.data(), static_cast<int>(buffer.size()), pipe.get()) != nullptr) {
        result += buffer.data();
    }
    return result;
}

```
 Pre-C++11 version: 
```
#include <iostream>
#include <stdexcept>
#include <stdio.h>
#include <string>

std::string exec(const char* cmd) {
    char buffer[128];
    std::string result = """";
    FILE* pipe = popen(cmd, ""r"");
    if (!pipe) throw std::runtime_error(""popen() failed!"");
    try {
        while (fgets(buffer, sizeof buffer, pipe) != NULL) {
            result += buffer;
        }
    } catch (...) {
        pclose(pipe);
        throw;
    }
    pclose(pipe);
    return result;
}

```
 Replace 
```
popen
```
 and 
```
pclose
```
 with 
```
_popen
```
 and 
```
_pclose
```
 for Windows. 2024 Edit: With newer versions of gnu g++ such as the one in Ubuntu 24.04, the code above results in an error because the 
```
std::unique_ptr
```
 deleter is ignoring the return value from 
```
pclose()
```
. 
```
error: ignoring attributes on template argument ‘int (*)(FILE*)’ [-Werror=ignored-attributes]

```
 Had to modify the code to wrap 
```
pclose()
```
. Used a lambda for the wrapper. Now looks like this: 
```
std::unique_ptr<FILE, void(*)(FILE*)> pipe(popen(cmd.c_str(), ""r""),
    [](FILE * f) -> void
    {
        // wrapper to ignore the return value from pclose() is needed with newer versions of gnu g++
        std::ignore = pclose(f);
    });

```
"
20731,How do you clear a stringstream variable?,https://stackoverflow.com/questions/20731/how-do-you-clear-a-stringstream-variable,12,944.0,"['For all the standard library types the member function \n```\nempty()\n```\n is a query, not a command, i.e. it means ""are you empty?"" not ""please throw away your contents"". The \n```\nclear()\n```\n member function is inherited from \n```\nios\n```\n and is used to clear the error state of the stream, e.g. if a file stream has the error state set to \n```\neofbit\n```\n (end-of-file), then calling \n```\nclear()\n```\n will set the error state back to \n```\ngoodbit\n```\n (no error). For clearing the contents of a \n```\nstringstream\n```\n, using: \n```\nm.str("""");\n\n```\n is correct, although using: \n```\nm.str(std::string());\n\n```\n is technically more efficient, because you avoid invoking the \n```\nstd::string\n```\n constructor that takes \n```\nconst char*\n```\n. But any compiler these days should be able to generate the same code in both cases - so I would just go with whatever is more readable.']","For all the standard library types the member function 
```
empty()
```
 is a query, not a command, i.e. it means ""are you empty?"" not ""please throw away your contents"". The 
```
clear()
```
 member function is inherited from 
```
ios
```
 and is used to clear the error state of the stream, e.g. if a file stream has the error state set to 
```
eofbit
```
 (end-of-file), then calling 
```
clear()
```
 will set the error state back to 
```
goodbit
```
 (no error). For clearing the contents of a 
```
stringstream
```
, using: 
```
m.str("""");

```
 is correct, although using: 
```
m.str(std::string());

```
 is technically more efficient, because you avoid invoking the 
```
std::string
```
 constructor that takes 
```
const char*
```
. But any compiler these days should be able to generate the same code in both cases - so I would just go with whatever is more readable."
5311515,GCC -fPIC option,https://stackoverflow.com/questions/5311515/gcc-fpic-option,5,731.0,"[""Position Independent Code means that the generated machine code is not dependent on being located at a specific address in order to work. E.g. jumps would be generated as relative rather than absolute. Pseudo-assembly: PIC: This would work whether the code was at address 100 or 1000 \n```\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL CURRENT+10\n...\n111: NOP\n\n```\n Non-PIC: This will only work if the code is at address 100 \n```\n100: COMPARE REG1, REG2\n101: JUMP_IF_EQUAL 111\n...\n111: NOP\n\n```\n EDIT: In response to comment. If your code is compiled with -fPIC, it's suitable for inclusion in a library - the library must be able to be relocated from its preferred location in memory to another address, there could be another already loaded library at the address your library prefers.""]","Position Independent Code means that the generated machine code is not dependent on being located at a specific address in order to work. E.g. jumps would be generated as relative rather than absolute. Pseudo-assembly: PIC: This would work whether the code was at address 100 or 1000 
```
100: COMPARE REG1, REG2
101: JUMP_IF_EQUAL CURRENT+10
...
111: NOP

```
 Non-PIC: This will only work if the code is at address 100 
```
100: COMPARE REG1, REG2
101: JUMP_IF_EQUAL 111
...
111: NOP

```
 EDIT: In response to comment. If your code is compiled with -fPIC, it's suitable for inclusion in a library - the library must be able to be relocated from its preferred location in memory to another address, there could be another already loaded library at the address your library prefers."
5029840,Convert char to int in C and C++,https://stackoverflow.com/questions/5029840/convert-char-to-int-in-c-and-c,14,,[],
6438086,Iterator invalidation rules for C++ containers,https://stackoverflow.com/questions/6438086/iterator-invalidation-rules-for-c-containers,6,196.0,"['C++17 (All references are from the final working draft of CPP17 - n4659) Insertion Sequence Containers \n```\nvector\n```\n: The functions \n```\ninsert\n```\n, \n```\nemplace_back\n```\n, \n```\nemplace\n```\n, \n```\npush_back\n```\n cause reallocation if the new size is greater than the old capacity. Reallocation invalidates all the references, pointers, and iterators referring to the elements in the sequence. If no reallocation happens, all the iterators and references before the insertion point remain valid. [26.3.11.5/1] With respect to the \n```\nreserve\n```\n function, reallocation invalidates all the references, pointers, and iterators referring to the elements in the sequence. No reallocation shall take place during insertions that happen after a call to \n```\nreserve()\n```\n until the time when an insertion would make the size of the vector greater than the value of \n```\ncapacity()\n```\n. [26.3.11.3/6] \n```\ndeque\n```', '```\nreserve()\n```\n until the time when an insertion would make the size of the vector greater than the value of \n```\ncapacity()\n```\n. [26.3.11.3/6] \n```\ndeque\n```\n: An insertion in the middle of the deque invalidates all the iterators and references to elements of the deque. An insertion at either end of the deque invalidates all the iterators to the deque, but has no effect on the validity of references to elements of the deque. [26.3.8.4/1] \n```\nlist\n```\n: Does not affect the validity of iterators and references. If an exception is thrown there are no effects. [26.3.10.4/1]. The \n```\ninsert\n```\n, \n```\nemplace_front\n```\n, \n```\nemplace_back\n```\n, \n```\nemplace\n```\n, \n```\npush_front\n```\n, \n```\npush_back\n```\n functions are covered under this rule. \n```\nforward_list\n```\n: None of the overloads of \n```\ninsert_after\n```\n shall affect the validity of iterators and references [26.3.9.5/1] \n```\narray\n```', '```\n functions are covered under this rule. \n```\nforward_list\n```\n: None of the overloads of \n```\ninsert_after\n```\n shall affect the validity of iterators and references [26.3.9.5/1] \n```\narray\n```\n: As a rule, iterators to an array are never invalidated throughout the lifetime of the array. One should take note, however, that during swap, the iterator will continue to point to the same array element, and will thus change its value. Associative Containers \n```\nAll Associative Containers\n```\n: The \n```\ninsert\n```\n and \n```\nemplace\n```\n members shall not affect the validity of iterators and references to the container [26.2.6/9] Unordered Associative Containers \n```\nAll Unordered Associative Containers\n```\n: Rehashing invalidates iterators, changes ordering between elements, and changes which buckets elements appear in, but does not invalidate pointers or references to elements. [26.2.7/9] The \n```\ninsert\n```\n and \n```\nemplace\n```', '```\ninsert\n```\n and \n```\nemplace\n```\n members shall not affect the validity of references to container elements, but may invalidate all iterators to the container. [26.2.7/14] The \n```\ninsert\n```\n and \n```\nemplace\n```\n members shall not affect the validity of iterators if \n```\n(N+n) <= z * B\n```\n, where \n```\nN\n```\n is the number of elements in the container prior to the insert operation, \n```\nn\n```\n is the number of elements inserted, \n```\nB\n```\n is the container’s bucket count, and \n```\nz\n```\n is the container’s maximum load factor. [26.2.7/15] \n```\nAll Unordered Associative Containers\n```\n: In case of a merge operation (e.g., \n```\na.merge(a2)\n```\n), iterators referring to the transferred elements and all iterators referring to \n```\na\n```\n will be invalidated, but iterators to elements remaining in \n```\na2\n```\n will remain valid. (Table 91 — Unordered associative container requirements) Container Adaptors \n```\nstack\n```\n: inherited from underlying container \n```\nqueue\n```', '```\na2\n```\n will remain valid. (Table 91 — Unordered associative container requirements) Container Adaptors \n```\nstack\n```\n: inherited from underlying container \n```\nqueue\n```\n: inherited from underlying container \n```\npriority_queue\n```\n: inherited from underlying container Erasure Sequence Containers \n```\nvector\n```\n: The functions \n```\nerase\n```\n and \n```\npop_back\n```\n invalidate iterators and references at or after the point of the erase. [26.3.11.5/3] \n```\ndeque\n```\n: An erase operation that erases the last element of a \n```\ndeque\n```\n invalidates only the past-the-end iterator and all iterators and references to the erased elements. An erase operation that erases the first element of a \n```\ndeque\n```\n but not the last element invalidates only iterators and references to the erased elements. An erase operation that erases neither the first element nor the last element of a \n```\ndeque\n```', 'deque\n```\n but not the last element invalidates only iterators and references to the erased elements. An erase operation that erases neither the first element nor the last element of a \n```\ndeque\n```\n invalidates the past-the-end iterator and all iterators and references to all the elements of the \n```\ndeque\n```\n. [ Note: \n```\npop_front\n```\n and \n```\npop_back\n```\n are erase operations. —end note ] [26.3.8.4/4] \n```\nlist\n```\n: Invalidates only the iterators and references to the erased elements. [26.3.10.4/3]. This applies to \n```\nerase\n```\n, \n```\npop_front\n```\n, \n```\npop_back\n```\n, \n```\nclear\n```\n functions. \n```\nremove\n```\n and \n```\nremove_if\n```\n member functions: Erases all the elements in the list referred by a list iterator \n```\ni\n```\n for which the following conditions hold: \n```\n*i == value\n```\n, \n```\npred(*i) != false\n```\n. Invalidates only the iterators and references to the erased elements [26.3.10.5/15]. \n```\nunique\n```', '```\n for which the following conditions hold: \n```\n*i == value\n```\n, \n```\npred(*i) != false\n```\n. Invalidates only the iterators and references to the erased elements [26.3.10.5/15]. \n```\nunique\n```\n member function - Erases all but the first element from every consecutive group of equal elements referred to by the iterator \n```\ni\n```\n in the range \n```\n[first + 1, last)\n```\n for which \n```\n*i == *(i-1)\n```\n (for the version of unique with no arguments) or \n```\npred(*i, *(i - 1))\n```\n (for the version of unique with a predicate argument) holds. Invalidates only the iterators and references to the erased elements. [26.3.10.5/19] \n```\nforward_list\n```\n: \n```\nerase_after\n```\n shall invalidate only iterators and references to the erased elements. [26.3.9.5/1]. \n```\nremove\n```\n and \n```\nremove_if\n```\n member functions - Erases all the elements in the list referred by a list iterator i for which the following conditions hold: \n```\n*i == value\n```\n (for \n```\nremove()\n```\n), \n```\npred(*i)\n```', '```\n member functions - Erases all the elements in the list referred by a list iterator i for which the following conditions hold: \n```\n*i == value\n```\n (for \n```\nremove()\n```\n), \n```\npred(*i)\n```\n is true (for \n```\nremove_if()\n```\n). Invalidates only the iterators and references to the erased elements. [26.3.9.6/12]. \n```\nunique\n```\n member function - Erases all but the first element from every consecutive group of equal elements referred to by the iterator i in the range [first + 1, last) for which \n```\n*i == *(i-1)\n```\n (for the version with no arguments) or \n```\npred(*i, *(i - 1))\n```\n (for the version with a predicate argument) holds. Invalidates only the iterators and references to the erased elements. [26.3.9.6/16] \n```\nAll Sequence Containers\n```\n: \n```\nclear\n```\n invalidates all references, pointers, and iterators referring to the elements of a and may invalidate the past-the-end iterator (Table 87 — Sequence container requirements). But for \n```\nforward_list\n```\n, \n```\nclear', '```\nforward_list\n```\n, \n```\nclear\n```\n does not invalidate past-the-end iterators. [26.3.9.5/32] \n```\nAll Sequence Containers\n```\n: \n```\nassign\n```\n invalidates all references, pointers and iterators referring to the elements of the container. For \n```\nvector\n```\n and \n```\ndeque\n```\n, also invalidates the past-the-end iterator. (Table 87 — Sequence container requirements) Associative Containers \n```\nAll Associative Containers\n```\n: The \n```\nerase\n```\n members shall invalidate only iterators and references to the erased elements [26.2.6/9] \n```\nAll Associative Containers\n```\n: The \n```\nextract\n```\n members invalidate only iterators to the removed element; pointers and references to the removed element remain valid [26.2.6/10] Container Adaptors \n```\nstack\n```\n: inherited from underlying container \n```\nqueue\n```\n: inherited from underlying container \n```\npriority_queue\n```', '```\nstack\n```\n: inherited from underlying container \n```\nqueue\n```\n: inherited from underlying container \n```\npriority_queue\n```\n: inherited from underlying container General container requirements relating to iterator invalidation: Unless otherwise specified (either explicitly or by defining a function in terms of other functions), invoking a container member function or passing a container as an argument to a library function shall not invalidate iterators to, or change the values of, objects within that container. [26.2.1/12] no \n```\nswap()\n```\n function invalidates any references, pointers, or iterators referring to the elements of the containers being swapped. [ Note: The end() iterator does not refer to any element, so it may be invalidated. —end note ] [26.2.1/(11.6)] As examples of the above requirements: \n```\ntransform\n```\n algorithm: The \n```\nop\n```\n and \n```\nbinary_op\n```\n functions shall not invalidate iterators or subranges, or modify elements in the ranges [28.6.4/1]', '```\ntransform\n```\n algorithm: The \n```\nop\n```\n and \n```\nbinary_op\n```\n functions shall not invalidate iterators or subranges, or modify elements in the ranges [28.6.4/1] \n```\naccumulate\n```\n algorithm: In the range [first, last], \n```\nbinary_op\n```\n shall neither modify elements nor invalidate iterators or subranges [29.8.2/1] \n```\nreduce\n```\n algorithm: binary_op shall neither invalidate iterators or subranges, nor modify elements in the range [first, last]. [29.8.3/5] and so on...']","C++17 (All references are from the final working draft of CPP17 - n4659) Insertion Sequence Containers 
```
vector
```
: The functions 
```
insert
```
, 
```
emplace_back
```
, 
```
emplace
```
, 
```
push_back
```
 cause reallocation if the new size is greater than the old capacity. Reallocation invalidates all the references, pointers, and iterators referring to the elements in the sequence. If no reallocation happens, all the iterators and references before the insertion point remain valid. [26.3.11.5/1] With respect to the 
```
reserve
```
 function, reallocation invalidates all the references, pointers, and iterators referring to the elements in the sequence. No reallocation shall take place during insertions that happen after a call to 
```
reserve()
```
 until the time when an insertion would make the size of the vector greater than the value of 
```
capacity()
```
. [26.3.11.3/6] 
```
deque
```
: An insertion in the middle of the deque invalidates all the iterators and references to elements of the deque. An insertion at either end of the deque invalidates all the iterators to the deque, but has no effect on the validity of references to elements of the deque. [26.3.8.4/1] 
```
list
```
: Does not affect the validity of iterators and references. If an exception is thrown there are no effects. [26.3.10.4/1]. The 
```
insert
```
, 
```
emplace_front
```
, 
```
emplace_back
```
, 
```
emplace
```
, 
```
push_front
```
, 
```
push_back
```
 functions are covered under this rule. 
```
forward_list
```
: None of the overloads of 
```
insert_after
```
 shall affect the validity of iterators and references [26.3.9.5/1] 
```
array
```
: As a rule, iterators to an array are never invalidated throughout the lifetime of the array. One should take note, however, that during swap, the iterator will continue to point to the same array element, and will thus change its value. Associative Containers 
```
All Associative Containers
```
: The 
```
insert
```
 and 
```
emplace
```
 members shall not affect the validity of iterators and references to the container [26.2.6/9] Unordered Associative Containers 
```
All Unordered Associative Containers
```
: Rehashing invalidates iterators, changes ordering between elements, and changes which buckets elements appear in, but does not invalidate pointers or references to elements. [26.2.7/9] The 
```
insert
```
 and 
```
emplace
```
 members shall not affect the validity of references to container elements, but may invalidate all iterators to the container. [26.2.7/14] The 
```
insert
```
 and 
```
emplace
```
 members shall not affect the validity of iterators if 
```
(N+n) <= z * B
```
, where 
```
N
```
 is the number of elements in the container prior to the insert operation, 
```
n
```
 is the number of elements inserted, 
```
B
```
 is the container’s bucket count, and 
```
z
```
 is the container’s maximum load factor. [26.2.7/15] 
```
All Unordered Associative Containers
```
: In case of a merge operation (e.g., 
```
a.merge(a2)
```
), iterators referring to the transferred elements and all iterators referring to 
```
a
```
 will be invalidated, but iterators to elements remaining in 
```
a2
```
 will remain valid. (Table 91 — Unordered associative container requirements) Container Adaptors 
```
stack
```
: inherited from underlying container 
```
queue
```
: inherited from underlying container 
```
priority_queue
```
: inherited from underlying container Erasure Sequence Containers 
```
vector
```
: The functions 
```
erase
```
 and 
```
pop_back
```
 invalidate iterators and references at or after the point of the erase. [26.3.11.5/3] 
```
deque
```
: An erase operation that erases the last element of a 
```
deque
```
 invalidates only the past-the-end iterator and all iterators and references to the erased elements. An erase operation that erases the first element of a 
```
deque
```
 but not the last element invalidates only iterators and references to the erased elements. An erase operation that erases neither the first element nor the last element of a 
```
deque
```
 invalidates the past-the-end iterator and all iterators and references to all the elements of the 
```
deque
```
. [ Note: 
```
pop_front
```
 and 
```
pop_back
```
 are erase operations. —end note ] [26.3.8.4/4] 
```
list
```
: Invalidates only the iterators and references to the erased elements. [26.3.10.4/3]. This applies to 
```
erase
```
, 
```
pop_front
```
, 
```
pop_back
```
, 
```
clear
```
 functions. 
```
remove
```
 and 
```
remove_if
```
 member functions: Erases all the elements in the list referred by a list iterator 
```
i
```
 for which the following conditions hold: 
```
*i == value
```
, 
```
pred(*i) != false
```
. Invalidates only the iterators and references to the erased elements [26.3.10.5/15]. 
```
unique
```
 member function - Erases all but the first element from every consecutive group of equal elements referred to by the iterator 
```
i
```
 in the range 
```
[first + 1, last)
```
 for which 
```
*i == *(i-1)
```
 (for the version of unique with no arguments) or 
```
pred(*i, *(i - 1))
```
 (for the version of unique with a predicate argument) holds. Invalidates only the iterators and references to the erased elements. [26.3.10.5/19] 
```
forward_list
```
: 
```
erase_after
```
 shall invalidate only iterators and references to the erased elements. [26.3.9.5/1]. 
```
remove
```
 and 
```
remove_if
```
 member functions - Erases all the elements in the list referred by a list iterator i for which the following conditions hold: 
```
*i == value
```
 (for 
```
remove()
```
), 
```
pred(*i)
```
 is true (for 
```
remove_if()
```
). Invalidates only the iterators and references to the erased elements. [26.3.9.6/12]. 
```
unique
```
 member function - Erases all but the first element from every consecutive group of equal elements referred to by the iterator i in the range [first + 1, last) for which 
```
*i == *(i-1)
```
 (for the version with no arguments) or 
```
pred(*i, *(i - 1))
```
 (for the version with a predicate argument) holds. Invalidates only the iterators and references to the erased elements. [26.3.9.6/16] 
```
All Sequence Containers
```
: 
```
clear
```
 invalidates all references, pointers, and iterators referring to the elements of a and may invalidate the past-the-end iterator (Table 87 — Sequence container requirements). But for 
```
forward_list
```
, 
```
clear
```
 does not invalidate past-the-end iterators. [26.3.9.5/32] 
```
All Sequence Containers
```
: 
```
assign
```
 invalidates all references, pointers and iterators referring to the elements of the container. For 
```
vector
```
 and 
```
deque
```
, also invalidates the past-the-end iterator. (Table 87 — Sequence container requirements) Associative Containers 
```
All Associative Containers
```
: The 
```
erase
```
 members shall invalidate only iterators and references to the erased elements [26.2.6/9] 
```
All Associative Containers
```
: The 
```
extract
```
 members invalidate only iterators to the removed element; pointers and references to the removed element remain valid [26.2.6/10] Container Adaptors 
```
stack
```
: inherited from underlying container 
```
queue
```
: inherited from underlying container 
```
priority_queue
```
: inherited from underlying container General container requirements relating to iterator invalidation: Unless otherwise specified (either explicitly or by defining a function in terms of other functions), invoking a container member function or passing a container as an argument to a library function shall not invalidate iterators to, or change the values of, objects within that container. [26.2.1/12] no 
```
swap()
```
 function invalidates any references, pointers, or iterators referring to the elements of the containers being swapped. [ Note: The end() iterator does not refer to any element, so it may be invalidated. —end note ] [26.2.1/(11.6)] As examples of the above requirements: 
```
transform
```
 algorithm: The 
```
op
```
 and 
```
binary_op
```
 functions shall not invalidate iterators or subranges, or modify elements in the ranges [28.6.4/1] 
```
accumulate
```
 algorithm: In the range [first, last], 
```
binary_op
```
 shall neither modify elements nor invalidate iterators or subranges [29.8.2/1] 
```
reduce
```
 algorithm: binary_op shall neither invalidate iterators or subranges, nor modify elements in the range [first, last]. [29.8.3/5] and so on..."
7724569,Debug vs Release in CMake,https://stackoverflow.com/questions/7724569/debug-vs-release-in-cmake,6,875.0,"['With CMake, it\'s generally recommended to do an ""out of source"" build. Create your \n```\nCMakeLists.txt\n```\n in the root of your project. Then from the root of your project: \n```\nmkdir Release\ncd Release\ncmake -DCMAKE_BUILD_TYPE=Release ..\nmake\n\n```\n And for \n```\nDebug\n```\n (again from the root of your project): \n```\nmkdir Debug\ncd Debug\ncmake -DCMAKE_BUILD_TYPE=Debug ..\nmake\n\n```\n \n```\nRelease\n```\n / \n```\nDebug\n```\n will add the appropriate flags for your compiler. There are also \n```\nRelWithDebInfo\n```\n and \n```\nMinSizeRel\n```\n build configurations. You can modify/add to the flags by specifying a toolchain file in which you can add \n```\nCMAKE_<LANG>_FLAGS_<CONFIG>_INIT\n```\n variables, e.g.: \n```\nset(CMAKE_CXX_FLAGS_DEBUG_INIT ""-Wall"")\nset(CMAKE_CXX_FLAGS_RELEASE_INIT ""-Wall"")', ""```\n See CMAKE_BUILD_TYPE for more details. As for your third question, I'm not sure what you are asking exactly. CMake should automatically detect and use the compiler appropriate for your different source files.""]","With CMake, it's generally recommended to do an ""out of source"" build. Create your 
```
CMakeLists.txt
```
 in the root of your project. Then from the root of your project: 
```
mkdir Release
cd Release
cmake -DCMAKE_BUILD_TYPE=Release ..
make

```
 And for 
```
Debug
```
 (again from the root of your project): 
```
mkdir Debug
cd Debug
cmake -DCMAKE_BUILD_TYPE=Debug ..
make

```
 
```
Release
```
 / 
```
Debug
```
 will add the appropriate flags for your compiler. There are also 
```
RelWithDebInfo
```
 and 
```
MinSizeRel
```
 build configurations. You can modify/add to the flags by specifying a toolchain file in which you can add 
```
CMAKE_<LANG>_FLAGS_<CONFIG>_INIT
```
 variables, e.g.: 
```
set(CMAKE_CXX_FLAGS_DEBUG_INIT ""-Wall"")
set(CMAKE_CXX_FLAGS_RELEASE_INIT ""-Wall"")

```
 See CMAKE_BUILD_TYPE for more details. As for your third question, I'm not sure what you are asking exactly. CMake should automatically detect and use the compiler appropriate for your different source files."
131803,unsigned int vs. size_t,https://stackoverflow.com/questions/131803/unsigned-int-vs-size-t,8,476.0,"['The \n```\nsize_t\n```\n type is the unsigned integer type that is the result of the \n```\nsizeof\n```\n operator (and the \n```\noffsetof\n```\n operator), so it is guaranteed to be big enough to contain the size of the biggest object your system can handle (e.g., a static array of 8Gb). The \n```\nsize_t\n```\n type may be bigger than, equal to, or smaller than an \n```\nunsigned int\n```\n, and your compiler might make assumptions about it for optimization. You may find more precise information in the C99 standard, section 7.17, a draft of which is available on the Internet in pdf format, or in the C11 standard, section 7.19, also available as a pdf draft.']","The 
```
size_t
```
 type is the unsigned integer type that is the result of the 
```
sizeof
```
 operator (and the 
```
offsetof
```
 operator), so it is guaranteed to be big enough to contain the size of the biggest object your system can handle (e.g., a static array of 8Gb). The 
```
size_t
```
 type may be bigger than, equal to, or smaller than an 
```
unsigned int
```
, and your compiler might make assumptions about it for optimization. You may find more precise information in the C99 standard, section 7.17, a draft of which is available on the Internet in pdf format, or in the C11 standard, section 7.19, also available as a pdf draft."
3582001,What are the main purposes of std::forward and which problems does it solve?,https://stackoverflow.com/questions/3582001/what-are-the-main-purposes-of-stdforward-and-which-problems-does-it-solve,8,,[],
1135841,How to write a multi-line string literal,https://stackoverflow.com/questions/1135841/how-to-write-a-multi-line-string-literal,11,767.0,"['Well ... Sort of. The easiest is to just use the fact that adjacent string literals are concatenated by the compiler: \n```\nconst char *text =\n  ""This text is pretty long, but will be ""\n  ""concatenated into just a single string. ""\n  ""The disadvantage is that you have to quote ""\n  ""each part, and newlines must be literal as ""\n  ""usual."";\n\n```\n The indentation doesn\'t matter, since it\'s not inside the quotes. You can also do this, as long as you take care to escape the embedded newline. Failure to do so, like my first answer did, will not compile: \n```\nconst char *text2 =\n  ""Here, on the other hand, I\'ve gone crazy \\\nand really let the literal span several lines, \\\nwithout bothering with quoting each line\'s \\\ncontent. This works, but you can\'t indent."";', ""```\n Again, note those backslashes at the end of each line, they must be immediately before the line ends, they are escaping the newline in the source, so that everything acts as if the newline wasn't there. You don't get newlines in the string at the locations where you had backslashes. With this form, you obviously can't indent the text since the indentation would then become part of the string, garbling it with random spaces.""]","Well ... Sort of. The easiest is to just use the fact that adjacent string literals are concatenated by the compiler: 
```
const char *text =
  ""This text is pretty long, but will be ""
  ""concatenated into just a single string. ""
  ""The disadvantage is that you have to quote ""
  ""each part, and newlines must be literal as ""
  ""usual."";

```
 The indentation doesn't matter, since it's not inside the quotes. You can also do this, as long as you take care to escape the embedded newline. Failure to do so, like my first answer did, will not compile: 
```
const char *text2 =
  ""Here, on the other hand, I've gone crazy \
and really let the literal span several lines, \
without bothering with quoting each line's \
content. This works, but you can't indent."";

```
 Again, note those backslashes at the end of each line, they must be immediately before the line ends, they are escaping the newline in the source, so that everything acts as if the newline wasn't there. You don't get newlines in the string at the locations where you had backslashes. With this form, you obviously can't indent the text since the indentation would then become part of the string, garbling it with random spaces."
54120862,Does the C++ standard allow for an uninitialized bool to crash a program?,https://stackoverflow.com/questions/54120862/does-the-c-standard-allow-for-an-uninitialized-bool-to-crash-a-program,6,324.0,"[""Yes, ISO C++ allows (but doesn't require) implementations to make this choice. But also note that ISO C++ allows a compiler to emit code that crashes on purpose (e.g. with an illegal instruction) if the program encounters UB, e.g. as a way to help you find errors. (Or because it's a DeathStation 9000. Being strictly conforming is not sufficient for a C++ implementation to be useful for any real purpose). So ISO C++ would allow a compiler to make asm that crashed (for totally different reasons) even on similar code that read an uninitialized \n```\nuint32_t\n```\n. Even though that's required to be a fixed-layout type with no trap representations. (Note that C has different rules from C++; an uninitialized variable has an indeterminate value in C which might be a trap representation, but reading one at all is fully UB in C++. Not sure if there are extra rules for C11 \n```\n_Bool\n```"", ""```\n_Bool\n```\n which could allow the same crash behaviour as C++.) It's an interesting question about how real implementations work, but remember that even if the answer was different, your code would still be unsafe because modern C++ is not a portable version of assembly language. You're compiling for the x86-64 System V ABI, which specifies that a \n```\nbool\n```\n as a function arg in a register is represented by the bit-patterns \n```\nfalse=0\n```\n and \n```\ntrue=1\n```\n in the low 8 bits of the register1. In memory, \n```\nbool\n```"", ""is a 1-byte type that again must have an integer value of 0 or 1. (An ABI is a set of implementation choices that compilers for the same platform agree on so they can make code that calls each other's functions, including type sizes, struct layout rules, and calling conventions. In terms of the ISO C++ standard, an ABI-violating object-representation is called a trap representation, despite the CPU itself not directly trapping when running instructions on the bytes. Only leading to faults later due to violated software assumptions. In ISO C17, 6.2.6.1 #5 - Certain object representations need not represent a value of the object type. If the stored value of an object has such a representation and is read by an lvalue expression that does not have character type, the behavior is undefined ... and goes on to say it's called a trap representation. I don't know if the same language is present in ISO C++.) ISO C++ doesn't specify it, but this ABI decision is widespread because it makes"", ""... and goes on to say it's called a trap representation. I don't know if the same language is present in ISO C++.) ISO C++ doesn't specify it, but this ABI decision is widespread because it makes bool->int conversion cheap (just zero-extension). I'm not aware of any ABIs that don't let the compiler assume 0 or 1 for"", '```\nbool\n```\n, for any architecture (not just x86). It allows optimizations like \n```\n!mybool\n```\n with \n```\nxor eax,1\n```\n to flip the low bit: Any possible code that can flip a bit/integer/bool between 0 and 1 in single CPU instruction. Or compiling \n```\na&&b\n```\n to a bitwise AND for \n```\nbool\n```', '```\nxor eax,1\n```\n to flip the low bit: Any possible code that can flip a bit/integer/bool between 0 and 1 in single CPU instruction. Or compiling \n```\na&&b\n```\n to a bitwise AND for \n```\nbool\n```\n types. Some compilers do actually take advantage Boolean values as 8 bit in compilers. Are operations on them inefficient?. In general, the as-if rule allows allows the compiler to take advantage of things that are true on the target platform being compiled for, because the end result will be executable code that implements the same externally-visible behaviour as the C++ source. (With all the restrictions that Undefined Behaviour places on what is actually ""externally visible"": not with a debugger, but from another thread in a well-formed / legal C++ program.) The compiler is definitely allowed to take full advantage of an ABI guarantee in its code-gen, and make code like you found which optimizes \n```\nstrlen(whichString)\n```\n to \n```\n5U - boolValue\n```', ""```\nstrlen(whichString)\n```\n to \n```\n5U - boolValue\n```\n. (BTW, this optimization is kind of clever, but maybe shortsighted vs. branching and inlining \n```\nmemcpy\n```\nas stores of immediate data2.) Or the compiler could have created a table of pointers and indexed it with the integer value of the \n```\nbool\n```\n, again assuming it was a 0 or 1. (This possibility is what @Barmar's answer suggested.) Your \n```\n__attribute((noinline))\n```\n constructor with optimization enabled led to clang just loading a byte from the stack to use as \n```\nuninitializedBool\n```\n. It made space for the object in \n```\nmain\n```\n with \n```\npush rax\n```\n (which is smaller and for various reason about as efficient as \n```\nsub rsp, 8\n```\n), so whatever garbage was in AL on entry to \n```\nmain\n```\n is the value it used for \n```\nuninitializedBool\n```\n. This is why you actually got values that weren't just \n```\n0\n```\n. \n```\n5U - random garbage\n```"", ""```\nmain\n```\n is the value it used for \n```\nuninitializedBool\n```\n. This is why you actually got values that weren't just \n```\n0\n```\n. \n```\n5U - random garbage\n```\n can easily wrap to a large unsigned value, leading memcpy to go into unmapped memory. The destination is in static storage, not the stack, so you're not overwriting a return address or something. Other implementations could make different choices, e.g. \n```\nfalse=0\n```\n and \n```\ntrue=any non-zero value\n```\n. Then clang probably wouldn't make code that crashes for this specific instance of UB. (But it would still be allowed to if it wanted to.) I don't know of any implementations that choose anything other what x86-64 does for \n```\nbool\n```\n, but the C++ standard allows many things that nobody does or even would want to do on hardware that's anything like current CPUs. ISO C++ leaves it unspecified what you'll find when you examine or modify the object representation of a \n```\nbool\n```\n. (e.g. by \n```\nmemcpy\n```\ning the"", '```\nbool\n```\n. (e.g. by \n```\nmemcpy\n```\ning the \n```\nbool\n```\n into \n```\nunsigned char\n```\n, which you\'re allowed to do because \n```\nchar*\n```\n can alias anything. And \n```\nunsigned char\n```\n is guaranteed to have no padding bits, so the C++ standard does formally let you hexdump object representations without any UB. Pointer-casting to copy the object representation is different from assigning \n```\nchar foo = my_bool\n```\n, of course, so booleanization to 0 or 1 wouldn\'t happen and you\'d get the raw object representation.) You\'ve partially ""hidden"" the UB on this execution path from the compiler with \n```\nnoinline\n```\n. Even if it doesn\'t inline, though, interprocedural optimizations could still make a version of the function that depends on the definition of another function. (First, clang is making an executable, not a Unix shared library where symbol-interposition can happen. Second, the definition in inside the \n```\nclass{}\n```', ""```\nclass{}\n```\n definition so all translation units must have the same definition. Like with the \n```\ninline\n```\n keyword.) So a compiler could emit just a \n```\nret\n```\n or \n```\nud2\n```\n (illegal instruction) as the definition for \n```\nmain\n```\n, because the path of execution starting at the top of \n```\nmain\n```\n unavoidably encounters Undefined Behaviour. (Which the compiler can see at compile time if it decided to follow the path through the non-inline constructor.) Any program that encounters UB is totally undefined for its entire existence. But UB inside a function or \n```\nif()\n```\n branch that never actually runs doesn't corrupt the rest of the program. In practice that means that compilers can decide to emit an illegal instruction, or a \n```\nret\n```\n, or not emit anything and fall into the next block / function, for the whole basic block that can be proven at compile time to contain or lead to UB. GCC and Clang in practice do actually sometimes emit \n```\nud2\n```"", '```\nud2\n```\n on UB, instead of even trying to generate code for paths of execution that make no sense. Or for cases like falling off the end of a non-\n```\nvoid\n```\n function, gcc will sometimes omit a \n```\nret\n```\n instruction. If you were thinking that ""my function will just return with whatever garbage is in RAX"", you are sorely mistaken. Modern C++ compilers don\'t treat the language like a portable assembly language any more. Your program really has to be valid C++, without making assumptions about how a stand-alone non inlined version of your function might look in asm. Another fun example is Why does unaligned access to mmap\'ed memory sometimes segfault on AMD64?. x86 doesn\'t fault on unaligned integers, right? So why would a misaligned \n```\nuint16_t*\n```\n be a problem? Because \n```\nalignof(uint16_t) == 2\n```', '```\nuint16_t*\n```\n be a problem? Because \n```\nalignof(uint16_t) == 2\n```\n, and violating that assumption led to a segfault when auto-vectorizing with SSE2. See also What Every C Programmer Should Know About Undefined Behavior #1/3, an article by a clang developer. Key point: if the compiler noticed the UB at compile time, it could ""break"" (emit surprising asm) the path through your code that causes UB even if targeting an ABI where any bit-pattern is a valid object representation for \n```\nbool\n```\n. Expect total hostility toward many mistakes by the programmer, especially things modern compilers warn about. This is why you should use \n```\n-Wall\n```\n and fix warnings. C++ is not a user-friendly language, and something in C++ can be unsafe even if it would be safe in asm on the target you\'re compiling for. (e.g. signed overflow is UB in C++ and compilers will assume it doesn\'t happen, even when compiling for 2\'s complement x86, unless you use \n```\nclang/gcc -fwrapv\n```', ""```\nclang/gcc -fwrapv\n```\n.) Compile-time-visible UB is always dangerous, and it's really hard to be sure (with link-time optimization) that you've really hidden UB from the compiler and can thus reason about what kind of asm it will generate. Not to be over-dramatic; often compilers do let you get away with some things and emit code like you're expecting even when something is UB. But maybe it will be a problem in the future if compiler devs implement some optimization that gains more info about value-ranges (e.g. that a variable is non-negative, maybe allowing it to optimize sign-extension to free zero-extension on x86-64). For example, in current gcc and clang, doing \n```\ntmp = a+INT_MIN\n```\n doesn't optimize \n```\na<0\n```\n as always-false, only that \n```\ntmp\n```\n is always negative. (Because \n```\nINT_MIN\n```\n + \n```\na=INT_MAX\n```\n is negative on this 2's complement target, and \n```\na\n```"", 'doesn\'t optimize \n```\na<0\n```\n as always-false, only that \n```\ntmp\n```\n is always negative. (Because \n```\nINT_MIN\n```\n + \n```\na=INT_MAX\n```\n is negative on this 2\'s complement target, and \n```\na\n```\n can\'t be any higher than that.) So gcc/clang don\'t currently backtrack to derive range info for the inputs of a calculation, only on the results based on the assumption of no signed overflow: example on Godbolt. I don\'t know if this is optimization is intentionally ""missed"" in the name of user-friendliness or what. Also note that implementations (aka compilers) are allowed to define behaviour that ISO C++ leaves undefined. For example, all compilers that support Intel\'s intrinsics (like \n```\n_mm_add_ps(__m128, __m128)\n```\n for manual SIMD vectorization) must allow forming mis-aligned pointers, which is UB in C++ even if you don\'t dereference them. \n```\n__m128i _mm_loadu_si128(const __m128i *)\n```\n does unaligned loads by taking a misaligned \n```\n__m128i*\n```\n arg, not a \n```\nvoid*\n```', '```\n__m128i _mm_loadu_si128(const __m128i *)\n```\n does unaligned loads by taking a misaligned \n```\n__m128i*\n```\n arg, not a \n```\nvoid*\n```\n or \n```\nchar*\n```\n. Is `reinterpret_cast`ing between hardware SIMD vector pointer and the corresponding type an undefined behavior? GNU C/C++ also defines the behaviour of left-shifting a negative signed number (even without \n```\n-fwrapv\n```', ""), separately from the normal signed-overflow UB rules. (This is UB in ISO C++, while right shifts of signed numbers are implementation-defined (logical vs. arithmetic); good quality implementations choose arithmetic on HW that has arithmetic right shifts, but ISO C++ doesn't specify). This is documented in the GCC manual's Integer section, along with defining implementation-defined behaviour that C standards require implementations to define one way or another. There are definitely quality-of-implementation issues that compiler developers care about; they generally aren't trying to make compilers that are intentionally hostile, but taking advantage of all the UB potholes in C++ (except ones they choose to define) to optimize better can be nearly indistinguishable at times. Footnote 1: The upper 56 bits can be garbage which the callee must ignore, as usual for types narrower than a register. (Other ABIs do make different choices here. Some do require narrow integer types to be zero-"", 'upper 56 bits can be garbage which the callee must ignore, as usual for types narrower than a register. (Other ABIs do make different choices here. Some do require narrow integer types to be zero- or sign-extended to fill a register when passed to or returned from functions, like MIPS64 and PowerPC64. See the last section of this x86-64 answer which compares vs. those earlier ISAs.) For example, a caller might have calculated', '```\na & 0x01010101\n```\n in RDI and used it for something else, before calling \n```\nbool_func(a&1)\n```\n. The caller could optimize away the \n```\n&1\n```\n because it already did that to the low byte as part of \n```\nand edi, 0x01010101\n```\n, and it knows the callee is required to ignore the high bytes. Or if a bool is passed as the 3rd arg, maybe a caller optimizing for code-size loads it with \n```\nmov dl, [mem]\n```\n instead of \n```\nmovzx edx, [mem]\n```\n, saving 1 byte at the cost of a false dependency on the old value of RDX (or other partial-register effect, depending on CPU model). Or for the first arg, \n```\nmov dil, byte [r10]\n```\n instead of \n```\nmovzx edi, byte [r10]\n```\n, because both require a REX prefix anyway. This is why clang emits \n```\nmovzx   eax, dil\n```\n in \n```\nSerialize\n```\n, instead of \n```\nsub eax, edi\n```', ""```\n instead of \n```\nmovzx edi, byte [r10]\n```\n, because both require a REX prefix anyway. This is why clang emits \n```\nmovzx   eax, dil\n```\n in \n```\nSerialize\n```\n, instead of \n```\nsub eax, edi\n```\n. (For integer args, clang violates this ABI rule, instead depending on the undocumented behaviour of gcc and clang to zero- or sign-extend narrow integers to 32 bits. Is a sign or zero extension required when adding a 32bit offset to a pointer for the x86-64 ABI? So I was interested to see that it doesn't do the same thing for \n```\nbool\n```\n.) Footnote 2: After branching, you'd just have a 4-byte \n```\nmov\n```\n-immediate, or a 4-byte + 1-byte store. The length is implicit in the store widths + offsets. OTOH, glibc memcpy will do two 4-byte loads/stores with an overlap that depends on length, so this really does end up making the whole thing free of conditional branches on the boolean. See the \n```\nL(between_4_7):\n```"", ""```\nL(between_4_7):\n```\n block in glibc's memcpy/memmove. Or at least, go the same way for either boolean in memcpy's branching to select a chunk size. If inlining, you could use 2x \n```\nmov\n```\n-immediate + \n```\ncmov\n```\n and a conditional offset, or you could leave the string data in memory. Or if tuning for Intel Ice Lake (with the Fast Short REP MOV feature), an actual \n```\nrep movsb\n```\n might be optimal. glibc \n```\nmemcpy\n```\n might start using \n```\nrep movsb\n```\n for small sizes on CPUs with that feature, saving a lot of branching. Tools for detecting UB and usage of uninitialized values In gcc and clang, you can compile with \n```\n-fsanitize=undefined\n```"", 'for small sizes on CPUs with that feature, saving a lot of branching. Tools for detecting UB and usage of uninitialized values In gcc and clang, you can compile with \n```\n-fsanitize=undefined\n```\n to add run-time instrumentation that will warn or error out on UB that happens at runtime. That won\'t catch unitialized variables, though. (Because it doesn\'t increase type sizes to make room for an ""uninitialized"" bit). See https://developers.redhat.com/blog/2014/10/16/gcc-undefined-behavior-sanitizer-ubsan/ To find usage of uninitialized data, there\'s Address Sanitizer and Memory Sanitizer in clang/LLVM. https://github.com/google/sanitizers/wiki/MemorySanitizer shows examples of \n```\nclang -fsanitize=memory -fPIE -pie\n```\n detecting uninitialized memory reads. It might work best if you compile without optimization, so all reads of variables end up actually loading from memory in the asm. They show it being used at \n```\n-O2\n```', ""```\n-O2\n```\n in a case where the load wouldn't optimize away. I haven't tried it myself. (In some cases, e.g. not initializing an accumulator before summing an array, clang -O3 will emit code that sums into a vector register that it never initialized. So with optimization, you can have a case where there's no memory read associated with the UB. But \n```\n-fsanitize=memory\n```\n changes the generated asm, and might result in a check for this.) It will tolerate copying of uninitialized memory, and also simple logic and arithmetic operations with it. In general, MemorySanitizer silently tracks the spread of uninitialized data in memory, and reports a warning when a code branch is taken (or not taken) depending on an uninitialized value. MemorySanitizer implements a subset of functionality found in Valgrind (Memcheck tool). It should work for this case because the call to glibc \n```\nmemcpy\n```\n with a \n```\nlength\n```"", '```\nmemcpy\n```\n with a \n```\nlength\n```\n calculated from uninitialized memory will (inside the library) result in a branch based on \n```\nlength\n```\n. If it had inlined a fully branchless version that just used \n```\ncmov\n```\n, indexing, and two stores, it might not have worked. Valgrind\'s \n```\nmemcheck\n```\n will also look for this kind of problem, again not complaining if the program simply copies around uninitialized data. But it says it will detect when a ""Conditional jump or move depends on uninitialised value(s)"", to try to catch any externally-visible behaviour that depends on uninitialized data. Perhaps the idea behind not flagging just a load is that structs can have padding, and copying the whole struct (including padding) with a wide vector load/store is not an error even if the individual members were only written one at a time. At the asm level, the information about what was padding and what is actually part of the value has been lost.']","Yes, ISO C++ allows (but doesn't require) implementations to make this choice. But also note that ISO C++ allows a compiler to emit code that crashes on purpose (e.g. with an illegal instruction) if the program encounters UB, e.g. as a way to help you find errors. (Or because it's a DeathStation 9000. Being strictly conforming is not sufficient for a C++ implementation to be useful for any real purpose). So ISO C++ would allow a compiler to make asm that crashed (for totally different reasons) even on similar code that read an uninitialized 
```
uint32_t
```
. Even though that's required to be a fixed-layout type with no trap representations. (Note that C has different rules from C++; an uninitialized variable has an indeterminate value in C which might be a trap representation, but reading one at all is fully UB in C++. Not sure if there are extra rules for C11 
```
_Bool
```
 which could allow the same crash behaviour as C++.) It's an interesting question about how real implementations work, but remember that even if the answer was different, your code would still be unsafe because modern C++ is not a portable version of assembly language. You're compiling for the x86-64 System V ABI, which specifies that a 
```
bool
```
 as a function arg in a register is represented by the bit-patterns 
```
false=0
```
 and 
```
true=1
```
 in the low 8 bits of the register1. In memory, 
```
bool
```
 is a 1-byte type that again must have an integer value of 0 or 1. (An ABI is a set of implementation choices that compilers for the same platform agree on so they can make code that calls each other's functions, including type sizes, struct layout rules, and calling conventions. In terms of the ISO C++ standard, an ABI-violating object-representation is called a trap representation, despite the CPU itself not directly trapping when running instructions on the bytes. Only leading to faults later due to violated software assumptions. In ISO C17, 6.2.6.1 #5 - Certain object representations need not represent a value of the object type. If the stored value of an object has such a representation and is read by an lvalue expression that does not have character type, the behavior is undefined ... and goes on to say it's called a trap representation. I don't know if the same language is present in ISO C++.) ISO C++ doesn't specify it, but this ABI decision is widespread because it makes bool->int conversion cheap (just zero-extension). I'm not aware of any ABIs that don't let the compiler assume 0 or 1 for 
```
bool
```
, for any architecture (not just x86). It allows optimizations like 
```
!mybool
```
 with 
```
xor eax,1
```
 to flip the low bit: Any possible code that can flip a bit/integer/bool between 0 and 1 in single CPU instruction. Or compiling 
```
a&&b
```
 to a bitwise AND for 
```
bool
```
 types. Some compilers do actually take advantage Boolean values as 8 bit in compilers. Are operations on them inefficient?. In general, the as-if rule allows allows the compiler to take advantage of things that are true on the target platform being compiled for, because the end result will be executable code that implements the same externally-visible behaviour as the C++ source. (With all the restrictions that Undefined Behaviour places on what is actually ""externally visible"": not with a debugger, but from another thread in a well-formed / legal C++ program.) The compiler is definitely allowed to take full advantage of an ABI guarantee in its code-gen, and make code like you found which optimizes 
```
strlen(whichString)
```
 to 
```
5U - boolValue
```
. (BTW, this optimization is kind of clever, but maybe shortsighted vs. branching and inlining 
```
memcpy
```
as stores of immediate data2.) Or the compiler could have created a table of pointers and indexed it with the integer value of the 
```
bool
```
, again assuming it was a 0 or 1. (This possibility is what @Barmar's answer suggested.) Your 
```
__attribute((noinline))
```
 constructor with optimization enabled led to clang just loading a byte from the stack to use as 
```
uninitializedBool
```
. It made space for the object in 
```
main
```
 with 
```
push rax
```
 (which is smaller and for various reason about as efficient as 
```
sub rsp, 8
```
), so whatever garbage was in AL on entry to 
```
main
```
 is the value it used for 
```
uninitializedBool
```
. This is why you actually got values that weren't just 
```
0
```
. 
```
5U - random garbage
```
 can easily wrap to a large unsigned value, leading memcpy to go into unmapped memory. The destination is in static storage, not the stack, so you're not overwriting a return address or something. Other implementations could make different choices, e.g. 
```
false=0
```
 and 
```
true=any non-zero value
```
. Then clang probably wouldn't make code that crashes for this specific instance of UB. (But it would still be allowed to if it wanted to.) I don't know of any implementations that choose anything other what x86-64 does for 
```
bool
```
, but the C++ standard allows many things that nobody does or even would want to do on hardware that's anything like current CPUs. ISO C++ leaves it unspecified what you'll find when you examine or modify the object representation of a 
```
bool
```
. (e.g. by 
```
memcpy
```
ing the 
```
bool
```
 into 
```
unsigned char
```
, which you're allowed to do because 
```
char*
```
 can alias anything. And 
```
unsigned char
```
 is guaranteed to have no padding bits, so the C++ standard does formally let you hexdump object representations without any UB. Pointer-casting to copy the object representation is different from assigning 
```
char foo = my_bool
```
, of course, so booleanization to 0 or 1 wouldn't happen and you'd get the raw object representation.) You've partially ""hidden"" the UB on this execution path from the compiler with 
```
noinline
```
. Even if it doesn't inline, though, interprocedural optimizations could still make a version of the function that depends on the definition of another function. (First, clang is making an executable, not a Unix shared library where symbol-interposition can happen. Second, the definition in inside the 
```
class{}
```
 definition so all translation units must have the same definition. Like with the 
```
inline
```
 keyword.) So a compiler could emit just a 
```
ret
```
 or 
```
ud2
```
 (illegal instruction) as the definition for 
```
main
```
, because the path of execution starting at the top of 
```
main
```
 unavoidably encounters Undefined Behaviour. (Which the compiler can see at compile time if it decided to follow the path through the non-inline constructor.) Any program that encounters UB is totally undefined for its entire existence. But UB inside a function or 
```
if()
```
 branch that never actually runs doesn't corrupt the rest of the program. In practice that means that compilers can decide to emit an illegal instruction, or a 
```
ret
```
, or not emit anything and fall into the next block / function, for the whole basic block that can be proven at compile time to contain or lead to UB. GCC and Clang in practice do actually sometimes emit 
```
ud2
```
 on UB, instead of even trying to generate code for paths of execution that make no sense. Or for cases like falling off the end of a non-
```
void
```
 function, gcc will sometimes omit a 
```
ret
```
 instruction. If you were thinking that ""my function will just return with whatever garbage is in RAX"", you are sorely mistaken. Modern C++ compilers don't treat the language like a portable assembly language any more. Your program really has to be valid C++, without making assumptions about how a stand-alone non inlined version of your function might look in asm. Another fun example is Why does unaligned access to mmap'ed memory sometimes segfault on AMD64?. x86 doesn't fault on unaligned integers, right? So why would a misaligned 
```
uint16_t*
```
 be a problem? Because 
```
alignof(uint16_t) == 2
```
, and violating that assumption led to a segfault when auto-vectorizing with SSE2. See also What Every C Programmer Should Know About Undefined Behavior #1/3, an article by a clang developer. Key point: if the compiler noticed the UB at compile time, it could ""break"" (emit surprising asm) the path through your code that causes UB even if targeting an ABI where any bit-pattern is a valid object representation for 
```
bool
```
. Expect total hostility toward many mistakes by the programmer, especially things modern compilers warn about. This is why you should use 
```
-Wall
```
 and fix warnings. C++ is not a user-friendly language, and something in C++ can be unsafe even if it would be safe in asm on the target you're compiling for. (e.g. signed overflow is UB in C++ and compilers will assume it doesn't happen, even when compiling for 2's complement x86, unless you use 
```
clang/gcc -fwrapv
```
.) Compile-time-visible UB is always dangerous, and it's really hard to be sure (with link-time optimization) that you've really hidden UB from the compiler and can thus reason about what kind of asm it will generate. Not to be over-dramatic; often compilers do let you get away with some things and emit code like you're expecting even when something is UB. But maybe it will be a problem in the future if compiler devs implement some optimization that gains more info about value-ranges (e.g. that a variable is non-negative, maybe allowing it to optimize sign-extension to free zero-extension on x86-64). For example, in current gcc and clang, doing 
```
tmp = a+INT_MIN
```
 doesn't optimize 
```
a<0
```
 as always-false, only that 
```
tmp
```
 is always negative. (Because 
```
INT_MIN
```
 + 
```
a=INT_MAX
```
 is negative on this 2's complement target, and 
```
a
```
 can't be any higher than that.) So gcc/clang don't currently backtrack to derive range info for the inputs of a calculation, only on the results based on the assumption of no signed overflow: example on Godbolt. I don't know if this is optimization is intentionally ""missed"" in the name of user-friendliness or what. Also note that implementations (aka compilers) are allowed to define behaviour that ISO C++ leaves undefined. For example, all compilers that support Intel's intrinsics (like 
```
_mm_add_ps(__m128, __m128)
```
 for manual SIMD vectorization) must allow forming mis-aligned pointers, which is UB in C++ even if you don't dereference them. 
```
__m128i _mm_loadu_si128(const __m128i *)
```
 does unaligned loads by taking a misaligned 
```
__m128i*
```
 arg, not a 
```
void*
```
 or 
```
char*
```
. Is `reinterpret_cast`ing between hardware SIMD vector pointer and the corresponding type an undefined behavior? GNU C/C++ also defines the behaviour of left-shifting a negative signed number (even without 
```
-fwrapv
```
), separately from the normal signed-overflow UB rules. (This is UB in ISO C++, while right shifts of signed numbers are implementation-defined (logical vs. arithmetic); good quality implementations choose arithmetic on HW that has arithmetic right shifts, but ISO C++ doesn't specify). This is documented in the GCC manual's Integer section, along with defining implementation-defined behaviour that C standards require implementations to define one way or another. There are definitely quality-of-implementation issues that compiler developers care about; they generally aren't trying to make compilers that are intentionally hostile, but taking advantage of all the UB potholes in C++ (except ones they choose to define) to optimize better can be nearly indistinguishable at times. Footnote 1: The upper 56 bits can be garbage which the callee must ignore, as usual for types narrower than a register. (Other ABIs do make different choices here. Some do require narrow integer types to be zero- or sign-extended to fill a register when passed to or returned from functions, like MIPS64 and PowerPC64. See the last section of this x86-64 answer which compares vs. those earlier ISAs.) For example, a caller might have calculated 
```
a & 0x01010101
```
 in RDI and used it for something else, before calling 
```
bool_func(a&1)
```
. The caller could optimize away the 
```
&1
```
 because it already did that to the low byte as part of 
```
and edi, 0x01010101
```
, and it knows the callee is required to ignore the high bytes. Or if a bool is passed as the 3rd arg, maybe a caller optimizing for code-size loads it with 
```
mov dl, [mem]
```
 instead of 
```
movzx edx, [mem]
```
, saving 1 byte at the cost of a false dependency on the old value of RDX (or other partial-register effect, depending on CPU model). Or for the first arg, 
```
mov dil, byte [r10]
```
 instead of 
```
movzx edi, byte [r10]
```
, because both require a REX prefix anyway. This is why clang emits 
```
movzx   eax, dil
```
 in 
```
Serialize
```
, instead of 
```
sub eax, edi
```
. (For integer args, clang violates this ABI rule, instead depending on the undocumented behaviour of gcc and clang to zero- or sign-extend narrow integers to 32 bits. Is a sign or zero extension required when adding a 32bit offset to a pointer for the x86-64 ABI? So I was interested to see that it doesn't do the same thing for 
```
bool
```
.) Footnote 2: After branching, you'd just have a 4-byte 
```
mov
```
-immediate, or a 4-byte + 1-byte store. The length is implicit in the store widths + offsets. OTOH, glibc memcpy will do two 4-byte loads/stores with an overlap that depends on length, so this really does end up making the whole thing free of conditional branches on the boolean. See the 
```
L(between_4_7):
```
 block in glibc's memcpy/memmove. Or at least, go the same way for either boolean in memcpy's branching to select a chunk size. If inlining, you could use 2x 
```
mov
```
-immediate + 
```
cmov
```
 and a conditional offset, or you could leave the string data in memory. Or if tuning for Intel Ice Lake (with the Fast Short REP MOV feature), an actual 
```
rep movsb
```
 might be optimal. glibc 
```
memcpy
```
 might start using 
```
rep movsb
```
 for small sizes on CPUs with that feature, saving a lot of branching. Tools for detecting UB and usage of uninitialized values In gcc and clang, you can compile with 
```
-fsanitize=undefined
```
 to add run-time instrumentation that will warn or error out on UB that happens at runtime. That won't catch unitialized variables, though. (Because it doesn't increase type sizes to make room for an ""uninitialized"" bit). See https://developers.redhat.com/blog/2014/10/16/gcc-undefined-behavior-sanitizer-ubsan/ To find usage of uninitialized data, there's Address Sanitizer and Memory Sanitizer in clang/LLVM. https://github.com/google/sanitizers/wiki/MemorySanitizer shows examples of 
```
clang -fsanitize=memory -fPIE -pie
```
 detecting uninitialized memory reads. It might work best if you compile without optimization, so all reads of variables end up actually loading from memory in the asm. They show it being used at 
```
-O2
```
 in a case where the load wouldn't optimize away. I haven't tried it myself. (In some cases, e.g. not initializing an accumulator before summing an array, clang -O3 will emit code that sums into a vector register that it never initialized. So with optimization, you can have a case where there's no memory read associated with the UB. But 
```
-fsanitize=memory
```
 changes the generated asm, and might result in a check for this.) It will tolerate copying of uninitialized memory, and also simple logic and arithmetic operations with it. In general, MemorySanitizer silently tracks the spread of uninitialized data in memory, and reports a warning when a code branch is taken (or not taken) depending on an uninitialized value. MemorySanitizer implements a subset of functionality found in Valgrind (Memcheck tool). It should work for this case because the call to glibc 
```
memcpy
```
 with a 
```
length
```
 calculated from uninitialized memory will (inside the library) result in a branch based on 
```
length
```
. If it had inlined a fully branchless version that just used 
```
cmov
```
, indexing, and two stores, it might not have worked. Valgrind's 
```
memcheck
```
 will also look for this kind of problem, again not complaining if the program simply copies around uninitialized data. But it says it will detect when a ""Conditional jump or move depends on uninitialised value(s)"", to try to catch any externally-visible behaviour that depends on uninitialized data. Perhaps the idea behind not flagging just a load is that structs can have padding, and copying the whole struct (including padding) with a wide vector load/store is not an error even if the individual members were only written one at a time. At the asm level, the information about what was padding and what is actually part of the value has been lost."
4295432,Typedef function pointer?,https://stackoverflow.com/questions/4295432/typedef-function-pointer,6,598.0,"['```\ntypedef\n```\n is a language construct that associates a name to a type. You use it the same way you would use the original type, for instance \n```\ntypedef int myinteger;\ntypedef char *mystring;\ntypedef void (*myfunc)();\n\n```\n using them like \n```\nmyinteger i;   // is equivalent to    int i;\nmystring s;    // is the same as      char *s;\nmyfunc f;      // compile equally as  void (*f)();', '```\n As you can see, you could just replace the typedefed name with its definition given above. The difficulty lies in the pointer to functions syntax and readability in C and C++, and the \n```\ntypedef\n```\n can improve the readability of such declarations. However, the syntax is appropriate, since functions - unlike other simpler types - may have a return value and parameters, thus the sometimes lengthy and complex declaration of a pointer to function. The readability may start to be really tricky with pointers to functions arrays, and some other even more indirect flavors. To answer your three questions Why is typedef used? To ease the reading of the code - especially for pointers to functions, or structure names. The syntax looks odd (in the pointer to function declaration) That syntax is not obvious to read, at least when beginning. Using a \n```\ntypedef\n```', '```\ntypedef\n```\n declaration instead eases the reading Is a function pointer created to store the memory address of a function? Yes, a function pointer stores the address of a function. This has nothing to do with the \n```\ntypedef\n```\n construct which only ease the writing/reading of a program ; the compiler just expands the typedef definition before compiling the actual code. Example: \n```\ntypedef int (*t_somefunc)(int,int);', 'int product(int u, int v) {\n  return u*v;\n}\n\nt_somefunc afunc = &product;\n...\nint x2 = (*afunc)(123, 456); // call product() to calculate 123*456\n\n```']","
```
typedef
```
 is a language construct that associates a name to a type. You use it the same way you would use the original type, for instance 
```
typedef int myinteger;
typedef char *mystring;
typedef void (*myfunc)();

```
 using them like 
```
myinteger i;   // is equivalent to    int i;
mystring s;    // is the same as      char *s;
myfunc f;      // compile equally as  void (*f)();

```
 As you can see, you could just replace the typedefed name with its definition given above. The difficulty lies in the pointer to functions syntax and readability in C and C++, and the 
```
typedef
```
 can improve the readability of such declarations. However, the syntax is appropriate, since functions - unlike other simpler types - may have a return value and parameters, thus the sometimes lengthy and complex declaration of a pointer to function. The readability may start to be really tricky with pointers to functions arrays, and some other even more indirect flavors. To answer your three questions Why is typedef used? To ease the reading of the code - especially for pointers to functions, or structure names. The syntax looks odd (in the pointer to function declaration) That syntax is not obvious to read, at least when beginning. Using a 
```
typedef
```
 declaration instead eases the reading Is a function pointer created to store the memory address of a function? Yes, a function pointer stores the address of a function. This has nothing to do with the 
```
typedef
```
 construct which only ease the writing/reading of a program ; the compiler just expands the typedef definition before compiling the actual code. Example: 
```
typedef int (*t_somefunc)(int,int);

int product(int u, int v) {
  return u*v;
}

t_somefunc afunc = &product;
...
int x2 = (*afunc)(123, 456); // call product() to calculate 123*456

```
"
10422034,When to use extern in C++,https://stackoverflow.com/questions/10422034/when-to-use-extern-in-c,4,756.0,"[""This comes in useful when you have global variables. You declare the existence of global variables in a header, so that each source file that includes the header knows about it, but you only need to “define” it once in one of your source files. To clarify, using \n```\nextern int x;\n```\n tells the compiler that an object of type \n```\nint\n```\n called \n```\nx\n```\n exists somewhere. It's not the compilers job to know where it exists, it just needs to know the type and name so it knows how to use it. Once all of the source files have been compiled, the linker will resolve all of the references of \n```\nx\n```\n to the one definition that it finds in one of the compiled source files. For it to work, the definition of the \n```\nx\n```\n variable needs to have what's called “external linkage”, which basically means that it needs to be declared outside of a function (at what's usually called “the file scope”) and without the \n```\nstatic\n```\n keyword. header: \n```\n#ifndef HEADER_H\n#define HEADER_H"", '// any source file that includes this will be able to use ""global_x""\nextern int global_x;\n\nvoid print_global_x();\n\n#endif\n\n```\n source 1: \n```\n#include ""header.h""\n\n// since global_x still needs to be defined somewhere,\n// we define it (for example) in this source file\nint global_x;\n\nint main()\n{\n    //set global_x here:\n    global_x = 5;\n\n    print_global_x();\n}\n\n```\n source 2: \n```\n#include <iostream>\n#include ""header.h""\n\nvoid print_global_x()\n{\n    //print global_x here:\n    std::cout << global_x << std::endl;\n}\n\n```']","This comes in useful when you have global variables. You declare the existence of global variables in a header, so that each source file that includes the header knows about it, but you only need to “define” it once in one of your source files. To clarify, using 
```
extern int x;
```
 tells the compiler that an object of type 
```
int
```
 called 
```
x
```
 exists somewhere. It's not the compilers job to know where it exists, it just needs to know the type and name so it knows how to use it. Once all of the source files have been compiled, the linker will resolve all of the references of 
```
x
```
 to the one definition that it finds in one of the compiled source files. For it to work, the definition of the 
```
x
```
 variable needs to have what's called “external linkage”, which basically means that it needs to be declared outside of a function (at what's usually called “the file scope”) and without the 
```
static
```
 keyword. header: 
```
#ifndef HEADER_H
#define HEADER_H

// any source file that includes this will be able to use ""global_x""
extern int global_x;

void print_global_x();

#endif

```
 source 1: 
```
#include ""header.h""

// since global_x still needs to be defined somewhere,
// we define it (for example) in this source file
int global_x;

int main()
{
    //set global_x here:
    global_x = 5;

    print_global_x();
}

```
 source 2: 
```
#include <iostream>
#include ""header.h""

void print_global_x()
{
    //print global_x here:
    std::cout << global_x << std::endl;
}

```
"
3065154,Undefined reference to vtable,https://stackoverflow.com/questions/3065154/undefined-reference-to-vtable,21,73.0,"[""So, I've figured out the issue and it was a combination of bad logic and not being totally familiar with the automake/autotools world. I was adding the correct files to my Makefile.am template, but I wasn't sure which step in our build process actually created the makefile itself. So, I was compiling with an old makefile that had no idea about my new files whatsoever. Thanks for the responses and the link to the GCC FAQ. I will be sure to read that to avoid this problem occurring for a real reason.""]","So, I've figured out the issue and it was a combination of bad logic and not being totally familiar with the automake/autotools world. I was adding the correct files to my Makefile.am template, but I wasn't sure which step in our build process actually created the makefile itself. So, I was compiling with an old makefile that had no idea about my new files whatsoever. Thanks for the responses and the link to the GCC FAQ. I will be sure to read that to avoid this problem occurring for a real reason."
28828957,How to convert an enum to a string in modern C++,https://stackoverflow.com/questions/28828957/how-to-convert-an-enum-to-a-string-in-modern-c,35,132.0,"['Magic Enum header-only library provides static reflection for enums (to string, from string, iteration) for C++17. (Disclosure: I\'m the author of the library.) \n```\n#include <magic_enum.hpp>\n\nenum Color { RED = 2, BLUE = 4, GREEN = 8 };\n\nColor color = Color::RED;\nauto color_name = magic_enum::enum_name(color);\n// color_name -> ""RED""\n\nstd::string color_name{""GREEN""};\nauto color = magic_enum::enum_cast<Color>(color_name)\nif (color.has_value()) {\n  // color.value() -> Color::GREEN\n};', '```\n For more examples check home repository https://github.com/Neargye/magic_enum. Where is the drawback? This library uses a compiler-specific hack (based on \n```\n__PRETTY_FUNCTION__\n```\n / \n```\n__FUNCSIG__\n```\n), which works on Clang >= 5, MSVC >= 15.3 and GCC >= 9. Enum value must be in range \n```\n[MAGIC_ENUM_RANGE_MIN, MAGIC_ENUM_RANGE_MAX]\n```\n. By default \n```\nMAGIC_ENUM_RANGE_MIN = -128\n```\n, \n```\nMAGIC_ENUM_RANGE_MAX = 128\n```\n. If need another range for all enum types by default, redefine the macro \n```\nMAGIC_ENUM_RANGE_MIN\n```\n and \n```\nMAGIC_ENUM_RANGE_MAX\n```\n. \n```\nMAGIC_ENUM_RANGE_MIN\n```\n must be less or equals than \n```\n0\n```\n and must be greater than \n```\nINT16_MIN\n```\n. \n```\nMAGIC_ENUM_RANGE_MAX\n```\n must be greater than \n```\n0\n```\n and must be less than \n```\nINT16_MAX\n```\n. If need another range for specific enum type, add specialization enum_range for necessary enum type. \n```\n#include <magic_enum.hpp>\n\nenum number { one = 100, two = 200, three = 300 };', 'enum number { one = 100, two = 200, three = 300 };\n\nnamespace magic_enum {\ntemplate <>\n  struct enum_range<number> {\n    static constexpr int min = 100;\n    static constexpr int max = 300;\n};\n}\n\n```']","Magic Enum header-only library provides static reflection for enums (to string, from string, iteration) for C++17. (Disclosure: I'm the author of the library.) 
```
#include <magic_enum.hpp>

enum Color { RED = 2, BLUE = 4, GREEN = 8 };

Color color = Color::RED;
auto color_name = magic_enum::enum_name(color);
// color_name -> ""RED""

std::string color_name{""GREEN""};
auto color = magic_enum::enum_cast<Color>(color_name)
if (color.has_value()) {
  // color.value() -> Color::GREEN
};

```
 For more examples check home repository https://github.com/Neargye/magic_enum. Where is the drawback? This library uses a compiler-specific hack (based on 
```
__PRETTY_FUNCTION__
```
 / 
```
__FUNCSIG__
```
), which works on Clang >= 5, MSVC >= 15.3 and GCC >= 9. Enum value must be in range 
```
[MAGIC_ENUM_RANGE_MIN, MAGIC_ENUM_RANGE_MAX]
```
. By default 
```
MAGIC_ENUM_RANGE_MIN = -128
```
, 
```
MAGIC_ENUM_RANGE_MAX = 128
```
. If need another range for all enum types by default, redefine the macro 
```
MAGIC_ENUM_RANGE_MIN
```
 and 
```
MAGIC_ENUM_RANGE_MAX
```
. 
```
MAGIC_ENUM_RANGE_MIN
```
 must be less or equals than 
```
0
```
 and must be greater than 
```
INT16_MIN
```
. 
```
MAGIC_ENUM_RANGE_MAX
```
 must be greater than 
```
0
```
 and must be less than 
```
INT16_MAX
```
. If need another range for specific enum type, add specialization enum_range for necessary enum type. 
```
#include <magic_enum.hpp>

enum number { one = 100, two = 200, three = 300 };

namespace magic_enum {
template <>
  struct enum_range<number> {
    static constexpr int min = 100;
    static constexpr int max = 300;
};
}

```
"
877523,error: request for member '..' in '..' which is of non-class type,https://stackoverflow.com/questions/877523/error-request-for-member-in-which-is-of-non-class-type,10,847.0,"['```\nFoo foo2();\n\n```\n change to \n```\nFoo foo2;\n\n```\n You get the error because compiler thinks of \n```\nFoo foo2()\n\n```\n as of function declaration with name \'foo2\' and the return type \'Foo\'. But in that case If we change to \n```\nFoo foo2\n```\n , the compiler might show the error \n```\n"" call of overloaded ‘Foo()’ is ambiguous""\n```\n.']","
```
Foo foo2();

```
 change to 
```
Foo foo2;

```
 You get the error because compiler thinks of 
```
Foo foo2()

```
 as of function declaration with name 'foo2' and the return type 'Foo'. But in that case If we change to 
```
Foo foo2
```
 , the compiler might show the error 
```
"" call of overloaded ‘Foo()’ is ambiguous""
```
."
150355,Programmatically find the number of cores on a machine,https://stackoverflow.com/questions/150355/programmatically-find-the-number-of-cores-on-a-machine,21,861.0,"[""C++11 \n```\n#include <thread>\n\n//may return 0 when not able to detect\nconst auto processor_count = std::thread::hardware_concurrency();\n\n```\n Reference: std::thread::hardware_concurrency In C++ prior to C++11, there's no portable way. Instead, you'll need to use one or more of the following methods (guarded by appropriate \n```\n#ifdef\n```\n lines): Win32 \n```\nSYSTEM_INFO sysinfo;\nGetSystemInfo(&sysinfo);\nint numCPU = sysinfo.dwNumberOfProcessors;\n\n```\n Linux, Solaris, AIX and Mac OS X >=10.4 (i.e. Tiger onwards) \n```\nint numCPU = sysconf(_SC_NPROCESSORS_ONLN);\n\n```\n FreeBSD, MacOS X, NetBSD, OpenBSD, etc. \n```\nint mib[4];\nint numCPU;\nstd::size_t len = sizeof(numCPU); \n\n/* set the mib for hw.ncpu */\nmib[0] = CTL_HW;\nmib[1] = HW_AVAILCPU;  // alternatively, try HW_NCPU;\n\n/* get the number of CPUs from the system */\nsysctl(mib, 2, &numCPU, &len, NULL, 0);\n\nif (numCPU < 1) \n{\n    mib[1] = HW_NCPU;\n    sysctl(mib, 2, &numCPU, &len, NULL, 0);\n    if (numCPU < 1)\n        numCPU = 1;\n}"", 'if (numCPU < 1) \n{\n    mib[1] = HW_NCPU;\n    sysctl(mib, 2, &numCPU, &len, NULL, 0);\n    if (numCPU < 1)\n        numCPU = 1;\n}\n\n```\n HPUX \n```\nint numCPU = mpctl(MPC_GETNUMSPUS, NULL, NULL);\n\n```\n IRIX \n```\nint numCPU = sysconf(_SC_NPROC_ONLN);\n\n```\n Objective-C (Mac OS X >=10.5 or iOS) \n```\nNSUInteger a = [[NSProcessInfo processInfo] processorCount];\nNSUInteger b = [[NSProcessInfo processInfo] activeProcessorCount];\n\n```']","C++11 
```
#include <thread>

//may return 0 when not able to detect
const auto processor_count = std::thread::hardware_concurrency();

```
 Reference: std::thread::hardware_concurrency In C++ prior to C++11, there's no portable way. Instead, you'll need to use one or more of the following methods (guarded by appropriate 
```
#ifdef
```
 lines): Win32 
```
SYSTEM_INFO sysinfo;
GetSystemInfo(&sysinfo);
int numCPU = sysinfo.dwNumberOfProcessors;

```
 Linux, Solaris, AIX and Mac OS X >=10.4 (i.e. Tiger onwards) 
```
int numCPU = sysconf(_SC_NPROCESSORS_ONLN);

```
 FreeBSD, MacOS X, NetBSD, OpenBSD, etc. 
```
int mib[4];
int numCPU;
std::size_t len = sizeof(numCPU); 

/* set the mib for hw.ncpu */
mib[0] = CTL_HW;
mib[1] = HW_AVAILCPU;  // alternatively, try HW_NCPU;

/* get the number of CPUs from the system */
sysctl(mib, 2, &numCPU, &len, NULL, 0);

if (numCPU < 1) 
{
    mib[1] = HW_NCPU;
    sysctl(mib, 2, &numCPU, &len, NULL, 0);
    if (numCPU < 1)
        numCPU = 1;
}

```
 HPUX 
```
int numCPU = mpctl(MPC_GETNUMSPUS, NULL, NULL);

```
 IRIX 
```
int numCPU = sysconf(_SC_NPROC_ONLN);

```
 Objective-C (Mac OS X >=10.5 or iOS) 
```
NSUInteger a = [[NSProcessInfo processInfo] processorCount];
NSUInteger b = [[NSProcessInfo processInfo] activeProcessorCount];

```
"
75191,What is an unsigned char?,https://stackoverflow.com/questions/75191/what-is-an-unsigned-char,16,620.0,"['In C++, there are three distinct character types: \n```\nchar\n```\n \n```\nsigned char\n```\n \n```\nunsigned char\n```\n 1. \n```\nchar\n```\n If you are using character types for text, use the unqualified \n```\nchar\n```\n: it is the type of character literals like \n```\n\'a\'\n```\n or \n```\n\'0\'\n```\n (in C++ only, in C their type is \n```\nint\n```\n) it is the type that makes up C strings like \n```\n""abcde""\n```\n It also works out as a number value, but it is unspecified whether that value is treated as signed or unsigned. Beware character comparisons through inequalities - although if you limit yourself to ASCII (0-127) you\'re just about safe. 2. \n```\nsigned char\n```\n/ 3. \n```\nunsigned char\n```\n If you are using character types as numbers, use: \n```\nsigned char\n```\n, which gives you at least the -127 to 127 range. (-128 to 127 is common) \n```\nunsigned char\n```', '/ 3. \n```\nunsigned char\n```\n If you are using character types as numbers, use: \n```\nsigned char\n```\n, which gives you at least the -127 to 127 range. (-128 to 127 is common) \n```\nunsigned char\n```\n, which gives you at least the 0 to 255 range. This might be useful for displaying an octet e.g. as hex value. ""At least"", because the C++ standard only gives the minimum range of values that each numeric type is required to cover. \n```\nsizeof (char)\n```\n is required to be 1 (i.e. one byte), but a byte could in theory be for example 32 bits. \n```\nsizeof\n```\n would still be report its size as \n```\n1\n```\n - meaning that you could have \n```\nsizeof (char) == sizeof (long) == 1\n```\n.']","In C++, there are three distinct character types: 
```
char
```
 
```
signed char
```
 
```
unsigned char
```
 1. 
```
char
```
 If you are using character types for text, use the unqualified 
```
char
```
: it is the type of character literals like 
```
'a'
```
 or 
```
'0'
```
 (in C++ only, in C their type is 
```
int
```
) it is the type that makes up C strings like 
```
""abcde""
```
 It also works out as a number value, but it is unspecified whether that value is treated as signed or unsigned. Beware character comparisons through inequalities - although if you limit yourself to ASCII (0-127) you're just about safe. 2. 
```
signed char
```
/ 3. 
```
unsigned char
```
 If you are using character types as numbers, use: 
```
signed char
```
, which gives you at least the -127 to 127 range. (-128 to 127 is common) 
```
unsigned char
```
, which gives you at least the 0 to 255 range. This might be useful for displaying an octet e.g. as hex value. ""At least"", because the C++ standard only gives the minimum range of values that each numeric type is required to cover. 
```
sizeof (char)
```
 is required to be 1 (i.e. one byte), but a byte could in theory be for example 32 bits. 
```
sizeof
```
 would still be report its size as 
```
1
```
 - meaning that you could have 
```
sizeof (char) == sizeof (long) == 1
```
."
333889,Why have header files and .cpp files?,https://stackoverflow.com/questions/333889/why-have-header-files-and-cpp-files,9,225.0,"['Well, the main reason would be for separating the interface from the implementation. The header declares ""what"" a class (or whatever is being implemented) will do, while the cpp file defines ""how"" it will perform those features. This reduces dependencies so that code that uses the header doesn\'t necessarily need to know all the details of the implementation and any other classes/headers needed only for that. This will reduce compilation times and also the amount of recompilation needed when something in the implementation changes. It\'s not perfect, and you would usually resort to techniques like the Pimpl Idiom to properly separate interface and implementation, but it\'s a good start.']","Well, the main reason would be for separating the interface from the implementation. The header declares ""what"" a class (or whatever is being implemented) will do, while the cpp file defines ""how"" it will perform those features. This reduces dependencies so that code that uses the header doesn't necessarily need to know all the details of the implementation and any other classes/headers needed only for that. This will reduce compilation times and also the amount of recompilation needed when something in the implementation changes. It's not perfect, and you would usually resort to techniques like the Pimpl Idiom to properly separate interface and implementation, but it's a good start."
2196995,Is there any advantage of using map over unordered_map in case of trivial keys?,https://stackoverflow.com/questions/2196995/is-there-any-advantage-of-using-map-over-unordered-map-in-case-of-trivial-keys,15,557.0,"[""Don't forget that \n```\nmap\n```\n keeps its elements ordered. If you can't give that up, obviously you can't use \n```\nunordered_map\n```\n. Something else to keep in mind is that \n```\nunordered_map\n```\n generally uses more memory. \n```\nmap\n```\n just has a few house-keeping pointers, and memory for each object. Contrarily, \n```\nunordered_map\n```\n has a big array (these can get quite big in some implementations), and then additional memory for each object. If you need to be memory-aware, \n```\nmap\n```\n should prove better, because it lacks the large array. So, if you need pure lookup-retrieval, I'd say \n```\nunordered_map\n```\n is the way to go. But there are always trade-offs, and if you can't afford them, then you can't use it. Just from personal experience, I found an enormous improvement in performance (measured, of course) when using \n```\nunordered_map\n```\n instead of \n```\nmap\n```"", ""```\nunordered_map\n```\n instead of \n```\nmap\n```\n in a main entity look-up table. On the other hand, I found it was much slower at repeatedly inserting and removing elements. It's great for a relatively static collection of elements, but if you're doing tons of insertions and deletions the hashing + bucketing seems to add up. (Note, this was over many iterations.)""]","Don't forget that 
```
map
```
 keeps its elements ordered. If you can't give that up, obviously you can't use 
```
unordered_map
```
. Something else to keep in mind is that 
```
unordered_map
```
 generally uses more memory. 
```
map
```
 just has a few house-keeping pointers, and memory for each object. Contrarily, 
```
unordered_map
```
 has a big array (these can get quite big in some implementations), and then additional memory for each object. If you need to be memory-aware, 
```
map
```
 should prove better, because it lacks the large array. So, if you need pure lookup-retrieval, I'd say 
```
unordered_map
```
 is the way to go. But there are always trade-offs, and if you can't afford them, then you can't use it. Just from personal experience, I found an enormous improvement in performance (measured, of course) when using 
```
unordered_map
```
 instead of 
```
map
```
 in a main entity look-up table. On the other hand, I found it was much slower at repeatedly inserting and removing elements. It's great for a relatively static collection of elements, but if you're doing tons of insertions and deletions the hashing + bucketing seems to add up. (Note, this was over many iterations.)"
161053,Which is faster: Stack allocation or Heap allocation,https://stackoverflow.com/questions/161053/which-is-faster-stack-allocation-or-heap-allocation,24,546.0,"['Stack allocation is much faster since all it really does is move the stack pointer. Using memory pools, you can get comparable performance out of heap allocation, but that comes with a slight added complexity and its own headaches. Also, stack vs. heap is not only a performance consideration; it also tells you a lot about the expected lifetime of objects.']","Stack allocation is much faster since all it really does is move the stack pointer. Using memory pools, you can get comparable performance out of heap allocation, but that comes with a slight added complexity and its own headaches. Also, stack vs. heap is not only a performance consideration; it also tells you a lot about the expected lifetime of objects."
12953127,What are copy elision and return value optimization?,https://stackoverflow.com/questions/12953127/what-are-copy-elision-and-return-value-optimization,5,382.0,"['Introduction For a technical overview - skip to this answer. For common cases where copy elision occurs - skip to this answer. Copy elision is an optimization implemented by most compilers to prevent extra (potentially expensive) copies in certain situations. It makes returning by value or pass-by-value feasible in practice (restrictions apply). It\'s the only form of optimization that elides (ha!) the as-if rule - copy elision can be applied even if copying/moving the object has side-effects. The following example taken from Wikipedia: \n```\nstruct C {\n  C() {}\n  C(const C&) { std::cout << ""A copy was made.\\n""; }\n};\n \nC f() {\n  return C();\n}\n \nint main() {\n  std::cout << ""Hello World!\\n"";\n  C obj = f();\n}', '```\n Depending on the compiler & settings, the following outputs are all valid: Hello World! A copy was made. A copy was made. Hello World! A copy was made. Hello World! This also means fewer objects can be created, so you also can\'t rely on a specific number of destructors being called. You shouldn\'t have critical logic inside copy/move-constructors or destructors, as you can\'t rely on them being called. If a call to a copy or move constructor is elided, that constructor must still exist and must be accessible. This ensures that copy elision does not allow copying objects which are not normally copyable, e.g. because they have a private or deleted copy/move constructor. C++17: As of C++17, Copy Elision is guaranteed when an object is returned directly, and in this case, the copy or move constructor need not be accessible or present: \n```\nstruct C {\n  C() {}\n  C(const C&) { std::cout << ""A copy was made.\\n""; }\n};\n \nC f() {\n  return C(); //Definitely performs copy elision\n}\nC g() {', '```\nstruct C {\n  C() {}\n  C(const C&) { std::cout << ""A copy was made.\\n""; }\n};\n \nC f() {\n  return C(); //Definitely performs copy elision\n}\nC g() {\n    C c;\n    return c; //Maybe performs copy elision\n}\n \nint main() {\n  std::cout << ""Hello World!\\n"";\n  C obj = f(); //Copy constructor isn\'t called\n}', '```']","Introduction For a technical overview - skip to this answer. For common cases where copy elision occurs - skip to this answer. Copy elision is an optimization implemented by most compilers to prevent extra (potentially expensive) copies in certain situations. It makes returning by value or pass-by-value feasible in practice (restrictions apply). It's the only form of optimization that elides (ha!) the as-if rule - copy elision can be applied even if copying/moving the object has side-effects. The following example taken from Wikipedia: 
```
struct C {
  C() {}
  C(const C&) { std::cout << ""A copy was made.\n""; }
};
 
C f() {
  return C();
}
 
int main() {
  std::cout << ""Hello World!\n"";
  C obj = f();
}

```
 Depending on the compiler & settings, the following outputs are all valid: Hello World! A copy was made. A copy was made. Hello World! A copy was made. Hello World! This also means fewer objects can be created, so you also can't rely on a specific number of destructors being called. You shouldn't have critical logic inside copy/move-constructors or destructors, as you can't rely on them being called. If a call to a copy or move constructor is elided, that constructor must still exist and must be accessible. This ensures that copy elision does not allow copying objects which are not normally copyable, e.g. because they have a private or deleted copy/move constructor. C++17: As of C++17, Copy Elision is guaranteed when an object is returned directly, and in this case, the copy or move constructor need not be accessible or present: 
```
struct C {
  C() {}
  C(const C&) { std::cout << ""A copy was made.\n""; }
};
 
C f() {
  return C(); //Definitely performs copy elision
}
C g() {
    C c;
    return c; //Maybe performs copy elision
}
 
int main() {
  std::cout << ""Hello World!\n"";
  C obj = f(); //Copy constructor isn't called
}

```
"
138600,"Initializing a static std::map<int, int> in C++",https://stackoverflow.com/questions/138600/initializing-a-static-stdmapint-int-in-c,12,,[],
25789644,What is the difference between using a Makefile and CMake to compile the code?,https://stackoverflow.com/questions/25789644/what-is-the-difference-between-using-a-makefile-and-cmake-to-compile-the-code,3,737.0,"[""Make (or rather a Makefile) is a buildsystem - it drives the compiler and other build tools to build your code. CMake is a generator of buildsystems. It can produce Makefiles, it can produce Ninja build files, it can produce KDEvelop or Xcode projects, it can produce Visual Studio solutions. From the same starting point, the same CMakeLists.txt file. So if you have a platform-independent project, CMake is a way to make it buildsystem-independent as well. If you have Windows developers used to Visual Studio and Unix developers who swear by GNU Make, CMake is (one of) the way(s) to go. I would always recommend using CMake (or another buildsystem generator, but CMake is my personal preference) if you intend your project to be multi-platform or widely usable. CMake itself also provides some nice features like dependency detection, library interface management, or integration with CTest, CDash and CPack. Using a buildsystem generator makes your project more future-proof. Even if you're"", ""nice features like dependency detection, library interface management, or integration with CTest, CDash and CPack. Using a buildsystem generator makes your project more future-proof. Even if you're GNU-Make-only now, what if you later decide to expand to other platforms (be it Windows or something embedded), or just want to use an IDE?""]","Make (or rather a Makefile) is a buildsystem - it drives the compiler and other build tools to build your code. CMake is a generator of buildsystems. It can produce Makefiles, it can produce Ninja build files, it can produce KDEvelop or Xcode projects, it can produce Visual Studio solutions. From the same starting point, the same CMakeLists.txt file. So if you have a platform-independent project, CMake is a way to make it buildsystem-independent as well. If you have Windows developers used to Visual Studio and Unix developers who swear by GNU Make, CMake is (one of) the way(s) to go. I would always recommend using CMake (or another buildsystem generator, but CMake is my personal preference) if you intend your project to be multi-platform or widely usable. CMake itself also provides some nice features like dependency detection, library interface management, or integration with CTest, CDash and CPack. Using a buildsystem generator makes your project more future-proof. Even if you're GNU-Make-only now, what if you later decide to expand to other platforms (be it Windows or something embedded), or just want to use an IDE?"
2152986,What are the benefits of std::distance over subtracting iterators?,https://stackoverflow.com/questions/2152986/what-are-the-benefits-of-stddistance-over-subtracting-iterators,9,707.0,"[""I would prefer \n```\nit - vec.begin()\n```\n precisely for the opposite reason given by Naveen: so it wouldn't compile if you change the vector into a list. If you do this during every iteration, you could easily end up turning an O(n) algorithm into an O(n^2) algorithm. Another option, if you don't jump around in the container during iteration, would be to keep the index as a second loop counter. Note: \n```\nit\n```\n is a common name for a container iterator,\n```\nstd::container_type::iterator it;\n```\n.""]","I would prefer 
```
it - vec.begin()
```
 precisely for the opposite reason given by Naveen: so it wouldn't compile if you change the vector into a list. If you do this during every iteration, you could easily end up turning an O(n) algorithm into an O(n^2) algorithm. Another option, if you don't jump around in the container during iteration, would be to keep the index as a second loop counter. Note: 
```
it
```
 is a common name for a container iterator,
```
std::container_type::iterator it;
```
."
2386772,What is the difference between float and double?,https://stackoverflow.com/questions/2386772/what-is-the-difference-between-float-and-double,14,644.0,"['Huge difference. As the name implies, a \n```\ndouble\n```\n has 2x the precision of \n```\nfloat\n```\n[1]. In general a \n```\ndouble\n```\n has 15 decimal digits of precision, while \n```\nfloat\n```\n has 7. Here\'s how the number of digits are calculated: \n```\ndouble\n```\n has 52 mantissa bits + 1 hidden bit: log(253)÷log(10) = 15.95 digits \n```\nfloat\n```\n has 23 mantissa bits + 1 hidden bit: log(224)÷log(10) = 7.22 digits This precision loss could lead to greater truncation errors being accumulated when repeated calculations are done, e.g. \n```\nfloat a = 1.f / 81;\nfloat b = 0;\nfor (int i = 0; i < 729; ++ i)\n    b += a;\nprintf(""%.7g\\n"", b); // prints 9.000023\n\n```\n while \n```\ndouble a = 1.0 / 81;\ndouble b = 0;\nfor (int i = 0; i < 729; ++ i)\n    b += a;\nprintf(""%.15g\\n"", b); // prints 8.99999999999996', '```\n Also, the maximum value of float is about \n```\n3e38\n```\n, but double is about \n```\n1.7e308\n```\n, so using \n```\nfloat\n```\n can hit ""infinity"" (i.e. a special floating-point number) much more easily than \n```\ndouble\n```\n for something simple, e.g. computing the factorial of 60. During testing, maybe a few test cases contain these huge numbers, which may cause your programs to fail if you use floats. Of course, sometimes, even \n```\ndouble\n```\n isn\'t accurate enough, hence we sometimes have \n```\nlong double\n```\n[1] (the above example gives 9.000000000000000066 on Mac), but all floating point types suffer from round-off errors, so if precision is very important (e.g. money processing) you should use \n```\nint\n```\n or a fraction class. Furthermore, don\'t use \n```\n+=\n```\n to sum lots of floating point numbers, as the errors accumulate quickly. If you\'re using Python, use \n```\nfsum\n```', ""```\nint\n```\n or a fraction class. Furthermore, don't use \n```\n+=\n```\n to sum lots of floating point numbers, as the errors accumulate quickly. If you're using Python, use \n```\nfsum\n```\n. Otherwise, try to implement the Kahan summation algorithm. [1]: The C and C++ standards do not specify the representation of \n```\nfloat\n```\n, \n```\ndouble\n```\n and \n```\nlong double\n```\n. It is possible that all three are implemented as IEEE double-precision. Nevertheless, for most architectures (gcc, MSVC; x86, x64, ARM) \n```\nfloat\n```\n is indeed a IEEE single-precision floating point number (binary32), and \n```\ndouble\n```\n is a IEEE double-precision floating point number (binary64).""]","Huge difference. As the name implies, a 
```
double
```
 has 2x the precision of 
```
float
```
[1]. In general a 
```
double
```
 has 15 decimal digits of precision, while 
```
float
```
 has 7. Here's how the number of digits are calculated: 
```
double
```
 has 52 mantissa bits + 1 hidden bit: log(253)÷log(10) = 15.95 digits 
```
float
```
 has 23 mantissa bits + 1 hidden bit: log(224)÷log(10) = 7.22 digits This precision loss could lead to greater truncation errors being accumulated when repeated calculations are done, e.g. 
```
float a = 1.f / 81;
float b = 0;
for (int i = 0; i < 729; ++ i)
    b += a;
printf(""%.7g\n"", b); // prints 9.000023

```
 while 
```
double a = 1.0 / 81;
double b = 0;
for (int i = 0; i < 729; ++ i)
    b += a;
printf(""%.15g\n"", b); // prints 8.99999999999996

```
 Also, the maximum value of float is about 
```
3e38
```
, but double is about 
```
1.7e308
```
, so using 
```
float
```
 can hit ""infinity"" (i.e. a special floating-point number) much more easily than 
```
double
```
 for something simple, e.g. computing the factorial of 60. During testing, maybe a few test cases contain these huge numbers, which may cause your programs to fail if you use floats. Of course, sometimes, even 
```
double
```
 isn't accurate enough, hence we sometimes have 
```
long double
```
[1] (the above example gives 9.000000000000000066 on Mac), but all floating point types suffer from round-off errors, so if precision is very important (e.g. money processing) you should use 
```
int
```
 or a fraction class. Furthermore, don't use 
```
+=
```
 to sum lots of floating point numbers, as the errors accumulate quickly. If you're using Python, use 
```
fsum
```
. Otherwise, try to implement the Kahan summation algorithm. [1]: The C and C++ standards do not specify the representation of 
```
float
```
, 
```
double
```
 and 
```
long double
```
. It is possible that all three are implemented as IEEE double-precision. Nevertheless, for most architectures (gcc, MSVC; x86, x64, ARM) 
```
float
```
 is indeed a IEEE single-precision floating point number (binary32), and 
```
double
```
 is a IEEE double-precision floating point number (binary64)."
137038,How do you get assembler output from C/C++ source in GCC?,https://stackoverflow.com/questions/137038/how-do-you-get-assembler-output-from-c-c-source-in-gcc,17,599.0,"['Use the -S option to \n```\ngcc\n```\n (or \n```\ng++\n```\n), optionally with -fverbose-asm which works well at the default -O0 to attach C names to asm operands as comments. It works less well at any optimization level, which you normally want to use to get asm worth looking at. \n```\ngcc -S helloworld.c\n\n```\n This will run the preprocessor (cpp) over helloworld.c, perform the initial compilation and then stop before the assembler is run. For useful compiler options to use in that case, see How to remove ""noise"" from GCC/clang assembly output? (or just look at your code on Matt Godbolt\'s online Compiler Explorer which filters out directives and stuff, and has highlighting to match up source lines with asm using debug information.) By default, this will output the file \n```\nhelloworld.s\n```\n. The output file can be still be set by using the -o option, including \n```\n-o -\n```\n to write to standard output for pipe into less. \n```\ngcc -S -o my_asm_output.s helloworld.c', '```\n Of course, this only works if you have the original source. An alternative if you only have the resultant object file is to use objdump, by setting the \n```\n--disassemble\n```\n option (or \n```\n-d\n```\n for the abbreviated form). \n```\nobjdump -S --disassemble helloworld > helloworld.dump', ""```\n \n```\n-S\n```\n interleaves source lines with normal disassembly output, so this option works best if debugging option is enabled for the object file (-g at compilation time) and the file hasn't been stripped. Running \n```\nfile helloworld\n```\n will give you some indication as to the level of detail that you will get by using objdump. Other useful \n```\nobjdump\n```\n options include \n```\n-rwC\n```\n (to show symbol relocations, disable line-wrapping of long machine code, and demangle C++ names). And if you don't like AT&T syntax for x86, \n```\n-Mintel\n```\n. See the man page. So for example, \n```\nobjdump -drwC -Mintel -S foo.o | less\n```\n. \n```\n-r\n```\n is very important with a \n```\n.o\n```\n that only has \n```\n00 00 00 00\n```\n placeholders for symbol references, as opposed to a linked executable.""]","Use the -S option to 
```
gcc
```
 (or 
```
g++
```
), optionally with -fverbose-asm which works well at the default -O0 to attach C names to asm operands as comments. It works less well at any optimization level, which you normally want to use to get asm worth looking at. 
```
gcc -S helloworld.c

```
 This will run the preprocessor (cpp) over helloworld.c, perform the initial compilation and then stop before the assembler is run. For useful compiler options to use in that case, see How to remove ""noise"" from GCC/clang assembly output? (or just look at your code on Matt Godbolt's online Compiler Explorer which filters out directives and stuff, and has highlighting to match up source lines with asm using debug information.) By default, this will output the file 
```
helloworld.s
```
. The output file can be still be set by using the -o option, including 
```
-o -
```
 to write to standard output for pipe into less. 
```
gcc -S -o my_asm_output.s helloworld.c

```
 Of course, this only works if you have the original source. An alternative if you only have the resultant object file is to use objdump, by setting the 
```
--disassemble
```
 option (or 
```
-d
```
 for the abbreviated form). 
```
objdump -S --disassemble helloworld > helloworld.dump

```
 
```
-S
```
 interleaves source lines with normal disassembly output, so this option works best if debugging option is enabled for the object file (-g at compilation time) and the file hasn't been stripped. Running 
```
file helloworld
```
 will give you some indication as to the level of detail that you will get by using objdump. Other useful 
```
objdump
```
 options include 
```
-rwC
```
 (to show symbol relocations, disable line-wrapping of long machine code, and demangle C++ names). And if you don't like AT&T syntax for x86, 
```
-Mintel
```
. See the man page. So for example, 
```
objdump -drwC -Mintel -S foo.o | less
```
. 
```
-r
```
 is very important with a 
```
.o
```
 that only has 
```
00 00 00 00
```
 placeholders for symbol references, as opposed to a linked executable."
117293,Does using const on function parameters have any effect? Why does it not affect the function signature?,https://stackoverflow.com/questions/117293/does-using-const-on-function-parameters-have-any-effect-why-does-it-not-affect,31,243.0,"[""The reason is that \n```\nconst\n```\n for the parameter only applies locally within the function, since it is working on a copy of the data. This means the function signature is really the same anyways. It's probably bad style to do this a lot though. I personally tend to not use \n```\nconst\n```\n except for reference and pointer parameters. For copied objects it doesn't really matter, although it can be safer as it signals intent within the function. It's really a judgement call. I do tend to use \n```\nconst_iterator\n```\n though when looping on something and I don't intend on modifying it, so I guess to each his own, as long as \n```\nconst\n```\n correctness for reference types is rigorously maintained.""]","The reason is that 
```
const
```
 for the parameter only applies locally within the function, since it is working on a copy of the data. This means the function signature is really the same anyways. It's probably bad style to do this a lot though. I personally tend to not use 
```
const
```
 except for reference and pointer parameters. For copied objects it doesn't really matter, although it can be safer as it signals intent within the function. It's really a judgement call. I do tend to use 
```
const_iterator
```
 though when looping on something and I don't intend on modifying it, so I guess to each his own, as long as 
```
const
```
 correctness for reference types is rigorously maintained."
20516773,std::unique_lock<std::mutex> or std::lock_guard<std::mutex>?,https://stackoverflow.com/questions/20516773/stdunique-lockstdmutex-or-stdlock-guardstdmutex,7,519.0,"['The difference is that you can lock and unlock a \n```\nstd::unique_lock\n```\n. \n```\nstd::lock_guard\n```\n will be locked only once on construction and unlocked on destruction. So for use case B you definitely need a \n```\nstd::unique_lock\n```\n for the condition variable. In case A it depends whether you need to relock the guard. \n```\nstd::unique_lock\n```\n has other features that allow it to e.g.: be constructed without locking the mutex immediately but to build the RAII wrapper (see here). \n```\nstd::lock_guard\n```\n also provides a convenient RAII wrapper, but cannot lock multiple mutexes safely. It can be used when you need a wrapper for a limited scope, e.g.: a member function: \n```\nclass MyClass{\n    std::mutex my_mutex;\n    void member_foo() {\n        std::lock_guard<mutex_type> lock(this->my_mutex);            \n        /*\n         block of code which needs mutual exclusion (e.g. open the same \n         file in multiple threads).\n        */', '//mutex is automatically released when lock goes out of scope\n    }           \n};\n\n```\n To clarify a question by chmike, by default \n```\nstd::lock_guard\n```\n and \n```\nstd::unique_lock\n```\n are the same. So in the above case, you could replace \n```\nstd::lock_guard\n```\n with \n```\nstd::unique_lock\n```\n. However, \n```\nstd::unique_lock\n```\n might have a tad more overhead. Note that these days (since, C++17) one should use \n```\nstd::scoped_lock\n```\n instead of \n```\nstd::lock_guard\n```\n.']","The difference is that you can lock and unlock a 
```
std::unique_lock
```
. 
```
std::lock_guard
```
 will be locked only once on construction and unlocked on destruction. So for use case B you definitely need a 
```
std::unique_lock
```
 for the condition variable. In case A it depends whether you need to relock the guard. 
```
std::unique_lock
```
 has other features that allow it to e.g.: be constructed without locking the mutex immediately but to build the RAII wrapper (see here). 
```
std::lock_guard
```
 also provides a convenient RAII wrapper, but cannot lock multiple mutexes safely. It can be used when you need a wrapper for a limited scope, e.g.: a member function: 
```
class MyClass{
    std::mutex my_mutex;
    void member_foo() {
        std::lock_guard<mutex_type> lock(this->my_mutex);            
        /*
         block of code which needs mutual exclusion (e.g. open the same 
         file in multiple threads).
        */

        //mutex is automatically released when lock goes out of scope
    }           
};

```
 To clarify a question by chmike, by default 
```
std::lock_guard
```
 and 
```
std::unique_lock
```
 are the same. So in the above case, you could replace 
```
std::lock_guard
```
 with 
```
std::unique_lock
```
. However, 
```
std::unique_lock
```
 might have a tad more overhead. Note that these days (since, C++17) one should use 
```
std::scoped_lock
```
 instead of 
```
std::lock_guard
```
."
1563897,How can you define a static data member of type const std::string?,https://stackoverflow.com/questions/1563897/how-can-you-define-a-static-data-member-of-type-const-stdstring,11,604.0,"['Since C++17, you can use an inline variable: \n```\n// In a header file (if it is in a header file in your case)\nclass A {   \nprivate:      \n  inline static const string RECTANGLE = ""rectangle"";\n};\n\n```\n Prior to C++17, you have to define your static member outside the class definition and provide the initializer there. \n```\n// In a header file (if it is in a header file in your case)\nclass A {   \nprivate:      \n  static const string RECTANGLE;\n};\n\n```\n \n```\n// In one of the implementation files\nconst string A::RECTANGLE = ""rectangle"";\n\n```\n The syntax you were originally trying to use (initializer inside class definition) is only allowed with integral and enum types.']","Since C++17, you can use an inline variable: 
```
// In a header file (if it is in a header file in your case)
class A {   
private:      
  inline static const string RECTANGLE = ""rectangle"";
};

```
 Prior to C++17, you have to define your static member outside the class definition and provide the initializer there. 
```
// In a header file (if it is in a header file in your case)
class A {   
private:      
  static const string RECTANGLE;
};

```
 
```
// In one of the implementation files
const string A::RECTANGLE = ""rectangle"";

```
 The syntax you were originally trying to use (initializer inside class definition) is only allowed with integral and enum types."
4437527,Why do we use the volatile keyword?,https://stackoverflow.com/questions/4437527/why-do-we-use-the-volatile-keyword,2,1525.0,"['Consider this code, \n```\nint some_int = 100;\n\nwhile(some_int == 100)\n{\n   //your code\n}', ""```\n When this program gets compiled, the compiler may optimize this code, if it finds that the program never ever makes any attempt to change the value of \n```\nsome_int\n```\n, so it may be tempted to optimize the \n```\nwhile\n```\n loop by changing it from \n```\nwhile(some_int == 100)\n```\n to something which is equivalent to \n```\nwhile(true)\n```\n so that the execution could be fast (since the condition in \n```\nwhile\n```\n loop appears to be \n```\ntrue\n```\n always). (if the compiler doesn't optimize it, then it has to fetch the value of \n```\nsome_int\n```\n and compare it with 100, in each iteration which obviously is a little bit slow.) However, sometimes, optimization (of some parts of your program) may be undesirable, because it may be that someone else is changing the value of \n```\nsome_int\n```"", ""```\nsome_int\n```\n from outside the program which compiler is not aware of, since it can't see it; but it's how you've designed it. In that case, compiler's optimization would not produce the desired result! So, to ensure the desired result, you need to somehow stop the compiler from optimizing the \n```\nwhile\n```\n loop. That is where the \n```\nvolatile\n```\n keyword plays its role. All you need to do is this, \n```\nvolatile int some_int = 100; //note the 'volatile' qualifier now!"", '```\n In other words, I would explain this as follows: \n```\nvolatile\n```\n tells the compiler that, ""Hey compiler, I\'m volatile and, you know, I can be changed by some XYZ that you\'re not even aware of. That XYZ could be anything. Maybe some alien outside this planet called program. Maybe some lightning, some form of interrupt, volcanoes, etc can mutate me. Maybe. You never know who is going to change me! So O you ignorant, stop playing an all-knowing god, and don\'t dare touch the code where I\'m present. Okay?"" Well, that is how \n```\nvolatile\n```\n prevents the compiler from optimizing code. Now search the web to see some sample examples. Quoting from the C++ Standard ($7.1.5.1/8) [..] volatile is a hint to the implementation to avoid aggressive optimization involving the object because the value of the object might be changed by means undetectable by an implementation.[...] Related topic: Does making a struct volatile make all its members volatile?']","Consider this code, 
```
int some_int = 100;

while(some_int == 100)
{
   //your code
}

```
 When this program gets compiled, the compiler may optimize this code, if it finds that the program never ever makes any attempt to change the value of 
```
some_int
```
, so it may be tempted to optimize the 
```
while
```
 loop by changing it from 
```
while(some_int == 100)
```
 to something which is equivalent to 
```
while(true)
```
 so that the execution could be fast (since the condition in 
```
while
```
 loop appears to be 
```
true
```
 always). (if the compiler doesn't optimize it, then it has to fetch the value of 
```
some_int
```
 and compare it with 100, in each iteration which obviously is a little bit slow.) However, sometimes, optimization (of some parts of your program) may be undesirable, because it may be that someone else is changing the value of 
```
some_int
```
 from outside the program which compiler is not aware of, since it can't see it; but it's how you've designed it. In that case, compiler's optimization would not produce the desired result! So, to ensure the desired result, you need to somehow stop the compiler from optimizing the 
```
while
```
 loop. That is where the 
```
volatile
```
 keyword plays its role. All you need to do is this, 
```
volatile int some_int = 100; //note the 'volatile' qualifier now!

```
 In other words, I would explain this as follows: 
```
volatile
```
 tells the compiler that, ""Hey compiler, I'm volatile and, you know, I can be changed by some XYZ that you're not even aware of. That XYZ could be anything. Maybe some alien outside this planet called program. Maybe some lightning, some form of interrupt, volcanoes, etc can mutate me. Maybe. You never know who is going to change me! So O you ignorant, stop playing an all-knowing god, and don't dare touch the code where I'm present. Okay?"" Well, that is how 
```
volatile
```
 prevents the compiler from optimizing code. Now search the web to see some sample examples. Quoting from the C++ Standard ($7.1.5.1/8) [..] volatile is a hint to the implementation to avoid aggressive optimization involving the object because the value of the object might be changed by means undetectable by an implementation.[...] Related topic: Does making a struct volatile make all its members volatile?"
4269034,"What is the meaning of prepended double colon ""::""?",https://stackoverflow.com/questions/4269034/what-is-the-meaning-of-prepended-double-colon,9,633.0,"[""This ensures that resolution occurs from the global namespace, instead of starting at the namespace you're currently in. For instance, if you had two different classes called \n```\nConfiguration\n```\n as such: \n```\nclass Configuration; // class 1, in global namespace\nnamespace MyApp\n{\n    class Configuration; // class 2, different from class 1\n    function blah()\n    {\n        // resolves to MyApp::Configuration, class 2\n        Configuration::doStuff(...) \n        // resolves to top-level Configuration, class 1\n        ::Configuration::doStuff(...)\n    }\n}\n\n```\n Basically, it allows you to traverse up to the global namespace since your name might get clobbered by a new definition inside another namespace, in this case \n```\nMyApp\n```\n.""]","This ensures that resolution occurs from the global namespace, instead of starting at the namespace you're currently in. For instance, if you had two different classes called 
```
Configuration
```
 as such: 
```
class Configuration; // class 1, in global namespace
namespace MyApp
{
    class Configuration; // class 2, different from class 1
    function blah()
    {
        // resolves to MyApp::Configuration, class 2
        Configuration::doStuff(...) 
        // resolves to top-level Configuration, class 1
        ::Configuration::doStuff(...)
    }
}

```
 Basically, it allows you to traverse up to the global namespace since your name might get clobbered by a new definition inside another namespace, in this case 
```
MyApp
```
."
6264249,How does the compilation/linking process work?,https://stackoverflow.com/questions/6264249/how-does-the-compilation-linking-process-work,5,709.0,"['The compilation of a C++ program involves three steps: Preprocessing: the preprocessor takes a C++ source code file and deals with the \n```\n#include\n```\ns, \n```\n#define\n```\ns and other preprocessor directives. The output of this step is a ""pure"" C++ file without pre-processor directives. Compilation: the compiler takes the pre-processor\'s output and produces an object file from it. Linking: the linker takes the object files produced by the compiler and produces either a library or an executable file. Preprocessing The preprocessor handles the preprocessor directives, like \n```\n#include\n```\n and \n```\n#define\n```\n. It is agnostic of the syntax of C++, which is why it must be used with care. It works on one C++ source file at a time by replacing \n```\n#include\n```\n directives with the content of the respective files (which is usually just declarations), doing replacement of macros (\n```\n#define\n```\n), and selecting different portions of text depending of \n```\n#if\n```\n, \n```\n#ifdef\n```', '```\n#define\n```\n), and selecting different portions of text depending of \n```\n#if\n```\n, \n```\n#ifdef\n```\n and \n```\n#ifndef\n```\n directives. The preprocessor works on a stream of preprocessing tokens. Macro substitution is defined as replacing tokens with other tokens (the operator \n```\n##\n```\n enables merging two tokens when it makes sense). After all this, the preprocessor produces a single output that is a stream of tokens resulting from the transformations described above. It also adds some special markers that tell the compiler where each line came from so that it can use those to produce sensible error messages. Some errors can be produced at this stage with clever use of the \n```\n#if\n```\n and \n```\n#error\n```', ""directives. Compilation The compilation step is performed on each output of the preprocessor. The compiler parses the pure C++ source code (now without any preprocessor directives) and converts it into assembly code. Then invokes underlying back-end(assembler in toolchain) that assembles that code into machine code producing actual binary file in some format(ELF, COFF, a.out, ...). This object file contains the compiled code (in binary form) of the symbols defined in the input. Symbols in object files are referred to by name. Object files can refer to symbols that are not defined. This is the case when you use a declaration, and don't provide a definition for it. The compiler doesn't mind this, and will happily produce the object file as long as the source code is well-formed. Compilers usually let you stop compilation at this point. This is very useful because with it you can compile each source code file separately. The advantage this provides is that you don't need to recompile"", 'usually let you stop compilation at this point. This is very useful because with it you can compile each source code file separately. The advantage this provides is that you don\'t need to recompile everything if you only change a single file. The produced object files can be put in special archives called static libraries, for easier reusing later on. It\'s at this stage that ""regular"" compiler errors, like syntax errors or failed overload resolution errors, are reported. Linking The linker is what produces the final compilation output from the object files the compiler produced. This output can be either a shared (or dynamic) library (and while the name is similar, they haven\'t got much in common with static libraries mentioned earlier) or an executable. It links all the object files by replacing the references to undefined symbols with the correct addresses. Each of these symbols can be defined in other object files or in libraries. If they are defined in libraries other than the', ""replacing the references to undefined symbols with the correct addresses. Each of these symbols can be defined in other object files or in libraries. If they are defined in libraries other than the standard library, you need to tell the linker about them. At this stage the most common errors are missing definitions or duplicate definitions. The former means that either the definitions don't exist (i.e. they are not written), or that the object files or libraries where they reside were not given to the linker. The latter is obvious: the same symbol was defined in two different object files or libraries.""]","The compilation of a C++ program involves three steps: Preprocessing: the preprocessor takes a C++ source code file and deals with the 
```
#include
```
s, 
```
#define
```
s and other preprocessor directives. The output of this step is a ""pure"" C++ file without pre-processor directives. Compilation: the compiler takes the pre-processor's output and produces an object file from it. Linking: the linker takes the object files produced by the compiler and produces either a library or an executable file. Preprocessing The preprocessor handles the preprocessor directives, like 
```
#include
```
 and 
```
#define
```
. It is agnostic of the syntax of C++, which is why it must be used with care. It works on one C++ source file at a time by replacing 
```
#include
```
 directives with the content of the respective files (which is usually just declarations), doing replacement of macros (
```
#define
```
), and selecting different portions of text depending of 
```
#if
```
, 
```
#ifdef
```
 and 
```
#ifndef
```
 directives. The preprocessor works on a stream of preprocessing tokens. Macro substitution is defined as replacing tokens with other tokens (the operator 
```
##
```
 enables merging two tokens when it makes sense). After all this, the preprocessor produces a single output that is a stream of tokens resulting from the transformations described above. It also adds some special markers that tell the compiler where each line came from so that it can use those to produce sensible error messages. Some errors can be produced at this stage with clever use of the 
```
#if
```
 and 
```
#error
```
 directives. Compilation The compilation step is performed on each output of the preprocessor. The compiler parses the pure C++ source code (now without any preprocessor directives) and converts it into assembly code. Then invokes underlying back-end(assembler in toolchain) that assembles that code into machine code producing actual binary file in some format(ELF, COFF, a.out, ...). This object file contains the compiled code (in binary form) of the symbols defined in the input. Symbols in object files are referred to by name. Object files can refer to symbols that are not defined. This is the case when you use a declaration, and don't provide a definition for it. The compiler doesn't mind this, and will happily produce the object file as long as the source code is well-formed. Compilers usually let you stop compilation at this point. This is very useful because with it you can compile each source code file separately. The advantage this provides is that you don't need to recompile everything if you only change a single file. The produced object files can be put in special archives called static libraries, for easier reusing later on. It's at this stage that ""regular"" compiler errors, like syntax errors or failed overload resolution errors, are reported. Linking The linker is what produces the final compilation output from the object files the compiler produced. This output can be either a shared (or dynamic) library (and while the name is similar, they haven't got much in common with static libraries mentioned earlier) or an executable. It links all the object files by replacing the references to undefined symbols with the correct addresses. Each of these symbols can be defined in other object files or in libraries. If they are defined in libraries other than the standard library, you need to tell the linker about them. At this stage the most common errors are missing definitions or duplicate definitions. The former means that either the definitions don't exist (i.e. they are not written), or that the object files or libraries where they reside were not given to the linker. The latter is obvious: the same symbol was defined in two different object files or libraries."
1903954,"Is there a standard sign function (signum, sgn) in C/C++?",https://stackoverflow.com/questions/1903954/is-there-a-standard-sign-function-signum-sgn-in-c-c,21,639.0,"['The type-safe C++ version: \n```\ntemplate <typename T> int sgn(T val) {\n    return (T(0) < val) - (val < T(0));\n}', '```\n Benefits: Actually implements signum (-1, 0, or 1). Implementations here using copysign only return -1 or 1, which is not signum. Also, some implementations here are returning a float (or T) rather than an int, which seems wasteful. Works for ints, floats, doubles, unsigned shorts, or any custom types constructible from integer 0 and orderable. Fast! \n```\ncopysign\n```', ""```\ncopysign\n```\n is slow, especially if you need to promote and then narrow again. This is branchless and optimizes excellently Standards-compliant! The bitshift hack is neat, but only works for some bit representations, and doesn't work when you have an unsigned type. It could be provided as a manual specialization when appropriate. Accurate! Simple comparisons with zero can maintain the machine's internal high-precision representation (e.g. 80 bit on x87), and avoid a premature round to zero. Caveats: It's a template so it might take longer to compile in some circumstances. Apparently some people think use of a new, somewhat esoteric, and very slow standard library function that doesn't even really implement signum is more understandable. The \n```\n< 0\n```\n part of the check triggers GCC's \n```\n-Wtype-limits\n```\n warning when instantiated for an unsigned type. You can avoid this by using some overloads: \n```\n template <typename T> inline constexpr"", ""```\n part of the check triggers GCC's \n```\n-Wtype-limits\n```\n warning when instantiated for an unsigned type. You can avoid this by using some overloads: \n```\n template <typename T> inline constexpr\n int signum(T x, std::false_type is_signed) {\n     return T(0) < x;\n }"", 'template <typename T> inline constexpr\n int signum(T x, std::true_type is_signed) {\n     return (T(0) < x) - (x < T(0));\n }\n\n template <typename T> inline constexpr\n int signum(T x) {\n     return signum(x, std::is_signed<T>());\n }\n\n```\n (Which is a good example of the first caveat.)']","The type-safe C++ version: 
```
template <typename T> int sgn(T val) {
    return (T(0) < val) - (val < T(0));
}

```
 Benefits: Actually implements signum (-1, 0, or 1). Implementations here using copysign only return -1 or 1, which is not signum. Also, some implementations here are returning a float (or T) rather than an int, which seems wasteful. Works for ints, floats, doubles, unsigned shorts, or any custom types constructible from integer 0 and orderable. Fast! 
```
copysign
```
 is slow, especially if you need to promote and then narrow again. This is branchless and optimizes excellently Standards-compliant! The bitshift hack is neat, but only works for some bit representations, and doesn't work when you have an unsigned type. It could be provided as a manual specialization when appropriate. Accurate! Simple comparisons with zero can maintain the machine's internal high-precision representation (e.g. 80 bit on x87), and avoid a premature round to zero. Caveats: It's a template so it might take longer to compile in some circumstances. Apparently some people think use of a new, somewhat esoteric, and very slow standard library function that doesn't even really implement signum is more understandable. The 
```
< 0
```
 part of the check triggers GCC's 
```
-Wtype-limits
```
 warning when instantiated for an unsigned type. You can avoid this by using some overloads: 
```
 template <typename T> inline constexpr
 int signum(T x, std::false_type is_signed) {
     return T(0) < x;
 }

 template <typename T> inline constexpr
 int signum(T x, std::true_type is_signed) {
     return (T(0) < x) - (x < T(0));
 }

 template <typename T> inline constexpr
 int signum(T x) {
     return signum(x, std::is_signed<T>());
 }

```
 (Which is a good example of the first caveat.)"
2872543,'printf' vs. 'cout' in C++,https://stackoverflow.com/questions/2872543/printf-vs-cout-in-c,18,,[],
140061,When to use dynamic vs. static libraries,https://stackoverflow.com/questions/140061/when-to-use-dynamic-vs-static-libraries,20,369.0,"[""Static libraries increase the size of the code in your binary. They're always loaded and whatever version of the code you compiled with is the version of the code that will run. Dynamic libraries are stored and versioned separately. It's possible for a version of the dynamic library to be loaded that wasn't the original one that shipped with your code if the update is considered binary compatible with the original version. Additionally dynamic libraries aren't necessarily loaded -- they're usually loaded when first called -- and can be shared among components that use the same library (multiple data loads, one code load). Dynamic libraries were considered to be the better approach most of the time, but originally they had a major flaw (google DLL hell), which has all but been eliminated by more recent Windows OSes (Windows XP in particular).""]","Static libraries increase the size of the code in your binary. They're always loaded and whatever version of the code you compiled with is the version of the code that will run. Dynamic libraries are stored and versioned separately. It's possible for a version of the dynamic library to be loaded that wasn't the original one that shipped with your code if the update is considered binary compatible with the original version. Additionally dynamic libraries aren't necessarily loaded -- they're usually loaded when first called -- and can be shared among components that use the same library (multiple data loads, one code load). Dynamic libraries were considered to be the better approach most of the time, but originally they had a major flaw (google DLL hell), which has all but been eliminated by more recent Windows OSes (Windows XP in particular)."
5205491,"What's the difference between ""STL"" and ""C++ Standard Library""?",https://stackoverflow.com/questions/5205491/whats-the-difference-between-stl-and-c-standard-library,7,657.0,"['The ""STL"" was written by Alexander Stepanov in the days long before C++ was standardised. C++ existed through the 80s, but what we now call ""C++"" is the language standardised in ISO/IEC 14882:2014 (and earlier versions, such as ISO/IEC 14882:2011). The STL was already widely used as a library for C++, giving programmers access to containers, iterators and algorithms. When the standardisation happened, the language committee designed parts of the C++ Standard Library (which is part of the language standard) to very closely match the STL. Over the years, many people — including prominent book authors, and various websites — have continued to refer to the C++ Standard Library as ""the STL"", despite the fact that the two entities are separate and that there are some differences. These differences are even more pronounced in the upcoming new C++ standard, which includes various features and significantly alters some classes. The original STL is now often called ""an implementation of the C++', 'are even more pronounced in the upcoming new C++ standard, which includes various features and significantly alters some classes. The original STL is now often called ""an implementation of the C++ Standard Template Library"" (rather backwards to actual history!), in the same way that your Microsoft Visual Studio or GCC ships an implementation of the C++ Standard Library. But the ""Standard Template Library"" and the ""Standard Library"" are not the same thing. The battle is about whether the current Standard Library should be called ""the STL"" in whole or in part, and/or whether it matters what it\'s called. For ""STL"" There is a school of thought that says that everybody knows now that ""STL"" means the standard library, just as everybody now knows that ""C++"" is the ISO-standardised language. It also includes those who believe that it doesn\'t really matter as long as all parties understand what is being talked about. It\'s a term made even more prevalent by the nature of the beast, much of', 'It also includes those who believe that it doesn\'t really matter as long as all parties understand what is being talked about. It\'s a term made even more prevalent by the nature of the beast, much of which makes heavy use of the C++ feature known as ""templates"". For ""C++ Standard Library"" (or stdlib) However, there is another school of thought — to which I subscribe — that says that this is confusing. People learning C++ for the first time do not know this distinction, and may not notice small language differences. The author of that article has numerous times encountered people who believe that the entire C++ Standard Library is the STL, including features that were never part of the STL itself. Most vocal proponents of ""the STL"", in contrast, know exactly what they mean by it and refuse to believe that not everybody ""gets it"". Clearly, the term\'s usage is not uniform. In addition, there are some STL-like libraries that are in fact implementations of the original STL, not the C++', 'to believe that not everybody ""gets it"". Clearly, the term\'s usage is not uniform. In addition, there are some STL-like libraries that are in fact implementations of the original STL, not the C++ Standard Library. Until recently, STLPort was one of them (and even there, the confusion abounds!). Further, the C++ Standard does not contain the text ""STL"" anywhere, and some people habitually employ phrases like ""the STL is included in the C++ Standard Library"", which is plain incorrect. It\'s my belief that continuing to propagate the usage of the term in this way will just lead to the misunderstanding going on forever. Alas, it may be entirely counter-productive to attempt to change things, even if it\'s supposed to be for the better. We may just be stuck with double-meanings forever. Conclusion I appreciate that this post has been a little biased: I wrote the article you linked to. :) Anyway, I hope this helps to explain the battle a bit better. Update 13/04/2011 Here are three perfect', 'I appreciate that this post has been a little biased: I wrote the article you linked to. :) Anyway, I hope this helps to explain the battle a bit better. Update 13/04/2011 Here are three perfect examples of someone who is using ""the STL"" to refer to the entire C++ Standard Library. It continues to baffle me that so many people swear blind that nobody ever does this, when it\'s plain to see almost on a daily basis.']","The ""STL"" was written by Alexander Stepanov in the days long before C++ was standardised. C++ existed through the 80s, but what we now call ""C++"" is the language standardised in ISO/IEC 14882:2014 (and earlier versions, such as ISO/IEC 14882:2011). The STL was already widely used as a library for C++, giving programmers access to containers, iterators and algorithms. When the standardisation happened, the language committee designed parts of the C++ Standard Library (which is part of the language standard) to very closely match the STL. Over the years, many people — including prominent book authors, and various websites — have continued to refer to the C++ Standard Library as ""the STL"", despite the fact that the two entities are separate and that there are some differences. These differences are even more pronounced in the upcoming new C++ standard, which includes various features and significantly alters some classes. The original STL is now often called ""an implementation of the C++ Standard Template Library"" (rather backwards to actual history!), in the same way that your Microsoft Visual Studio or GCC ships an implementation of the C++ Standard Library. But the ""Standard Template Library"" and the ""Standard Library"" are not the same thing. The battle is about whether the current Standard Library should be called ""the STL"" in whole or in part, and/or whether it matters what it's called. For ""STL"" There is a school of thought that says that everybody knows now that ""STL"" means the standard library, just as everybody now knows that ""C++"" is the ISO-standardised language. It also includes those who believe that it doesn't really matter as long as all parties understand what is being talked about. It's a term made even more prevalent by the nature of the beast, much of which makes heavy use of the C++ feature known as ""templates"". For ""C++ Standard Library"" (or stdlib) However, there is another school of thought — to which I subscribe — that says that this is confusing. People learning C++ for the first time do not know this distinction, and may not notice small language differences. The author of that article has numerous times encountered people who believe that the entire C++ Standard Library is the STL, including features that were never part of the STL itself. Most vocal proponents of ""the STL"", in contrast, know exactly what they mean by it and refuse to believe that not everybody ""gets it"". Clearly, the term's usage is not uniform. In addition, there are some STL-like libraries that are in fact implementations of the original STL, not the C++ Standard Library. Until recently, STLPort was one of them (and even there, the confusion abounds!). Further, the C++ Standard does not contain the text ""STL"" anywhere, and some people habitually employ phrases like ""the STL is included in the C++ Standard Library"", which is plain incorrect. It's my belief that continuing to propagate the usage of the term in this way will just lead to the misunderstanding going on forever. Alas, it may be entirely counter-productive to attempt to change things, even if it's supposed to be for the better. We may just be stuck with double-meanings forever. Conclusion I appreciate that this post has been a little biased: I wrote the article you linked to. :) Anyway, I hope this helps to explain the battle a bit better. Update 13/04/2011 Here are three perfect examples of someone who is using ""the STL"" to refer to the entire C++ Standard Library. It continues to baffle me that so many people swear blind that nobody ever does this, when it's plain to see almost on a daily basis."
4986673,C++11 rvalues and move semantics with return statement,https://stackoverflow.com/questions/4986673/c11-rvalues-and-move-semantics-with-return-statement,6,672.0,"[""First example \n```\nstd::vector<int> return_vector(void)\n{\n    std::vector<int> tmp {1,2,3,4,5};\n    return tmp;\n}\n\nstd::vector<int> &&rval_ref = return_vector();\n\n```\n The first example returns a temporary which is caught by \n```\nrval_ref\n```\n. That temporary will have its life extended beyond the \n```\nrval_ref\n```\n definition and you can use it as if you had caught it by value. This is very similar to the following: \n```\nconst std::vector<int>& rval_ref = return_vector();\n\n```\n except that in my rewrite you obviously can't use \n```\nrval_ref\n```\n in a non-const manner. Second example \n```\nstd::vector<int>&& return_vector(void)\n{\n    std::vector<int> tmp {1,2,3,4,5};\n    return std::move(tmp);\n}\n\nstd::vector<int> &&rval_ref = return_vector();"", ""std::vector<int> &&rval_ref = return_vector();\n\n```\n In the second example you have created a run time error. \n```\nrval_ref\n```\n now holds a reference to the destructed \n```\ntmp\n```\n inside the function. With any luck, this code would immediately crash. Third example \n```\nstd::vector<int> return_vector(void)\n{\n    std::vector<int> tmp {1,2,3,4,5};\n    return std::move(tmp);\n}\n\nstd::vector<int> &&rval_ref = return_vector();\n\n```\n Your third example is roughly equivalent to your first. The \n```\nstd::move\n```\n on \n```\ntmp\n```\n is unnecessary and can actually be a performance pessimization as it will inhibit return value optimization. The best way to code what you're doing is: Best practice \n```\nstd::vector<int> return_vector(void)\n{\n    std::vector<int> tmp {1,2,3,4,5};\n    return tmp;\n}\n\nstd::vector<int> rval_ref = return_vector();"", ""std::vector<int> rval_ref = return_vector();\n\n```\n I.e. just as you would in C++03. \n```\ntmp\n```\n is implicitly treated as an rvalue in the return statement. It will either be returned via return-value-optimization (no copy, no move), or if the compiler decides it can not perform RVO, then it will use vector's move constructor to do the return. Only if RVO is not performed, and if the returned type did not have a move constructor would the copy constructor be used for the return.""]","First example 
```
std::vector<int> return_vector(void)
{
    std::vector<int> tmp {1,2,3,4,5};
    return tmp;
}

std::vector<int> &&rval_ref = return_vector();

```
 The first example returns a temporary which is caught by 
```
rval_ref
```
. That temporary will have its life extended beyond the 
```
rval_ref
```
 definition and you can use it as if you had caught it by value. This is very similar to the following: 
```
const std::vector<int>& rval_ref = return_vector();

```
 except that in my rewrite you obviously can't use 
```
rval_ref
```
 in a non-const manner. Second example 
```
std::vector<int>&& return_vector(void)
{
    std::vector<int> tmp {1,2,3,4,5};
    return std::move(tmp);
}

std::vector<int> &&rval_ref = return_vector();

```
 In the second example you have created a run time error. 
```
rval_ref
```
 now holds a reference to the destructed 
```
tmp
```
 inside the function. With any luck, this code would immediately crash. Third example 
```
std::vector<int> return_vector(void)
{
    std::vector<int> tmp {1,2,3,4,5};
    return std::move(tmp);
}

std::vector<int> &&rval_ref = return_vector();

```
 Your third example is roughly equivalent to your first. The 
```
std::move
```
 on 
```
tmp
```
 is unnecessary and can actually be a performance pessimization as it will inhibit return value optimization. The best way to code what you're doing is: Best practice 
```
std::vector<int> return_vector(void)
{
    std::vector<int> tmp {1,2,3,4,5};
    return tmp;
}

std::vector<int> rval_ref = return_vector();

```
 I.e. just as you would in C++03. 
```
tmp
```
 is implicitly treated as an rvalue in the return statement. It will either be returned via return-value-optimization (no copy, no move), or if the compiler decides it can not perform RVO, then it will use vector's move constructor to do the return. Only if RVO is not performed, and if the returned type did not have a move constructor would the copy constructor be used for the return."
5973427,error: passing const xxx as 'this' argument of member function discards qualifiers,https://stackoverflow.com/questions/5973427/error-passing-const-xxx-as-this-argument-of-member-function-discards-qualifie,4,598.0,"[""The objects in the \n```\nstd::set\n```\n are stored as \n```\nconst StudentT\n```\n. So when you try to call \n```\ngetId()\n```\n with the \n```\nconst\n```\n object the compiler detects a problem, mainly you're calling a non-const member function on const object which is not allowed because non-const member functions make NO PROMISE not to modify the object; so the compiler is going to make a safe assumption that \n```\ngetId()\n```\n might attempt to modify the object but at the same time, it also notices that the object is const; so any attempt to modify the const object should be an error. Hence compiler generates an error message. The solution is simple: make the functions const as: \n```\nint getId() const {\n    return id;\n}\nstring getName() const {\n    return name;\n}"", '```\n This is necessary because now you can call \n```\ngetId()\n```\n and \n```\ngetName()\n```\n on const objects as: \n```\nvoid f(const StudentT & s)\n{\n     cout << s.getId();   //now okay, but error with your versions\n     cout << s.getName(); //now okay, but error with your versions\n}\n\n```\n As a sidenote, you should implement \n```\noperator<\n```\n as : \n```\ninline bool operator< (const StudentT & s1, const StudentT & s2)\n{\n    return  s1.getId() < s2.getId();\n}\n\n```\n Note parameters are now \n```\nconst\n```\n reference.']","The objects in the 
```
std::set
```
 are stored as 
```
const StudentT
```
. So when you try to call 
```
getId()
```
 with the 
```
const
```
 object the compiler detects a problem, mainly you're calling a non-const member function on const object which is not allowed because non-const member functions make NO PROMISE not to modify the object; so the compiler is going to make a safe assumption that 
```
getId()
```
 might attempt to modify the object but at the same time, it also notices that the object is const; so any attempt to modify the const object should be an error. Hence compiler generates an error message. The solution is simple: make the functions const as: 
```
int getId() const {
    return id;
}
string getName() const {
    return name;
}

```
 This is necessary because now you can call 
```
getId()
```
 and 
```
getName()
```
 on const objects as: 
```
void f(const StudentT & s)
{
     cout << s.getId();   //now okay, but error with your versions
     cout << s.getName(); //now okay, but error with your versions
}

```
 As a sidenote, you should implement 
```
operator<
```
 as : 
```
inline bool operator< (const StudentT & s1, const StudentT & s2)
{
    return  s1.getId() < s2.getId();
}

```
 Note parameters are now 
```
const
```
 reference."
222557,"What uses are there for ""placement new""?",https://stackoverflow.com/questions/222557/what-uses-are-there-for-placement-new,25,475.0,"['Placement new allows you to construct an object in memory that\'s already allocated. You may want to do this for optimization when you need to construct multiple instances of an object, and it is faster not to re-allocate memory each time you need a new instance. Instead, it might be more efficient to perform a single allocation for a chunk of memory that can hold multiple objects, even though you don\'t want to use all of it at once. DevX gives a good example: Standard C++ also supports placement new operator, which constructs an object on a pre-allocated buffer. This is useful when building a memory pool, a garbage collector or simply when performance and exception safety are paramount (there\'s no danger of allocation failure since the memory has already been allocated, and constructing an object on a pre-allocated buffer takes less time): \n```\nchar *buf  = new char[sizeof(string)]; // pre-allocated buffer\nstring *p = new (buf) string(""hi"");    // placement new', '```\nchar *buf  = new char[sizeof(string)]; // pre-allocated buffer\nstring *p = new (buf) string(""hi"");    // placement new\nstring *q = new string(""hi"");          // ordinary heap allocation', '```\n You may also want to be sure there can be no allocation failure at a certain part of critical code (for instance, in code executed by a pacemaker). In that case you would want to allocate memory earlier, then use placement new within the critical section. Deallocation in placement new You should not deallocate every object that is using the memory buffer. Instead you should delete[] only the original buffer. You would have to then call the destructors of your classes manually. For a good suggestion on this, please see Stroustrup\'s FAQ on: Is there a ""placement delete""?']","Placement new allows you to construct an object in memory that's already allocated. You may want to do this for optimization when you need to construct multiple instances of an object, and it is faster not to re-allocate memory each time you need a new instance. Instead, it might be more efficient to perform a single allocation for a chunk of memory that can hold multiple objects, even though you don't want to use all of it at once. DevX gives a good example: Standard C++ also supports placement new operator, which constructs an object on a pre-allocated buffer. This is useful when building a memory pool, a garbage collector or simply when performance and exception safety are paramount (there's no danger of allocation failure since the memory has already been allocated, and constructing an object on a pre-allocated buffer takes less time): 
```
char *buf  = new char[sizeof(string)]; // pre-allocated buffer
string *p = new (buf) string(""hi"");    // placement new
string *q = new string(""hi"");          // ordinary heap allocation

```
 You may also want to be sure there can be no allocation failure at a certain part of critical code (for instance, in code executed by a pacemaker). In that case you would want to allocate memory earlier, then use placement new within the critical section. Deallocation in placement new You should not deallocate every object that is using the memory buffer. Instead you should delete[] only the original buffer. You would have to then call the destructors of your classes manually. For a good suggestion on this, please see Stroustrup's FAQ on: Is there a ""placement delete""?"
19470873,Why does GCC generate 15-20% faster code if I optimize for size instead of speed?,https://stackoverflow.com/questions/19470873/why-does-gcc-generate-15-20-faster-code-if-i-optimize-for-size-instead-of-speed,6,215.0,"['My colleague helped me find a plausible answer to my question. He noticed the importance of the 256 byte boundary. He is not registered here and encouraged me to post the answer myself (and take all the fame). Short answer: Is it the padding that is the culprit in this case? Why and how? It all boils down to alignment. Alignments can have a significant impact on the performance, that is why we have the \n```\n-falign-*\n```\n flags in the first place. I have submitted a (bogus?) bug report to the gcc developers. It turns out that the default behavior is ""we align loops to 8 byte by default but try to align it to 16 byte if we don\'t need to fill in over 10 bytes."" Apparently, this default is not the best choice in this particular case and on my machine. Clang 3.4 (trunk) with \n```\n-O3\n```', '```\n-O3\n```\n does the appropriate alignment and the generated code does not show this weird behavior. Of course, if an inappropriate alignment is done, it makes things worse. An unnecessary / bad alignment just eats up bytes for no reason and potentially increases cache misses, etc. The noise it makes pretty much makes timing micro-optimizations impossible. How can I make sure that such accidental lucky / unlucky alignments are not interfering when I do micro-optimizations (unrelated to stack alignment) on C or C++ source codes? Simply by telling gcc to do the right alignment: \n```\ng++ -O2 -falign-functions=16 -falign-loops=16\n```\n Long answer: The code will run slower if: an \n```\nXX\n```\n byte boundary cuts \n```\nadd()\n```\n in the middle (\n```\nXX\n```\n being machine dependent). if the call to \n```\nadd()\n```\n has to jump over an \n```\nXX\n```\n byte boundary and the target is not aligned. if \n```\nadd()\n```', '```\nadd()\n```\n in the middle (\n```\nXX\n```\n being machine dependent). if the call to \n```\nadd()\n```\n has to jump over an \n```\nXX\n```\n byte boundary and the target is not aligned. if \n```\nadd()\n```\n is not aligned. if the loop is not aligned. The first 2 are beautifully visible on the codes and results that Marat Dukhan kindly posted. In this case, \n```\ngcc-4.8.1 -Os\n```\n (executes in 0.994 secs): \n```\n00000000004004fd <_ZL3addRKiS0_.isra.0>:\n  4004fd:       8d 04 37                lea    eax,[rdi+rsi*1]\n  400500:       c3', '```\n a 256 byte boundary cuts \n```\nadd()\n```\n right in the middle and neither \n```\nadd()\n```\n nor the loop is aligned. Surprise, surprise, this is the slowest case! In case \n```\ngcc-4.7.3 -Os\n```\n (executes in 0.822 secs), the 256 byte boundary only cuts into a cold section (but neither the loop, nor \n```\nadd()\n```\n is cut): \n```\n00000000004004fa <_ZL3addRKiS0_.isra.0>:\n  4004fa:       8d 04 37                lea    eax,[rdi+rsi*1]\n  4004fd:       c3                      ret\n\n[...]\n\n  40051a:       e8 db ff ff ff          call   4004fa <_ZL3addRKiS0_.isra.0>', ""[...]\n\n  40051a:       e8 db ff ff ff          call   4004fa <_ZL3addRKiS0_.isra.0>\n\n```\n Nothing is aligned, and the call to \n```\nadd()\n```\n has to jump over the 256 byte boundary. This code is the second slowest. In case \n```\ngcc-4.6.4 -Os\n```\n (executes in 0.709 secs), although nothing is aligned, the call to \n```\nadd()\n```\n doesn't have to jump over the 256 byte boundary and the target is exactly 32 byte away: \n```\n  4004f2:       e8 db ff ff ff          call   4004d2 <_ZL3addRKiS0_.isra.0>\n  4004f7:       01 c3                   add    ebx,eax\n  4004f9:       ff cd                   dec    ebp\n  4004fb:       75 ec                   jne    4004e9 <_ZL4workii+0x13>"", ""```\n This is the fastest of all three. Why the 256 byte boundary is speacial on his machine, I will leave it up to him to figure it out. I don't have such a processor. Now, on my machine I don't get this 256 byte boundary effect. Only the function and the loop alignment kicks in on my machine. If I pass \n```\ng++ -O2 -falign-functions=16 -falign-loops=16\n```\n then everything is back to normal: I always get the fastest case and the time isn't sensitive to the \n```\n-fno-omit-frame-pointer\n```\n flag anymore. I can pass \n```\ng++ -O2 -falign-functions=32 -falign-loops=32\n```"", '```\n-fno-omit-frame-pointer\n```\n flag anymore. I can pass \n```\ng++ -O2 -falign-functions=32 -falign-loops=32\n```\n or any multiples of 16, the code is not sensitive to that either. I first noticed in 2009 that gcc (at least on my projects and on my machines) have the tendency to generate noticeably faster code if I optimize for size (-Os) instead of speed (-O2 or -O3) and I have been wondering ever since why. A likely explanation is that I had hotspots which were sensitive to the alignment, just like the one in this example. By messing with the flags (passing \n```\n-Os\n```\n instead of \n```\n-O2\n```', '```\n-Os\n```\n instead of \n```\n-O2\n```\n), those hotspots were aligned in a lucky way by accident and the code became faster. It had nothing to do with optimizing for size: These were by sheer accident that the hotspots got aligned better. From now on, I will check the effects of alignment on my projects. Oh, and one more thing. How can such hotspots arise, like the one shown in the example? How can the inlining of such a tiny function like \n```\nadd()\n```\n fail? Consider this: \n```\n// add.cpp\nint add(const int& x, const int& y) {\n    return x + y;\n}', ""```\n and in a separate file: \n```\n// main.cpp\nint add(const int& x, const int& y);\n\nconst int LOOP_BOUND = 200000000;\n\n__attribute__((noinline))\nstatic int work(int xval, int yval) {\n    int sum(0);\n    for (int i=0; i<LOOP_BOUND; ++i) {\n        int x(xval+sum);\n        int y(yval+sum);\n        int z = add(x, y);\n        sum += z;\n    }\n    return sum;\n}\n\nint main(int , char* argv[]) {\n    int result = work(*argv[1], *argv[2]);\n    return result;\n}\n\n```\n and compiled as: \n```\ng++ -O2 add.cpp main.cpp\n```\n. gcc won't inline \n```\nadd()\n```\n! That's all, it's that easy to unintendedly create hotspots like the one in the OP. Of course it is partly my fault: gcc is an excellent compiler. If compile the above as: \n```\ng++ -O2 -flto add.cpp main.cpp\n```\n, that is, if I perform link time optimization, the code runs in 0.19s! (Inlining is artificially disabled in the OP, hence, the code in the OP was 2x slower).""]","My colleague helped me find a plausible answer to my question. He noticed the importance of the 256 byte boundary. He is not registered here and encouraged me to post the answer myself (and take all the fame). Short answer: Is it the padding that is the culprit in this case? Why and how? It all boils down to alignment. Alignments can have a significant impact on the performance, that is why we have the 
```
-falign-*
```
 flags in the first place. I have submitted a (bogus?) bug report to the gcc developers. It turns out that the default behavior is ""we align loops to 8 byte by default but try to align it to 16 byte if we don't need to fill in over 10 bytes."" Apparently, this default is not the best choice in this particular case and on my machine. Clang 3.4 (trunk) with 
```
-O3
```
 does the appropriate alignment and the generated code does not show this weird behavior. Of course, if an inappropriate alignment is done, it makes things worse. An unnecessary / bad alignment just eats up bytes for no reason and potentially increases cache misses, etc. The noise it makes pretty much makes timing micro-optimizations impossible. How can I make sure that such accidental lucky / unlucky alignments are not interfering when I do micro-optimizations (unrelated to stack alignment) on C or C++ source codes? Simply by telling gcc to do the right alignment: 
```
g++ -O2 -falign-functions=16 -falign-loops=16
```
 Long answer: The code will run slower if: an 
```
XX
```
 byte boundary cuts 
```
add()
```
 in the middle (
```
XX
```
 being machine dependent). if the call to 
```
add()
```
 has to jump over an 
```
XX
```
 byte boundary and the target is not aligned. if 
```
add()
```
 is not aligned. if the loop is not aligned. The first 2 are beautifully visible on the codes and results that Marat Dukhan kindly posted. In this case, 
```
gcc-4.8.1 -Os
```
 (executes in 0.994 secs): 
```
00000000004004fd <_ZL3addRKiS0_.isra.0>:
  4004fd:       8d 04 37                lea    eax,[rdi+rsi*1]
  400500:       c3   

```
 a 256 byte boundary cuts 
```
add()
```
 right in the middle and neither 
```
add()
```
 nor the loop is aligned. Surprise, surprise, this is the slowest case! In case 
```
gcc-4.7.3 -Os
```
 (executes in 0.822 secs), the 256 byte boundary only cuts into a cold section (but neither the loop, nor 
```
add()
```
 is cut): 
```
00000000004004fa <_ZL3addRKiS0_.isra.0>:
  4004fa:       8d 04 37                lea    eax,[rdi+rsi*1]
  4004fd:       c3                      ret

[...]

  40051a:       e8 db ff ff ff          call   4004fa <_ZL3addRKiS0_.isra.0>

```
 Nothing is aligned, and the call to 
```
add()
```
 has to jump over the 256 byte boundary. This code is the second slowest. In case 
```
gcc-4.6.4 -Os
```
 (executes in 0.709 secs), although nothing is aligned, the call to 
```
add()
```
 doesn't have to jump over the 256 byte boundary and the target is exactly 32 byte away: 
```
  4004f2:       e8 db ff ff ff          call   4004d2 <_ZL3addRKiS0_.isra.0>
  4004f7:       01 c3                   add    ebx,eax
  4004f9:       ff cd                   dec    ebp
  4004fb:       75 ec                   jne    4004e9 <_ZL4workii+0x13>

```
 This is the fastest of all three. Why the 256 byte boundary is speacial on his machine, I will leave it up to him to figure it out. I don't have such a processor. Now, on my machine I don't get this 256 byte boundary effect. Only the function and the loop alignment kicks in on my machine. If I pass 
```
g++ -O2 -falign-functions=16 -falign-loops=16
```
 then everything is back to normal: I always get the fastest case and the time isn't sensitive to the 
```
-fno-omit-frame-pointer
```
 flag anymore. I can pass 
```
g++ -O2 -falign-functions=32 -falign-loops=32
```
 or any multiples of 16, the code is not sensitive to that either. I first noticed in 2009 that gcc (at least on my projects and on my machines) have the tendency to generate noticeably faster code if I optimize for size (-Os) instead of speed (-O2 or -O3) and I have been wondering ever since why. A likely explanation is that I had hotspots which were sensitive to the alignment, just like the one in this example. By messing with the flags (passing 
```
-Os
```
 instead of 
```
-O2
```
), those hotspots were aligned in a lucky way by accident and the code became faster. It had nothing to do with optimizing for size: These were by sheer accident that the hotspots got aligned better. From now on, I will check the effects of alignment on my projects. Oh, and one more thing. How can such hotspots arise, like the one shown in the example? How can the inlining of such a tiny function like 
```
add()
```
 fail? Consider this: 
```
// add.cpp
int add(const int& x, const int& y) {
    return x + y;
}

```
 and in a separate file: 
```
// main.cpp
int add(const int& x, const int& y);

const int LOOP_BOUND = 200000000;

__attribute__((noinline))
static int work(int xval, int yval) {
    int sum(0);
    for (int i=0; i<LOOP_BOUND; ++i) {
        int x(xval+sum);
        int y(yval+sum);
        int z = add(x, y);
        sum += z;
    }
    return sum;
}

int main(int , char* argv[]) {
    int result = work(*argv[1], *argv[2]);
    return result;
}

```
 and compiled as: 
```
g++ -O2 add.cpp main.cpp
```
. gcc won't inline 
```
add()
```
! That's all, it's that easy to unintendedly create hotspots like the one in the OP. Of course it is partly my fault: gcc is an excellent compiler. If compile the above as: 
```
g++ -O2 -flto add.cpp main.cpp
```
, that is, if I perform link time optimization, the code runs in 0.19s! (Inlining is artificially disabled in the OP, hence, the code in the OP was 2x slower)."
4810664,How do I use arrays in C++?,https://stackoverflow.com/questions/4810664/how-do-i-use-arrays-in-c,5,325.0,"['Arrays on the type level An array type is denoted as \n```\nT[n]\n```\n where \n```\nT\n```\n is the element type and \n```\nn\n```\n is a positive size, the number of elements in the array. The array type is a product type of the element type and the size. If one or both of those ingredients differ, you get a distinct type: \n```\n#include <type_traits>\n\nstatic_assert(!std::is_same<int[8], float[8]>::value, ""distinct element type"");\nstatic_assert(!std::is_same<int[8],   int[9]>::value, ""distinct size"");', '```\n Note that the size is part of the type, that is, array types of different size are incompatible types that have absolutely nothing to do with each other. \n```\nsizeof(T[n])\n```\n is equivalent to \n```\nn * sizeof(T)\n```\n. Array-to-pointer decay The only ""connection"" between \n```\nT[n]\n```\n and \n```\nT[m]\n```\n is that both types can implicitly be converted to \n```\nT*\n```\n, and the result of this conversion is a pointer to the first element of the array. That is, anywhere a \n```\nT*\n```\n is required, you can provide a \n```\nT[n]\n```\n, and the compiler will silently provide that pointer: \n```\n                  +---+---+---+---+---+---+---+---+\nthe_actual_array: |   |   |   |   |   |   |   |   |   int[8]\n                  +---+---+---+---+---+---+---+---+\n                    ^\n                    |\n                    |\n                    |\n                    |  pointer_to_the_first_element   int*', '```\n This conversion is known as ""array-to-pointer decay"", and it is a major source of confusion. The size of the array is lost in this process, since it is no longer part of the type (\n```\nT*\n```', '```\nT*\n```\n). Pro: Forgetting the size of an array on the type level allows a pointer to point to the first element of an array of any size. Con: Given a pointer to the first (or any other) element of an array, there is no way to detect how large that array is or where exactly the pointer points to relative to the bounds of the array. Pointers are extremely stupid. Arrays are not pointers The compiler will silently generate a pointer to the first element of an array whenever it is deemed useful, that is, whenever an operation would fail on an array but succeed on a pointer. This conversion from array to pointer is trivial, since the resulting pointer value is simply the address of the array. Note that the pointer is not stored as part of the array itself (or anywhere else in memory). An array is not a pointer. \n```\nstatic_assert(!std::is_same<int[8], int*>::value, ""an array is not a pointer"");', '```\n One important context in which an array does not decay into a pointer to its first element is when the \n```\n&\n```\n operator is applied to it. In that case, the \n```\n&\n```\n operator yields a pointer to the entire array, not just a pointer to its first element. Although in that case the values (the addresses) are the same, a pointer to the first element of an array and a pointer to the entire array are completely distinct types: \n```\nstatic_assert(!std::is_same<int*, int(*)[8]>::value, ""distinct element type"");\n\n```\n The following ASCII art explains this distinction: \n```\n      +-----------------------------------+\n      | +---+---+---+---+---+---+---+---+ |\n+---> | |   |   |   |   |   |   |   |   | | int[8]\n|     | +---+---+---+---+---+---+---+---+ |\n|     +---^-------------------------------+\n|         |\n|         |\n|         |\n|         |  pointer_to_the_first_element   int*\n|\n|  pointer_to_the_entire_array              int(*)[8]', '```\n Note how the pointer to the first element only points to a single integer (depicted as a small box), whereas the pointer to the entire array points to an array of 8 integers (depicted as a large box). The same situation arises in classes and is maybe more obvious. A pointer to an object and a pointer to its first data member have the same value (the same address), yet they are completely distinct types. If you are unfamiliar with the C declarator syntax, the parenthesis in the type \n```\nint(*)[8]\n```\n are essential: \n```\nint(*)[8]\n```\n is a pointer to an array of 8 integers. \n```\nint*[8]\n```\n is an array of 8 pointers, each element of type \n```\nint*\n```\n. Accessing elements C++ provides two syntactic variations to access individual elements of an array. Neither of them is superior to the other, and you should familiarize yourself with both. Pointer arithmetic Given a pointer \n```\np\n```\n to the first element of an array, the expression \n```\np+i\n```', '```\np\n```\n to the first element of an array, the expression \n```\np+i\n```\n yields a pointer to the i-th element of the array. By dereferencing that pointer afterwards, one can access individual elements: \n```\nstd::cout << *(x+3) << "", "" << *(x+7) << std::endl;', '```\n If \n```\nx\n```\n denotes an array, then array-to-pointer decay will kick in, because adding an array and an integer is meaningless (there is no plus operation on arrays), but adding a pointer and an integer makes sense: \n```\n   +---+---+---+---+---+---+---+---+\nx: |   |   |   |   |   |   |   |   |   int[8]\n   +---+---+---+---+---+---+---+---+\n     ^           ^               ^\n     |           |               |\n     |           |               |\n     |           |               |\nx+0  |      x+3  |          x+7  |     int*', '```\n (Note that the implicitly generated pointer has no name, so I wrote \n```\nx+0\n```\n in order to identify it.) If, on the other hand, \n```\nx\n```\n denotes a pointer to the first (or any other) element of an array, then array-to-pointer decay is not necessary, because the pointer on which \n```\ni\n```\n is going to be added already exists: \n```\n   +---+---+---+---+---+---+---+---+\n   |   |   |   |   |   |   |   |   |   int[8]\n   +---+---+---+---+---+---+---+---+\n     ^           ^               ^\n     |           |               |\n     |           |               |\n   +-|-+         |               |\nx: | | |    x+3  |          x+7  |     int*\n   +---+', '```\n Note that in the depicted case, \n```\nx\n```\n is a pointer variable (discernible by the small box next to \n```\nx\n```\n), but it could just as well be the result of a function returning a pointer (or any other expression of type \n```\nT*\n```\n). Indexing operator Since the syntax \n```\n*(x+i)\n```\n is a bit clumsy, C++ provides the alternative syntax \n```\nx[i]\n```\n: \n```\nstd::cout << x[3] << "", "" << x[7] << std::endl;\n\n```\n Due to the fact that addition is commutative, the following code does exactly the same: \n```\nstd::cout << 3[x] << "", "" << 7[x] << std::endl;\n\n```\n The definition of the indexing operator leads to the following interesting equivalence: \n```\n&x[i]  ==  &*(x+i)  ==  x+i', '```\n The definition of the indexing operator leads to the following interesting equivalence: \n```\n&x[i]  ==  &*(x+i)  ==  x+i\n\n```\n However, \n```\n&x[0]\n```\n is generally not equivalent to \n```\nx\n```\n. The former is a pointer, the latter an array. Only when the context triggers array-to-pointer decay can \n```\nx\n```\n and \n```\n&x[0]\n```\n be used interchangeably. For example: \n```\nT* p = &array[0];  // rewritten as &*(array+0), decay happens due to the addition\nT* q = array;      // decay happens due to the assignment', '```\n On the first line, the compiler detects an assignment from a pointer to a pointer, which trivially succeeds. On the second line, it detects an assignment from an array to a pointer. Since this is meaningless (but pointer to pointer assignment makes sense), array-to-pointer decay kicks in as usual. Ranges An array of type \n```\nT[n]\n```\n has \n```\nn\n```\n elements, indexed from \n```\n0\n```\n to \n```\nn-1\n```\n; there is no element \n```\nn\n```\n. And yet, to support half-open ranges (where the beginning is inclusive and the end is exclusive), C++ allows the computation of a pointer to the (non-existent) n-th element, but it is illegal to dereference that pointer: \n```\n   +---+---+---+---+---+---+---+---+....\nx: |   |   |   |   |   |   |   |   |   .   int[8]\n   +---+---+---+---+---+---+---+---+....\n     ^                               ^\n     |                               |\n     |                               |\n     |                               |', '+---+---+---+---+---+---+---+---+....\n     ^                               ^\n     |                               |\n     |                               |\n     |                               |\nx+0  |                          x+8  |     int*', '```\n For example, if you want to sort an array, both of the following would work equally well: \n```\nstd::sort(x + 0, x + n);\nstd::sort(&x[0], &x[0] + n);\n\n```\n Note that it is illegal to provide \n```\n&x[n]\n```\n as the second argument since this is equivalent to \n```\n&*(x+n)\n```\n, and the sub-expression \n```\n*(x+n)\n```\n technically invokes undefined behavior in C++ (but not in C99). Also note that you could simply provide \n```\nx\n```\n as the first argument. That is a little too terse for my taste, and it also makes template argument deduction a bit harder for the compiler, because in that case the first argument is an array but the second argument is a pointer. (Again, array-to-pointer decay kicks in.)']","Arrays on the type level An array type is denoted as 
```
T[n]
```
 where 
```
T
```
 is the element type and 
```
n
```
 is a positive size, the number of elements in the array. The array type is a product type of the element type and the size. If one or both of those ingredients differ, you get a distinct type: 
```
#include <type_traits>

static_assert(!std::is_same<int[8], float[8]>::value, ""distinct element type"");
static_assert(!std::is_same<int[8],   int[9]>::value, ""distinct size"");

```
 Note that the size is part of the type, that is, array types of different size are incompatible types that have absolutely nothing to do with each other. 
```
sizeof(T[n])
```
 is equivalent to 
```
n * sizeof(T)
```
. Array-to-pointer decay The only ""connection"" between 
```
T[n]
```
 and 
```
T[m]
```
 is that both types can implicitly be converted to 
```
T*
```
, and the result of this conversion is a pointer to the first element of the array. That is, anywhere a 
```
T*
```
 is required, you can provide a 
```
T[n]
```
, and the compiler will silently provide that pointer: 
```
                  +---+---+---+---+---+---+---+---+
the_actual_array: |   |   |   |   |   |   |   |   |   int[8]
                  +---+---+---+---+---+---+---+---+
                    ^
                    |
                    |
                    |
                    |  pointer_to_the_first_element   int*

```
 This conversion is known as ""array-to-pointer decay"", and it is a major source of confusion. The size of the array is lost in this process, since it is no longer part of the type (
```
T*
```
). Pro: Forgetting the size of an array on the type level allows a pointer to point to the first element of an array of any size. Con: Given a pointer to the first (or any other) element of an array, there is no way to detect how large that array is or where exactly the pointer points to relative to the bounds of the array. Pointers are extremely stupid. Arrays are not pointers The compiler will silently generate a pointer to the first element of an array whenever it is deemed useful, that is, whenever an operation would fail on an array but succeed on a pointer. This conversion from array to pointer is trivial, since the resulting pointer value is simply the address of the array. Note that the pointer is not stored as part of the array itself (or anywhere else in memory). An array is not a pointer. 
```
static_assert(!std::is_same<int[8], int*>::value, ""an array is not a pointer"");

```
 One important context in which an array does not decay into a pointer to its first element is when the 
```
&
```
 operator is applied to it. In that case, the 
```
&
```
 operator yields a pointer to the entire array, not just a pointer to its first element. Although in that case the values (the addresses) are the same, a pointer to the first element of an array and a pointer to the entire array are completely distinct types: 
```
static_assert(!std::is_same<int*, int(*)[8]>::value, ""distinct element type"");

```
 The following ASCII art explains this distinction: 
```
      +-----------------------------------+
      | +---+---+---+---+---+---+---+---+ |
+---> | |   |   |   |   |   |   |   |   | | int[8]
|     | +---+---+---+---+---+---+---+---+ |
|     +---^-------------------------------+
|         |
|         |
|         |
|         |  pointer_to_the_first_element   int*
|
|  pointer_to_the_entire_array              int(*)[8]

```
 Note how the pointer to the first element only points to a single integer (depicted as a small box), whereas the pointer to the entire array points to an array of 8 integers (depicted as a large box). The same situation arises in classes and is maybe more obvious. A pointer to an object and a pointer to its first data member have the same value (the same address), yet they are completely distinct types. If you are unfamiliar with the C declarator syntax, the parenthesis in the type 
```
int(*)[8]
```
 are essential: 
```
int(*)[8]
```
 is a pointer to an array of 8 integers. 
```
int*[8]
```
 is an array of 8 pointers, each element of type 
```
int*
```
. Accessing elements C++ provides two syntactic variations to access individual elements of an array. Neither of them is superior to the other, and you should familiarize yourself with both. Pointer arithmetic Given a pointer 
```
p
```
 to the first element of an array, the expression 
```
p+i
```
 yields a pointer to the i-th element of the array. By dereferencing that pointer afterwards, one can access individual elements: 
```
std::cout << *(x+3) << "", "" << *(x+7) << std::endl;

```
 If 
```
x
```
 denotes an array, then array-to-pointer decay will kick in, because adding an array and an integer is meaningless (there is no plus operation on arrays), but adding a pointer and an integer makes sense: 
```
   +---+---+---+---+---+---+---+---+
x: |   |   |   |   |   |   |   |   |   int[8]
   +---+---+---+---+---+---+---+---+
     ^           ^               ^
     |           |               |
     |           |               |
     |           |               |
x+0  |      x+3  |          x+7  |     int*

```
 (Note that the implicitly generated pointer has no name, so I wrote 
```
x+0
```
 in order to identify it.) If, on the other hand, 
```
x
```
 denotes a pointer to the first (or any other) element of an array, then array-to-pointer decay is not necessary, because the pointer on which 
```
i
```
 is going to be added already exists: 
```
   +---+---+---+---+---+---+---+---+
   |   |   |   |   |   |   |   |   |   int[8]
   +---+---+---+---+---+---+---+---+
     ^           ^               ^
     |           |               |
     |           |               |
   +-|-+         |               |
x: | | |    x+3  |          x+7  |     int*
   +---+

```
 Note that in the depicted case, 
```
x
```
 is a pointer variable (discernible by the small box next to 
```
x
```
), but it could just as well be the result of a function returning a pointer (or any other expression of type 
```
T*
```
). Indexing operator Since the syntax 
```
*(x+i)
```
 is a bit clumsy, C++ provides the alternative syntax 
```
x[i]
```
: 
```
std::cout << x[3] << "", "" << x[7] << std::endl;

```
 Due to the fact that addition is commutative, the following code does exactly the same: 
```
std::cout << 3[x] << "", "" << 7[x] << std::endl;

```
 The definition of the indexing operator leads to the following interesting equivalence: 
```
&x[i]  ==  &*(x+i)  ==  x+i

```
 However, 
```
&x[0]
```
 is generally not equivalent to 
```
x
```
. The former is a pointer, the latter an array. Only when the context triggers array-to-pointer decay can 
```
x
```
 and 
```
&x[0]
```
 be used interchangeably. For example: 
```
T* p = &array[0];  // rewritten as &*(array+0), decay happens due to the addition
T* q = array;      // decay happens due to the assignment

```
 On the first line, the compiler detects an assignment from a pointer to a pointer, which trivially succeeds. On the second line, it detects an assignment from an array to a pointer. Since this is meaningless (but pointer to pointer assignment makes sense), array-to-pointer decay kicks in as usual. Ranges An array of type 
```
T[n]
```
 has 
```
n
```
 elements, indexed from 
```
0
```
 to 
```
n-1
```
; there is no element 
```
n
```
. And yet, to support half-open ranges (where the beginning is inclusive and the end is exclusive), C++ allows the computation of a pointer to the (non-existent) n-th element, but it is illegal to dereference that pointer: 
```
   +---+---+---+---+---+---+---+---+....
x: |   |   |   |   |   |   |   |   |   .   int[8]
   +---+---+---+---+---+---+---+---+....
     ^                               ^
     |                               |
     |                               |
     |                               |
x+0  |                          x+8  |     int*

```
 For example, if you want to sort an array, both of the following would work equally well: 
```
std::sort(x + 0, x + n);
std::sort(&x[0], &x[0] + n);

```
 Note that it is illegal to provide 
```
&x[n]
```
 as the second argument since this is equivalent to 
```
&*(x+n)
```
, and the sub-expression 
```
*(x+n)
```
 technically invokes undefined behavior in C++ (but not in C99). Also note that you could simply provide 
```
x
```
 as the first argument. That is a little too terse for my taste, and it also makes template argument deduction a bit harder for the compiler, because in that case the first argument is an array but the second argument is a pointer. (Again, array-to-pointer decay kicks in.)"
4316727,Why can you return a std::unique_ptr without std::move?,https://stackoverflow.com/questions/4316727/why-can-you-return-a-stdunique-ptr-without-stdmove,7,293.0,"['is there some other clause in the language specification that this exploits? Yes, see 12.8 §34 and §35: When certain criteria are met, an implementation is allowed to omit the copy/move construction of a class object [...] This elision of copy/move operations, called copy elision, is permitted [...] in a return statement in a function with a class return type, when the expression is the name of a non-volatile automatic object with the same cv-unqualified type as the function return type [...] When the criteria for elision of a copy operation are met and the object to be copied is designated by an lvalue, overload resolution to select the constructor for the copy is first performed as if the object were designated by an rvalue. Just wanted to add one more point that returning by value should be the default choice here because a named value in the return statement in the worst case, i.e. without elisions in C++11, C++14 and C++17 is treated as an rvalue. So for example the following', 'be the default choice here because a named value in the return statement in the worst case, i.e. without elisions in C++11, C++14 and C++17 is treated as an rvalue. So for example the following function compiles with the', '```\n-fno-elide-constructors\n```\n flag \n```\nstd::unique_ptr<int> get_unique() {\n  auto ptr = std::unique_ptr<int>{new int{2}}; // <- 1\n  return ptr; // <- 2, moved into the to be returned unique_ptr\n}', '...\n\nauto int_uptr = get_unique(); // <- 3\n\n```\n With the flag set on compilation there are two moves (1 and 2) happening in this function and then one move later on (3).']","is there some other clause in the language specification that this exploits? Yes, see 12.8 §34 and §35: When certain criteria are met, an implementation is allowed to omit the copy/move construction of a class object [...] This elision of copy/move operations, called copy elision, is permitted [...] in a return statement in a function with a class return type, when the expression is the name of a non-volatile automatic object with the same cv-unqualified type as the function return type [...] When the criteria for elision of a copy operation are met and the object to be copied is designated by an lvalue, overload resolution to select the constructor for the copy is first performed as if the object were designated by an rvalue. Just wanted to add one more point that returning by value should be the default choice here because a named value in the return statement in the worst case, i.e. without elisions in C++11, C++14 and C++17 is treated as an rvalue. So for example the following function compiles with the 
```
-fno-elide-constructors
```
 flag 
```
std::unique_ptr<int> get_unique() {
  auto ptr = std::unique_ptr<int>{new int{2}}; // <- 1
  return ptr; // <- 2, moved into the to be returned unique_ptr
}

...

auto int_uptr = get_unique(); // <- 3

```
 With the flag set on compilation there are two moves (1 and 2) happening in this function and then one move later on (3)."
1127396,Can a struct have a constructor in C++?,https://stackoverflow.com/questions/1127396/can-a-struct-have-a-constructor-in-c,17,,[],
92859,What are the differences between struct and class in C++?,https://stackoverflow.com/questions/92859/what-are-the-differences-between-struct-and-class-in-c,29,503.0,"[""You forget the tricky 2nd difference between classes and structs. Quoth the standard (§11.2.2 in C++98 through C++11): In absence of an access-specifier for a base class, public is assumed when the derived class is declared struct and private is assumed when the class is declared class. And just for completeness' sake, the more widely known difference between class and struct is defined in (11.2): Member of a class defined with the keyword class are private by default. Members of a class defined with the keywords struct or union are public by default. Additional difference: the keyword \n```\nclass\n```\n can be used to declare template parameters, while the \n```\nstruct\n```\n keyword cannot be so used.""]","You forget the tricky 2nd difference between classes and structs. Quoth the standard (§11.2.2 in C++98 through C++11): In absence of an access-specifier for a base class, public is assumed when the derived class is declared struct and private is assumed when the class is declared class. And just for completeness' sake, the more widely known difference between class and struct is defined in (11.2): Member of a class defined with the keyword class are private by default. Members of a class defined with the keywords struct or union are public by default. Additional difference: the keyword 
```
class
```
 can be used to declare template parameters, while the 
```
struct
```
 keyword cannot be so used."
2321511,What is meant by Resource Acquisition is Initialization (RAII)?,https://stackoverflow.com/questions/2321511/what-is-meant-by-resource-acquisition-is-initialization-raii,10,,[],
1993390,Static linking vs dynamic linking,https://stackoverflow.com/questions/1993390/static-linking-vs-dynamic-linking,16,431.0,"['Dynamic linking can reduce total resource consumption (if more than one process shares the same library (including the version in ""the same"", of course)). I believe this is the argument that drives its presence in most environments. Here ""resources"" include disk space, RAM, and cache space. Of course, if your dynamic linker is insufficiently flexible there is a risk of DLL hell. Dynamic linking means that bug fixes and upgrades to libraries propagate to improve your product without requiring you to ship anything. Plugins always call for dynamic linking. Static linking, means that you can know the code will run in very limited environments (early in the boot process, or in rescue mode). Static linking can make binaries easier to distribute to diverse user environments (at the cost of sending a larger and more resource-hungry program). Static linking may allow slightly faster startup times, but this depends to some degree on both the size and complexity of your program and on the details', ""a larger and more resource-hungry program). Static linking may allow slightly faster startup times, but this depends to some degree on both the size and complexity of your program and on the details of the OS's loading strategy. Some edits to include the very relevant suggestions in the comments and in other answers. I'd like to note that the way you break on this depends a lot on what environment you plan to run in. Minimal embedded systems may not have enough resources to support dynamic linking. Slightly larger small systems may well support dynamic linking because their memory is small enough to make the RAM savings from dynamic linking very attractive. Full-blown consumer PCs have, as Mark notes, enormous resources, and you can probably let the convenience issues drive your thinking on this matter. To address the performance and efficiency issues: it depends. Classically, dynamic libraries require some kind of glue layer which often means double dispatch or an extra layer of"", ""on this matter. To address the performance and efficiency issues: it depends. Classically, dynamic libraries require some kind of glue layer which often means double dispatch or an extra layer of indirection in function addressing and can cost a little speed (but is the function calling time actually a big part of your running time???). However, if you are running multiple processes which all call the same library a lot, you can end up saving cache lines (and thus winning on running performance) when using dynamic linking relative to using static linking. (Unless modern OS's are smart enough to notice identical segments in statically linked binaries. Seems hard, does anyone know?) Another issue: loading time. You pay loading costs at some point. When you pay this cost depends on how the OS works as well as what linking you use. Maybe you'd rather put off paying it until you know you need it. Note that static-vs-dynamic linking is traditionally not an optimization issue, because they"", 'OS works as well as what linking you use. Maybe you\'d rather put off paying it until you know you need it. Note that static-vs-dynamic linking is traditionally not an optimization issue, because they both involve separate compilation down to object files. However, this is not required: a compiler can in principle, ""compile"" ""static libraries"" to a digested AST form initially, and ""link"" them by adding those ASTs to the ones generated for the main code, thus empowering global optimization. None of the systems I use do this, so I can\'t comment on how well it works. The way to answer performance questions is always by testing (and use a test environment as much like the deployment environment as possible).']","Dynamic linking can reduce total resource consumption (if more than one process shares the same library (including the version in ""the same"", of course)). I believe this is the argument that drives its presence in most environments. Here ""resources"" include disk space, RAM, and cache space. Of course, if your dynamic linker is insufficiently flexible there is a risk of DLL hell. Dynamic linking means that bug fixes and upgrades to libraries propagate to improve your product without requiring you to ship anything. Plugins always call for dynamic linking. Static linking, means that you can know the code will run in very limited environments (early in the boot process, or in rescue mode). Static linking can make binaries easier to distribute to diverse user environments (at the cost of sending a larger and more resource-hungry program). Static linking may allow slightly faster startup times, but this depends to some degree on both the size and complexity of your program and on the details of the OS's loading strategy. Some edits to include the very relevant suggestions in the comments and in other answers. I'd like to note that the way you break on this depends a lot on what environment you plan to run in. Minimal embedded systems may not have enough resources to support dynamic linking. Slightly larger small systems may well support dynamic linking because their memory is small enough to make the RAM savings from dynamic linking very attractive. Full-blown consumer PCs have, as Mark notes, enormous resources, and you can probably let the convenience issues drive your thinking on this matter. To address the performance and efficiency issues: it depends. Classically, dynamic libraries require some kind of glue layer which often means double dispatch or an extra layer of indirection in function addressing and can cost a little speed (but is the function calling time actually a big part of your running time???). However, if you are running multiple processes which all call the same library a lot, you can end up saving cache lines (and thus winning on running performance) when using dynamic linking relative to using static linking. (Unless modern OS's are smart enough to notice identical segments in statically linked binaries. Seems hard, does anyone know?) Another issue: loading time. You pay loading costs at some point. When you pay this cost depends on how the OS works as well as what linking you use. Maybe you'd rather put off paying it until you know you need it. Note that static-vs-dynamic linking is traditionally not an optimization issue, because they both involve separate compilation down to object files. However, this is not required: a compiler can in principle, ""compile"" ""static libraries"" to a digested AST form initially, and ""link"" them by adding those ASTs to the ones generated for the main code, thus empowering global optimization. None of the systems I use do this, so I can't comment on how well it works. The way to answer performance questions is always by testing (and use a test environment as much like the deployment environment as possible)."
8114276,How do I pass a unique_ptr argument to a constructor or a function?,https://stackoverflow.com/questions/8114276/how-do-i-pass-a-unique-ptr-argument-to-a-constructor-or-a-function,7,1008.0,"['Here are the possible ways to take a unique pointer as an argument, as well as their associated meaning. (A) By Value \n```\nBase(std::unique_ptr<Base> n)\n  : next(std::move(n)) {}\n\n```\n In order for the user to call this, they must do one of the following: \n```\nBase newBase(std::move(nextBase));\nBase fromTemp(std::unique_ptr<Base>(new Base(...));', ""```\n To take a unique pointer by value means that you are transferring ownership of the pointer to the function/object/etc in question. After \n```\nnewBase\n```\n is constructed, \n```\nnextBase\n```\n is guaranteed to be empty. You don't own the object, and you don't even have a pointer to it anymore. It's gone. This is ensured because we take the parameter by value. \n```\nstd::move\n```\n doesn't actually move anything; it's just a fancy cast. \n```\nstd::move(nextBase)\n```\n returns a \n```\nBase&&\n```\n that is an r-value reference to \n```\nnextBase\n```\n. That's all it does. Because \n```\nBase::Base(std::unique_ptr<Base> n)\n```\n takes its argument by value rather than by r-value reference, C++ will automatically construct a temporary for us. It creates a \n```\nstd::unique_ptr<Base>\n```\n from the \n```\nBase&&\n```\n that we gave the function via \n```\nstd::move(nextBase)\n```\n. It is the construction of this temporary that actually moves the value from \n```\nnextBase\n```\n into the function argument \n```\nn"", '```\n that we gave the function via \n```\nstd::move(nextBase)\n```\n. It is the construction of this temporary that actually moves the value from \n```\nnextBase\n```\n into the function argument \n```\nn\n```\n. (B) By non-const l-value reference \n```\nBase(std::unique_ptr<Base> &n)\n  : next(std::move(n)) {}', ""```\n This has to be called on an actual l-value (a named variable). It cannot be called with a temporary like this: \n```\nBase newBase(std::unique_ptr<Base>(new Base)); //Illegal in this case.\n\n```\n The meaning of this is the same as the meaning of any other use of non-const references: the function may or may not claim ownership of the pointer. Given this code: \n```\nBase newBase(nextBase);\n\n```\n There is no guarantee that \n```\nnextBase\n```\n is empty. It may be empty; it may not. It really depends on what \n```\nBase::Base(std::unique_ptr<Base> &n)\n```\n wants to do. Because of that, it's not very evident just from the function signature what's going to happen; you have to read the implementation (or associated documentation). Because of that, I wouldn't suggest this as an interface. (C) By const l-value reference \n```\nBase(std::unique_ptr<Base> const &n);"", '```\n I don\'t show an implementation, because you cannot move from a \n```\nconst&\n```\n. By passing a \n```\nconst&\n```\n, you are saying that the function can access the \n```\nBase\n```\n via the pointer, but it cannot store it anywhere. It cannot claim ownership of it. This can be useful. Not necessarily for your specific case, but it\'s always good to be able to hand someone a pointer and know that they cannot (without breaking rules of C++, like no casting away \n```\nconst\n```\n) claim ownership of it. They can\'t store it. They can pass it to others, but those others have to abide by the same rules. (D) By r-value reference \n```\nBase(std::unique_ptr<Base> &&n)\n  : next(std::move(n)) {}\n\n```\n This is more or less identical to the ""by non-const l-value reference"" case. The differences are two things. You can pass a temporary: \n```\nBase newBase(std::unique_ptr<Base>(new Base)); //legal now..', '```\n You must use \n```\nstd::move\n```\n when passing non-temporary arguments. The latter is really the problem. If you see this line: \n```\nBase newBase(std::move(nextBase));', ""```\n You have a reasonable expectation that, after this line completes, \n```\nnextBase\n```\n should be empty. It should have been moved from. After all, you have that \n```\nstd::move\n```\n sitting there, telling you that movement has occurred. The problem is that it hasn't. It is not guaranteed to have been moved from. It may have been moved from, but you will only know by looking at the source code. You cannot tell just from the function signature. Recommendations (A) By Value: If you mean for a function to claim ownership of a \n```\nunique_ptr\n```\n, take it by value. (C) By const l-value reference: If you mean for a function to simply use the \n```\nunique_ptr\n```\n for the duration of that function's execution, take it by \n```\nconst&\n```\n. Alternatively, pass a \n```\n&\n```\n or \n```\nconst&\n```\n to the actual type pointed to, rather than using a \n```\nunique_ptr\n```\n. (D) By r-value reference: If a function may or may not claim ownership (depending on internal code paths), then take it by"", ""to the actual type pointed to, rather than using a \n```\nunique_ptr\n```\n. (D) By r-value reference: If a function may or may not claim ownership (depending on internal code paths), then take it by \n```\n&&\n```\n. But I strongly advise against doing this whenever possible. How to manipulate unique_ptr You cannot copy a \n```\nunique_ptr\n```\n. You can only move it. The proper way to do this is with the \n```\nstd::move\n```\n standard library function. If you take a \n```\nunique_ptr\n```\n by value, you can move from it freely. But movement doesn't actually happen because of \n```\nstd::move\n```\n. Take the following statement: \n```\nstd::unique_ptr<Base> newPtr(std::move(oldPtr));"", ""```\n This is really two statements: \n```\nstd::unique_ptr<Base> &&temporary = std::move(oldPtr);\nstd::unique_ptr<Base> newPtr(temporary);\n\n```\n (note: The above code does not technically compile, since non-temporary r-value references are not actually r-values. It is here for demo purposes only). The \n```\ntemporary\n```\n is just an r-value reference to \n```\noldPtr\n```\n. It is in the constructor of \n```\nnewPtr\n```\n where the movement happens. \n```\nunique_ptr\n```\n's move constructor (a constructor that takes a \n```\n&&\n```\n to itself) is what does the actual movement. If you have a \n```\nunique_ptr\n```\n value and you want to store it somewhere, you must use \n```\nstd::move\n```\n to do the storage.""]","Here are the possible ways to take a unique pointer as an argument, as well as their associated meaning. (A) By Value 
```
Base(std::unique_ptr<Base> n)
  : next(std::move(n)) {}

```
 In order for the user to call this, they must do one of the following: 
```
Base newBase(std::move(nextBase));
Base fromTemp(std::unique_ptr<Base>(new Base(...));

```
 To take a unique pointer by value means that you are transferring ownership of the pointer to the function/object/etc in question. After 
```
newBase
```
 is constructed, 
```
nextBase
```
 is guaranteed to be empty. You don't own the object, and you don't even have a pointer to it anymore. It's gone. This is ensured because we take the parameter by value. 
```
std::move
```
 doesn't actually move anything; it's just a fancy cast. 
```
std::move(nextBase)
```
 returns a 
```
Base&&
```
 that is an r-value reference to 
```
nextBase
```
. That's all it does. Because 
```
Base::Base(std::unique_ptr<Base> n)
```
 takes its argument by value rather than by r-value reference, C++ will automatically construct a temporary for us. It creates a 
```
std::unique_ptr<Base>
```
 from the 
```
Base&&
```
 that we gave the function via 
```
std::move(nextBase)
```
. It is the construction of this temporary that actually moves the value from 
```
nextBase
```
 into the function argument 
```
n
```
. (B) By non-const l-value reference 
```
Base(std::unique_ptr<Base> &n)
  : next(std::move(n)) {}

```
 This has to be called on an actual l-value (a named variable). It cannot be called with a temporary like this: 
```
Base newBase(std::unique_ptr<Base>(new Base)); //Illegal in this case.

```
 The meaning of this is the same as the meaning of any other use of non-const references: the function may or may not claim ownership of the pointer. Given this code: 
```
Base newBase(nextBase);

```
 There is no guarantee that 
```
nextBase
```
 is empty. It may be empty; it may not. It really depends on what 
```
Base::Base(std::unique_ptr<Base> &n)
```
 wants to do. Because of that, it's not very evident just from the function signature what's going to happen; you have to read the implementation (or associated documentation). Because of that, I wouldn't suggest this as an interface. (C) By const l-value reference 
```
Base(std::unique_ptr<Base> const &n);

```
 I don't show an implementation, because you cannot move from a 
```
const&
```
. By passing a 
```
const&
```
, you are saying that the function can access the 
```
Base
```
 via the pointer, but it cannot store it anywhere. It cannot claim ownership of it. This can be useful. Not necessarily for your specific case, but it's always good to be able to hand someone a pointer and know that they cannot (without breaking rules of C++, like no casting away 
```
const
```
) claim ownership of it. They can't store it. They can pass it to others, but those others have to abide by the same rules. (D) By r-value reference 
```
Base(std::unique_ptr<Base> &&n)
  : next(std::move(n)) {}

```
 This is more or less identical to the ""by non-const l-value reference"" case. The differences are two things. You can pass a temporary: 
```
Base newBase(std::unique_ptr<Base>(new Base)); //legal now..

```
 You must use 
```
std::move
```
 when passing non-temporary arguments. The latter is really the problem. If you see this line: 
```
Base newBase(std::move(nextBase));

```
 You have a reasonable expectation that, after this line completes, 
```
nextBase
```
 should be empty. It should have been moved from. After all, you have that 
```
std::move
```
 sitting there, telling you that movement has occurred. The problem is that it hasn't. It is not guaranteed to have been moved from. It may have been moved from, but you will only know by looking at the source code. You cannot tell just from the function signature. Recommendations (A) By Value: If you mean for a function to claim ownership of a 
```
unique_ptr
```
, take it by value. (C) By const l-value reference: If you mean for a function to simply use the 
```
unique_ptr
```
 for the duration of that function's execution, take it by 
```
const&
```
. Alternatively, pass a 
```
&
```
 or 
```
const&
```
 to the actual type pointed to, rather than using a 
```
unique_ptr
```
. (D) By r-value reference: If a function may or may not claim ownership (depending on internal code paths), then take it by 
```
&&
```
. But I strongly advise against doing this whenever possible. How to manipulate unique_ptr You cannot copy a 
```
unique_ptr
```
. You can only move it. The proper way to do this is with the 
```
std::move
```
 standard library function. If you take a 
```
unique_ptr
```
 by value, you can move from it freely. But movement doesn't actually happen because of 
```
std::move
```
. Take the following statement: 
```
std::unique_ptr<Base> newPtr(std::move(oldPtr));

```
 This is really two statements: 
```
std::unique_ptr<Base> &&temporary = std::move(oldPtr);
std::unique_ptr<Base> newPtr(temporary);

```
 (note: The above code does not technically compile, since non-temporary r-value references are not actually r-values. It is here for demo purposes only). The 
```
temporary
```
 is just an r-value reference to 
```
oldPtr
```
. It is in the constructor of 
```
newPtr
```
 where the movement happens. 
```
unique_ptr
```
's move constructor (a constructor that takes a 
```
&&
```
 to itself) is what does the actual movement. If you have a 
```
unique_ptr
```
 value and you want to store it somewhere, you must use 
```
std::move
```
 to do the storage."
9158894,Differences between C++ string == and compare()?,https://stackoverflow.com/questions/9158894/differences-between-c-string-and-compare,9,586.0,"[""This is what the standard has to say about \n```\noperator==\n```\n 21.4.8.2 operator== \n```\ntemplate<class charT, class traits, class Allocator>\nbool operator==(const basic_string<charT,traits,Allocator>& lhs,\n                const basic_string<charT,traits,Allocator>& rhs) noexcept;\n\n```\n Returns: lhs.compare(rhs) == 0. Seems like there isn't much of a difference!""]","This is what the standard has to say about 
```
operator==
```
 21.4.8.2 operator== 
```
template<class charT, class traits, class Allocator>
bool operator==(const basic_string<charT,traits,Allocator>& lhs,
                const basic_string<charT,traits,Allocator>& rhs) noexcept;

```
 Returns: lhs.compare(rhs) == 0. Seems like there isn't much of a difference!"
26281979,How do you loop through a std::map?,https://stackoverflow.com/questions/26281979/how-do-you-loop-through-a-stdmap,8,1005.0,"[""You can achieve this like following : \n```\nmap<string, int>::iterator it;\n\nfor (it = table.begin(); it != table.end(); it++)\n{\n    std::cout << it->first    // string (key)\n              << ':'\n              << it->second   // string's value \n              << std::endl;\n}\n\n```\n With C++11 ( and onwards ), \n```\nfor (auto const& x : table)\n{\n    std::cout << x.first  // string (key)\n              << ':' \n              << x.second // string's value \n              << std::endl;\n}\n\n```\n With C++17 ( and onwards ), \n```\nfor (auto const& [key, val] : table)\n{\n    std::cout << key        // string (key)\n              << ':'  \n              << val        // string's value\n              << std::endl;\n}\n\n```""]","You can achieve this like following : 
```
map<string, int>::iterator it;

for (it = table.begin(); it != table.end(); it++)
{
    std::cout << it->first    // string (key)
              << ':'
              << it->second   // string's value 
              << std::endl;
}

```
 With C++11 ( and onwards ), 
```
for (auto const& x : table)
{
    std::cout << x.first  // string (key)
              << ':' 
              << x.second // string's value 
              << std::endl;
}

```
 With C++17 ( and onwards ), 
```
for (auto const& [key, val] : table)
{
    std::cout << key        // string (key)
              << ':'  
              << val        // string's value
              << std::endl;
}

```
"
1461432,What is array-to-pointer conversion aka. decay?,https://stackoverflow.com/questions/1461432/what-is-array-to-pointer-conversion-aka-decay,11,364.0,"['It\'s said that arrays ""decay"" into pointers. A C++ array declared as \n```\nint numbers [5]\n```\n cannot be re-pointed, i.e. you can\'t say \n```\nnumbers = 0x5a5aff23\n```\n. More importantly the term decay signifies loss of type and dimension; \n```\nnumbers\n```\n decay into \n```\nint*\n```\n by losing the dimension information (count 5) and the type is not \n```\nint [5]\n```\n any more. Look here for cases where the decay doesn\'t happen. If you\'re passing an array by value, what you\'re really doing is copying a pointer - a pointer to the array\'s first element is copied to the parameter (whose type should also be a pointer the array element\'s type). This works due to array\'s decaying nature; once decayed, \n```\nsizeof\n```\n no longer gives the complete array\'s size, because it essentially becomes a pointer. This is why it\'s preferred (among other reasons) to pass by reference or pointer. Three ways to pass in an array1: \n```\nvoid by_value(const T* array)   // const T array[] means the same', '```\nvoid by_value(const T* array)   // const T array[] means the same\nvoid by_pointer(const T (*array)[U])\nvoid by_reference(const T (&array)[U])', ""```\n The last two will give proper \n```\nsizeof\n```\n info, while the first one won't since the array argument has decayed to be assigned to the parameter. 1 The constant U should be known at compile-time.""]","It's said that arrays ""decay"" into pointers. A C++ array declared as 
```
int numbers [5]
```
 cannot be re-pointed, i.e. you can't say 
```
numbers = 0x5a5aff23
```
. More importantly the term decay signifies loss of type and dimension; 
```
numbers
```
 decay into 
```
int*
```
 by losing the dimension information (count 5) and the type is not 
```
int [5]
```
 any more. Look here for cases where the decay doesn't happen. If you're passing an array by value, what you're really doing is copying a pointer - a pointer to the array's first element is copied to the parameter (whose type should also be a pointer the array element's type). This works due to array's decaying nature; once decayed, 
```
sizeof
```
 no longer gives the complete array's size, because it essentially becomes a pointer. This is why it's preferred (among other reasons) to pass by reference or pointer. Three ways to pass in an array1: 
```
void by_value(const T* array)   // const T array[] means the same
void by_pointer(const T (*array)[U])
void by_reference(const T (&array)[U])

```
 The last two will give proper 
```
sizeof
```
 info, while the first one won't since the array argument has decayed to be assigned to the parameter. 1 The constant U should be known at compile-time."
409348,Iteration over std::vector: unsigned vs signed index variable,https://stackoverflow.com/questions/409348/iteration-over-stdvector-unsigned-vs-signed-index-variable,18,858.0,"[""For iterating backwards see this answer. Iterating forwards is almost identical. Just change the iterators / swap decrement by increment. You should prefer iterators. Some people tell you to use \n```\nstd::size_t\n```\n as the index variable type. However, that is not portable. Always use the \n```\nsize_type\n```\n typedef of the container (While you could get away with only a conversion in the forward iterating case, it could actually go wrong all the way in the backward iterating case when using \n```\nstd::size_t\n```\n, in case \n```\nstd::size_t\n```\n is wider than what is the typedef of \n```\nsize_type\n```\n): Using std::vector Using iterators \n```\nfor(std::vector<T>::iterator it = v.begin(); it != v.end(); ++it) {\n    /* std::cout << *it; ... */\n}\n\n```\n Important is, always use the prefix increment form for iterators whose definitions you don't know. That will ensure your code runs as generic as possible. Using Range C++11 \n```\nfor(auto const& value: a) {\n     /* std::cout << value; ... */"", '```\n Using indices \n```\nfor(std::vector<int>::size_type i = 0; i != v.size(); i++) {\n    /* std::cout << v[i]; ... */\n}\n\n```\n Using arrays Using iterators \n```\nfor(element_type* it = a; it != (a + (sizeof a / sizeof *a)); it++) {\n    /* std::cout << *it; ... */\n}\n\n```\n Using Range C++11 \n```\nfor(auto const& value: a) {\n     /* std::cout << value; ... */\n\n```\n Using indices \n```\nfor(std::size_t i = 0; i != (sizeof a / sizeof *a); i++) {\n    /* std::cout << a[i]; ... */\n}\n\n```\n Read in the backward iterating answer what problem the \n```\nsizeof\n```\n approach can yield to, though.']","For iterating backwards see this answer. Iterating forwards is almost identical. Just change the iterators / swap decrement by increment. You should prefer iterators. Some people tell you to use 
```
std::size_t
```
 as the index variable type. However, that is not portable. Always use the 
```
size_type
```
 typedef of the container (While you could get away with only a conversion in the forward iterating case, it could actually go wrong all the way in the backward iterating case when using 
```
std::size_t
```
, in case 
```
std::size_t
```
 is wider than what is the typedef of 
```
size_type
```
): Using std::vector Using iterators 
```
for(std::vector<T>::iterator it = v.begin(); it != v.end(); ++it) {
    /* std::cout << *it; ... */
}

```
 Important is, always use the prefix increment form for iterators whose definitions you don't know. That will ensure your code runs as generic as possible. Using Range C++11 
```
for(auto const& value: a) {
     /* std::cout << value; ... */

```
 Using indices 
```
for(std::vector<int>::size_type i = 0; i != v.size(); i++) {
    /* std::cout << v[i]; ... */
}

```
 Using arrays Using iterators 
```
for(element_type* it = a; it != (a + (sizeof a / sizeof *a)); it++) {
    /* std::cout << *it; ... */
}

```
 Using Range C++11 
```
for(auto const& value: a) {
     /* std::cout << value; ... */

```
 Using indices 
```
for(std::size_t i = 0; i != (sizeof a / sizeof *a); i++) {
    /* std::cout << a[i]; ... */
}

```
 Read in the backward iterating answer what problem the 
```
sizeof
```
 approach can yield to, though."
12717138,What is Linux’s native GUI API?,https://stackoverflow.com/questions/12717138/what-is-linux-s-native-gui-api,11,655.0,"['In Linux the graphical user interface is not a part of the operating system. The graphical user interface found on most Linux desktops is provided by software called the X Window System, which defines a device independent way of dealing with screens, keyboards and pointer devices. X Window defines a network protocol for communication, and any program that knows how to ""speak"" this protocol can use it. There is a C library called Xlib that makes it easier to use this protocol, so Xlib is kind of the native GUI API. Xlib is not the only way to access an X Window server; there is also XCB. Toolkit libraries such as GTK+ (used by GNOME) and Qt (used by KDE), built on top of Xlib, are used because they are easier to program with. For example they give you a consistent look and feel across applications, make it easier to use drag-and-drop, provide components standard to a modern desktop environment, and so on. How X draws on the screen internally depends on the implementation. X.org has a', 'make it easier to use drag-and-drop, provide components standard to a modern desktop environment, and so on. How X draws on the screen internally depends on the implementation. X.org has a device independent part and a device dependent part. The former manages screen resources such as windows, while the latter communicates with the graphics card driver, usually a kernel module. The communication may happen over direct memory access or through system calls to the kernel. The driver translates the commands into a form that the hardware on the card understands. As of 2013, a new window system called Wayland is starting to become usable, and many distributions have said they will at some point migrate to it, though there is still no clear schedule. This system is based on OpenGL/ES API, which means that in the future OpenGL will be the ""native GUI API"" in Linux. Work is being done to port GTK+ and QT to Wayland, so that current popular applications and desktop systems would need minimal', 'means that in the future OpenGL will be the ""native GUI API"" in Linux. Work is being done to port GTK+ and QT to Wayland, so that current popular applications and desktop systems would need minimal changes. The applications that cannot be ported will be supported through an X11 server, much like OS X supports X11 apps through Xquartz. The GTK+ port is expected to be finished within a year, while Qt 5 already has complete Wayland support. To further complicate matters, Ubuntu has announced they are developing a new system called Mir because of problems they perceive with Wayland. This window system is also based on the OpenGL/ES API.']","In Linux the graphical user interface is not a part of the operating system. The graphical user interface found on most Linux desktops is provided by software called the X Window System, which defines a device independent way of dealing with screens, keyboards and pointer devices. X Window defines a network protocol for communication, and any program that knows how to ""speak"" this protocol can use it. There is a C library called Xlib that makes it easier to use this protocol, so Xlib is kind of the native GUI API. Xlib is not the only way to access an X Window server; there is also XCB. Toolkit libraries such as GTK+ (used by GNOME) and Qt (used by KDE), built on top of Xlib, are used because they are easier to program with. For example they give you a consistent look and feel across applications, make it easier to use drag-and-drop, provide components standard to a modern desktop environment, and so on. How X draws on the screen internally depends on the implementation. X.org has a device independent part and a device dependent part. The former manages screen resources such as windows, while the latter communicates with the graphics card driver, usually a kernel module. The communication may happen over direct memory access or through system calls to the kernel. The driver translates the commands into a form that the hardware on the card understands. As of 2013, a new window system called Wayland is starting to become usable, and many distributions have said they will at some point migrate to it, though there is still no clear schedule. This system is based on OpenGL/ES API, which means that in the future OpenGL will be the ""native GUI API"" in Linux. Work is being done to port GTK+ and QT to Wayland, so that current popular applications and desktop systems would need minimal changes. The applications that cannot be ported will be supported through an X11 server, much like OS X supports X11 apps through Xquartz. The GTK+ port is expected to be finished within a year, while Qt 5 already has complete Wayland support. To further complicate matters, Ubuntu has announced they are developing a new system called Mir because of problems they perceive with Wayland. This window system is also based on the OpenGL/ES API."
625799,Resolve build errors due to circular dependency amongst classes,https://stackoverflow.com/questions/625799/resolve-build-errors-due-to-circular-dependency-amongst-classes,12,396.0,"['The way to think about this is to ""think like a compiler"". Imagine you are writing a compiler. And you see code like this. \n```\n// file: A.h\nclass A {\n  B _b;\n};\n\n// file: B.h\nclass B {\n  A _a;\n};\n\n// file main.cc\n#include ""A.h""\n#include ""B.h""\nint main(...) {\n  A a;\n}', '// file: B.h\nclass B {\n  A _a;\n};\n\n// file main.cc\n#include ""A.h""\n#include ""B.h""\nint main(...) {\n  A a;\n}\n\n```\n When you are compiling the .cc file (remember that the .cc and not the .h is the unit of compilation), you need to allocate space for object \n```\nA\n```\n. So, well, how much space then? Enough to store \n```\nB\n```\n! What\'s the size of \n```\nB\n```\n then? Enough to store \n```\nA\n```\n! Oops. Clearly a circular reference that you must break. You can break it by allowing the compiler to instead reserve as much space as it knows about upfront - pointers and references, for example, will always be 32 or 64 bits (depending on the architecture) and so if you replaced (either one) by a pointer or reference, things would be great. Let\'s say we replace in \n```\nA\n```\n: \n```\n// file: A.h\nclass A {\n  // both these are fine, so are various const versions of the same.\n  B& _b_ref;\n  B* _b_ptr;\n};', '```\n Now things are better. Somewhat. \n```\nmain()\n```\n still says: \n```\n// file: main.cc\n#include ""A.h""  // <-- Houston, we have a problem\n\n```\n \n```\n#include\n```\n, for all extents and purposes (if you take the preprocessor out) just copies the file into the .cc. So really, the .cc looks like: \n```\n// file: partially_pre_processed_main.cc\nclass A {\n  B& _b_ref;\n  B* _b_ptr;\n};\n#include ""B.h""\nint main (...) {\n  A a;\n}\n\n```\n You can see why the compiler can\'t deal with this - it has no idea what \n```\nB\n```\n is - it has never even seen the symbol before. So let\'s tell the compiler about \n```\nB\n```\n. This is known as a forward declaration, and is discussed further in this answer. \n```\n// main.cc\nclass B;\n#include ""A.h""\n#include ""B.h""\nint main (...) {\n  A a;\n}', '```\n This works. It is not great. But at this point you should have an understanding of the circular reference problem and what we did to ""fix"" it, albeit the fix is bad. The reason this fix is bad is because the next person to \n```\n#include ""A.h""\n```\n will have to declare \n```\nB\n```\n before they can use it and will get a terrible \n```\n#include\n```\n error. So let\'s move the declaration into A.h itself. \n```\n// file: A.h\nclass B;\nclass A {\n  B* _b; // or any of the other variants.\n};\n\n```\n And in B.h, at this point, you can just \n```\n#include ""A.h""\n```\n directly. \n```\n// file: B.h\n#include ""A.h""\nclass B {\n  // note that this is cool because the compiler knows by this time\n  // how much space A will need.\n  A _a; \n}\n\n```\n HTH.']","The way to think about this is to ""think like a compiler"". Imagine you are writing a compiler. And you see code like this. 
```
// file: A.h
class A {
  B _b;
};

// file: B.h
class B {
  A _a;
};

// file main.cc
#include ""A.h""
#include ""B.h""
int main(...) {
  A a;
}

```
 When you are compiling the .cc file (remember that the .cc and not the .h is the unit of compilation), you need to allocate space for object 
```
A
```
. So, well, how much space then? Enough to store 
```
B
```
! What's the size of 
```
B
```
 then? Enough to store 
```
A
```
! Oops. Clearly a circular reference that you must break. You can break it by allowing the compiler to instead reserve as much space as it knows about upfront - pointers and references, for example, will always be 32 or 64 bits (depending on the architecture) and so if you replaced (either one) by a pointer or reference, things would be great. Let's say we replace in 
```
A
```
: 
```
// file: A.h
class A {
  // both these are fine, so are various const versions of the same.
  B& _b_ref;
  B* _b_ptr;
};

```
 Now things are better. Somewhat. 
```
main()
```
 still says: 
```
// file: main.cc
#include ""A.h""  // <-- Houston, we have a problem

```
 
```
#include
```
, for all extents and purposes (if you take the preprocessor out) just copies the file into the .cc. So really, the .cc looks like: 
```
// file: partially_pre_processed_main.cc
class A {
  B& _b_ref;
  B* _b_ptr;
};
#include ""B.h""
int main (...) {
  A a;
}

```
 You can see why the compiler can't deal with this - it has no idea what 
```
B
```
 is - it has never even seen the symbol before. So let's tell the compiler about 
```
B
```
. This is known as a forward declaration, and is discussed further in this answer. 
```
// main.cc
class B;
#include ""A.h""
#include ""B.h""
int main (...) {
  A a;
}

```
 This works. It is not great. But at this point you should have an understanding of the circular reference problem and what we did to ""fix"" it, albeit the fix is bad. The reason this fix is bad is because the next person to 
```
#include ""A.h""
```
 will have to declare 
```
B
```
 before they can use it and will get a terrible 
```
#include
```
 error. So let's move the declaration into A.h itself. 
```
// file: A.h
class B;
class A {
  B* _b; // or any of the other variants.
};

```
 And in B.h, at this point, you can just 
```
#include ""A.h""
```
 directly. 
```
// file: B.h
#include ""A.h""
class B {
  // note that this is cool because the compiler knows by this time
  // how much space A will need.
  A _a; 
}

```
 HTH."
7352099,std::string to char*,https://stackoverflow.com/questions/7352099/stdstring-to-char,18,850.0,"['It won\'t automatically convert (thank god). You\'ll have to use the method \n```\nc_str()\n```\n to get the C string version. \n```\nstd::string str = ""string"";\nconst char *cstr = str.c_str();\n\n```\n \n```\n.c_str()\n```\n returns a \n```\nconst char *\n```\n. If you want a non-const \n```\nchar *\n```\n, use \n```\n.data()\n```\n: \n```\nstd::string str = ""string"";\nchar *cstr = str.data();\n\n```\n Some other options: Copying the characters into a vector: \n```\nstd::vector<char> cstr(str.c_str(), str.c_str() + str.size() + 1);\n\n```\n Then \n```\ncstr.data()\n```\n will give you the pointer. This version copies the terminating \n```\n\\0\n```\n. If you don\'t want it, remove \n```\n+ 1\n```\n or do \n```\nstd::vector<char> cstr(str.begin(), str.end());\n```\n. Copying into a manually allocated array: (should normally be avoided, as manual memory management is easy to get wrong) \n```\nstd::string str = ""string"";\nchar *cstr = new char[str.size() + 1];\nstd::strcpy(cstr, str.c_str());\n// do stuff\ndelete [] cstr;\n\n```']","It won't automatically convert (thank god). You'll have to use the method 
```
c_str()
```
 to get the C string version. 
```
std::string str = ""string"";
const char *cstr = str.c_str();

```
 
```
.c_str()
```
 returns a 
```
const char *
```
. If you want a non-const 
```
char *
```
, use 
```
.data()
```
: 
```
std::string str = ""string"";
char *cstr = str.data();

```
 Some other options: Copying the characters into a vector: 
```
std::vector<char> cstr(str.c_str(), str.c_str() + str.size() + 1);

```
 Then 
```
cstr.data()
```
 will give you the pointer. This version copies the terminating 
```
\0
```
. If you don't want it, remove 
```
+ 1
```
 or do 
```
std::vector<char> cstr(str.begin(), str.end());
```
. Copying into a manually allocated array: (should normally be avoided, as manual memory management is easy to get wrong) 
```
std::string str = ""string"";
char *cstr = new char[str.size() + 1];
std::strcpy(cstr, str.c_str());
// do stuff
delete [] cstr;

```
"
13346879,const vs constexpr on variables,https://stackoverflow.com/questions/13346879/const-vs-constexpr-on-variables,6,544.0,"['I believe there is a difference. Let\'s rename them so that we can talk about them more easily: \n```\nconst     double PI1 = 3.141592653589793;\nconstexpr double PI2 = 3.141592653589793;\n\n```\n Both \n```\nPI1\n```\n and \n```\nPI2\n```\n are constant, meaning you can not modify them. However only \n```\nPI2\n```\n is a compile-time constant. It shall be initialized at compile time. \n```\nPI1\n```\n may be initialized at compile time or run time. Furthermore, only \n```\nPI2\n```\n can be used in a context that requires a compile-time constant. For example: \n```\nconstexpr double PI3 = PI1;  // error\n\n```\n but: \n```\nconstexpr double PI3 = PI2;  // ok\n\n```\n and: \n```\nstatic_assert(PI1 == 3.141592653589793, """");  // error\n\n```\n but: \n```\nstatic_assert(PI2 == 3.141592653589793, """");  // ok', '```\n but: \n```\nconstexpr double PI3 = PI2;  // ok\n\n```\n and: \n```\nstatic_assert(PI1 == 3.141592653589793, """");  // error\n\n```\n but: \n```\nstatic_assert(PI2 == 3.141592653589793, """");  // ok\n\n```\n As to which you should use? Use whichever meets your needs. Do you want to ensure that you have a compile time constant that can be used in contexts where a compile-time constant is required? Do you want to be able to initialize it with a computation done at run time? Etc.']","I believe there is a difference. Let's rename them so that we can talk about them more easily: 
```
const     double PI1 = 3.141592653589793;
constexpr double PI2 = 3.141592653589793;

```
 Both 
```
PI1
```
 and 
```
PI2
```
 are constant, meaning you can not modify them. However only 
```
PI2
```
 is a compile-time constant. It shall be initialized at compile time. 
```
PI1
```
 may be initialized at compile time or run time. Furthermore, only 
```
PI2
```
 can be used in a context that requires a compile-time constant. For example: 
```
constexpr double PI3 = PI1;  // error

```
 but: 
```
constexpr double PI3 = PI2;  // ok

```
 and: 
```
static_assert(PI1 == 3.141592653589793, """");  // error

```
 but: 
```
static_assert(PI2 == 3.141592653589793, """");  // ok

```
 As to which you should use? Use whichever meets your needs. Do you want to ensure that you have a compile time constant that can be used in contexts where a compile-time constant is required? Do you want to be able to initialize it with a computation done at run time? Etc."
2923272,How to convert vector to array,https://stackoverflow.com/questions/2923272/how-to-convert-vector-to-array,10,686.0,"[""There's a fairly simple trick to do so, since the spec now guarantees vectors store their elements contiguously: \n```\nstd::vector<double> v;\ndouble* a = &v[0];\n\n```""]","There's a fairly simple trick to do so, since the spec now guarantees vectors store their elements contiguously: 
```
std::vector<double> v;
double* a = &v[0];

```
"
53849,How do I tokenize a string in C++?,https://stackoverflow.com/questions/53849/how-do-i-tokenize-a-string-in-c,37,178.0,"['C++ standard library algorithms are pretty universally based around iterators rather than concrete containers. Unfortunately this makes it hard to provide a Java-like \n```\nsplit\n```\n function in the C++ standard library, even though nobody argues that this would be convenient. But what would its return type be? \n```\nstd::vector<std::basic_string<…>>\n```\n? Maybe, but then we’re forced to perform (potentially redundant and costly) allocations. Instead, C++ offers a plethora of ways to split strings based on arbitrarily complex delimiters, but none of them is encapsulated as nicely as in other languages. The numerous ways fill whole blog posts. At its simplest, you could iterate using \n```\nstd::string::find\n```\n until you hit \n```\nstd::string::npos\n```\n, and extract the contents using \n```\nstd::string::substr\n```\n. A more fluid (and idiomatic, but basic) version for splitting on whitespace would use a \n```\nstd::istringstream\n```\n: \n```\nauto iss = std::istringstream{""The quick brown fox""};', '```\n. A more fluid (and idiomatic, but basic) version for splitting on whitespace would use a \n```\nstd::istringstream\n```\n: \n```\nauto iss = std::istringstream{""The quick brown fox""};\nauto str = std::string{};', 'while (iss >> str) {\n    process(str);\n}\n\n```\n Using \n```\nstd::istream_iterator\n```\ns, the contents of the string stream could also be copied into a vector using its iterator range constructor. Multiple libraries (such as Boost.Tokenizer) offer specific tokenisers. More advanced splitting require regular expressions. C++ provides the \n```\nstd::regex_token_iterator\n```\n for this purpose in particular: \n```\nauto const str = ""The quick brown fox""s;\nauto const re = std::regex{R""(\\s+)""};\nauto const vec = std::vector<std::string>(\n    std::sregex_token_iterator{begin(str), end(str), re, -1},\n    std::sregex_token_iterator{}\n);\n\n```']","C++ standard library algorithms are pretty universally based around iterators rather than concrete containers. Unfortunately this makes it hard to provide a Java-like 
```
split
```
 function in the C++ standard library, even though nobody argues that this would be convenient. But what would its return type be? 
```
std::vector<std::basic_string<…>>
```
? Maybe, but then we’re forced to perform (potentially redundant and costly) allocations. Instead, C++ offers a plethora of ways to split strings based on arbitrarily complex delimiters, but none of them is encapsulated as nicely as in other languages. The numerous ways fill whole blog posts. At its simplest, you could iterate using 
```
std::string::find
```
 until you hit 
```
std::string::npos
```
, and extract the contents using 
```
std::string::substr
```
. A more fluid (and idiomatic, but basic) version for splitting on whitespace would use a 
```
std::istringstream
```
: 
```
auto iss = std::istringstream{""The quick brown fox""};
auto str = std::string{};

while (iss >> str) {
    process(str);
}

```
 Using 
```
std::istream_iterator
```
s, the contents of the string stream could also be copied into a vector using its iterator range constructor. Multiple libraries (such as Boost.Tokenizer) offer specific tokenisers. More advanced splitting require regular expressions. C++ provides the 
```
std::regex_token_iterator
```
 for this purpose in particular: 
```
auto const str = ""The quick brown fox""s;
auto const re = std::regex{R""(\s+)""};
auto const vec = std::vector<std::string>(
    std::sregex_token_iterator{begin(str), end(str), re, -1},
    std::sregex_token_iterator{}
);

```
"
1701067,How to check that an element is in a std::set?,https://stackoverflow.com/questions/1701067/how-to-check-that-an-element-is-in-a-stdset,12,587.0,"['Starting with C++20 you can use \n```\ncontains\n```\n to check for existence in many STL containers such as \n```\nstd::map\n```\n, \n```\nstd::set\n```\n, ...: \n```\nconst bool is_in = container.contains(element);\n\n```\n Pre C++20 the typical way was: \n```\nconst bool is_in = container.find(element) != container.end();\n\n```']","Starting with C++20 you can use 
```
contains
```
 to check for existence in many STL containers such as 
```
std::map
```
, 
```
std::set
```
, ...: 
```
const bool is_in = container.contains(element);

```
 Pre C++20 the typical way was: 
```
const bool is_in = container.find(element) != container.end();

```
"
10087113,How many levels of pointers can we have?,https://stackoverflow.com/questions/10087113/how-many-levels-of-pointers-can-we-have,15,,[],
21558,"In C++, what is a virtual base class?",https://stackoverflow.com/questions/21558/in-c-what-is-a-virtual-base-class,11,595.0,"['Virtual base classes, used in virtual inheritance, is a way of preventing multiple ""instances"" of a given class appearing in an inheritance hierarchy when using multiple inheritance. Consider the following scenario: \n```\nclass A { public: void Foo() {} };\nclass B : public A {};\nclass C : public A {};\nclass D : public B, public C {};\n\n```\n The above class hierarchy results in the ""dreaded diamond"" which looks like this: \n```\n  A\n / \\\nB   C\n \\ /\n  D\n\n```\n An instance of D will be made up of B, which includes A, and C which also includes A. So you have two ""instances"" (for want of a better expression) of A. When you have this scenario, you have the possibility of ambiguity. What happens when you do this: \n```\nD d;\nd.Foo(); // is this B\'s Foo() or C\'s Foo() ??', '```\n Virtual inheritance is there to solve this problem. When you specify virtual when inheriting your classes, you\'re telling the compiler that you only want a single instance. \n```\nclass A { public: void Foo() {} };\nclass B : public virtual A {};\nclass C : public virtual A {};\nclass D : public B, public C {};\n\n```\n This means that there is only one ""instance"" of A included in the hierarchy. Hence \n```\nD d;\nd.Foo(); // no longer ambiguous\n\n```\n This is a mini summary. For more information, have a read of this and this. A good example is also available here.']","Virtual base classes, used in virtual inheritance, is a way of preventing multiple ""instances"" of a given class appearing in an inheritance hierarchy when using multiple inheritance. Consider the following scenario: 
```
class A { public: void Foo() {} };
class B : public A {};
class C : public A {};
class D : public B, public C {};

```
 The above class hierarchy results in the ""dreaded diamond"" which looks like this: 
```
  A
 / \
B   C
 \ /
  D

```
 An instance of D will be made up of B, which includes A, and C which also includes A. So you have two ""instances"" (for want of a better expression) of A. When you have this scenario, you have the possibility of ambiguity. What happens when you do this: 
```
D d;
d.Foo(); // is this B's Foo() or C's Foo() ??

```
 Virtual inheritance is there to solve this problem. When you specify virtual when inheriting your classes, you're telling the compiler that you only want a single instance. 
```
class A { public: void Foo() {} };
class B : public virtual A {};
class C : public virtual A {};
class D : public B, public C {};

```
 This means that there is only one ""instance"" of A included in the hierarchy. Hence 
```
D d;
d.Foo(); // no longer ambiguous

```
 This is a mini summary. For more information, have a read of this and this. A good example is also available here."
1143936,#pragma once vs include guards?,https://stackoverflow.com/questions/1143936/pragma-once-vs-include-guards,13,436.0,"[""I don't think it will make a significant difference in compile time but \n```\n#pragma once\n```\n is very well supported across compilers but not actually part of the standard. The preprocessor may be a little faster with it as it is more simple to understand your exact intent. \n```\n#pragma once\n```\n is less prone to making mistakes and it is less code to type. To speed up compile time more just forward declare instead of including in .h files when you can. I prefer to use \n```\n#pragma once\n```\n. See this wikipedia article about the possibility of using both.""]","I don't think it will make a significant difference in compile time but 
```
#pragma once
```
 is very well supported across compilers but not actually part of the standard. The preprocessor may be a little faster with it as it is more simple to understand your exact intent. 
```
#pragma once
```
 is less prone to making mistakes and it is less code to type. To speed up compile time more just forward declare instead of including in .h files when you can. I prefer to use 
```
#pragma once
```
. See this wikipedia article about the possibility of using both."
5727,What are the barriers to understanding pointers and what can be done to overcome them?,https://stackoverflow.com/questions/5727/what-are-the-barriers-to-understanding-pointers-and-what-can-be-done-to-overcome,28,754.0,"['Pointers is a concept that for many can be confusing at first, in particular when it comes to copying pointer values around and still referencing the same memory block. I\'ve found that the best analogy is to consider the pointer as a piece of paper with a house address on it, and the memory block it references as the actual house. All sorts of operations can thus be easily explained. I\'ve added some Delphi code down below, and some comments where appropriate. I chose Delphi since my other main programming language, C#, does not exhibit things like memory leaks in the same way. If you only wish to learn the high-level concept of pointers, then you should ignore the parts labelled ""Memory layout"" in the explanation below. They are intended to give examples of what memory could look like after operations, but they are more low-level in nature. However, in order to accurately explain how buffer overruns really work, it was important that I added these diagrams. Disclaimer: For all intents', ""operations, but they are more low-level in nature. However, in order to accurately explain how buffer overruns really work, it was important that I added these diagrams. Disclaimer: For all intents and purposes, this explanation and the example memory layouts are vastly simplified. There's more overhead and a lot more details you would need to know if you need to deal with memory on a low-level basis. However, for the intents of explaining memory and pointers, it is accurate enough. Let's assume the THouse class used below looks like this:"", '```\ntype\n    THouse = class\n    private\n        FName : array[0..9] of Char;\n    public\n        constructor Create(name: PChar);\n    end;', '```', 'When you initialize the house object, the name given to the constructor is copied into the private field FName. There is a reason it is defined as a fixed-size array. In memory, there will be some overhead associated with the house allocation, I\'ll illustrate this below like this: ---[ttttNNNNNNNNNN]--- ^ ^ | | | +- the FName array | +- overhead The ""tttt"" area is overhead, there will typically be more of this for various types of runtimes and languages, like 8 or 12 bytes. It is imperative that whatever values are stored in this area never gets changed by anything other than the memory allocator or the core system routines, or you risk crashing the program. Allocate memory Get an entrepreneur to build your house, and give you the address to the house. In contrast to the real world, memory allocation cannot be told where to allocate, but will find a suitable spot with enough room, and report back the address to the allocated memory. In other words, the entrepreneur will choose the', 'allocation cannot be told where to allocate, but will find a suitable spot with enough room, and report back the address to the allocated memory. In other words, the entrepreneur will choose the spot.', ""```\nTHouse.Create('My house');"", ""```\n Memory layout: ---[ttttNNNNNNNNNN]--- 1234My house Keep a variable with the address Write the address to your new house down on a piece of paper. This paper will serve as your reference to your house. Without this piece of paper, you're lost, and cannot find the house, unless you're already in it. \n```\nvar\n    h: THouse;\nbegin\n    h := THouse.Create('My house');\n    ..."", ""```\n Memory layout: h v ---[ttttNNNNNNNNNN]--- 1234My house Copy pointer value Just write the address on a new piece of paper. You now have two pieces of paper that will get you to the same house, not two separate houses. Any attempts to follow the address from one paper and rearrange the furniture at that house will make it seem that the other house has been modified in the same manner, unless you can explicitly detect that it's actually just one house. Note This is usually the concept that I have the most problem explaining to people, two pointers does not mean two objects or memory blocks. \n```\nvar\n    h1, h2: THouse;\nbegin\n    h1 := THouse.Create('My house');\n    h2 := h1; // copies the address, not the house\n    ..."", ""```\n h1 v ---[ttttNNNNNNNNNN]--- 1234My house ^ h2 Freeing the memory Demolish the house. You can then later on reuse the paper for a new address if you so wish, or clear it to forget the address to the house that no longer exists. \n```\nvar\n    h: THouse;\nbegin\n    h := THouse.Create('My house');\n    ...\n    h.Free;\n    h := nil;"", ""```\n Here I first construct the house, and get hold of its address. Then I do something to the house (use it, the ... code, left as an exercise for the reader), and then I free it. Lastly I clear the address from my variable. Memory layout: h <--+ v +- before free ---[ttttNNNNNNNNNN]--- | 1234My house <--+ h (now points nowhere) <--+ +- after free ---------------------- | (note, memory might still xx34My house <--+ contain some data) Dangling pointers You tell your entrepreneur to destroy the house, but you forget to erase the address from your piece of paper. When later on you look at the piece of paper, you've forgotten that the house is no longer there, and goes to visit it, with failed results (see also the part about an invalid reference below). \n```\nvar\n    h: THouse;\nbegin\n    h := THouse.Create('My house');\n    ...\n    h.Free;\n    ... // forgot to clear h here\n    h.OpenFrontDoor; // will most likely fail"", ""```\n Using \n```\nh\n```\n after the call to \n```\n.Free\n```\n might work, but that is just pure luck. Most likely it will fail, at a customers place, in the middle of a critical operation. h <--+ v +- before free ---[ttttNNNNNNNNNN]--- | 1234My house <--+ h <--+ v +- after free ---------------------- | xx34My house <--+ As you can see, h still points to the remnants of the data in memory, but since it might not be complete, using it as before might fail. Memory leak You lose the piece of paper and cannot find the house. The house is still standing somewhere though, and when you later on want to construct a new house, you cannot reuse that spot. \n```\nvar\n    h: THouse;\nbegin\n    h := THouse.Create('My house');\n    h := THouse.Create('My house'); // uh-oh, what happened to our first house?\n    ...\n    h.Free;\n    h := nil;"", ""```\n Here we overwrote the contents of the \n```\nh\n```\n variable with the address of a new house, but the old one is still standing... somewhere. After this code, there is no way to reach that house, and it will be left standing. In other words, the allocated memory will stay allocated until the application closes, at which point the operating system will tear it down. Memory layout after first allocation: h v ---[ttttNNNNNNNNNN]--- 1234My house Memory layout after second allocation: h v ---[ttttNNNNNNNNNN]---[ttttNNNNNNNNNN] 1234My house 5678My house A more common way to get this method is just to forget to free something, instead of overwriting it as above. In Delphi terms, this will occur with the following method: \n```\nprocedure OpenTheFrontDoorOfANewHouse;\nvar\n    h: THouse;\nbegin\n    h := THouse.Create('My house');\n    h.OpenFrontDoor;\n    // uh-oh, no .Free here, where does the address go?\nend;"", '```', ""After this method has executed, there's no place in our variables that the address to the house exists, but the house is still out there. Memory layout: h <--+ v +- before losing pointer ---[ttttNNNNNNNNNN]--- | 1234My house <--+ h (now points nowhere) <--+ +- after losing pointer ---[ttttNNNNNNNNNN]--- | 1234My house <--+ As you can see, the old data is left intact in memory, and will not be reused by the memory allocator. The allocator keeps track of which areas of memory has been used, and will not reuse them unless you free it. Freeing the memory but keeping a (now invalid) reference Demolish the house, erase one of the pieces of paper but you also have another piece of paper with the old address on it, when you go to the address, you won't find a house, but you might find something that resembles the ruins of one. Perhaps you will even find a house, but it is not the house you were originally given the address to, and thus any attempts to use it as though it belongs to you might"", 'resembles the ruins of one. Perhaps you will even find a house, but it is not the house you were originally given the address to, and thus any attempts to use it as though it belongs to you might fail horribly. Sometimes you might even find that a neighbouring address has a rather big house set up on it that occupies three address (Main Street 1-3), and your address goes to the middle of the house. Any attempts to treat that part of the large 3-address house as a single small house might also fail horribly.', ""```\nvar\n    h1, h2: THouse;\nbegin\n    h1 := THouse.Create('My house');\n    h2 := h1; // copies the address, not the house\n    ...\n    h1.Free;\n    h1 := nil;\n    h2.OpenFrontDoor; // uh-oh, what happened to our house?"", ""```\n Here the house was torn down, through the reference in \n```\nh1\n```\n, and while \n```\nh1\n```\n was cleared as well, \n```\nh2\n```\n still has the old, out-of-date, address. Access to the house that is no longer standing might or might not work. This is a variation of the dangling pointer above. See its memory layout. Buffer overrun You move more stuff into the house than you can possibly fit, spilling into the neighbours house or yard. When the owner of that neighbouring house later on comes home, he'll find all sorts of things he'll consider his own. This is the reason I chose a fixed-size array. To set the stage, assume that the second house we allocate will, for some reason, be placed before the first one in memory. In other words, the second house will have a lower address than the first one. Also, they're allocated right next to each other. Thus, this code: \n```\nvar\n    h1, h2: THouse;\nbegin\n    h1 := THouse.Create('My house');\n    h2 := THouse.Create('My other house somewhere');"", ""```\nvar\n    h1, h2: THouse;\nbegin\n    h1 := THouse.Create('My house');\n    h2 := THouse.Create('My other house somewhere');\n                         ^-----------------------^\n                          longer than 10 characters\n                         0123456789 <-- 10 characters"", ""```\n Memory layout after first allocation: h1 v -----------------------[ttttNNNNNNNNNN] 5678My house Memory layout after second allocation: h2 h1 v v ---[ttttNNNNNNNNNN]----[ttttNNNNNNNNNN] 1234My other house somewhereouse ^---+--^ | +- overwritten The part that will most often cause crash is when you overwrite important parts of the data you stored that really should not be randomly changed. For instance it might not be a problem that parts of the name of the h1-house was changed, in terms of crashing the program, but overwriting the overhead of the object will most likely crash when you try to use the broken object, as will overwriting links that is stored to other objects in the object. Linked lists When you follow an address on a piece of paper, you get to a house, and at that house there is another piece of paper with a new address on it, for the next house in the chain, and so on. \n```\nvar\n    h1, h2: THouse;\nbegin\n    h1 := THouse.Create('Home');"", ""```\nvar\n    h1, h2: THouse;\nbegin\n    h1 := THouse.Create('Home');\n    h2 := THouse.Create('Cabin');\n    h1.NextHouse := h2;"", ""```\n Here we create a link from our home house to our cabin. We can follow the chain until a house has no \n```\nNextHouse\n```\n reference, which means it's the last one. To visit all our houses, we could use the following code: \n```\nvar\n    h1, h2: THouse;\n    h: THouse;\nbegin\n    h1 := THouse.Create('Home');\n    h2 := THouse.Create('Cabin');\n    h1.NextHouse := h2;\n    ...\n    h := h1;\n    while h <> nil do\n    begin\n        h.LockAllDoors;\n        h.CloseAllWindows;\n        h := h.NextHouse;\n    end;"", '```', 'Memory layout (added NextHouse as a link in the object, noted with the four LLLL\'s in the below diagram): h1 h2 v v ---[ttttNNNNNNNNNNLLLL]----[ttttNNNNNNNNNNLLLL] 1234Home + 5678Cabin + | ^ | +--------+ * (no link) In basic terms, what is a memory address? A memory address is in basic terms just a number. If you think of memory as a big array of bytes, the very first byte has the address 0, the next one the address 1 and so on upwards. This is simplified, but good enough. So this memory layout: h1 h2 v v ---[ttttNNNNNNNNNN]---[ttttNNNNNNNNNN] 1234My house 5678My house Might have these two address (the leftmost - is address 0): h1 = 4 h2 = 23 Which means that our linked list above might actuall look like this: h1 (=4) h2 (=28) v v ---[ttttNNNNNNNNNNLLLL]----[ttttNNNNNNNNNNLLLL] 1234Home 0028 5678Cabin 0000 | ^ | +--------+ * (no link) It is typical to store an address that ""points nowhere"" as a zero-address. In basic terms, what is a pointer? A pointer is just a variable holding a', '0028 5678Cabin 0000 | ^ | +--------+ * (no link) It is typical to store an address that ""points nowhere"" as a zero-address. In basic terms, what is a pointer? A pointer is just a variable holding a memory address. You can typically ask the programming language to give you its number, but most programming languages and runtimes tries to hide the fact that there is a number beneath, just because the number itself does not really hold any meaning to you. It is best to think of a pointer as a black box, ie. you don\'t really know or care about how it is actually implemented, just as long as it works.']","Pointers is a concept that for many can be confusing at first, in particular when it comes to copying pointer values around and still referencing the same memory block. I've found that the best analogy is to consider the pointer as a piece of paper with a house address on it, and the memory block it references as the actual house. All sorts of operations can thus be easily explained. I've added some Delphi code down below, and some comments where appropriate. I chose Delphi since my other main programming language, C#, does not exhibit things like memory leaks in the same way. If you only wish to learn the high-level concept of pointers, then you should ignore the parts labelled ""Memory layout"" in the explanation below. They are intended to give examples of what memory could look like after operations, but they are more low-level in nature. However, in order to accurately explain how buffer overruns really work, it was important that I added these diagrams. Disclaimer: For all intents and purposes, this explanation and the example memory layouts are vastly simplified. There's more overhead and a lot more details you would need to know if you need to deal with memory on a low-level basis. However, for the intents of explaining memory and pointers, it is accurate enough. Let's assume the THouse class used below looks like this: 
```
type
    THouse = class
    private
        FName : array[0..9] of Char;
    public
        constructor Create(name: PChar);
    end;

```
 When you initialize the house object, the name given to the constructor is copied into the private field FName. There is a reason it is defined as a fixed-size array. In memory, there will be some overhead associated with the house allocation, I'll illustrate this below like this: ---[ttttNNNNNNNNNN]--- ^ ^ | | | +- the FName array | +- overhead The ""tttt"" area is overhead, there will typically be more of this for various types of runtimes and languages, like 8 or 12 bytes. It is imperative that whatever values are stored in this area never gets changed by anything other than the memory allocator or the core system routines, or you risk crashing the program. Allocate memory Get an entrepreneur to build your house, and give you the address to the house. In contrast to the real world, memory allocation cannot be told where to allocate, but will find a suitable spot with enough room, and report back the address to the allocated memory. In other words, the entrepreneur will choose the spot. 
```
THouse.Create('My house');

```
 Memory layout: ---[ttttNNNNNNNNNN]--- 1234My house Keep a variable with the address Write the address to your new house down on a piece of paper. This paper will serve as your reference to your house. Without this piece of paper, you're lost, and cannot find the house, unless you're already in it. 
```
var
    h: THouse;
begin
    h := THouse.Create('My house');
    ...

```
 Memory layout: h v ---[ttttNNNNNNNNNN]--- 1234My house Copy pointer value Just write the address on a new piece of paper. You now have two pieces of paper that will get you to the same house, not two separate houses. Any attempts to follow the address from one paper and rearrange the furniture at that house will make it seem that the other house has been modified in the same manner, unless you can explicitly detect that it's actually just one house. Note This is usually the concept that I have the most problem explaining to people, two pointers does not mean two objects or memory blocks. 
```
var
    h1, h2: THouse;
begin
    h1 := THouse.Create('My house');
    h2 := h1; // copies the address, not the house
    ...

```
 h1 v ---[ttttNNNNNNNNNN]--- 1234My house ^ h2 Freeing the memory Demolish the house. You can then later on reuse the paper for a new address if you so wish, or clear it to forget the address to the house that no longer exists. 
```
var
    h: THouse;
begin
    h := THouse.Create('My house');
    ...
    h.Free;
    h := nil;

```
 Here I first construct the house, and get hold of its address. Then I do something to the house (use it, the ... code, left as an exercise for the reader), and then I free it. Lastly I clear the address from my variable. Memory layout: h <--+ v +- before free ---[ttttNNNNNNNNNN]--- | 1234My house <--+ h (now points nowhere) <--+ +- after free ---------------------- | (note, memory might still xx34My house <--+ contain some data) Dangling pointers You tell your entrepreneur to destroy the house, but you forget to erase the address from your piece of paper. When later on you look at the piece of paper, you've forgotten that the house is no longer there, and goes to visit it, with failed results (see also the part about an invalid reference below). 
```
var
    h: THouse;
begin
    h := THouse.Create('My house');
    ...
    h.Free;
    ... // forgot to clear h here
    h.OpenFrontDoor; // will most likely fail

```
 Using 
```
h
```
 after the call to 
```
.Free
```
 might work, but that is just pure luck. Most likely it will fail, at a customers place, in the middle of a critical operation. h <--+ v +- before free ---[ttttNNNNNNNNNN]--- | 1234My house <--+ h <--+ v +- after free ---------------------- | xx34My house <--+ As you can see, h still points to the remnants of the data in memory, but since it might not be complete, using it as before might fail. Memory leak You lose the piece of paper and cannot find the house. The house is still standing somewhere though, and when you later on want to construct a new house, you cannot reuse that spot. 
```
var
    h: THouse;
begin
    h := THouse.Create('My house');
    h := THouse.Create('My house'); // uh-oh, what happened to our first house?
    ...
    h.Free;
    h := nil;

```
 Here we overwrote the contents of the 
```
h
```
 variable with the address of a new house, but the old one is still standing... somewhere. After this code, there is no way to reach that house, and it will be left standing. In other words, the allocated memory will stay allocated until the application closes, at which point the operating system will tear it down. Memory layout after first allocation: h v ---[ttttNNNNNNNNNN]--- 1234My house Memory layout after second allocation: h v ---[ttttNNNNNNNNNN]---[ttttNNNNNNNNNN] 1234My house 5678My house A more common way to get this method is just to forget to free something, instead of overwriting it as above. In Delphi terms, this will occur with the following method: 
```
procedure OpenTheFrontDoorOfANewHouse;
var
    h: THouse;
begin
    h := THouse.Create('My house');
    h.OpenFrontDoor;
    // uh-oh, no .Free here, where does the address go?
end;

```
 After this method has executed, there's no place in our variables that the address to the house exists, but the house is still out there. Memory layout: h <--+ v +- before losing pointer ---[ttttNNNNNNNNNN]--- | 1234My house <--+ h (now points nowhere) <--+ +- after losing pointer ---[ttttNNNNNNNNNN]--- | 1234My house <--+ As you can see, the old data is left intact in memory, and will not be reused by the memory allocator. The allocator keeps track of which areas of memory has been used, and will not reuse them unless you free it. Freeing the memory but keeping a (now invalid) reference Demolish the house, erase one of the pieces of paper but you also have another piece of paper with the old address on it, when you go to the address, you won't find a house, but you might find something that resembles the ruins of one. Perhaps you will even find a house, but it is not the house you were originally given the address to, and thus any attempts to use it as though it belongs to you might fail horribly. Sometimes you might even find that a neighbouring address has a rather big house set up on it that occupies three address (Main Street 1-3), and your address goes to the middle of the house. Any attempts to treat that part of the large 3-address house as a single small house might also fail horribly. 
```
var
    h1, h2: THouse;
begin
    h1 := THouse.Create('My house');
    h2 := h1; // copies the address, not the house
    ...
    h1.Free;
    h1 := nil;
    h2.OpenFrontDoor; // uh-oh, what happened to our house?

```
 Here the house was torn down, through the reference in 
```
h1
```
, and while 
```
h1
```
 was cleared as well, 
```
h2
```
 still has the old, out-of-date, address. Access to the house that is no longer standing might or might not work. This is a variation of the dangling pointer above. See its memory layout. Buffer overrun You move more stuff into the house than you can possibly fit, spilling into the neighbours house or yard. When the owner of that neighbouring house later on comes home, he'll find all sorts of things he'll consider his own. This is the reason I chose a fixed-size array. To set the stage, assume that the second house we allocate will, for some reason, be placed before the first one in memory. In other words, the second house will have a lower address than the first one. Also, they're allocated right next to each other. Thus, this code: 
```
var
    h1, h2: THouse;
begin
    h1 := THouse.Create('My house');
    h2 := THouse.Create('My other house somewhere');
                         ^-----------------------^
                          longer than 10 characters
                         0123456789 <-- 10 characters

```
 Memory layout after first allocation: h1 v -----------------------[ttttNNNNNNNNNN] 5678My house Memory layout after second allocation: h2 h1 v v ---[ttttNNNNNNNNNN]----[ttttNNNNNNNNNN] 1234My other house somewhereouse ^---+--^ | +- overwritten The part that will most often cause crash is when you overwrite important parts of the data you stored that really should not be randomly changed. For instance it might not be a problem that parts of the name of the h1-house was changed, in terms of crashing the program, but overwriting the overhead of the object will most likely crash when you try to use the broken object, as will overwriting links that is stored to other objects in the object. Linked lists When you follow an address on a piece of paper, you get to a house, and at that house there is another piece of paper with a new address on it, for the next house in the chain, and so on. 
```
var
    h1, h2: THouse;
begin
    h1 := THouse.Create('Home');
    h2 := THouse.Create('Cabin');
    h1.NextHouse := h2;

```
 Here we create a link from our home house to our cabin. We can follow the chain until a house has no 
```
NextHouse
```
 reference, which means it's the last one. To visit all our houses, we could use the following code: 
```
var
    h1, h2: THouse;
    h: THouse;
begin
    h1 := THouse.Create('Home');
    h2 := THouse.Create('Cabin');
    h1.NextHouse := h2;
    ...
    h := h1;
    while h <> nil do
    begin
        h.LockAllDoors;
        h.CloseAllWindows;
        h := h.NextHouse;
    end;

```
 Memory layout (added NextHouse as a link in the object, noted with the four LLLL's in the below diagram): h1 h2 v v ---[ttttNNNNNNNNNNLLLL]----[ttttNNNNNNNNNNLLLL] 1234Home + 5678Cabin + | ^ | +--------+ * (no link) In basic terms, what is a memory address? A memory address is in basic terms just a number. If you think of memory as a big array of bytes, the very first byte has the address 0, the next one the address 1 and so on upwards. This is simplified, but good enough. So this memory layout: h1 h2 v v ---[ttttNNNNNNNNNN]---[ttttNNNNNNNNNN] 1234My house 5678My house Might have these two address (the leftmost - is address 0): h1 = 4 h2 = 23 Which means that our linked list above might actuall look like this: h1 (=4) h2 (=28) v v ---[ttttNNNNNNNNNNLLLL]----[ttttNNNNNNNNNNLLLL] 1234Home 0028 5678Cabin 0000 | ^ | +--------+ * (no link) It is typical to store an address that ""points nowhere"" as a zero-address. In basic terms, what is a pointer? A pointer is just a variable holding a memory address. You can typically ask the programming language to give you its number, but most programming languages and runtimes tries to hide the fact that there is a number beneath, just because the number itself does not really hold any meaning to you. It is best to think of a pointer as a black box, ie. you don't really know or care about how it is actually implemented, just as long as it works."
31816095,Why should I not #include <bits/stdc++.h>?,https://stackoverflow.com/questions/31816095/why-should-i-not-include-bits-stdc-h,10,527.0,"['Including \n```\n<bits/stdc++.h>\n```\n appears to be an increasingly common thing to see on Stack Overflow, perhaps something newly added to a national curriculum in the current academic year. I imagine the advantages are vaguely given thus: You only need write one \n```\n#include\n```\n line. You do not need to look up which standard header everything is in. Unfortunately, this is a lazy hack, naming a GCC internal header directly instead of individual standard headers like \n```\n<string>\n```\n, \n```\n<iostream>\n```\n and \n```\n<vector>\n```', ""```\n<string>\n```\n, \n```\n<iostream>\n```\n and \n```\n<vector>\n```\n. It ruins portability and fosters terrible habits. The disadvantages include: It will probably only work on that compiler. You have no idea what it'll do when you use it, because its contents are not set by a standard. Even just upgrading your compiler to its own next version may break your program. Every single standard header must be parsed and compiled along with your source code, which is slow and results in a bulky executable under certain compilation settings. Don't do it! More information: #include <bits/stdc++.h> with visual studio does not compile How does #include <bits/stdc++.h> work in C++? Example of why Quora is bad: Is it good practice to use #include <bits/stdc++.h> in programming contests instead of listing a lot of includes?""]","Including 
```
<bits/stdc++.h>
```
 appears to be an increasingly common thing to see on Stack Overflow, perhaps something newly added to a national curriculum in the current academic year. I imagine the advantages are vaguely given thus: You only need write one 
```
#include
```
 line. You do not need to look up which standard header everything is in. Unfortunately, this is a lazy hack, naming a GCC internal header directly instead of individual standard headers like 
```
<string>
```
, 
```
<iostream>
```
 and 
```
<vector>
```
. It ruins portability and fosters terrible habits. The disadvantages include: It will probably only work on that compiler. You have no idea what it'll do when you use it, because its contents are not set by a standard. Even just upgrading your compiler to its own next version may break your program. Every single standard header must be parsed and compiled along with your source code, which is slow and results in a bulky executable under certain compilation settings. Don't do it! More information: #include <bits/stdc++.h> with visual studio does not compile How does #include <bits/stdc++.h> work in C++? Example of why Quora is bad: Is it good practice to use #include <bits/stdc++.h> in programming contests instead of listing a lot of includes?"
233328,How do I print the full value of a long string in gdb?,https://stackoverflow.com/questions/233328/how-do-i-print-the-full-value-of-a-long-string-in-gdb,6,630.0,"['```\nset print elements 0\n\n```\n From the GDB manual: \n```\nset print elements \n```\n\n```\nnumber-of-elements\n```\n Set a limit on how many elements of an array GDB will print. If GDB is printing a large array, it stops printing after it has printed the number of elements set by the \n```\nset print elements\n```\n command. This limit also applies to the display of strings. When GDB starts, this limit is set to 200. Setting number-of-elements to zero means that the printing is unlimited.']","
```
set print elements 0

```
 From the GDB manual: 
```
set print elements 
```

```
number-of-elements
```
 Set a limit on how many elements of an array GDB will print. If GDB is printing a large array, it stops printing after it has printed the number of elements set by the 
```
set print elements
```
 command. This limit also applies to the display of strings. When GDB starts, this limit is set to 200. Setting number-of-elements to zero means that the printing is unlimited."
1358400,What is external linkage and internal linkage?,https://stackoverflow.com/questions/1358400/what-is-external-linkage-and-internal-linkage,9,402.0,"['When you write an implementation file (\n```\n.cpp\n```\n, \n```\n.cxx\n```\n, etc) your compiler generates a translation unit. This is the source file from your implementation plus all the headers you \n```\n#include\n```\nd in it. Internal linkage refers to everything only in scope of a translation unit. External linkage refers to things that exist beyond a particular translation unit. In other words, accessible through the whole program, which is the combination of all translation units (or object files).']","When you write an implementation file (
```
.cpp
```
, 
```
.cxx
```
, etc) your compiler generates a translation unit. This is the source file from your implementation plus all the headers you 
```
#include
```
d in it. Internal linkage refers to everything only in scope of a translation unit. External linkage refers to things that exist beyond a particular translation unit. In other words, accessible through the whole program, which is the combination of all translation units (or object files)."
7058339,When should I use pointers instead of references in API-design?,https://stackoverflow.com/questions/7058339/when-should-i-use-pointers-instead-of-references-in-api-design,17,385.0,"[""Use references wherever you can, and pointers wherever you must. Avoid pointers until you can't. The reason is that pointers make things harder to follow/read, less safe and far more dangerous manipulations than any other constructs. So the rule of thumb is to use pointers only if there is no other choice. For example, returning a pointer to an object is a valid option when the function can return \n```\nnullptr\n```\n in some cases and it is assumed it will. That said, a better option would be to use something similar to \n```\nstd::optional\n```\n (requires C++17; before that, there's \n```\nboost::optional\n```\n). Another example is to use pointers to raw memory for specific memory manipulations. That should be hidden and localized in very narrow parts of the code, to help limit the dangerous parts of the whole code base. In your example, there is no point in using a pointer as an argument because: if you provide \n```\nnullptr\n```"", ""```\nnullptr\n```\n as the argument, you're going in undefined-behaviour-land; the reference attribute version doesn't allow (without easy-to-spot tricks) the problem with 1. the reference attribute version is simpler to understand for the user: you have to provide a valid object, not something that could be null. If the behaviour of the function would have to work with or without a given object, then using a pointer as an attribute suggests that you can pass \n```\nnullptr\n```\n as the argument and it is fine for the function. That's kind of a contract between the user and the implementation.""]","Use references wherever you can, and pointers wherever you must. Avoid pointers until you can't. The reason is that pointers make things harder to follow/read, less safe and far more dangerous manipulations than any other constructs. So the rule of thumb is to use pointers only if there is no other choice. For example, returning a pointer to an object is a valid option when the function can return 
```
nullptr
```
 in some cases and it is assumed it will. That said, a better option would be to use something similar to 
```
std::optional
```
 (requires C++17; before that, there's 
```
boost::optional
```
). Another example is to use pointers to raw memory for specific memory manipulations. That should be hidden and localized in very narrow parts of the code, to help limit the dangerous parts of the whole code base. In your example, there is no point in using a pointer as an argument because: if you provide 
```
nullptr
```
 as the argument, you're going in undefined-behaviour-land; the reference attribute version doesn't allow (without easy-to-spot tricks) the problem with 1. the reference attribute version is simpler to understand for the user: you have to provide a valid object, not something that could be null. If the behaviour of the function would have to work with or without a given object, then using a pointer as an attribute suggests that you can pass 
```
nullptr
```
 as the argument and it is fine for the function. That's kind of a contract between the user and the implementation."
162941,Why use pointers?,https://stackoverflow.com/questions/162941/why-use-pointers,17,,[],
5508110,Why is this program erroneously rejected by three C++ compilers?,https://stackoverflow.com/questions/5508110/why-is-this-program-erroneously-rejected-by-three-c-compilers,31,173.0,"[""In the standard, §2.1/1 specifies: Physical source file characters are mapped, in an implementation-defined manner, to the basic source character set (introducing new-line characters for end-of-line indicators) if necessary. Your compiler doesn't support that format (aka cannot map it to the basic source character set), so it cannot move into further processing stages, hence the error. It is entirely possible that your compiler support a mapping from image to basic source character set, but is not required to. Since this mapping is implementation-defined, you'll need to look at your implementations documentation to see the file formats it supports. Typically, every major compiler vendor supports (canonically defined) text files: any file produced by a text editor, typically a series of characters. Note that the C++ standard is based off the C standard (§1.1/2), and the C(99) standard says, in §1.2: This International Standard does not specify — the mechanism by which C programs are"", 'characters. Note that the C++ standard is based off the C standard (§1.1/2), and the C(99) standard says, in §1.2: This International Standard does not specify — the mechanism by which C programs are transformed for use by a data-processing system; — the mechanism by which C programs are invoked for use by a data-processing system; — the mechanism by which input data are transformed for use by a C program; So, again, the treatment of source files is something you need to find in your compilers documentation.']","In the standard, §2.1/1 specifies: Physical source file characters are mapped, in an implementation-defined manner, to the basic source character set (introducing new-line characters for end-of-line indicators) if necessary. Your compiler doesn't support that format (aka cannot map it to the basic source character set), so it cannot move into further processing stages, hence the error. It is entirely possible that your compiler support a mapping from image to basic source character set, but is not required to. Since this mapping is implementation-defined, you'll need to look at your implementations documentation to see the file formats it supports. Typically, every major compiler vendor supports (canonically defined) text files: any file produced by a text editor, typically a series of characters. Note that the C++ standard is based off the C standard (§1.1/2), and the C(99) standard says, in §1.2: This International Standard does not specify — the mechanism by which C programs are transformed for use by a data-processing system; — the mechanism by which C programs are invoked for use by a data-processing system; — the mechanism by which input data are transformed for use by a C program; So, again, the treatment of source files is something you need to find in your compilers documentation."
1887097,Why aren't variable-length arrays part of the C++ standard?,https://stackoverflow.com/questions/1887097/why-arent-variable-length-arrays-part-of-the-c-standard,10,252.0,"[""There recently was a discussion about this kicked off in usenet: Why no VLAs in C++0x. I agree with those people that seem to agree that having to create a potential large array on the stack, which usually has only little space available, isn't good. The argument is, if you know the size beforehand, you can use a static array. And if you don't know the size beforehand, you will write unsafe code. C99 VLAs could provide a small benefit of being able to create small arrays without wasting space or calling constructors for unused elements, but they will introduce rather large changes to the type system (you need to be able to specify types depending on runtime values - this does not yet exist in current C++, except for \n```\nnew\n```\n operator type-specifiers, but they are treated specially, so that the runtime-ness doesn't escape the scope of the \n```\nnew\n```\n operator). You can use \n```\nstd::vector\n```"", ""```\nnew\n```\n operator type-specifiers, but they are treated specially, so that the runtime-ness doesn't escape the scope of the \n```\nnew\n```\n operator). You can use \n```\nstd::vector\n```\n, but it is not quite the same, as it uses dynamic memory, and making it use one's own stack-allocator isn't exactly easy (alignment is an issue, too). It also doesn't solve the same problem, because a vector is a resizable container, whereas VLAs are fixed-size. The C++ Dynamic Array proposal is intended to introduce a library based solution, as alternative to a language based VLA. However, it's not going to be part of C++0x, as far as I know.""]","There recently was a discussion about this kicked off in usenet: Why no VLAs in C++0x. I agree with those people that seem to agree that having to create a potential large array on the stack, which usually has only little space available, isn't good. The argument is, if you know the size beforehand, you can use a static array. And if you don't know the size beforehand, you will write unsafe code. C99 VLAs could provide a small benefit of being able to create small arrays without wasting space or calling constructors for unused elements, but they will introduce rather large changes to the type system (you need to be able to specify types depending on runtime values - this does not yet exist in current C++, except for 
```
new
```
 operator type-specifiers, but they are treated specially, so that the runtime-ness doesn't escape the scope of the 
```
new
```
 operator). You can use 
```
std::vector
```
, but it is not quite the same, as it uses dynamic memory, and making it use one's own stack-allocator isn't exactly easy (alignment is an issue, too). It also doesn't solve the same problem, because a vector is a resizable container, whereas VLAs are fixed-size. The C++ Dynamic Array proposal is intended to introduce a library based solution, as alternative to a language based VLA. However, it's not going to be part of C++0x, as far as I know."
45723819,"What is a ""span"" and when should I use one?",https://stackoverflow.com/questions/45723819/what-is-a-span-and-when-should-i-use-one,4,539.0,"['What is it? A \n```\nspan<T>\n```\n is: A very lightweight abstraction of a contiguous sequence of values of type \n```\nT\n```\n somewhere in memory. Basically a \n```\nstruct { T * ptr; std::size_t length; }\n```\n with a bunch of convenience methods. A non-owning type (i.e. a ""reference-type"" rather than a ""value type""): It never allocates nor deallocates anything and does not keep smart pointers alive. It was formerly known as an \n```\narray_view\n```\n and even earlier as \n```\narray_ref\n```\n. When should I use it? First, when not to use spans: Don\'t use a span in code that could just take any pair of start & end iterators (like \n```\nstd::sort\n```\n, \n```\nstd::find_if\n```\n, \n```\nstd::copy\n```\n and other templated functions from \n```\n<algorithm>\n```', ""```\nstd::sort\n```\n, \n```\nstd::find_if\n```\n, \n```\nstd::copy\n```\n and other templated functions from \n```\n<algorithm>\n```\n), and also not in code that takes an arbitrary range (see The C++20 ranges library for information about those). A span has stricter requirements than a pair of iterators or a range: element contiguity and presence of the elements in memory. Don't use a span if you have a standard library container (or a Boost container etc.) which you know is the right fit for your code. spans are not intended to supplant existing containers. Now for when to actually use a span: Use \n```\nspan<T>\n```\n (respectively, \n```\nspan<const T>\n```\n) instead of a free-standing \n```\nT*\n```\n (respectively \n```\nconst T*\n```\n) when the allocated length or size also matter. So, replace functions like: \n```\nvoid read_into(int* buffer, size_t buffer_size);"", '```\n with: \n```\nvoid read_into(span<int> buffer);\n\n```\n Why should I use it? Why is it a good thing? Oh, spans are awesome! Using a span... means that you can work with that pointer+length / start+end pointer combination like you would with a fancy, pimped-out standard library container, e.g.: \n```\nfor (auto& x : my_span) { /* do stuff */ }\n```\n \n```\nstd::find_if(my_span.cbegin(), my_span.cend(), some_predicate);\n```\n \n```\nstd::ranges::find_if(my_span, some_predicate);\n```\n (in C++20) ... but with absolutely none of the overhead most container classes incur. lets the compiler do more work for you sometimes. For example, this: \n```\nint buffer[BUFFER_SIZE];\nread_into(buffer, BUFFER_SIZE);\n\n```\n becomes this: \n```\nint buffer[BUFFER_SIZE];\nread_into(buffer);', ""```\n ... which will do what you would want it to do. See also Guideline P.5. is the reasonable alternative to passing \n```\nconst vector<T>&\n```\n to functions when you expect your data to be contiguous in memory. No more getting scolded by high-and-mighty C++ gurus! facilitates static analysis, so the compiler might be able to help you catch silly bugs. allows for debug-compilation instrumentation for runtime bounds-checking (i.e. \n```\nspan\n```\n's methods will have some bounds-checking code within \n```\n#ifndef NDEBUG\n```\n ... \n```\n#endif\n```\n) indicates that your code (that's using the span) doesn't own the pointed-to memory. There's even more motivation for using \n```\nspan\n```\ns, which you could find in the C++ core guidelines - but you catch the drift. But is it in the standard library? edit: Yes, \n```\nstd::span\n```"", ""```\nspan\n```\ns, which you could find in the C++ core guidelines - but you catch the drift. But is it in the standard library? edit: Yes, \n```\nstd::span\n```\n was added to C++ with the C++20 version of the language! Why only in C++20? Well, While the idea is not new - its current form was conceived in conjunction with the C++ core guidelines project, which only started taking shape in 2015. So it took a while. So how do I use it if I'm writing C++17 or earlier? It's part of the Core Guidelines's Support Library (GSL). Implementations: Microsoft / Neil Macintosh's GSL contains a standalone implementation: \n```\ngsl/span\n```\n GSL-Lite is a single-header implementation of the whole GSL (it's not that big, don't worry), including \n```\nspan<T>\n```\n. The GSL implementation does generally assume a platform that implements C++14 support [12]. These alternative single-header implementations do not depend on GSL facilities: \n```\nmartinmoene/span-lite\n```\n requires C++98 or later \n```"", ""```\nmartinmoene/span-lite\n```\n requires C++98 or later \n```\ntcbrindle/span\n```\n requires C++11 or later Note that these different span implementations have some differences in what methods/support functions they come with; and they may also differ somewhat from the version adopted into the standard library in C++20. Further reading: You can find all the details and design considerations in the final official proposal before C++17, P0122R7: span: bounds-safe views for sequences of objects by Neal Macintosh and Stephan J. Lavavej. It's a bit long though. Also, in C++20, the span comparison semantics changed (following this short paper by Tony van Eerd). There is also a multi-dimensional extension of spans: mdspans; see this SO question.""]","What is it? A 
```
span<T>
```
 is: A very lightweight abstraction of a contiguous sequence of values of type 
```
T
```
 somewhere in memory. Basically a 
```
struct { T * ptr; std::size_t length; }
```
 with a bunch of convenience methods. A non-owning type (i.e. a ""reference-type"" rather than a ""value type""): It never allocates nor deallocates anything and does not keep smart pointers alive. It was formerly known as an 
```
array_view
```
 and even earlier as 
```
array_ref
```
. When should I use it? First, when not to use spans: Don't use a span in code that could just take any pair of start & end iterators (like 
```
std::sort
```
, 
```
std::find_if
```
, 
```
std::copy
```
 and other templated functions from 
```
<algorithm>
```
), and also not in code that takes an arbitrary range (see The C++20 ranges library for information about those). A span has stricter requirements than a pair of iterators or a range: element contiguity and presence of the elements in memory. Don't use a span if you have a standard library container (or a Boost container etc.) which you know is the right fit for your code. spans are not intended to supplant existing containers. Now for when to actually use a span: Use 
```
span<T>
```
 (respectively, 
```
span<const T>
```
) instead of a free-standing 
```
T*
```
 (respectively 
```
const T*
```
) when the allocated length or size also matter. So, replace functions like: 
```
void read_into(int* buffer, size_t buffer_size);

```
 with: 
```
void read_into(span<int> buffer);

```
 Why should I use it? Why is it a good thing? Oh, spans are awesome! Using a span... means that you can work with that pointer+length / start+end pointer combination like you would with a fancy, pimped-out standard library container, e.g.: 
```
for (auto& x : my_span) { /* do stuff */ }
```
 
```
std::find_if(my_span.cbegin(), my_span.cend(), some_predicate);
```
 
```
std::ranges::find_if(my_span, some_predicate);
```
 (in C++20) ... but with absolutely none of the overhead most container classes incur. lets the compiler do more work for you sometimes. For example, this: 
```
int buffer[BUFFER_SIZE];
read_into(buffer, BUFFER_SIZE);

```
 becomes this: 
```
int buffer[BUFFER_SIZE];
read_into(buffer);

```
 ... which will do what you would want it to do. See also Guideline P.5. is the reasonable alternative to passing 
```
const vector<T>&
```
 to functions when you expect your data to be contiguous in memory. No more getting scolded by high-and-mighty C++ gurus! facilitates static analysis, so the compiler might be able to help you catch silly bugs. allows for debug-compilation instrumentation for runtime bounds-checking (i.e. 
```
span
```
's methods will have some bounds-checking code within 
```
#ifndef NDEBUG
```
 ... 
```
#endif
```
) indicates that your code (that's using the span) doesn't own the pointed-to memory. There's even more motivation for using 
```
span
```
s, which you could find in the C++ core guidelines - but you catch the drift. But is it in the standard library? edit: Yes, 
```
std::span
```
 was added to C++ with the C++20 version of the language! Why only in C++20? Well, While the idea is not new - its current form was conceived in conjunction with the C++ core guidelines project, which only started taking shape in 2015. So it took a while. So how do I use it if I'm writing C++17 or earlier? It's part of the Core Guidelines's Support Library (GSL). Implementations: Microsoft / Neil Macintosh's GSL contains a standalone implementation: 
```
gsl/span
```
 GSL-Lite is a single-header implementation of the whole GSL (it's not that big, don't worry), including 
```
span<T>
```
. The GSL implementation does generally assume a platform that implements C++14 support [12]. These alternative single-header implementations do not depend on GSL facilities: 
```
martinmoene/span-lite
```
 requires C++98 or later 
```
tcbrindle/span
```
 requires C++11 or later Note that these different span implementations have some differences in what methods/support functions they come with; and they may also differ somewhat from the version adopted into the standard library in C++20. Further reading: You can find all the details and design considerations in the final official proposal before C++17, P0122R7: span: bounds-safe views for sequences of objects by Neal Macintosh and Stephan J. Lavavej. It's a bit long though. Also, in C++20, the span comparison semantics changed (following this short paper by Tony van Eerd). There is also a multi-dimensional extension of spans: mdspans; see this SO question."
922360,Why can't I make a vector of references?,https://stackoverflow.com/questions/922360/why-cant-i-make-a-vector-of-references,11,,[],
11004273,What is std::promise?,https://stackoverflow.com/questions/11004273/what-is-stdpromise,9,216.0,"['In the words of [futures.state] a \n```\nstd::future\n```\n is an asynchronous return object (""an object that reads results from a shared state"") and a \n```\nstd::promise\n```\n is an asynchronous provider (""an object that provides a result to a shared state"") i.e. a promise is the thing that you set a result on, so that you can get it from the associated future. The asynchronous provider is what initially creates the shared state that a future refers to. \n```\nstd::promise\n```\n is one type of asynchronous provider, \n```\nstd::packaged_task\n```\n is another, and the internal detail of \n```\nstd::async\n```\n is another. Each of those can create a shared state and give you a \n```\nstd::future\n```\n that shares that state, and can make the state ready. \n```\nstd::async\n```', ""```\nstd::async\n```\n is another. Each of those can create a shared state and give you a \n```\nstd::future\n```\n that shares that state, and can make the state ready. \n```\nstd::async\n```\n is a higher-level convenience utility that gives you an asynchronous result object and internally takes care of creating the asynchronous provider and making the shared state ready when the task completes. You could emulate it with a \n```\nstd::packaged_task\n```\n (or \n```\nstd::bind\n```\n and a \n```\nstd::promise\n```\n) and a \n```\nstd::thread\n```\n but it's safer and easier to use \n```\nstd::async\n```\n. \n```\nstd::promise\n```\n is a bit lower-level, for when you want to pass an asynchronous result to the future, but the code that makes the result ready cannot be wrapped up in a single function suitable for passing to \n```\nstd::async\n```\n. For example, you might have an array of several \n```\npromise\n```\ns and associated \n```\nfuture\n```"", '```\nstd::async\n```\n. For example, you might have an array of several \n```\npromise\n```\ns and associated \n```\nfuture\n```\ns and have a single thread which does several calculations and sets a result on each promise. \n```\nasync\n```\n would only allow you to return a single result, to return several you would need to call \n```\nasync\n```\n several times, which might waste resources.']","In the words of [futures.state] a 
```
std::future
```
 is an asynchronous return object (""an object that reads results from a shared state"") and a 
```
std::promise
```
 is an asynchronous provider (""an object that provides a result to a shared state"") i.e. a promise is the thing that you set a result on, so that you can get it from the associated future. The asynchronous provider is what initially creates the shared state that a future refers to. 
```
std::promise
```
 is one type of asynchronous provider, 
```
std::packaged_task
```
 is another, and the internal detail of 
```
std::async
```
 is another. Each of those can create a shared state and give you a 
```
std::future
```
 that shares that state, and can make the state ready. 
```
std::async
```
 is a higher-level convenience utility that gives you an asynchronous result object and internally takes care of creating the asynchronous provider and making the shared state ready when the task completes. You could emulate it with a 
```
std::packaged_task
```
 (or 
```
std::bind
```
 and a 
```
std::promise
```
) and a 
```
std::thread
```
 but it's safer and easier to use 
```
std::async
```
. 
```
std::promise
```
 is a bit lower-level, for when you want to pass an asynchronous result to the future, but the code that makes the result ready cannot be wrapped up in a single function suitable for passing to 
```
std::async
```
. For example, you might have an array of several 
```
promise
```
s and associated 
```
future
```
s and have a single thread which does several calculations and sets a result on each promise. 
```
async
```
 would only allow you to return a single result, to return several you would need to call 
```
async
```
 several times, which might waste resources."
3211771,How to convert int to QString?,https://stackoverflow.com/questions/3211771/how-to-convert-int-to-qstring,9,817.0,['Use \n```\nQString::number()\n```\n: \n```\nint i = 42;\nQString s = QString::number(i);\n\n```'],"Use 
```
QString::number()
```
: 
```
int i = 42;
QString s = QString::number(i);

```
"
2795023,C++ template typedef,https://stackoverflow.com/questions/2795023/c-template-typedef,1,678.0,"['C++11 added alias declarations, which are generalization of \n```\ntypedef\n```\n, allowing templates: \n```\ntemplate <size_t N>\nusing Vector = Matrix<N, 1>;\n\n```\n The type \n```\nVector<3>\n```\n is equivalent to \n```\nMatrix<3, 1>\n```\n. In C++03, the closest approximation was: \n```\ntemplate <size_t N>\nstruct Vector\n{\n    typedef Matrix<N, 1> type;\n};\n\n```\n Here, the type \n```\nVector<3>::type\n```\n is equivalent to \n```\nMatrix<3, 1>\n```\n.']","C++11 added alias declarations, which are generalization of 
```
typedef
```
, allowing templates: 
```
template <size_t N>
using Vector = Matrix<N, 1>;

```
 The type 
```
Vector<3>
```
 is equivalent to 
```
Matrix<3, 1>
```
. In C++03, the closest approximation was: 
```
template <size_t N>
struct Vector
{
    typedef Matrix<N, 1> type;
};

```
 Here, the type 
```
Vector<3>::type
```
 is equivalent to 
```
Matrix<3, 1>
```
."
554063,How do I print a double value with full precision using cout?,https://stackoverflow.com/questions/554063/how-do-i-print-a-double-value-with-full-precision-using-cout,16,111.0,"['In C++20 you can use \n```\nstd::format\n```\n to do this: \n```\nstd::cout << std::format(""{}"", std::numbers::pi_v<double>);\n\n```\n Output (assuming IEEE 754 \n```\ndouble\n```\n): \n```\n3.141592653589793\n\n```\n The default floating-point format is the shortest decimal representation with a round-trip guarantee. The advantage of this method compared to the \n```\nsetprecision\n```\n I/O manipulator is that it doesn\'t print unnecessary digits and is not affected by global state (see this blog post for more details). In the meantime you can use the {fmt} library, \n```\nstd::format\n```\n is based on. {fmt} also provides the \n```\nprint\n```\n function that makes this even easier and more efficient (godbolt): \n```\nfmt::print(""{}"", M_PI);', '```\n The question doesn’t actually define what it means by ""full precision"". Normally it is understood as the precision enough for a round trip through decimal but there is another possible but unlikely interpretation of the maximum number of (significant) decimal digits. For IEEE 754 double the latter is 767 digits. Disclaimer: I\'m the author of {fmt} and C++20 \n```\nstd::format\n```\n.']","In C++20 you can use 
```
std::format
```
 to do this: 
```
std::cout << std::format(""{}"", std::numbers::pi_v<double>);

```
 Output (assuming IEEE 754 
```
double
```
): 
```
3.141592653589793

```
 The default floating-point format is the shortest decimal representation with a round-trip guarantee. The advantage of this method compared to the 
```
setprecision
```
 I/O manipulator is that it doesn't print unnecessary digits and is not affected by global state (see this blog post for more details). In the meantime you can use the {fmt} library, 
```
std::format
```
 is based on. {fmt} also provides the 
```
print
```
 function that makes this even easier and more efficient (godbolt): 
```
fmt::print(""{}"", M_PI);

```
 The question doesn’t actually define what it means by ""full precision"". Normally it is understood as the precision enough for a round trip through decimal but there is another possible but unlikely interpretation of the maximum number of (significant) decimal digits. For IEEE 754 double the latter is 767 digits. Disclaimer: I'm the author of {fmt} and C++20 
```
std::format
```
."
8767166,Passing a 2D array to a C++ function,https://stackoverflow.com/questions/8767166/passing-a-2d-array-to-a-c-function,19,541.0,['There are three ways to pass a 2D array to a function: The parameter is a 2D array \n```\nint array[10][10];\nvoid passFunc(int a[][10])\n{\n    // ...\n}\npassFunc(array);\n\n```\n The parameter is an array containing pointers \n```\nint *array[10];\nfor(int i = 0; i < 10; i++)\n    array[i] = new int[10];\nvoid passFunc(int *a[10]) //Array containing pointers\n{\n    // ...\n}\npassFunc(array);\n\n```\n The parameter is a pointer to a pointer \n```\nint **array;\narray = new int *[10];\nfor(int i = 0; i <10; i++)\n    array[i] = new int[10];\nvoid passFunc(int **a)\n{\n    // ...\n}\npassFunc(array);\n\n```'],"There are three ways to pass a 2D array to a function: The parameter is a 2D array 
```
int array[10][10];
void passFunc(int a[][10])
{
    // ...
}
passFunc(array);

```
 The parameter is an array containing pointers 
```
int *array[10];
for(int i = 0; i < 10; i++)
    array[i] = new int[10];
void passFunc(int *a[10]) //Array containing pointers
{
    // ...
}
passFunc(array);

```
 The parameter is a pointer to a pointer 
```
int **array;
array = new int *[10];
for(int i = 0; i <10; i++)
    array[i] = new int[10];
void passFunc(int **a)
{
    // ...
}
passFunc(array);

```
"
2298242,Callback functions in C++,https://stackoverflow.com/questions/2298242/callback-functions-in-c,12,700.0,"['Note: Most of the answers cover function pointers which is one possibility to achieve ""callback"" logic in C++, but as of today not the most favourable one I think. What are callbacks(?) and why to use them(!) A callback is a callable (see further down) accepted by a class or function, used to customize the current logic depending on that callback. One reason to use callbacks is to write generic code which is independent of the logic in the called function and can be reused with different callbacks. Many functions of the standard algorithms library \n```\n<algorithm>\n```\n use callbacks. For example, the \n```\nfor_each\n```\n algorithm applies a unary callback to every item in a range of iterators: \n```\ntemplate<class InputIt, class UnaryFunction>\nUnaryFunction for_each(InputIt first, InputIt last, UnaryFunction f)\n{\n  for (; first != last; ++first) {\n    f(*first);\n  }\n  return f;\n}', '```\n which can be used to first increment and then print a vector by passing appropriate callables for example: \n```\nstd::vector<double> v{ 1.0, 2.2, 4.0, 5.5, 7.2 };\ndouble r = 4.0;\nstd::for_each(v.begin(), v.end(), [&](double & v) { v += r; });\nstd::for_each(v.begin(), v.end(), [](double v) { std::cout << v << "" ""; });\n\n```\n which prints \n```\n5 6.2 8 9.5 11.2', '```', ""Another application of callbacks is the notification of callers of certain events which enables a certain amount of static / compile time flexibility. Personally, I use a local optimization library that uses two different callbacks: The first callback is called if a function value and the gradient based on a vector of input values are required (logic callback: function value determination/gradient derivation). The second callback is called once for each algorithm step and receives certain information about the convergence of the algorithm (notification callback). Thus, the library designer is not in charge of deciding what happens with the information that is given to the programmer via the notification callback and he needn't worry about how to actually determine function values because they're provided by the logic callback. Getting those things right is a task due to the library user and keeps the library slim and more generic. Furthermore, callbacks can enable dynamic runtime"", ""they're provided by the logic callback. Getting those things right is a task due to the library user and keeps the library slim and more generic. Furthermore, callbacks can enable dynamic runtime behaviour. Imagine some kind of game engine class which has a function that is fired, each time the user presses a button on his keyboard and a set of functions that control your game behaviour. With callbacks, you can (re)decide at runtime which action will be taken."", '```\nvoid player_jump();\nvoid player_crouch();', 'class game_core\n{\n    std::array<void(*)(), total_num_keys> actions;\n    // \n    void key_pressed(unsigned key_id)\n    {\n        if(actions[key_id])\n            actions[key_id]();\n    }\n    \n    // update keybind from the menu\n    void update_keybind(unsigned key_id, void(*new_action)())\n    {\n        actions[key_id] = new_action;\n    }\n};\n\n```\n Here the function \n```\nkey_pressed\n```\n uses the callbacks stored in \n```\nactions\n```\n to obtain the desired behaviour when a certain key is pressed. If the player chooses to change the button for jumping, the engine can call \n```\ngame_core_instance.update_keybind(newly_selected_key, &player_jump);', '```\n and thus change the behaviour of a call to \n```\nkey_pressed\n```\n (which calls \n```\nplayer_jump\n```\n) once this button is pressed the next time ingame. What are callables in C++(11)? See C++ concepts: Callable on cppreference for a more formal description. Callback functionality can be realized in several ways in C++(11) since several different things turn out to be callable*: Function pointers (including pointers to member functions) \n```\nstd::function\n```\n objects Lambda expressions Bind expressions Function objects (classes with overloaded function call operator \n```\noperator()\n```', '```\nstd::function\n```\n objects Lambda expressions Bind expressions Function objects (classes with overloaded function call operator \n```\noperator()\n```\n) * Note: Pointer to data members are callable as well but no function is called at all. Several important ways to write callbacks in detail X.1 ""Writing"" a callback in this post means the syntax to declare and name the callback type. X.2 ""Calling"" a callback refers to the syntax to call those objects. X.3 ""Using"" a callback means the syntax when passing arguments to a function using a callback. Note: As of C++17, a call like \n```\nf(...)\n```\n can be written as \n```\nstd::invoke(f, ...)\n```\n which also handles the pointer to member case. 1. Function pointers A function pointer is the \'simplest\' (in terms of generality; in terms of readability arguably the worst) type a callback can have. Let\'s have a simple function \n```\nfoo\n```\n: \n```\nint foo (int x) { return 2+x; }', '```\n 1.1 Writing a function pointer / type notation A function pointer type has the notation \n```\nreturn_type (*)(parameter_type_1, parameter_type_2, parameter_type_3)\n// i.e. a pointer to foo has the type:\nint (*)(int)\n\n```\n where a named function pointer type will look like \n```\nreturn_type (* name) (parameter_type_1, parameter_type_2, parameter_type_3)\n\n// i.e. f_int_t is a type: function pointer taking one int argument, returning int\ntypedef int (*f_int_t) (int); \n\n// foo_p is a pointer to a function taking int returning int\n// initialized by pointer to function foo taking int returning int\nint (* foo_p)(int) = &foo; \n// can alternatively be written as \nf_int_t foo_p = &foo;\n\n```\n The \n```\nusing\n```\n declaration gives us the option to make things a little bit more readable, since the \n```\ntypedef\n```\n for \n```\nf_int_t\n```\n can also be written as: \n```\nusing f_int_t = int(*)(int);', '```\n Where (at least for me) it is clearer that \n```\nf_int_t\n```\n is the new type alias and recognition of the function pointer type is also easier And a declaration of a function using a callback of function pointer type will be: \n```\n// foobar having a callback argument named moo of type \n// pointer to function returning int taking int as its argument\nint foobar (int x, int (*moo)(int));\n// if f_int is the function pointer typedef from above we can also write foobar as:\nint foobar (int x, f_int_t moo);\n\n```\n 1.2 Callback call notation The call notation follows the simple function call syntax: \n```\nint foobar (int x, int (*moo)(int))\n{\n    return x + moo(x); // function pointer moo called using argument x\n}\n// analog\nint foobar (int x, f_int_t moo)\n{\n    return x + moo(x); // function pointer moo called using argument x\n}', ""```\n 1.3 Callback use notation and compatible types A callback function taking a function pointer can be called using function pointers. Using a function that takes a function pointer callback is rather simple: \n```\n int a = 5;\n int b = foobar(a, foo); // call foobar with pointer to foo as callback\n // can also be\n int b = foobar(a, &foo); // call foobar with pointer to foo as callback\n\n```\n 1.4 Example A function can be written that doesn't rely on how the callback works: \n```\nvoid tranform_every_int(int * v, unsigned n, int (*fp)(int))\n{\n  for (unsigned i = 0; i < n; ++i)\n  {\n    v[i] = fp(v[i]);\n  }\n}\n\n```\n where possible callbacks could be \n```\nint double_int(int x) { return 2*x; }\nint square_int(int x) { return x*x; }\n\n```\n used like \n```\nint a[5] = {1, 2, 3, 4, 5};\ntranform_every_int(&a[0], 5, double_int);\n// now a == {2, 4, 6, 8, 10};\ntranform_every_int(&a[0], 5, square_int);\n// now a == {4, 16, 36, 64, 100};"", '```\n used like \n```\nint a[5] = {1, 2, 3, 4, 5};\ntranform_every_int(&a[0], 5, double_int);\n// now a == {2, 4, 6, 8, 10};\ntranform_every_int(&a[0], 5, square_int);\n// now a == {4, 16, 36, 64, 100};\n\n```\n 2. Pointer to a member function A pointer to a member function (of some class \n```\nC\n```\n) is a special type of (and even more complex) function pointer which requires an object of type \n```\nC\n```\n to operate on. \n```\nstruct C\n{\n    int y;\n    int foo(int x) const { return x+y; }\n};\n\n```\n 2.1 Writing pointer to member function / type notation A pointer to member function type for some class \n```\nT\n```\n has the notation \n```\n// can have more or less parameters\nreturn_type (T::*)(parameter_type_1, parameter_type_2, parameter_type_3)\n// i.e. a pointer to C::foo has the type\nint (C::*) (int)\n\n```\n where a named pointer to member function will -in analogy to the function pointer- look like this: \n```\nreturn_type (T::* name) (parameter_type_1, parameter_type_2, parameter_type_3)', '```\n where a named pointer to member function will -in analogy to the function pointer- look like this: \n```\nreturn_type (T::* name) (parameter_type_1, parameter_type_2, parameter_type_3)\n\n// i.e. a type `f_C_int` representing a pointer to a member function of `C`\n// taking int returning int is:\ntypedef int (C::* f_C_int_t) (int x); \n\n// The type of C_foo_p is a pointer to a member function of C taking int returning int\n// Its value is initialized by a pointer to foo of C\nint (C::* C_foo_p)(int) = &C::foo;\n// which can also be written using the typedef:\nf_C_int_t C_foo_p = &C::foo;', '```\n Example: Declaring a function taking a pointer to member function callback as one of its arguments: \n```\n// C_foobar having an argument named moo of type pointer to a member function of C\n// where the callback returns int taking int as its argument\n// also needs an object of type c\nint C_foobar (int x, C const &c, int (C::*moo)(int));\n// can equivalently be declared using the typedef above:\nint C_foobar (int x, C const &c, f_C_int_t moo);\n\n```\n 2.2 Callback call notation The pointer to member function of \n```\nC\n```\n can be invoked, with respect to an object of type \n```\nC\n```\n by using member access operations on the dereferenced pointer. Note: Parenthesis required! \n```\nint C_foobar (int x, C const &c, int (C::*moo)(int))\n{\n    return x + (c.*moo)(x); // function pointer moo called for object c using argument x\n}\n// analog\nint C_foobar (int x, C const &c, f_C_int_t moo)\n{\n    return x + (c.*moo)(x); // function pointer moo called for object c using argument x\n}', '```\n Note: If a pointer to \n```\nC\n```\n is available the syntax is equivalent (where the pointer to \n```\nC\n```\n must be dereferenced as well): \n```\nint C_foobar_2 (int x, C const * c, int (C::*meow)(int))\n{\n    if (!c) return x;\n    // function pointer meow called for object *c using argument x\n    return x + ((*c).*meow)(x); \n}\n// or equivalent:\nint C_foobar_2 (int x, C const * c, int (C::*meow)(int))\n{\n    if (!c) return x;\n    // function pointer meow called for object *c using argument x\n    return x + (c->*meow)(x); \n}\n\n```\n 2.3 Callback use notation and compatible types A callback function taking a member function pointer of class \n```\nT\n```\n can be called using a member function pointer of class \n```\nT\n```\n. Using a function that takes a pointer to a member function callback is -in analogy to function pointers- quite simple as well: \n```\n C my_c{2}; // aggregate initialization\n int a = 5;\n int b = C_foobar(a, my_c, &C::foo); // call C_foobar with pointer to foo as its callback', '```\n 3. \n```\nstd::function\n```\n objects (header \n```\n<functional>\n```\n) The \n```\nstd::function\n```\n class is a polymorphic function wrapper to store, copy or invoke callables. 3.1 Writing a \n```\nstd::function\n```\n object / type notation The type of a \n```\nstd::function\n```\n object storing a callable looks like: \n```\nstd::function<return_type(parameter_type_1, parameter_type_2, parameter_type_3)>\n\n// i.e. using the above function declaration of foo:\nstd::function<int(int)> stdf_foo = &foo;\n// or C::foo:\nstd::function<int(const C&, int)> stdf_C_foo = &C::foo;\n\n```\n 3.2 Callback call notation The class \n```\nstd::function\n```\n has \n```\noperator()\n```\n defined which can be used to invoke its target. \n```\nint stdf_foobar (int x, std::function<int(int)> moo)\n{\n    return x + moo(x); // std::function moo called\n}\n// or \nint stdf_C_foobar (int x, C const &c, std::function<int(C const &, int)> moo)\n{\n    return x + moo(c, x); // std::function moo called using c and x\n}', '```\n 3.3 Callback use notation and compatible types The \n```\nstd::function\n```\n callback is more generic than function pointers or pointer to member function since different types can be passed and implicitly converted into a \n```\nstd::function\n```\n object. 3.3.1 Function pointers and pointers to member functions A function pointer \n```\nint a = 2;\nint b = stdf_foobar(a, &foo);\n// b == 6 ( 2 + (2+2) )\n\n```\n or a pointer to member function \n```\nint a = 2;\nC my_c{7}; // aggregate initialization\nint b = stdf_C_foobar(a, c, &C::foo);\n// b == 11 == ( 2 + (7+2) )\n\n```\n can be used. 3.3.2 Lambda expressions An unnamed closure from a lambda expression can be stored in a \n```\nstd::function\n```\n object: \n```\nint a = 2;\nint c = 3;\nint b = stdf_foobar(a, [c](int x) -> int { return 7+c*x; });\n// b == 15 == a + (7 + c*a) == 2 + (7 + 3*2)', '```\n 3.3.3 \n```\nstd::bind\n```\n expressions The result of a \n```\nstd::bind\n```\n expression can be passed. For example by binding parameters to a function pointer call: \n```\nint foo_2 (int x, int y) { return 9*x + y; }\nusing std::placeholders::_1;\n\nint a = 2;\nint b = stdf_foobar(a, std::bind(foo_2, _1, 3));\n// b == 23 == 2 + ( 9*2 + 3 )\nint c = stdf_foobar(a, std::bind(foo_2, 5, _1));\n// c == 49 == 2 + ( 9*5 + 2 )\n\n```\n Where also objects can be bound as the object for the invocation of pointer to member functions: \n```\nint a = 2;\nC const my_c{7}; // aggregate initialization\nint b = stdf_foobar(a, std::bind(&C::foo, my_c, _1));\n// b == 1 == 2 + ( 2 + 7 )\n\n```\n 3.3.4 Function objects Objects of classes having a proper \n```\noperator()\n```\n overload can be stored inside a \n```\nstd::function\n```\n object, as well. \n```\nstruct Meow\n{\n  int y = 0;\n  Meow(int y_) : y(y_) {}\n  int operator()(int x) { return y * x; }\n};\nint a = 11;\nint b = stdf_foobar(a, Meow{8});\n// b == 99 == 11 + ( 8 * 11 )', '```\n 3.4 Example Changing the function pointer example to use \n```\nstd::function\n```\n \n```\nvoid stdf_tranform_every_int(int * v, unsigned n, std::function<int(int)> fp)\n{\n  for (unsigned i = 0; i < n; ++i)\n  {\n    v[i] = fp(v[i]);\n  }\n}\n\n```\n gives a whole lot more utility to that function because (see 3.3) we have more possibilities to use it: \n```\n// using function pointer still possible\nint a[5] = {1, 2, 3, 4, 5};\nstdf_tranform_every_int(&a[0], 5, double_int);\n// now a == {2, 4, 6, 8, 10};\n\n// use it without having to write another function by using a lambda\nstdf_tranform_every_int(&a[0], 5, [](int x) -> int { return x/2; });\n// now a == {1, 2, 3, 4, 5}; again\n\n// use std::bind :\nint nine_x_and_y (int x, int y) { return 9*x + y; }\nusing std::placeholders::_1;\n// calls nine_x_and_y for every int in a with y being 4 every time\nstdf_tranform_every_int(&a[0], 5, std::bind(nine_x_and_y, _1, 4));\n// now a == {13, 22, 31, 40, 49};', ""```\n 4. Templated callback type Using templates, the code calling the callback can be even more general than using \n```\nstd::function\n```\n objects. Note that templates are a compile-time feature and are a design tool for compile-time polymorphism. If runtime dynamic behaviour is to be achieved through callbacks, templates will help but they won't induce runtime dynamics. 4.1 Writing (type notations) and calling templated callbacks Generalizing i.e. the \n```\nstd_ftransform_every_int\n```\n code from above even further can be achieved by using templates: \n```\ntemplate<class R, class T>\nvoid stdf_transform_every_int_templ(int * v,\n  unsigned const n, std::function<R(T)> fp)\n{\n  for (unsigned i = 0; i < n; ++i)\n  {\n    v[i] = fp(v[i]);\n  }\n}"", '```\n with an even more general (as well as easiest) syntax for a callback type being a plain, to-be-deduced templated argument: \n```\ntemplate<class F>\nvoid transform_every_int_templ(int * v, \n  unsigned const n, F f)\n{\n  std::cout << ""transform_every_int_templ<"" \n    << type_name<F>() << "">\\n"";\n  for (unsigned i = 0; i < n; ++i)\n  {\n    v[i] = f(v[i]);\n  }\n}\n\n```\n Note: The included output prints the type name deduced for templated type \n```\nF\n```\n. The implementation of \n```\ntype_name\n```\n is given at the end of this post. The most general implementation for the unary transformation of a range is part of the standard library, namely \n```\nstd::transform\n```\n, which is also templated with respect to the iterated types. \n```\ntemplate<class InputIt, class OutputIt, class UnaryOperation>\nOutputIt transform(InputIt first1, InputIt last1, OutputIt d_first,\n  UnaryOperation unary_op)\n{\n  while (first1 != last1) {\n    *d_first++ = unary_op(*first1++);\n  }\n  return d_first;\n}', '```\n 4.2 Examples using templated callbacks and compatible types The compatible types for the templated \n```\nstd::function\n```\n callback method \n```\nstdf_transform_every_int_templ\n```\n are identical to the above-mentioned types (see 3.4). Using the templated version, however, the signature of the used callback may change a little: \n```\n// Let\nint foo (int x) { return 2+x; }\nint muh (int const &x) { return 3+x; }\nint & woof (int &x) { x *= 4; return x; }\n\nint a[5] = {1, 2, 3, 4, 5};\nstdf_transform_every_int_templ<int,int>(&a[0], 5, &foo);\n// a == {3, 4, 5, 6, 7}\nstdf_transform_every_int_templ<int, int const &>(&a[0], 5, &muh);\n// a == {6, 7, 8, 9, 10}\nstdf_transform_every_int_templ<int, int &>(&a[0], 5, &woof);', '```\n Note: \n```\nstd_ftransform_every_int\n```\n (non templated version; see above) does work with \n```\nfoo\n```\n but not using \n```\nmuh\n```\n. \n```\n// Let\nvoid print_int(int * p, unsigned const n)\n{\n  bool f{ true };\n  for (unsigned i = 0; i < n; ++i)\n  {\n    std::cout << (f ? """" : "" "") << p[i]; \n    f = false;\n  }\n  std::cout << ""\\n"";\n}', '```\n The plain templated parameter of \n```\ntransform_every_int_templ\n```\n can be every possible callable type. \n```\nint a[5] = { 1, 2, 3, 4, 5 };\nprint_int(a, 5);\ntransform_every_int_templ(&a[0], 5, foo);\nprint_int(a, 5);\ntransform_every_int_templ(&a[0], 5, muh);\nprint_int(a, 5);\ntransform_every_int_templ(&a[0], 5, woof);\nprint_int(a, 5);\ntransform_every_int_templ(&a[0], 5, [](int x) -> int { return x + x + x; });\nprint_int(a, 5);\ntransform_every_int_templ(&a[0], 5, Meow{ 4 });\nprint_int(a, 5);\nusing std::placeholders::_1;\ntransform_every_int_templ(&a[0], 5, std::bind(foo_2, _1, 3));\nprint_int(a, 5);\ntransform_every_int_templ(&a[0], 5, std::function<int(int)>{&foo});\nprint_int(a, 5);', '```\n The above code prints: \n```\n1 2 3 4 5\ntransform_every_int_templ <int(*)(int)>\n3 4 5 6 7\ntransform_every_int_templ <int(*)(int&)>\n6 8 10 12 14\ntransform_every_int_templ <int& (*)(int&)>\n9 11 13 15 17\ntransform_every_int_templ <main::{lambda(int)#1} >\n27 33 39 45 51\ntransform_every_int_templ <Meow>\n108 132 156 180 204\ntransform_every_int_templ <std::_Bind<int(*(std::_Placeholder<1>, int))(int, int)>>\n975 1191 1407 1623 1839\ntransform_every_int_templ <std::function<int(int)>>\n977 1193 1409 1625 1841\n\n```\n \n```\ntype_name\n```\n implementation used above \n```\n#include <type_traits>\n#include <typeinfo>\n#include <string>\n#include <memory>\n#include <cxxabi.h>', '```\n \n```\ntype_name\n```\n implementation used above \n```\n#include <type_traits>\n#include <typeinfo>\n#include <string>\n#include <memory>\n#include <cxxabi.h>\n\ntemplate <class T>\nstd::string type_name()\n{\n  typedef typename std::remove_reference<T>::type TR;\n  std::unique_ptr<char, void(*)(void*)> own\n    (abi::__cxa_demangle(typeid(TR).name(), nullptr,\n    nullptr, nullptr), std::free);\n  std::string r = own != nullptr?own.get():typeid(TR).name();\n  if (std::is_const<TR>::value)\n    r += "" const"";\n  if (std::is_volatile<TR>::value)\n    r += "" volatile"";\n  if (std::is_lvalue_reference<T>::value)\n    r += "" &"";\n  else if (std::is_rvalue_reference<T>::value)\n    r += "" &&"";\n  return r;\n}\n        \n\n```']","Note: Most of the answers cover function pointers which is one possibility to achieve ""callback"" logic in C++, but as of today not the most favourable one I think. What are callbacks(?) and why to use them(!) A callback is a callable (see further down) accepted by a class or function, used to customize the current logic depending on that callback. One reason to use callbacks is to write generic code which is independent of the logic in the called function and can be reused with different callbacks. Many functions of the standard algorithms library 
```
<algorithm>
```
 use callbacks. For example, the 
```
for_each
```
 algorithm applies a unary callback to every item in a range of iterators: 
```
template<class InputIt, class UnaryFunction>
UnaryFunction for_each(InputIt first, InputIt last, UnaryFunction f)
{
  for (; first != last; ++first) {
    f(*first);
  }
  return f;
}

```
 which can be used to first increment and then print a vector by passing appropriate callables for example: 
```
std::vector<double> v{ 1.0, 2.2, 4.0, 5.5, 7.2 };
double r = 4.0;
std::for_each(v.begin(), v.end(), [&](double & v) { v += r; });
std::for_each(v.begin(), v.end(), [](double v) { std::cout << v << "" ""; });

```
 which prints 
```
5 6.2 8 9.5 11.2

```
 Another application of callbacks is the notification of callers of certain events which enables a certain amount of static / compile time flexibility. Personally, I use a local optimization library that uses two different callbacks: The first callback is called if a function value and the gradient based on a vector of input values are required (logic callback: function value determination/gradient derivation). The second callback is called once for each algorithm step and receives certain information about the convergence of the algorithm (notification callback). Thus, the library designer is not in charge of deciding what happens with the information that is given to the programmer via the notification callback and he needn't worry about how to actually determine function values because they're provided by the logic callback. Getting those things right is a task due to the library user and keeps the library slim and more generic. Furthermore, callbacks can enable dynamic runtime behaviour. Imagine some kind of game engine class which has a function that is fired, each time the user presses a button on his keyboard and a set of functions that control your game behaviour. With callbacks, you can (re)decide at runtime which action will be taken. 
```
void player_jump();
void player_crouch();

class game_core
{
    std::array<void(*)(), total_num_keys> actions;
    // 
    void key_pressed(unsigned key_id)
    {
        if(actions[key_id])
            actions[key_id]();
    }
    
    // update keybind from the menu
    void update_keybind(unsigned key_id, void(*new_action)())
    {
        actions[key_id] = new_action;
    }
};

```
 Here the function 
```
key_pressed
```
 uses the callbacks stored in 
```
actions
```
 to obtain the desired behaviour when a certain key is pressed. If the player chooses to change the button for jumping, the engine can call 
```
game_core_instance.update_keybind(newly_selected_key, &player_jump);

```
 and thus change the behaviour of a call to 
```
key_pressed
```
 (which calls 
```
player_jump
```
) once this button is pressed the next time ingame. What are callables in C++(11)? See C++ concepts: Callable on cppreference for a more formal description. Callback functionality can be realized in several ways in C++(11) since several different things turn out to be callable*: Function pointers (including pointers to member functions) 
```
std::function
```
 objects Lambda expressions Bind expressions Function objects (classes with overloaded function call operator 
```
operator()
```
) * Note: Pointer to data members are callable as well but no function is called at all. Several important ways to write callbacks in detail X.1 ""Writing"" a callback in this post means the syntax to declare and name the callback type. X.2 ""Calling"" a callback refers to the syntax to call those objects. X.3 ""Using"" a callback means the syntax when passing arguments to a function using a callback. Note: As of C++17, a call like 
```
f(...)
```
 can be written as 
```
std::invoke(f, ...)
```
 which also handles the pointer to member case. 1. Function pointers A function pointer is the 'simplest' (in terms of generality; in terms of readability arguably the worst) type a callback can have. Let's have a simple function 
```
foo
```
: 
```
int foo (int x) { return 2+x; }

```
 1.1 Writing a function pointer / type notation A function pointer type has the notation 
```
return_type (*)(parameter_type_1, parameter_type_2, parameter_type_3)
// i.e. a pointer to foo has the type:
int (*)(int)

```
 where a named function pointer type will look like 
```
return_type (* name) (parameter_type_1, parameter_type_2, parameter_type_3)

// i.e. f_int_t is a type: function pointer taking one int argument, returning int
typedef int (*f_int_t) (int); 

// foo_p is a pointer to a function taking int returning int
// initialized by pointer to function foo taking int returning int
int (* foo_p)(int) = &foo; 
// can alternatively be written as 
f_int_t foo_p = &foo;

```
 The 
```
using
```
 declaration gives us the option to make things a little bit more readable, since the 
```
typedef
```
 for 
```
f_int_t
```
 can also be written as: 
```
using f_int_t = int(*)(int);

```
 Where (at least for me) it is clearer that 
```
f_int_t
```
 is the new type alias and recognition of the function pointer type is also easier And a declaration of a function using a callback of function pointer type will be: 
```
// foobar having a callback argument named moo of type 
// pointer to function returning int taking int as its argument
int foobar (int x, int (*moo)(int));
// if f_int is the function pointer typedef from above we can also write foobar as:
int foobar (int x, f_int_t moo);

```
 1.2 Callback call notation The call notation follows the simple function call syntax: 
```
int foobar (int x, int (*moo)(int))
{
    return x + moo(x); // function pointer moo called using argument x
}
// analog
int foobar (int x, f_int_t moo)
{
    return x + moo(x); // function pointer moo called using argument x
}

```
 1.3 Callback use notation and compatible types A callback function taking a function pointer can be called using function pointers. Using a function that takes a function pointer callback is rather simple: 
```
 int a = 5;
 int b = foobar(a, foo); // call foobar with pointer to foo as callback
 // can also be
 int b = foobar(a, &foo); // call foobar with pointer to foo as callback

```
 1.4 Example A function can be written that doesn't rely on how the callback works: 
```
void tranform_every_int(int * v, unsigned n, int (*fp)(int))
{
  for (unsigned i = 0; i < n; ++i)
  {
    v[i] = fp(v[i]);
  }
}

```
 where possible callbacks could be 
```
int double_int(int x) { return 2*x; }
int square_int(int x) { return x*x; }

```
 used like 
```
int a[5] = {1, 2, 3, 4, 5};
tranform_every_int(&a[0], 5, double_int);
// now a == {2, 4, 6, 8, 10};
tranform_every_int(&a[0], 5, square_int);
// now a == {4, 16, 36, 64, 100};

```
 2. Pointer to a member function A pointer to a member function (of some class 
```
C
```
) is a special type of (and even more complex) function pointer which requires an object of type 
```
C
```
 to operate on. 
```
struct C
{
    int y;
    int foo(int x) const { return x+y; }
};

```
 2.1 Writing pointer to member function / type notation A pointer to member function type for some class 
```
T
```
 has the notation 
```
// can have more or less parameters
return_type (T::*)(parameter_type_1, parameter_type_2, parameter_type_3)
// i.e. a pointer to C::foo has the type
int (C::*) (int)

```
 where a named pointer to member function will -in analogy to the function pointer- look like this: 
```
return_type (T::* name) (parameter_type_1, parameter_type_2, parameter_type_3)

// i.e. a type `f_C_int` representing a pointer to a member function of `C`
// taking int returning int is:
typedef int (C::* f_C_int_t) (int x); 

// The type of C_foo_p is a pointer to a member function of C taking int returning int
// Its value is initialized by a pointer to foo of C
int (C::* C_foo_p)(int) = &C::foo;
// which can also be written using the typedef:
f_C_int_t C_foo_p = &C::foo;

```
 Example: Declaring a function taking a pointer to member function callback as one of its arguments: 
```
// C_foobar having an argument named moo of type pointer to a member function of C
// where the callback returns int taking int as its argument
// also needs an object of type c
int C_foobar (int x, C const &c, int (C::*moo)(int));
// can equivalently be declared using the typedef above:
int C_foobar (int x, C const &c, f_C_int_t moo);

```
 2.2 Callback call notation The pointer to member function of 
```
C
```
 can be invoked, with respect to an object of type 
```
C
```
 by using member access operations on the dereferenced pointer. Note: Parenthesis required! 
```
int C_foobar (int x, C const &c, int (C::*moo)(int))
{
    return x + (c.*moo)(x); // function pointer moo called for object c using argument x
}
// analog
int C_foobar (int x, C const &c, f_C_int_t moo)
{
    return x + (c.*moo)(x); // function pointer moo called for object c using argument x
}

```
 Note: If a pointer to 
```
C
```
 is available the syntax is equivalent (where the pointer to 
```
C
```
 must be dereferenced as well): 
```
int C_foobar_2 (int x, C const * c, int (C::*meow)(int))
{
    if (!c) return x;
    // function pointer meow called for object *c using argument x
    return x + ((*c).*meow)(x); 
}
// or equivalent:
int C_foobar_2 (int x, C const * c, int (C::*meow)(int))
{
    if (!c) return x;
    // function pointer meow called for object *c using argument x
    return x + (c->*meow)(x); 
}

```
 2.3 Callback use notation and compatible types A callback function taking a member function pointer of class 
```
T
```
 can be called using a member function pointer of class 
```
T
```
. Using a function that takes a pointer to a member function callback is -in analogy to function pointers- quite simple as well: 
```
 C my_c{2}; // aggregate initialization
 int a = 5;
 int b = C_foobar(a, my_c, &C::foo); // call C_foobar with pointer to foo as its callback

```
 3. 
```
std::function
```
 objects (header 
```
<functional>
```
) The 
```
std::function
```
 class is a polymorphic function wrapper to store, copy or invoke callables. 3.1 Writing a 
```
std::function
```
 object / type notation The type of a 
```
std::function
```
 object storing a callable looks like: 
```
std::function<return_type(parameter_type_1, parameter_type_2, parameter_type_3)>

// i.e. using the above function declaration of foo:
std::function<int(int)> stdf_foo = &foo;
// or C::foo:
std::function<int(const C&, int)> stdf_C_foo = &C::foo;

```
 3.2 Callback call notation The class 
```
std::function
```
 has 
```
operator()
```
 defined which can be used to invoke its target. 
```
int stdf_foobar (int x, std::function<int(int)> moo)
{
    return x + moo(x); // std::function moo called
}
// or 
int stdf_C_foobar (int x, C const &c, std::function<int(C const &, int)> moo)
{
    return x + moo(c, x); // std::function moo called using c and x
}

```
 3.3 Callback use notation and compatible types The 
```
std::function
```
 callback is more generic than function pointers or pointer to member function since different types can be passed and implicitly converted into a 
```
std::function
```
 object. 3.3.1 Function pointers and pointers to member functions A function pointer 
```
int a = 2;
int b = stdf_foobar(a, &foo);
// b == 6 ( 2 + (2+2) )

```
 or a pointer to member function 
```
int a = 2;
C my_c{7}; // aggregate initialization
int b = stdf_C_foobar(a, c, &C::foo);
// b == 11 == ( 2 + (7+2) )

```
 can be used. 3.3.2 Lambda expressions An unnamed closure from a lambda expression can be stored in a 
```
std::function
```
 object: 
```
int a = 2;
int c = 3;
int b = stdf_foobar(a, [c](int x) -> int { return 7+c*x; });
// b == 15 == a + (7 + c*a) == 2 + (7 + 3*2)

```
 3.3.3 
```
std::bind
```
 expressions The result of a 
```
std::bind
```
 expression can be passed. For example by binding parameters to a function pointer call: 
```
int foo_2 (int x, int y) { return 9*x + y; }
using std::placeholders::_1;

int a = 2;
int b = stdf_foobar(a, std::bind(foo_2, _1, 3));
// b == 23 == 2 + ( 9*2 + 3 )
int c = stdf_foobar(a, std::bind(foo_2, 5, _1));
// c == 49 == 2 + ( 9*5 + 2 )

```
 Where also objects can be bound as the object for the invocation of pointer to member functions: 
```
int a = 2;
C const my_c{7}; // aggregate initialization
int b = stdf_foobar(a, std::bind(&C::foo, my_c, _1));
// b == 1 == 2 + ( 2 + 7 )

```
 3.3.4 Function objects Objects of classes having a proper 
```
operator()
```
 overload can be stored inside a 
```
std::function
```
 object, as well. 
```
struct Meow
{
  int y = 0;
  Meow(int y_) : y(y_) {}
  int operator()(int x) { return y * x; }
};
int a = 11;
int b = stdf_foobar(a, Meow{8});
// b == 99 == 11 + ( 8 * 11 )

```
 3.4 Example Changing the function pointer example to use 
```
std::function
```
 
```
void stdf_tranform_every_int(int * v, unsigned n, std::function<int(int)> fp)
{
  for (unsigned i = 0; i < n; ++i)
  {
    v[i] = fp(v[i]);
  }
}

```
 gives a whole lot more utility to that function because (see 3.3) we have more possibilities to use it: 
```
// using function pointer still possible
int a[5] = {1, 2, 3, 4, 5};
stdf_tranform_every_int(&a[0], 5, double_int);
// now a == {2, 4, 6, 8, 10};

// use it without having to write another function by using a lambda
stdf_tranform_every_int(&a[0], 5, [](int x) -> int { return x/2; });
// now a == {1, 2, 3, 4, 5}; again

// use std::bind :
int nine_x_and_y (int x, int y) { return 9*x + y; }
using std::placeholders::_1;
// calls nine_x_and_y for every int in a with y being 4 every time
stdf_tranform_every_int(&a[0], 5, std::bind(nine_x_and_y, _1, 4));
// now a == {13, 22, 31, 40, 49};

```
 4. Templated callback type Using templates, the code calling the callback can be even more general than using 
```
std::function
```
 objects. Note that templates are a compile-time feature and are a design tool for compile-time polymorphism. If runtime dynamic behaviour is to be achieved through callbacks, templates will help but they won't induce runtime dynamics. 4.1 Writing (type notations) and calling templated callbacks Generalizing i.e. the 
```
std_ftransform_every_int
```
 code from above even further can be achieved by using templates: 
```
template<class R, class T>
void stdf_transform_every_int_templ(int * v,
  unsigned const n, std::function<R(T)> fp)
{
  for (unsigned i = 0; i < n; ++i)
  {
    v[i] = fp(v[i]);
  }
}

```
 with an even more general (as well as easiest) syntax for a callback type being a plain, to-be-deduced templated argument: 
```
template<class F>
void transform_every_int_templ(int * v, 
  unsigned const n, F f)
{
  std::cout << ""transform_every_int_templ<"" 
    << type_name<F>() << "">\n"";
  for (unsigned i = 0; i < n; ++i)
  {
    v[i] = f(v[i]);
  }
}

```
 Note: The included output prints the type name deduced for templated type 
```
F
```
. The implementation of 
```
type_name
```
 is given at the end of this post. The most general implementation for the unary transformation of a range is part of the standard library, namely 
```
std::transform
```
, which is also templated with respect to the iterated types. 
```
template<class InputIt, class OutputIt, class UnaryOperation>
OutputIt transform(InputIt first1, InputIt last1, OutputIt d_first,
  UnaryOperation unary_op)
{
  while (first1 != last1) {
    *d_first++ = unary_op(*first1++);
  }
  return d_first;
}

```
 4.2 Examples using templated callbacks and compatible types The compatible types for the templated 
```
std::function
```
 callback method 
```
stdf_transform_every_int_templ
```
 are identical to the above-mentioned types (see 3.4). Using the templated version, however, the signature of the used callback may change a little: 
```
// Let
int foo (int x) { return 2+x; }
int muh (int const &x) { return 3+x; }
int & woof (int &x) { x *= 4; return x; }

int a[5] = {1, 2, 3, 4, 5};
stdf_transform_every_int_templ<int,int>(&a[0], 5, &foo);
// a == {3, 4, 5, 6, 7}
stdf_transform_every_int_templ<int, int const &>(&a[0], 5, &muh);
// a == {6, 7, 8, 9, 10}
stdf_transform_every_int_templ<int, int &>(&a[0], 5, &woof);

```
 Note: 
```
std_ftransform_every_int
```
 (non templated version; see above) does work with 
```
foo
```
 but not using 
```
muh
```
. 
```
// Let
void print_int(int * p, unsigned const n)
{
  bool f{ true };
  for (unsigned i = 0; i < n; ++i)
  {
    std::cout << (f ? """" : "" "") << p[i]; 
    f = false;
  }
  std::cout << ""\n"";
}

```
 The plain templated parameter of 
```
transform_every_int_templ
```
 can be every possible callable type. 
```
int a[5] = { 1, 2, 3, 4, 5 };
print_int(a, 5);
transform_every_int_templ(&a[0], 5, foo);
print_int(a, 5);
transform_every_int_templ(&a[0], 5, muh);
print_int(a, 5);
transform_every_int_templ(&a[0], 5, woof);
print_int(a, 5);
transform_every_int_templ(&a[0], 5, [](int x) -> int { return x + x + x; });
print_int(a, 5);
transform_every_int_templ(&a[0], 5, Meow{ 4 });
print_int(a, 5);
using std::placeholders::_1;
transform_every_int_templ(&a[0], 5, std::bind(foo_2, _1, 3));
print_int(a, 5);
transform_every_int_templ(&a[0], 5, std::function<int(int)>{&foo});
print_int(a, 5);

```
 The above code prints: 
```
1 2 3 4 5
transform_every_int_templ <int(*)(int)>
3 4 5 6 7
transform_every_int_templ <int(*)(int&)>
6 8 10 12 14
transform_every_int_templ <int& (*)(int&)>
9 11 13 15 17
transform_every_int_templ <main::{lambda(int)#1} >
27 33 39 45 51
transform_every_int_templ <Meow>
108 132 156 180 204
transform_every_int_templ <std::_Bind<int(*(std::_Placeholder<1>, int))(int, int)>>
975 1191 1407 1623 1839
transform_every_int_templ <std::function<int(int)>>
977 1193 1409 1625 1841

```
 
```
type_name
```
 implementation used above 
```
#include <type_traits>
#include <typeinfo>
#include <string>
#include <memory>
#include <cxxabi.h>

template <class T>
std::string type_name()
{
  typedef typename std::remove_reference<T>::type TR;
  std::unique_ptr<char, void(*)(void*)> own
    (abi::__cxa_demangle(typeid(TR).name(), nullptr,
    nullptr, nullptr), std::free);
  std::string r = own != nullptr?own.get():typeid(TR).name();
  if (std::is_const<TR>::value)
    r += "" const"";
  if (std::is_volatile<TR>::value)
    r += "" volatile"";
  if (std::is_lvalue_reference<T>::value)
    r += "" &"";
  else if (std::is_rvalue_reference<T>::value)
    r += "" &&"";
  return r;
}
        

```
"
1711990,"What is this weird colon-member ("" : "") syntax in the constructor?",https://stackoverflow.com/questions/1711990/what-is-this-weird-colon-member-syntax-in-the-constructor,14,249.0,"[""It's a member initialization list. You should find information about it in any good C++ book. You should, in most cases, initialize all member objects in the member initialization list (however, do note the exceptions listed at the end of the FAQ entry). The takeaway point from the FAQ entry is that, All other things being equal, your code will run faster if you use initialization lists rather than assignment.""]","It's a member initialization list. You should find information about it in any good C++ book. You should, in most cases, initialize all member objects in the member initialization list (however, do note the exceptions listed at the end of the FAQ entry). The takeaway point from the FAQ entry is that, All other things being equal, your code will run faster if you use initialization lists rather than assignment."
2053029,How exactly does __attribute__((constructor)) work?,https://stackoverflow.com/questions/2053029/how-exactly-does-attribute-constructor-work,5,357.0,"[""It runs when a shared library is loaded, typically during program startup. That's how all GCC attributes are; presumably to distinguish them from function calls. GCC-specific syntax. Yes, this works in C and C++. No, the function does not need to be static. The destructor runs when the shared library is unloaded, typically at program exit. So, the way the constructors and destructors work is that the shared object file contains special sections (.ctors and .dtors on ELF) which contain references to the functions marked with the constructor and destructor attributes, respectively. When the library is loaded/unloaded the dynamic loader program (ld.so or somesuch) checks whether such sections exist, and if so, calls the functions referenced therein. Come to think of it, there is probably some similar magic in the normal static linker so that the same code is run on startup/shutdown regardless if the user chooses static or dynamic linking.""]","It runs when a shared library is loaded, typically during program startup. That's how all GCC attributes are; presumably to distinguish them from function calls. GCC-specific syntax. Yes, this works in C and C++. No, the function does not need to be static. The destructor runs when the shared library is unloaded, typically at program exit. So, the way the constructors and destructors work is that the shared object file contains special sections (.ctors and .dtors on ELF) which contain references to the functions marked with the constructor and destructor attributes, respectively. When the library is loaded/unloaded the dynamic loader program (ld.so or somesuch) checks whether such sections exist, and if so, calls the functions referenced therein. Come to think of it, there is probably some similar magic in the normal static linker so that the same code is run on startup/shutdown regardless if the user chooses static or dynamic linking."
205945,"Why does the C++ STL not provide any ""tree"" containers?",https://stackoverflow.com/questions/205945/why-does-the-c-stl-not-provide-any-tree-containers,16,204.0,['There are two reasons you could want to use a tree: You want to mirror the problem using a tree-like structure: For this we have boost graph library Or you want a container that has tree like access characteristics For this we have \n```\nstd::map\n```\n (and \n```\nstd::multimap\n```\n) \n```\nstd::set\n```\n (and \n```\nstd::multiset\n```\n) Basically the characteristics of these two containers is such that they practically have to be implemented using trees (though this is not actually a requirement). See also this question: C tree Implementation'],"There are two reasons you could want to use a tree: You want to mirror the problem using a tree-like structure: For this we have boost graph library Or you want a container that has tree like access characteristics For this we have 
```
std::map
```
 (and 
```
std::multimap
```
) 
```
std::set
```
 (and 
```
std::multiset
```
) Basically the characteristics of these two containers is such that they practically have to be implemented using trees (though this is not actually a requirement). See also this question: C tree Implementation"
14589346,Is C++ context-free or context-sensitive?,https://stackoverflow.com/questions/14589346/is-c-context-free-or-context-sensitive,20,391.0,"['Below is my (current) favorite demonstration of why parsing C++ is (probably) Turing-complete, since it shows a program which is syntactically correct if and only if a given integer is prime. So I assert that C++ is neither context-free nor context-sensitive. If you allow arbitrary symbol sequences on both sides of any production, you produce a Type-0 grammar (""unrestricted"") in the Chomsky hierarchy, which is more powerful than a context-sensitive grammar; unrestricted grammars are Turing-complete. A context-sensitive (Type-1) grammar allows multiple symbols of context on the left hand side of a production, but the same context must appear on the right hand side of the production (hence the name ""context-sensitive""). [1] Context-sensitive grammars are equivalent to linear-bounded Turing machines. In the example program, the prime computation could be performed by a linear-bounded Turing machine, so it does not quite prove Turing equivalence, but the important part is that the parser', 'machines. In the example program, the prime computation could be performed by a linear-bounded Turing machine, so it does not quite prove Turing equivalence, but the important part is that the parser needs to perform the computation in order to perform syntactic analysis. It could have been any computation expressible as a template instantiation and there is every reason to believe that C++ template instantiation is Turing-complete. See, for example, Todd L. Veldhuizen\'s 2003 paper. Regardless, C++ can be parsed by a computer, so it could certainly be parsed by a Turing machine. Consequently, an unrestricted grammar could recognize it. Actually writing such a grammar would be impractical, which is why the standard doesn\'t try to do so. (See below.) The issue with ""ambiguity"" of certain expressions is mostly a red herring. To start with, ambiguity is a feature of a particular grammar, not a language. Even if a language can be proven to have no unambiguous grammars, if it can be', ""expressions is mostly a red herring. To start with, ambiguity is a feature of a particular grammar, not a language. Even if a language can be proven to have no unambiguous grammars, if it can be recognized by a context-free grammar, it's context-free. Similarly, if it cannot be recognized by a context-free grammar but it can be recognized by a context-sensitive grammar, it's context-sensitive. Ambiguity is not relevant. But in any event, like line 21 (i.e."", '```\nauto b = foo<IsPrime<234799>>::typen<1>();\n```', ') in the program below, the expressions are not ambiguous at all; they are simply parsed differently depending on context. In the simplest expression of the issue, the syntactic category of certain identifiers is dependent on how they have been declared (types and functions, for example), which means that the formal language would have to recognize the fact that two arbitrary-length strings in the same program are identical (declaration and use). This can be modelled by the ""copy"" grammar, which is the grammar which recognizes two consecutive exact copies of the same word. It\'s easy to prove with the pumping lemma that this language is not context-free. A context-sensitive grammar for this language is possible, and a Type-0 grammar is provided in the answer to this question: https://math.stackexchange.com/questions/163830/context-sensitive-grammar-for-the-copy-language . If one were to attempt to write a context-sensitive (or unrestricted) grammar to parse C++, it would quite possibly', "". If one were to attempt to write a context-sensitive (or unrestricted) grammar to parse C++, it would quite possibly fill the universe with scribblings. Writing a Turing machine to parse C++ would be an equally impossible undertaking. Even writing a C++ program is difficult, and as far as I know none have been proven correct. This is why the standard does not attempt to provide a complete formal grammar, and why it chooses to write some of the parsing rules in technical English. What looks like a formal grammar in the C++ standard is not the complete formal definition of the syntax of the C++ language. It's not even the complete formal definition of the language after preprocessing, which might be easier to formalize. (That wouldn't be the language, though: the C++ language as defined by the standard includes the preprocessor, and the operation of the preprocessor is described algorithmically since it would be extremely hard to describe in any grammatical formalism. It is in that"", 'by the standard includes the preprocessor, and the operation of the preprocessor is described algorithmically since it would be extremely hard to describe in any grammatical formalism. It is in that section of the standard where lexical decomposition is described, including the rules where it must be applied more than once.) The various grammars (two overlapping grammars for lexical analysis, one which takes place before preprocessing and the other, if necessary, afterwards, plus the ""syntactic"" grammar) are collected in Appendix A, with this important note (emphasis added): This summary of C++ syntax is intended to be an aid to comprehension. It is not an exact statement of the language. In particular, the grammar described here accepts a superset of valid C++ constructs. Disambiguation rules (6.8, 7.1, 10.2) must be applied to distinguish expressions from declarations. Further, access control, ambiguity, and type rules must be used to weed out syntactically valid but meaningless', ""rules (6.8, 7.1, 10.2) must be applied to distinguish expressions from declarations. Further, access control, ambiguity, and type rules must be used to weed out syntactically valid but meaningless constructs. Finally, here's the promised program. Line 21 is syntactically correct if and only if the N in"", '```\nIsPrime<N>\n```\n is prime. Otherwise, \n```\ntypen\n```\n is an integer, not a template, so \n```\ntypen<1>()\n```\n is parsed as \n```\n(typen<1)>()\n```\n which is syntactically incorrect because \n```\n()\n```\n is not a syntactically valid expression. \n```\ntemplate<bool V> struct answer { answer(int) {} bool operator()(){return V;}};', 'template<bool no, bool yes, int f, int p> struct IsPrimeHelper\n  : IsPrimeHelper<p % f == 0, f * f >= p, f + 2, p> {};\ntemplate<bool yes, int f, int p> struct IsPrimeHelper<true, yes, f, p> { using type = answer<false>; };\ntemplate<int f, int p> struct IsPrimeHelper<false, true, f, p> { using type = answer<true>; };\n\ntemplate<int I> using IsPrime = typename IsPrimeHelper<!(I&1), false, 3, I>::type;\ntemplate<int I>\nstruct X { static const int i = I; int a[i]; }; \n\ntemplate<typename A> struct foo;\ntemplate<>struct foo<answer<true>>{\n  template<int I> using typen = X<I>;\n};\ntemplate<> struct foo<answer<false>>{\n  static const int typen = 0;\n};\n\nint main() {\n  auto b = foo<IsPrime<234799>>::typen<1>(); // Syntax error if not prime\n  return 0;\n}', '```\n [1] To put it more technically, every production in a context-sensitive grammar must be of the form: \n```\nαAβ → αγβ\n```\n where \n```\nA\n```\n is a non-terminal and \n```\nα\n```\n, \n```\nβ\n```\n are possibly empty sequences of grammar symbols, and \n```\nγ\n```\n is a non-empty sequence. (Grammar symbols may be either terminals or non-terminals). This can be read as \n```\nA → γ\n```\n only in the context \n```\n[α, β]\n```\n. In a context-free (Type 2) grammar, \n```\nα\n```\n and \n```\nβ\n```\n must be empty. It turns out that you can also restrict grammars with the ""monotonic"" restriction, where every production must be of the form: \n```\nα → β\n```\n where \n```\n|α| ≥ |β| > 0\n```\n (\n```\n|α|\n```\n means ""the length of \n```\nα\n```', '```\nα → β\n```\n where \n```\n|α| ≥ |β| > 0\n```\n (\n```\n|α|\n```\n means ""the length of \n```\nα\n```\n"") It\'s possible to prove that the set of languages recognized by monotonic grammars is exactly the same as the set of languages recognized by context-sensitive grammars, and it\'s often the case that it\'s easier to base proofs on monotonic grammars. Consequently, it\'s pretty common to see ""context-sensitive"" used as though it meant ""monotonic"".']","Below is my (current) favorite demonstration of why parsing C++ is (probably) Turing-complete, since it shows a program which is syntactically correct if and only if a given integer is prime. So I assert that C++ is neither context-free nor context-sensitive. If you allow arbitrary symbol sequences on both sides of any production, you produce a Type-0 grammar (""unrestricted"") in the Chomsky hierarchy, which is more powerful than a context-sensitive grammar; unrestricted grammars are Turing-complete. A context-sensitive (Type-1) grammar allows multiple symbols of context on the left hand side of a production, but the same context must appear on the right hand side of the production (hence the name ""context-sensitive""). [1] Context-sensitive grammars are equivalent to linear-bounded Turing machines. In the example program, the prime computation could be performed by a linear-bounded Turing machine, so it does not quite prove Turing equivalence, but the important part is that the parser needs to perform the computation in order to perform syntactic analysis. It could have been any computation expressible as a template instantiation and there is every reason to believe that C++ template instantiation is Turing-complete. See, for example, Todd L. Veldhuizen's 2003 paper. Regardless, C++ can be parsed by a computer, so it could certainly be parsed by a Turing machine. Consequently, an unrestricted grammar could recognize it. Actually writing such a grammar would be impractical, which is why the standard doesn't try to do so. (See below.) The issue with ""ambiguity"" of certain expressions is mostly a red herring. To start with, ambiguity is a feature of a particular grammar, not a language. Even if a language can be proven to have no unambiguous grammars, if it can be recognized by a context-free grammar, it's context-free. Similarly, if it cannot be recognized by a context-free grammar but it can be recognized by a context-sensitive grammar, it's context-sensitive. Ambiguity is not relevant. But in any event, like line 21 (i.e. 
```
auto b = foo<IsPrime<234799>>::typen<1>();
```
) in the program below, the expressions are not ambiguous at all; they are simply parsed differently depending on context. In the simplest expression of the issue, the syntactic category of certain identifiers is dependent on how they have been declared (types and functions, for example), which means that the formal language would have to recognize the fact that two arbitrary-length strings in the same program are identical (declaration and use). This can be modelled by the ""copy"" grammar, which is the grammar which recognizes two consecutive exact copies of the same word. It's easy to prove with the pumping lemma that this language is not context-free. A context-sensitive grammar for this language is possible, and a Type-0 grammar is provided in the answer to this question: https://math.stackexchange.com/questions/163830/context-sensitive-grammar-for-the-copy-language . If one were to attempt to write a context-sensitive (or unrestricted) grammar to parse C++, it would quite possibly fill the universe with scribblings. Writing a Turing machine to parse C++ would be an equally impossible undertaking. Even writing a C++ program is difficult, and as far as I know none have been proven correct. This is why the standard does not attempt to provide a complete formal grammar, and why it chooses to write some of the parsing rules in technical English. What looks like a formal grammar in the C++ standard is not the complete formal definition of the syntax of the C++ language. It's not even the complete formal definition of the language after preprocessing, which might be easier to formalize. (That wouldn't be the language, though: the C++ language as defined by the standard includes the preprocessor, and the operation of the preprocessor is described algorithmically since it would be extremely hard to describe in any grammatical formalism. It is in that section of the standard where lexical decomposition is described, including the rules where it must be applied more than once.) The various grammars (two overlapping grammars for lexical analysis, one which takes place before preprocessing and the other, if necessary, afterwards, plus the ""syntactic"" grammar) are collected in Appendix A, with this important note (emphasis added): This summary of C++ syntax is intended to be an aid to comprehension. It is not an exact statement of the language. In particular, the grammar described here accepts a superset of valid C++ constructs. Disambiguation rules (6.8, 7.1, 10.2) must be applied to distinguish expressions from declarations. Further, access control, ambiguity, and type rules must be used to weed out syntactically valid but meaningless constructs. Finally, here's the promised program. Line 21 is syntactically correct if and only if the N in 
```
IsPrime<N>
```
 is prime. Otherwise, 
```
typen
```
 is an integer, not a template, so 
```
typen<1>()
```
 is parsed as 
```
(typen<1)>()
```
 which is syntactically incorrect because 
```
()
```
 is not a syntactically valid expression. 
```
template<bool V> struct answer { answer(int) {} bool operator()(){return V;}};

template<bool no, bool yes, int f, int p> struct IsPrimeHelper
  : IsPrimeHelper<p % f == 0, f * f >= p, f + 2, p> {};
template<bool yes, int f, int p> struct IsPrimeHelper<true, yes, f, p> { using type = answer<false>; };
template<int f, int p> struct IsPrimeHelper<false, true, f, p> { using type = answer<true>; };

template<int I> using IsPrime = typename IsPrimeHelper<!(I&1), false, 3, I>::type;
template<int I>
struct X { static const int i = I; int a[i]; }; 

template<typename A> struct foo;
template<>struct foo<answer<true>>{
  template<int I> using typen = X<I>;
};
template<> struct foo<answer<false>>{
  static const int typen = 0;
};

int main() {
  auto b = foo<IsPrime<234799>>::typen<1>(); // Syntax error if not prime
  return 0;
}

```
 [1] To put it more technically, every production in a context-sensitive grammar must be of the form: 
```
αAβ → αγβ
```
 where 
```
A
```
 is a non-terminal and 
```
α
```
, 
```
β
```
 are possibly empty sequences of grammar symbols, and 
```
γ
```
 is a non-empty sequence. (Grammar symbols may be either terminals or non-terminals). This can be read as 
```
A → γ
```
 only in the context 
```
[α, β]
```
. In a context-free (Type 2) grammar, 
```
α
```
 and 
```
β
```
 must be empty. It turns out that you can also restrict grammars with the ""monotonic"" restriction, where every production must be of the form: 
```
α → β
```
 where 
```
|α| ≥ |β| > 0
```
 (
```
|α|
```
 means ""the length of 
```
α
```
"") It's possible to prove that the set of languages recognized by monotonic grammars is exactly the same as the set of languages recognized by context-sensitive grammars, and it's often the case that it's easier to base proofs on monotonic grammars. Consequently, it's pretty common to see ""context-sensitive"" used as though it meant ""monotonic""."
787533,Is #pragma once a safe include guard?,https://stackoverflow.com/questions/787533/is-pragma-once-a-safe-include-guard,16,274.0,"[""Using \n```\n#pragma once\n```\n should work on any modern compiler, but I don't see any reason not to use a standard \n```\n#ifndef\n```\n include guard. It works just fine. The one caveat is that GCC didn't support \n```\n#pragma once\n```\n before version 3.4. I also found that, at least on GCC, it recognizes the standard \n```\n#ifndef\n```\n include guard and optimizes it, so it shouldn't be much slower than \n```\n#pragma once\n```\n.""]","Using 
```
#pragma once
```
 should work on any modern compiler, but I don't see any reason not to use a standard 
```
#ifndef
```
 include guard. It works just fine. The one caveat is that GCC didn't support 
```
#pragma once
```
 before version 3.4. I also found that, at least on GCC, it recognizes the standard 
```
#ifndef
```
 include guard and optimizes it, so it shouldn't be much slower than 
```
#pragma once
```
."
677620,Do I need to explicitly call the base virtual destructor?,https://stackoverflow.com/questions/677620/do-i-need-to-explicitly-call-the-base-virtual-destructor,7,600.0,"['No, destructors are called automatically in the reverse order of construction. (Base classes last). Do not call base class destructors.']","No, destructors are called automatically in the reverse order of construction. (Base classes last). Do not call base class destructors."
1306778,Virtual/pure virtual explained,https://stackoverflow.com/questions/1306778/virtual-pure-virtual-explained,12,400.0,"[""From Wikipedia's Virtual function ... In object-oriented programming, in languages such as C++, and Object Pascal, a virtual function or virtual method is an inheritable and overridable function or method for which dynamic dispatch is facilitated. This concept is an important part of the (runtime) polymorphism portion of object-oriented programming (OOP). In short, a virtual function defines a target function to be executed, but the target might not be known at compile time. Unlike a non-virtual function, when a virtual function is overridden the most-derived version is used at all levels of the class hierarchy, rather than just the level at which it was created. Therefore if one method of the base class calls a virtual method, the version defined in the derived class will be used instead of the version defined in the base class. For example, if ewe run this code \n```\nstruct Base\n{\n    virtual ~Base() = default;"", 'virtual void foo()\n    {\n        std::cout << ""Base::Foo"" << std::endl;\n    }\n};\n\nstruct Derived final: Base\n{\n    void foo() override\n    {\n        std::cout << ""Derived::Foo"" << std::endl;\n    }\n};\n\nint main()\n{\n    Base base;\n    base.foo();\n\n    Derived derived;\n    derived.foo();\n\n    Base* derived_as_base = &derived;\n    derived_as_base->foo();\n}\n\n```\n This is the output we get \n```\nBase::Foo\nDerived::Foo\nDerived::Foo\n\n```\n This is in contrast to non-virtual functions, which can still be overridden in a derived class, but the ""new"" version will only be used by the derived class and below, but will not change the functionality of the base class at all. We can see this by changing the above code to this \n```\nstruct Base\n{\n    void foo()\n    {\n        std::cout << ""Base::Foo"" << std::endl;\n    }\n};\n\nstruct Derived final: Base\n{\n    void foo()\n    {\n        std::cout << ""Derived::Foo"" << std::endl;\n    }\n};', 'struct Derived final: Base\n{\n    void foo()\n    {\n        std::cout << ""Derived::Foo"" << std::endl;\n    }\n};\n\n```\n Which produces the following output \n```\nBase::Foo\nDerived::Foo\nBase::Foo\n\n```\n whereas.. A pure virtual function or pure virtual method is a virtual function that is required to be implemented by a derived class if the derived class is not abstract. When a pure virtual method exists, the class is ""abstract"" and can not be instantiated on its own. Instead, a derived class that implements the pure-virtual method(s) must be used. A pure-virtual isn\'t defined in the base-class at all, so a derived class must define it, or that derived class is also abstract, and can not be instantiated. Only a class that has no abstract methods can be instantiated. This is what a pure virtual setup would look like \n```\nstruct Base\n{\n    virtual ~Base() = default;\n\n    virtual void foo() = 0;\n};', 'virtual void foo() = 0;\n};\n\nstruct Derived final: Base\n{\n    void foo() override\n    {\n        std::cout << ""Derived::Foo"" << std::endl;\n    }\n};\n\nint main()\n{\n    // error: cannot declare variable \'base\' to be of abstract type \'Base\'\n    // Base base;\n    // base.foo();\n\n    Derived derived;\n    derived.foo();\n\n    Base* derived_as_base = &derived;\n    derived_as_base->foo();\n}\n\n```\n With output matching what we\'d expect from a virtual function, pure or otherwise. \n```\nDerived::Foo\nDerived::Foo\n\n```\n In short, a virtual provides a way to override the functionality of the base class, and a pure-virtual requires it.']","From Wikipedia's Virtual function ... In object-oriented programming, in languages such as C++, and Object Pascal, a virtual function or virtual method is an inheritable and overridable function or method for which dynamic dispatch is facilitated. This concept is an important part of the (runtime) polymorphism portion of object-oriented programming (OOP). In short, a virtual function defines a target function to be executed, but the target might not be known at compile time. Unlike a non-virtual function, when a virtual function is overridden the most-derived version is used at all levels of the class hierarchy, rather than just the level at which it was created. Therefore if one method of the base class calls a virtual method, the version defined in the derived class will be used instead of the version defined in the base class. For example, if ewe run this code 
```
struct Base
{
    virtual ~Base() = default;

    virtual void foo()
    {
        std::cout << ""Base::Foo"" << std::endl;
    }
};

struct Derived final: Base
{
    void foo() override
    {
        std::cout << ""Derived::Foo"" << std::endl;
    }
};

int main()
{
    Base base;
    base.foo();

    Derived derived;
    derived.foo();

    Base* derived_as_base = &derived;
    derived_as_base->foo();
}

```
 This is the output we get 
```
Base::Foo
Derived::Foo
Derived::Foo

```
 This is in contrast to non-virtual functions, which can still be overridden in a derived class, but the ""new"" version will only be used by the derived class and below, but will not change the functionality of the base class at all. We can see this by changing the above code to this 
```
struct Base
{
    void foo()
    {
        std::cout << ""Base::Foo"" << std::endl;
    }
};

struct Derived final: Base
{
    void foo()
    {
        std::cout << ""Derived::Foo"" << std::endl;
    }
};

```
 Which produces the following output 
```
Base::Foo
Derived::Foo
Base::Foo

```
 whereas.. A pure virtual function or pure virtual method is a virtual function that is required to be implemented by a derived class if the derived class is not abstract. When a pure virtual method exists, the class is ""abstract"" and can not be instantiated on its own. Instead, a derived class that implements the pure-virtual method(s) must be used. A pure-virtual isn't defined in the base-class at all, so a derived class must define it, or that derived class is also abstract, and can not be instantiated. Only a class that has no abstract methods can be instantiated. This is what a pure virtual setup would look like 
```
struct Base
{
    virtual ~Base() = default;

    virtual void foo() = 0;
};

struct Derived final: Base
{
    void foo() override
    {
        std::cout << ""Derived::Foo"" << std::endl;
    }
};

int main()
{
    // error: cannot declare variable 'base' to be of abstract type 'Base'
    // Base base;
    // base.foo();

    Derived derived;
    derived.foo();

    Base* derived_as_base = &derived;
    derived_as_base->foo();
}

```
 With output matching what we'd expect from a virtual function, pure or otherwise. 
```
Derived::Foo
Derived::Foo

```
 In short, a virtual provides a way to override the functionality of the base class, and a pure-virtual requires it."
712279,What is the usefulness of `enable_shared_from_this`?,https://stackoverflow.com/questions/712279/what-is-the-usefulness-of-enable-shared-from-this,6,444.0,"['It enables you to get a valid \n```\nshared_ptr\n```\n instance to \n```\nthis\n```\n, when all you have is \n```\nthis\n```\n. Without it, you would have no way of getting a \n```\nshared_ptr\n```\n to \n```\nthis\n```\n, unless you already had one as a member. This example from the boost documentation for enable_shared_from_this: \n```\nclass Y: public enable_shared_from_this<Y>\n{\npublic:\n\n    shared_ptr<Y> f()\n    {\n        return shared_from_this();\n    }\n}\n\nint main()\n{\n    shared_ptr<Y> p(new Y);\n    shared_ptr<Y> q = p->f();\n    assert(p == q);\n    assert(!(p < q || q < p)); // p and q must share ownership\n}\n\n```\n The method \n```\nf()\n```\n returns a valid \n```\nshared_ptr\n```\n, even though it had no member instance. Note that you cannot simply do this: \n```\nclass Y: public enable_shared_from_this<Y>\n{\npublic:\n\n    shared_ptr<Y> f()\n    {\n        return shared_ptr<Y>(this);\n    }\n}', 'shared_ptr<Y> f()\n    {\n        return shared_ptr<Y>(this);\n    }\n}\n\n```\n The shared pointer that this returned will have a different reference count from the ""proper"" one, and one of them will end up losing and holding a dangling reference when the object is deleted. \n```\nenable_shared_from_this\n```\n has become part of C++ 11 standard. You can also get it from there as well as from boost.']","It enables you to get a valid 
```
shared_ptr
```
 instance to 
```
this
```
, when all you have is 
```
this
```
. Without it, you would have no way of getting a 
```
shared_ptr
```
 to 
```
this
```
, unless you already had one as a member. This example from the boost documentation for enable_shared_from_this: 
```
class Y: public enable_shared_from_this<Y>
{
public:

    shared_ptr<Y> f()
    {
        return shared_from_this();
    }
}

int main()
{
    shared_ptr<Y> p(new Y);
    shared_ptr<Y> q = p->f();
    assert(p == q);
    assert(!(p < q || q < p)); // p and q must share ownership
}

```
 The method 
```
f()
```
 returns a valid 
```
shared_ptr
```
, even though it had no member instance. Note that you cannot simply do this: 
```
class Y: public enable_shared_from_this<Y>
{
public:

    shared_ptr<Y> f()
    {
        return shared_ptr<Y>(this);
    }
}

```
 The shared pointer that this returned will have a different reference count from the ""proper"" one, and one of them will end up losing and holding a dangling reference when the object is deleted. 
```
enable_shared_from_this
```
 has become part of C++ 11 standard. You can also get it from there as well as from boost."
9017573,Define a preprocessor macro through CMake,https://stackoverflow.com/questions/9017573/define-a-preprocessor-macro-through-cmake,6,538.0,"[""For a long time, CMake only had the \n```\nadd_definitions\n```\n command for this purpose. However, since CMake version 3.12 (released July 2018) the command has been superseded by a more fine grained approach (separate commands for compile definitions, include directories, and compiler options). An example using the new add_compile_definitions: \n```\nadd_compile_definitions(OPENCV_VERSION=${OpenCV_VERSION})\nadd_compile_definitions(WITH_OPENCV2)\n\n```\n Or: \n```\nadd_compile_definitions(OPENCV_VERSION=${OpenCV_VERSION} WITH_OPENCV2)\n\n```\n The good part about this is that it circumvents the shabby trickery CMake has in place for \n```\nadd_definitions\n```\n. CMake is such a shabby system, but they are finally finding some sanity. Find more explanation on which commands to use for compiler flags here: https://cmake.org/cmake/help/latest/command/add_definitions.html Likewise, you can do this per-target as explained in Jim Hunziker's answer.""]","For a long time, CMake only had the 
```
add_definitions
```
 command for this purpose. However, since CMake version 3.12 (released July 2018) the command has been superseded by a more fine grained approach (separate commands for compile definitions, include directories, and compiler options). An example using the new add_compile_definitions: 
```
add_compile_definitions(OPENCV_VERSION=${OpenCV_VERSION})
add_compile_definitions(WITH_OPENCV2)

```
 Or: 
```
add_compile_definitions(OPENCV_VERSION=${OpenCV_VERSION} WITH_OPENCV2)

```
 The good part about this is that it circumvents the shabby trickery CMake has in place for 
```
add_definitions
```
. CMake is such a shabby system, but they are finally finding some sanity. Find more explanation on which commands to use for compiler flags here: https://cmake.org/cmake/help/latest/command/add_definitions.html Likewise, you can do this per-target as explained in Jim Hunziker's answer."
10363646,Compiling C++11 with g++,https://stackoverflow.com/questions/10363646/compiling-c11-with-g,6,630.0,"[""Flags (or compiler options) are nothing but ordinary command line arguments passed to the compiler executable. Assuming you are invoking g++ from the command line (terminal): \n```\n$ g++ -std=c++11 your_file.cpp -o your_program\n```\n or \n```\n$ g++ -std=c++0x your_file.cpp -o your_program\n```\n if the above doesn't work.""]","Flags (or compiler options) are nothing but ordinary command line arguments passed to the compiler executable. Assuming you are invoking g++ from the command line (terminal): 
```
$ g++ -std=c++11 your_file.cpp -o your_program
```
 or 
```
$ g++ -std=c++0x your_file.cpp -o your_program
```
 if the above doesn't work."
261963,How can I iterate over an enum?,https://stackoverflow.com/questions/261963/how-can-i-iterate-over-an-enum,29,335.0,"['The typical way is as follows: \n```\nenum Foo {\n  One,\n  Two,\n  Three,\n  Last\n};\n\nfor ( int fooInt = One; fooInt != Last; fooInt++ )\n{\n   Foo foo = static_cast<Foo>(fooInt);\n   // ...\n}\n\n```\n Please note, the enum \n```\nLast\n```\n is meant to be skipped by the iteration. Utilizing this ""fake"" \n```\nLast\n```\n enum, you don\'t have to update your terminating condition in the for loop to the last ""real"" enum each time you want to add a new enum. If you want to add more enums later, just add them before Last. The loop in this example will still work. Of course, this breaks down if the enum values are specified: \n```\nenum Foo {\n  One = 1,\n  Two = 9,\n  Three = 4,\n  Last\n};', '```\n This illustrates that an enum is not really meant to iterate through. The typical way to deal with an enum is to use it in a switch statement. \n```\nswitch ( foo )\n{\n    case One:\n        // ..\n        break;\n    case Two:  // intentional fall-through\n    case Three:\n        // ..\n        break;\n    case Four:\n        // ..\n        break;\n     default:\n        assert( ! ""Invalid Foo enum value"" );\n        break;\n}\n\n```\n If you really want to enumerate, stuff the enum values in a vector and iterate over that. This will properly deal with the specified enum values as well.']","The typical way is as follows: 
```
enum Foo {
  One,
  Two,
  Three,
  Last
};

for ( int fooInt = One; fooInt != Last; fooInt++ )
{
   Foo foo = static_cast<Foo>(fooInt);
   // ...
}

```
 Please note, the enum 
```
Last
```
 is meant to be skipped by the iteration. Utilizing this ""fake"" 
```
Last
```
 enum, you don't have to update your terminating condition in the for loop to the last ""real"" enum each time you want to add a new enum. If you want to add more enums later, just add them before Last. The loop in this example will still work. Of course, this breaks down if the enum values are specified: 
```
enum Foo {
  One = 1,
  Two = 9,
  Three = 4,
  Last
};

```
 This illustrates that an enum is not really meant to iterate through. The typical way to deal with an enum is to use it in a switch statement. 
```
switch ( foo )
{
    case One:
        // ..
        break;
    case Two:  // intentional fall-through
    case Three:
        // ..
        break;
    case Four:
        // ..
        break;
     default:
        assert( ! ""Invalid Foo enum value"" );
        break;
}

```
 If you really want to enumerate, stuff the enum values in a vector and iterate over that. This will properly deal with the specified enum values as well."
11016220,What are inline namespaces for?,https://stackoverflow.com/questions/11016220/what-are-inline-namespaces-for,6,415.0,"['Inline namespaces are a library versioning feature akin to symbol versioning, but implemented purely at the C++11 level (ie. cross-platform) instead of being a feature of a specific binary executable format (ie. platform-specific). It is a mechanism by which a library author can make a nested namespace look and act as if all its declarations were in the surrounding namespace (inline namespaces can be nested, so ""more-nested"" names percolate up all the way to the first non-inline namespace and look and act as if their declarations were in any of the namespaces in between, too). As an example, consider the STL implementation of \n```\nvector\n```\n. If we had inline namespaces from the beginning of C++, then in C++98 the header \n```\n<vector>\n```\n might have looked like this: \n```\nnamespace std {\n\n#if __cplusplus < 1997L // pre-standard C++\n    inline\n#endif', ""#if __cplusplus < 1997L // pre-standard C++\n    inline\n#endif\n\n    namespace pre_cxx_1997 {\n        template <class T> __vector_impl; // implementation class\n        template <class T> // e.g. w/o allocator argument\n        class vector : __vector_impl<T> { // private inheritance\n            // ...\n        };\n    }\n#if __cplusplus >= 1997L // C++98/03 or later\n                         // (ifdef'ed out b/c it probably uses new language\n                         // features that a pre-C++98 compiler would choke on)\n#  if __cplusplus == 1997L // C++98/03\n    inline\n#  endif\n\n    namespace cxx_1997 {\n\n        // std::vector now has an allocator argument\n        template <class T, class Alloc=std::allocator<T> >\n        class vector : pre_cxx_1997::__vector_impl<T> { // the old impl is still good\n            // ...\n        };\n\n        // and vector<bool> is special:\n        template <class Alloc=std::allocator<bool> >\n        class vector<bool> {\n            // ...\n        };\n\n    };"", '// and vector<bool> is special:\n        template <class Alloc=std::allocator<bool> >\n        class vector<bool> {\n            // ...\n        };\n\n    };\n\n#endif // C++98/03 or later\n\n} // namespace std', '};\n\n#endif // C++98/03 or later\n\n} // namespace std\n\n```\n Depending on the value of \n```\n__cplusplus\n```\n, either one or the other \n```\nvector\n```\n implementation is chosen. If your codebase was written in pre-C++98 times, and you find that the C++98 version of \n```\nvector\n```\n is causing trouble for you when you upgrade your compiler, ""all"" you have to do is to find the references to \n```\nstd::vector\n```\n in your codebase and replace them by \n```\nstd::pre_cxx_1997::vector\n```\n. Come the next standard, and the STL vendor just repeats the procedure again, introducing a new namespace for \n```\nstd::vector\n```\n with \n```\nemplace_back\n```\n support (which requires C++11) and inlining that one iff \n```\n__cplusplus == 201103L\n```\n. OK, so why do I need a new language feature for this? I can already do the following to have the same effect, no? \n```\nnamespace std {', ""namespace pre_cxx_1997 {\n        // ...\n    }\n#if __cplusplus < 1997L // pre-standard C++\n    using namespace pre_cxx_1997;\n#endif\n\n#if __cplusplus >= 1997L // C++98/03 or later\n                         // (ifdef'ed out b/c it probably uses new language\n                         // features that a pre-C++98 compiler would choke on)\n\n    namespace cxx_1997 {\n        // ...\n    };\n#  if __cplusplus == 1997L // C++98/03\n    using namespace cxx_1997;\n#  endif\n\n#endif // C++98/03 or later\n\n} // namespace std"", ""namespace cxx_1997 {\n        // ...\n    };\n#  if __cplusplus == 1997L // C++98/03\n    using namespace cxx_1997;\n#  endif\n\n#endif // C++98/03 or later\n\n} // namespace std\n\n```\n Depending on the value of \n```\n__cplusplus\n```\n, I get either one or the other of the implementations. And you'd be almost correct. Consider the following valid C++98 user code (it was permitted to fully specialize templates that live in namespace \n```\nstd\n```\n in C++98 already): \n```\n// I don't trust my STL vendor to do this optimisation, so force these \n// specializations myself:\nnamespace std {\n    template <>\n    class vector<MyType> : my_special_vector<MyType> {\n        // ...\n    };\n    template <>\n    class vector<MyOtherType> : my_special_vector<MyOtherType> {\n        // ...\n    };\n    // ...etc...\n} // namespace std"", ""```\n This is perfectly valid code where the user supplies its own implementation of a vector for a set of type where she apparently knows a more efficient implementation than the one found in (her copy of) the STL. But: When specializing a template, you need to do so in the namespace it was declared in. The Standard says that \n```\nvector\n```\n is declared in namespace \n```\nstd\n```\n, so that's where the user rightfully expects to specialize the type. This code works with a non-versioned namespace \n```\nstd\n```\n, or with the C++11 inline namespace feature, but not with the versioning trick that used \n```\nusing namespace <nested>\n```\n, because that exposes the implementation detail that the true namespace in which \n```\nvector\n```\n was defined was not \n```\nstd\n```"", ""```\nusing namespace <nested>\n```\n, because that exposes the implementation detail that the true namespace in which \n```\nvector\n```\n was defined was not \n```\nstd\n```\n directly. There are other holes by which you could detect the nested namespace (see comments below), but inline namespaces plug them all. And that's all there is to it. Immensely useful for the future, but AFAIK the Standard doesn't prescribe inline namespace names for its own standard library (I'd love to be proven wrong on this, though), so it can only be used for third-party libraries, not the standard itself (unless the compiler vendors agree on a naming scheme).""]","Inline namespaces are a library versioning feature akin to symbol versioning, but implemented purely at the C++11 level (ie. cross-platform) instead of being a feature of a specific binary executable format (ie. platform-specific). It is a mechanism by which a library author can make a nested namespace look and act as if all its declarations were in the surrounding namespace (inline namespaces can be nested, so ""more-nested"" names percolate up all the way to the first non-inline namespace and look and act as if their declarations were in any of the namespaces in between, too). As an example, consider the STL implementation of 
```
vector
```
. If we had inline namespaces from the beginning of C++, then in C++98 the header 
```
<vector>
```
 might have looked like this: 
```
namespace std {

#if __cplusplus < 1997L // pre-standard C++
    inline
#endif

    namespace pre_cxx_1997 {
        template <class T> __vector_impl; // implementation class
        template <class T> // e.g. w/o allocator argument
        class vector : __vector_impl<T> { // private inheritance
            // ...
        };
    }
#if __cplusplus >= 1997L // C++98/03 or later
                         // (ifdef'ed out b/c it probably uses new language
                         // features that a pre-C++98 compiler would choke on)
#  if __cplusplus == 1997L // C++98/03
    inline
#  endif

    namespace cxx_1997 {

        // std::vector now has an allocator argument
        template <class T, class Alloc=std::allocator<T> >
        class vector : pre_cxx_1997::__vector_impl<T> { // the old impl is still good
            // ...
        };

        // and vector<bool> is special:
        template <class Alloc=std::allocator<bool> >
        class vector<bool> {
            // ...
        };

    };

#endif // C++98/03 or later

} // namespace std

```
 Depending on the value of 
```
__cplusplus
```
, either one or the other 
```
vector
```
 implementation is chosen. If your codebase was written in pre-C++98 times, and you find that the C++98 version of 
```
vector
```
 is causing trouble for you when you upgrade your compiler, ""all"" you have to do is to find the references to 
```
std::vector
```
 in your codebase and replace them by 
```
std::pre_cxx_1997::vector
```
. Come the next standard, and the STL vendor just repeats the procedure again, introducing a new namespace for 
```
std::vector
```
 with 
```
emplace_back
```
 support (which requires C++11) and inlining that one iff 
```
__cplusplus == 201103L
```
. OK, so why do I need a new language feature for this? I can already do the following to have the same effect, no? 
```
namespace std {

    namespace pre_cxx_1997 {
        // ...
    }
#if __cplusplus < 1997L // pre-standard C++
    using namespace pre_cxx_1997;
#endif

#if __cplusplus >= 1997L // C++98/03 or later
                         // (ifdef'ed out b/c it probably uses new language
                         // features that a pre-C++98 compiler would choke on)

    namespace cxx_1997 {
        // ...
    };
#  if __cplusplus == 1997L // C++98/03
    using namespace cxx_1997;
#  endif

#endif // C++98/03 or later

} // namespace std

```
 Depending on the value of 
```
__cplusplus
```
, I get either one or the other of the implementations. And you'd be almost correct. Consider the following valid C++98 user code (it was permitted to fully specialize templates that live in namespace 
```
std
```
 in C++98 already): 
```
// I don't trust my STL vendor to do this optimisation, so force these 
// specializations myself:
namespace std {
    template <>
    class vector<MyType> : my_special_vector<MyType> {
        // ...
    };
    template <>
    class vector<MyOtherType> : my_special_vector<MyOtherType> {
        // ...
    };
    // ...etc...
} // namespace std

```
 This is perfectly valid code where the user supplies its own implementation of a vector for a set of type where she apparently knows a more efficient implementation than the one found in (her copy of) the STL. But: When specializing a template, you need to do so in the namespace it was declared in. The Standard says that 
```
vector
```
 is declared in namespace 
```
std
```
, so that's where the user rightfully expects to specialize the type. This code works with a non-versioned namespace 
```
std
```
, or with the C++11 inline namespace feature, but not with the versioning trick that used 
```
using namespace <nested>
```
, because that exposes the implementation detail that the true namespace in which 
```
vector
```
 was defined was not 
```
std
```
 directly. There are other holes by which you could detect the nested namespace (see comments below), but inline namespaces plug them all. And that's all there is to it. Immensely useful for the future, but AFAIK the Standard doesn't prescribe inline namespace names for its own standard library (I'd love to be proven wrong on this, though), so it can only be used for third-party libraries, not the standard itself (unless the compiler vendors agree on a naming scheme)."
10750057,How do I print out the contents of a vector?,https://stackoverflow.com/questions/10750057/how-do-i-print-out-the-contents-of-a-vector,33,545.0,"[""If you have a C++11 compiler, I would suggest using a range-based for-loop (see below); or else use an iterator. But you have several options, all of which I will explain in what follows. Range-based for-loop (C++11) In C++11 (and later) you can use the new range-based for-loop, which looks like this: \n```\nstd::vector<char> path;\n// ...\nfor (char i: path)\n    std::cout << i << ' ';\n\n```\n The type \n```\nchar\n```\n in the for-loop statement should be the type of the elements of the vector \n```\npath\n```\n and not an integer indexing type. In other words, since \n```\npath\n```\n is of type \n```\nstd::vector<char>\n```\n, the type that should appear in the range-based for-loop is \n```\nchar\n```\n. However, you will likely often see the explicit type replaced with the \n```\nauto\n```\n placeholder type: \n```\nfor (auto i: path)\n    std::cout << i << ' ';"", '```\n Regardless of whether you use the explicit type or the \n```\nauto\n```\n keyword, the object \n```\ni\n```\n has a value that is a copy of the actual item in the \n```\npath\n```\n object. Thus, all changes to \n```\ni\n```\n in the loop are not preserved in \n```\npath\n```\n itself: \n```\nstd::vector<char> path{\'a\', \'b\', \'c\'};\n\nfor (auto i: path) {\n    i = \'_\'; // \'i\' is a copy of the element in \'path\', so although\n             // we can change \'i\' here perfectly fine, the elements\n             // of \'path\' have not changed\n    std::cout << i << \' \'; // will print: ""_ _ _""\n}\n\nfor (auto i: path) {\n    std::cout << i << \' \'; // will print: ""a b c""\n}\n\n```\n If you would like to proscribe being able to change this copied value of \n```\ni\n```\n in the for-loop as well, you can force the type of \n```\ni\n```\n to be \n```\nconst char\n```\n like this: \n```\nfor (const auto i: path) {\n    i = \'_\'; // this will now produce a compiler error\n    std::cout << i << \' \';\n}', ""```\n If you would like to modify the items in \n```\npath\n```\n so that those changes persist in \n```\npath\n```\n outside of the for-loop, then you can use a reference like so: \n```\nfor (auto& i: path) {\n    i = '_'; // changes to 'i' will now also change the\n             // element in 'path' itself to that value\n    std::cout << i << ' ';\n}\n\n```\n and even if you don't want to modify \n```\npath\n```\n, if the copying of objects is expensive you should use a const reference instead of copying by value: \n```\nfor (const auto& i: path)\n    std::cout << i << ' ';\n\n```\n Iterators Before C++11 the canonical solution would have been to use an iterator, and that is still perfectly acceptable. They are used as follows: \n```\nstd::vector<char> path;\n// ...\nfor (std::vector<char>::const_iterator i = path.begin(); i != path.end(); ++i)\n    std::cout << *i << ' ';"", ""```\n If you want to modify the vector's contents in the for-loop, then use \n```\niterator\n```\n rather than \n```\nconst_iterator\n```\n. Supplement: typedef / type alias (C++11) / auto (C++11) This is not another solution, but a supplement to the above \n```\niterator\n```\n solution. If you are using the C++11 standard (or later), then you can use the \n```\nauto\n```\n keyword to help the readability: \n```\nfor (auto i = path.begin(); i != path.end(); ++i)\n    std::cout << *i << ' ';"", '```\n Here the type of \n```\ni\n```\n will be non-const (i.e., the compiler will use \n```\nstd::vector<char>::iterator\n```\n as the type of \n```\ni\n```\n). This is because we called the \n```\nbegin\n```\n method, so the compiler deduced the type for \n```\ni\n```\n from that. If we call the \n```\ncbegin\n```\n method instead (""c"" for const), then \n```\ni\n```\n will be a \n```\nstd::vector<char>::const_iterator\n```\n: \n```\nfor (auto i = path.cbegin(); i != path.cend(); ++i) {\n    *i = \'_\'; // will produce a compiler error\n    std::cout << *i << \' \';\n}\n\n```\n If you\'re not comfortable with the compiler deducing types, then in C++11 you can use a type alias to avoid having to type the vector out all the time (a good habit to get into): \n```\nusing Path = std::vector<char>; // C++11 onwards only\nPath path; // \'Path\' is an alias for std::vector<char>\n// ...\nfor (Path::const_iterator i = path.begin(); i != path.end(); ++i)\n    std::cout << *i << \' \';', ""```\n If you do not have access to a C++11 compiler (or don't like the type alias syntax for whatever reason), then you can use the more traditional \n```\ntypedef\n```\n: \n```\ntypedef std::vector<char> Path; // 'Path' now a synonym for std::vector<char>\nPath path;\n// ...\nfor (Path::const_iterator i = path.begin(); i != path.end(); ++i)\n    std::cout << *i << ' ';"", '```\n Side note: At this point, you may or may not have come across iterators before, and you may or may not have heard that iterators are what you are ""supposed"" to use, and may be wondering why. The answer is not easy to appreciate, but, in brief, the idea is that iterators are an abstraction that shield you from the details of the operation. It is convenient to have an object (the iterator) that does the operation you want (like sequential access) rather than you writing the details yourself (the ""details"" being the code that does the actual accessing of the elements of the vector). You should notice that in the for-loop you are only ever asking the iterator to return you a value (\n```\n*i\n```\n, where \n```\ni\n```\n is the iterator) -- you are never interacting with \n```\npath\n```\n directly itself. The logic goes like this: you create an iterator and give it the object you want to loop over (\n```\niterator i = path.begin()\n```', ""```\npath\n```\n directly itself. The logic goes like this: you create an iterator and give it the object you want to loop over (\n```\niterator i = path.begin()\n```\n), and then all you do is ask the iterator to get the next value for you (\n```\n*i\n```\n); you never had to worry exactly how the iterator did that -- that's its business, not yours. OK, but what's the point? Well, imagine if getting a value wasn't simple. What if it involves a bit of work? You don't need to worry, because the iterator has handled that for you -- it sorts out the details, all you need to do is ask it for a value. Additionally, what if you change the container from \n```\nstd::vector\n```"", ""```\nstd::vector\n```\n to something else? In theory, your code doesn't change even if the details of how accessing elements in the new container does: remember, the iterator sorts all the details out for you behind the scenes, so you don't need to change your code at all -- you just ask the iterator for the next value in the container, same as before. So, whilst this may seem like confusing overkill for looping through a vector, there are good reasons behind the concept of iterators and so you might as well get used to using them. Indexing You can also use a integer type to index through the elements of the vector in the for-loop explicitly: \n```\nfor (int i=0; i<path.size(); ++i)\n    std::cout << path[i] << ' ';"", ""```\n If you are going to do this, it's better to use the container's member types, if they are available and appropriate. \n```\nstd::vector\n```\n has a member type called \n```\nsize_type\n```\n for this job: it is the type returned by the \n```\nsize\n```\n method. \n```\ntypedef std::vector<char> Path; // 'Path' now a synonym for std::vector<char>\nfor (Path::size_type i=0; i<path.size(); ++i)\n    std::cout << path[i] << ' ';"", '```\n Why not use this in preference to the \n```\niterator\n```\n solution? For simple cases, you can do that, but using an \n```\niterator\n```\n brings several advantages, which I have briefly outlined above. As such, my advice would be to avoid this method unless you have good reasons for it. std::copy (C++11) See Joshua\'s answer. You can use the STL algorithm \n```\nstd::copy\n```\n to copy the vector contents onto the output stream. I don\'t have anything to add, except to say that I don\'t use this method; but there\'s no good reason for that besides habit. std::ranges::copy (C++20) For completeness, C++20 introduced ranges, which can act on the whole range of a \n```\nstd::vector\n```\n, so no need for \n```\nbegin\n```\n and \n```\nend\n```\n: \n```\n#include <iterator> // for std::ostream_iterator\n#include <algorithm> // for std::ranges::copy depending on lib support\n\nstd::vector<char> path;\n// ...\nstd::ranges::copy(path, std::ostream_iterator<char>(std::cout, "" ""));', 'std::vector<char> path;\n// ...\nstd::ranges::copy(path, std::ostream_iterator<char>(std::cout, "" ""));\n\n```\n Unless you have a recent compiler (on GCC apparently at least version 10.1), likely you will not have ranges support even if you might have some C++20 features available. Overload std::ostream::operator<< See also Chris\'s answer below. This is more a complement to the other answers since you will still need to implement one of the solutions above in the overloading, but the benefit is much cleaner code. This is how you could use the \n```\nstd::ranges::copy\n```\n solution above: \n```\n#include <iostream>\n#include <vector>\n#include <iterator> // for std::ostream_iterator\n#include <algorithm> // for std::ranges::copy depending on lib support\n\nusing Path = std::vector<char>; // type alias for std::vector<char>', 'using Path = std::vector<char>; // type alias for std::vector<char>\n\nstd::ostream& operator<< (std::ostream& out, const Path& v) {\n    if ( !v.empty() ) {\n        out << \'[\';\n        std::ranges::copy(v, std::ostream_iterator<char>(out, "", ""));\n        out << ""\\b\\b]""; // use two ANSI backspace characters \'\\b\' to overwrite final "", ""\n    }\n    return out;\n}\n\nint main() {\n    Path path{\'/\', \'f\', \'o\', \'o\'};\n\n    // will output: ""path: [/, f, o, o]""\n    std::cout << ""path: "" << path << std::endl;\n\n    return 0;\n}', '```\n Now you can pass your \n```\nPath\n```', '```\nPath\n```\n objects to your output stream just like fundamental types. Using any of the other solutions above should also be equally straightforward. Conclusion Any of the solutions presented here will work. It\'s up to you (and context or your coding standards) on which one is the ""best"". Anything more detailed than this is probably best left for another question where the pros/cons can be properly evaluated, but as always user preference will always play a part: none of the solutions presented are objectively wrong, but some will look nicer to each coder. Addendum This is an expanded solution of an earlier one I posted. Since that post kept getting attention, I decided to expand on it and refer to the other excellent solutions posted here, at least those that I have personally used in the past at least once. I would, however, encourage the reader to look at the answers below because there are probably good suggestions that I have forgotten, or do not know, about.']","If you have a C++11 compiler, I would suggest using a range-based for-loop (see below); or else use an iterator. But you have several options, all of which I will explain in what follows. Range-based for-loop (C++11) In C++11 (and later) you can use the new range-based for-loop, which looks like this: 
```
std::vector<char> path;
// ...
for (char i: path)
    std::cout << i << ' ';

```
 The type 
```
char
```
 in the for-loop statement should be the type of the elements of the vector 
```
path
```
 and not an integer indexing type. In other words, since 
```
path
```
 is of type 
```
std::vector<char>
```
, the type that should appear in the range-based for-loop is 
```
char
```
. However, you will likely often see the explicit type replaced with the 
```
auto
```
 placeholder type: 
```
for (auto i: path)
    std::cout << i << ' ';

```
 Regardless of whether you use the explicit type or the 
```
auto
```
 keyword, the object 
```
i
```
 has a value that is a copy of the actual item in the 
```
path
```
 object. Thus, all changes to 
```
i
```
 in the loop are not preserved in 
```
path
```
 itself: 
```
std::vector<char> path{'a', 'b', 'c'};

for (auto i: path) {
    i = '_'; // 'i' is a copy of the element in 'path', so although
             // we can change 'i' here perfectly fine, the elements
             // of 'path' have not changed
    std::cout << i << ' '; // will print: ""_ _ _""
}

for (auto i: path) {
    std::cout << i << ' '; // will print: ""a b c""
}

```
 If you would like to proscribe being able to change this copied value of 
```
i
```
 in the for-loop as well, you can force the type of 
```
i
```
 to be 
```
const char
```
 like this: 
```
for (const auto i: path) {
    i = '_'; // this will now produce a compiler error
    std::cout << i << ' ';
}

```
 If you would like to modify the items in 
```
path
```
 so that those changes persist in 
```
path
```
 outside of the for-loop, then you can use a reference like so: 
```
for (auto& i: path) {
    i = '_'; // changes to 'i' will now also change the
             // element in 'path' itself to that value
    std::cout << i << ' ';
}

```
 and even if you don't want to modify 
```
path
```
, if the copying of objects is expensive you should use a const reference instead of copying by value: 
```
for (const auto& i: path)
    std::cout << i << ' ';

```
 Iterators Before C++11 the canonical solution would have been to use an iterator, and that is still perfectly acceptable. They are used as follows: 
```
std::vector<char> path;
// ...
for (std::vector<char>::const_iterator i = path.begin(); i != path.end(); ++i)
    std::cout << *i << ' ';

```
 If you want to modify the vector's contents in the for-loop, then use 
```
iterator
```
 rather than 
```
const_iterator
```
. Supplement: typedef / type alias (C++11) / auto (C++11) This is not another solution, but a supplement to the above 
```
iterator
```
 solution. If you are using the C++11 standard (or later), then you can use the 
```
auto
```
 keyword to help the readability: 
```
for (auto i = path.begin(); i != path.end(); ++i)
    std::cout << *i << ' ';

```
 Here the type of 
```
i
```
 will be non-const (i.e., the compiler will use 
```
std::vector<char>::iterator
```
 as the type of 
```
i
```
). This is because we called the 
```
begin
```
 method, so the compiler deduced the type for 
```
i
```
 from that. If we call the 
```
cbegin
```
 method instead (""c"" for const), then 
```
i
```
 will be a 
```
std::vector<char>::const_iterator
```
: 
```
for (auto i = path.cbegin(); i != path.cend(); ++i) {
    *i = '_'; // will produce a compiler error
    std::cout << *i << ' ';
}

```
 If you're not comfortable with the compiler deducing types, then in C++11 you can use a type alias to avoid having to type the vector out all the time (a good habit to get into): 
```
using Path = std::vector<char>; // C++11 onwards only
Path path; // 'Path' is an alias for std::vector<char>
// ...
for (Path::const_iterator i = path.begin(); i != path.end(); ++i)
    std::cout << *i << ' ';

```
 If you do not have access to a C++11 compiler (or don't like the type alias syntax for whatever reason), then you can use the more traditional 
```
typedef
```
: 
```
typedef std::vector<char> Path; // 'Path' now a synonym for std::vector<char>
Path path;
// ...
for (Path::const_iterator i = path.begin(); i != path.end(); ++i)
    std::cout << *i << ' ';

```
 Side note: At this point, you may or may not have come across iterators before, and you may or may not have heard that iterators are what you are ""supposed"" to use, and may be wondering why. The answer is not easy to appreciate, but, in brief, the idea is that iterators are an abstraction that shield you from the details of the operation. It is convenient to have an object (the iterator) that does the operation you want (like sequential access) rather than you writing the details yourself (the ""details"" being the code that does the actual accessing of the elements of the vector). You should notice that in the for-loop you are only ever asking the iterator to return you a value (
```
*i
```
, where 
```
i
```
 is the iterator) -- you are never interacting with 
```
path
```
 directly itself. The logic goes like this: you create an iterator and give it the object you want to loop over (
```
iterator i = path.begin()
```
), and then all you do is ask the iterator to get the next value for you (
```
*i
```
); you never had to worry exactly how the iterator did that -- that's its business, not yours. OK, but what's the point? Well, imagine if getting a value wasn't simple. What if it involves a bit of work? You don't need to worry, because the iterator has handled that for you -- it sorts out the details, all you need to do is ask it for a value. Additionally, what if you change the container from 
```
std::vector
```
 to something else? In theory, your code doesn't change even if the details of how accessing elements in the new container does: remember, the iterator sorts all the details out for you behind the scenes, so you don't need to change your code at all -- you just ask the iterator for the next value in the container, same as before. So, whilst this may seem like confusing overkill for looping through a vector, there are good reasons behind the concept of iterators and so you might as well get used to using them. Indexing You can also use a integer type to index through the elements of the vector in the for-loop explicitly: 
```
for (int i=0; i<path.size(); ++i)
    std::cout << path[i] << ' ';

```
 If you are going to do this, it's better to use the container's member types, if they are available and appropriate. 
```
std::vector
```
 has a member type called 
```
size_type
```
 for this job: it is the type returned by the 
```
size
```
 method. 
```
typedef std::vector<char> Path; // 'Path' now a synonym for std::vector<char>
for (Path::size_type i=0; i<path.size(); ++i)
    std::cout << path[i] << ' ';

```
 Why not use this in preference to the 
```
iterator
```
 solution? For simple cases, you can do that, but using an 
```
iterator
```
 brings several advantages, which I have briefly outlined above. As such, my advice would be to avoid this method unless you have good reasons for it. std::copy (C++11) See Joshua's answer. You can use the STL algorithm 
```
std::copy
```
 to copy the vector contents onto the output stream. I don't have anything to add, except to say that I don't use this method; but there's no good reason for that besides habit. std::ranges::copy (C++20) For completeness, C++20 introduced ranges, which can act on the whole range of a 
```
std::vector
```
, so no need for 
```
begin
```
 and 
```
end
```
: 
```
#include <iterator> // for std::ostream_iterator
#include <algorithm> // for std::ranges::copy depending on lib support

std::vector<char> path;
// ...
std::ranges::copy(path, std::ostream_iterator<char>(std::cout, "" ""));

```
 Unless you have a recent compiler (on GCC apparently at least version 10.1), likely you will not have ranges support even if you might have some C++20 features available. Overload std::ostream::operator<< See also Chris's answer below. This is more a complement to the other answers since you will still need to implement one of the solutions above in the overloading, but the benefit is much cleaner code. This is how you could use the 
```
std::ranges::copy
```
 solution above: 
```
#include <iostream>
#include <vector>
#include <iterator> // for std::ostream_iterator
#include <algorithm> // for std::ranges::copy depending on lib support

using Path = std::vector<char>; // type alias for std::vector<char>

std::ostream& operator<< (std::ostream& out, const Path& v) {
    if ( !v.empty() ) {
        out << '[';
        std::ranges::copy(v, std::ostream_iterator<char>(out, "", ""));
        out << ""\b\b]""; // use two ANSI backspace characters '\b' to overwrite final "", ""
    }
    return out;
}

int main() {
    Path path{'/', 'f', 'o', 'o'};

    // will output: ""path: [/, f, o, o]""
    std::cout << ""path: "" << path << std::endl;

    return 0;
}

```
 Now you can pass your 
```
Path
```
 objects to your output stream just like fundamental types. Using any of the other solutions above should also be equally straightforward. Conclusion Any of the solutions presented here will work. It's up to you (and context or your coding standards) on which one is the ""best"". Anything more detailed than this is probably best left for another question where the pros/cons can be properly evaluated, but as always user preference will always play a part: none of the solutions presented are objectively wrong, but some will look nicer to each coder. Addendum This is an expanded solution of an earlier one I posted. Since that post kept getting attention, I decided to expand on it and refer to the other excellent solutions posted here, at least those that I have personally used in the past at least once. I would, however, encourage the reader to look at the answers below because there are probably good suggestions that I have forgotten, or do not know, about."
570669,Checking if a double (or float) is NaN in C++,https://stackoverflow.com/questions/570669/checking-if-a-double-or-float-is-nan-in-c,21,406.0,"[""According to the IEEE standard, NaN values have the odd property that comparisons involving them are always false. That is, for a float f, \n```\nf != f\n```\n will be true only if f is NaN. Note that, as some comments below have pointed out, not all compilers respect this when optimizing code. For any compiler which claims to use IEEE floating point, this trick should work. But I can't guarantee that it will work in practice. Check with your compiler, if in doubt.""]","According to the IEEE standard, NaN values have the odd property that comparisons involving them are always false. That is, for a float f, 
```
f != f
```
 will be true only if f is NaN. Note that, as some comments below have pointed out, not all compilers respect this when optimizing code. For any compiler which claims to use IEEE floating point, this trick should work. But I can't guarantee that it will work in practice. Check with your compiler, if in doubt."
1257744,Can I use break to exit multiple nested 'for' loops?,https://stackoverflow.com/questions/1257744/can-i-use-break-to-exit-multiple-nested-for-loops,19,298.0,"[""AFAIK, C++ doesn't support naming loops, like Java and other languages do. You can use a goto, or create a flag value that you use. At the end of each loop check the flag value. If it is set to true, then you can break out of that iteration.""]","AFAIK, C++ doesn't support naming loops, like Java and other languages do. You can use a goto, or create a flag value that you use. At the end of each loop check the flag value. If it is set to true, then you can break out of that iteration."
1878001,"How do I check if a C++ std::string starts with a certain string, and convert a substring to an int?",https://stackoverflow.com/questions/1878001/how-do-i-check-if-a-c-stdstring-starts-with-a-certain-string-and-convert-a,24,839.0,"['Use \n```\nrfind\n```\n overload that takes the search position \n```\npos\n```\n parameter, and pass zero for it: \n```\nstd::string s = ""tititoto"";\nif (s.rfind(""titi"", 0) == 0) { // pos=0 limits the search to the prefix\n  // s starts with prefix\n}', '```\n Who needs anything else? Pure STL! Many have misread this to mean ""search backwards through the whole string looking for the prefix"". That would give the wrong result (e.g. \n```\nstring(""tititito"").rfind(""titi"")\n```\n returns 2 so when compared against \n```\n== 0\n```\n would return false) and it would be inefficient (looking through the whole string instead of just the start). But it does not do that because it passes the \n```\npos\n```\n parameter as \n```\n0\n```\n, which limits the search to only match at that position or earlier. For example: \n```\nstd::string test = ""0123123"";\nsize_t match1 = test.rfind(""123"");    // returns 4 (rightmost match)\nsize_t match2 = test.rfind(""123"", 2); // returns 1 (skipped over later match)\nsize_t match3 = test.rfind(""123"", 0); // returns std::string::npos (i.e. not found)', '```\n For C++20 onwards it got way simpler as both \n```\nstd::string\n```\n and \n```\nstd::string_view\n```\n has \n```\nstarts_with\n```\n: \n```\nstd::string s = ""tititoto"";\nif (s.starts_with(""titi""s)) {\n  // s starts with prefix\n}\n\n```']","Use 
```
rfind
```
 overload that takes the search position 
```
pos
```
 parameter, and pass zero for it: 
```
std::string s = ""tititoto"";
if (s.rfind(""titi"", 0) == 0) { // pos=0 limits the search to the prefix
  // s starts with prefix
}

```
 Who needs anything else? Pure STL! Many have misread this to mean ""search backwards through the whole string looking for the prefix"". That would give the wrong result (e.g. 
```
string(""tititito"").rfind(""titi"")
```
 returns 2 so when compared against 
```
== 0
```
 would return false) and it would be inefficient (looking through the whole string instead of just the start). But it does not do that because it passes the 
```
pos
```
 parameter as 
```
0
```
, which limits the search to only match at that position or earlier. For example: 
```
std::string test = ""0123123"";
size_t match1 = test.rfind(""123"");    // returns 4 (rightmost match)
size_t match2 = test.rfind(""123"", 2); // returns 1 (skipped over later match)
size_t match3 = test.rfind(""123"", 0); // returns std::string::npos (i.e. not found)

```
 For C++20 onwards it got way simpler as both 
```
std::string
```
 and 
```
std::string_view
```
 has 
```
starts_with
```
: 
```
std::string s = ""tititoto"";
if (s.starts_with(""titi""s)) {
  // s starts with prefix
}

```
"
59670,How to get rid of `deprecated conversion from string constant to ‘char*’` warnings in GCC,https://stackoverflow.com/questions/59670/how-to-get-rid-of-deprecated-conversion-from-string-constant-to-char-warnin,23,241.0,['I believe passing -Wno-write-strings to GCC will suppress this warning.'],I believe passing -Wno-write-strings to GCC will suppress this warning.
8542591,C++11 reverse range-based for-loop,https://stackoverflow.com/questions/8542591/c11-reverse-range-based-for-loop,12,284.0,"[""Actually Boost does have such adaptor: \n```\nboost::adaptors::reverse\n```\n. \n```\n#include <list>\n#include <iostream>\n#include <boost/range/adaptor/reversed.hpp>\n\nint main()\n{\n    std::list<int> x { 2, 3, 5, 7, 11, 13, 17, 19 };\n    for (auto i : boost::adaptors::reverse(x))\n        std::cout << i << '\\n';\n    for (auto i : x)\n        std::cout << i << '\\n';\n}\n\n```""]","Actually Boost does have such adaptor: 
```
boost::adaptors::reverse
```
. 
```
#include <list>
#include <iostream>
#include <boost/range/adaptor/reversed.hpp>

int main()
{
    std::list<int> x { 2, 3, 5, 7, 11, 13, 17, 19 };
    for (auto i : boost::adaptors::reverse(x))
        std::cout << i << '\n';
    for (auto i : x)
        std::cout << i << '\n';
}

```
"
13703647,How to properly add include directories with CMake,https://stackoverflow.com/questions/13703647/how-to-properly-add-include-directories-with-cmake,11,436.0,"['Two things must be done. First add the directory to be included: \n```\ntarget_include_directories(test PRIVATE ${YOUR_DIRECTORY})\n\n```\n In case you are stuck with a very old CMake version (2.8.10 or older) without support for \n```\ntarget_include_directories\n```\n, you can also use the legacy \n```\ninclude_directories\n```\n instead: \n```\ninclude_directories(${YOUR_DIRECTORY})\n\n```\n Then you also must add the header files to the list of your source files for the current target, for instance: \n```\nset(SOURCES file.cpp file2.cpp ${YOUR_DIRECTORY}/file1.h ${YOUR_DIRECTORY}/file2.h)\nadd_executable(test ${SOURCES})\n\n```\n This way, the header files will appear as dependencies in the Makefile, and also for example in the generated Visual Studio project, if you generate one. How to use those header files for several targets: \n```\nset(HEADER_FILES ${YOUR_DIRECTORY}/file1.h ${YOUR_DIRECTORY}/file2.h)', 'add_library(mylib libsrc.cpp ${HEADER_FILES})\ntarget_include_directories(mylib PRIVATE ${YOUR_DIRECTORY})\nadd_executable(myexec execfile.cpp ${HEADER_FILES})\ntarget_include_directories(myexec PRIVATE ${YOUR_DIRECTORY})\n\n```']","Two things must be done. First add the directory to be included: 
```
target_include_directories(test PRIVATE ${YOUR_DIRECTORY})

```
 In case you are stuck with a very old CMake version (2.8.10 or older) without support for 
```
target_include_directories
```
, you can also use the legacy 
```
include_directories
```
 instead: 
```
include_directories(${YOUR_DIRECTORY})

```
 Then you also must add the header files to the list of your source files for the current target, for instance: 
```
set(SOURCES file.cpp file2.cpp ${YOUR_DIRECTORY}/file1.h ${YOUR_DIRECTORY}/file2.h)
add_executable(test ${SOURCES})

```
 This way, the header files will appear as dependencies in the Makefile, and also for example in the generated Visual Studio project, if you generate one. How to use those header files for several targets: 
```
set(HEADER_FILES ${YOUR_DIRECTORY}/file1.h ${YOUR_DIRECTORY}/file2.h)

add_library(mylib libsrc.cpp ${HEADER_FILES})
target_include_directories(mylib PRIVATE ${YOUR_DIRECTORY})
add_executable(myexec execfile.cpp ${HEADER_FILES})
target_include_directories(myexec PRIVATE ${YOUR_DIRECTORY})

```
"
672373,Can I call a base class's virtual function if I'm overriding it?,https://stackoverflow.com/questions/672373/can-i-call-a-base-classs-virtual-function-if-im-overriding-it,8,549.0,"[""In C++ you have to explicitly name the base class in calling the derived class method. This can be done from any method from the derived class. The override is a special case of the method of the same name. In Java there is no multi inheritance, so you can use super which will uniquely name the base class. The C++ syntax is like this: \n```\nclass Bar : public Foo {\n  // ...\n\n  void printStuff() override {  // help the compiler to check\n    Foo::printStuff(); // calls base class' function\n  }\n};\n\n```""]","In C++ you have to explicitly name the base class in calling the derived class method. This can be done from any method from the derived class. The override is a special case of the method of the same name. In Java there is no multi inheritance, so you can use super which will uniquely name the base class. The C++ syntax is like this: 
```
class Bar : public Foo {
  // ...

  void printStuff() override {  // help the compiler to check
    Foo::printStuff(); // calls base class' function
  }
};

```
"
246564,What is the lifetime of a static variable in a C++ function?,https://stackoverflow.com/questions/246564/what-is-the-lifetime-of-a-static-variable-in-a-c-function,5,307.0,"['The lifetime of function \n```\nstatic\n```\n variables begins the first time[0] the program flow encounters the declaration and it ends at program termination. This means that the run-time must perform some book keeping in order to destruct it only if it was actually constructed. Additionally, since the standard says that the destructors of static objects must run in the reverse order of the completion of their construction[1], and the order of construction may depend on the specific program run, the order of construction must be taken into account. Example \n```\nstruct emitter {\n    string str;\n    emitter(const string& s) : str(s) { cout << ""Created "" << str << endl; }\n    ~emitter() { cout << ""Destroyed "" << str << endl; }\n};\n\nvoid foo(bool skip_first) \n{\n    if (!skip_first)\n        static emitter a(""in if"");\n    static emitter b(""in foo"");\n}\n\nint main(int argc, char*[])\n{\n    foo(argc != 2);\n    if (argc == 3)\n        foo(false);\n}', 'int main(int argc, char*[])\n{\n    foo(argc != 2);\n    if (argc == 3)\n        foo(false);\n}\n\n```\n Output: C:>sample.exe Created in foo Destroyed in foo C:>sample.exe 1 Created in if Created in foo Destroyed in foo Destroyed in if C:>sample.exe 1 2 Created in foo Created in if Destroyed in if Destroyed in foo \n```\n[0]\n```\n Since C++98[2] has no reference to multiple threads how this will be behave in a multi-threaded environment is unspecified, and can be problematic as Roddy mentions. \n```\n[1]\n```\n C++98 section \n```\n3.6.3.1\n```\n [basic.start.term] \n```\n[2]\n```\n In C++11 statics are initialized in a thread safe way, this is also known as Magic Statics.']","The lifetime of function 
```
static
```
 variables begins the first time[0] the program flow encounters the declaration and it ends at program termination. This means that the run-time must perform some book keeping in order to destruct it only if it was actually constructed. Additionally, since the standard says that the destructors of static objects must run in the reverse order of the completion of their construction[1], and the order of construction may depend on the specific program run, the order of construction must be taken into account. Example 
```
struct emitter {
    string str;
    emitter(const string& s) : str(s) { cout << ""Created "" << str << endl; }
    ~emitter() { cout << ""Destroyed "" << str << endl; }
};

void foo(bool skip_first) 
{
    if (!skip_first)
        static emitter a(""in if"");
    static emitter b(""in foo"");
}

int main(int argc, char*[])
{
    foo(argc != 2);
    if (argc == 3)
        foo(false);
}

```
 Output: C:>sample.exe Created in foo Destroyed in foo C:>sample.exe 1 Created in if Created in foo Destroyed in foo Destroyed in if C:>sample.exe 1 2 Created in foo Created in if Destroyed in if Destroyed in foo 
```
[0]
```
 Since C++98[2] has no reference to multiple threads how this will be behave in a multi-threaded environment is unspecified, and can be problematic as Roddy mentions. 
```
[1]
```
 C++98 section 
```
3.6.3.1
```
 [basic.start.term] 
```
[2]
```
 In C++11 statics are initialized in a thread safe way, this is also known as Magic Statics."
2808398,Easily measure elapsed time,https://stackoverflow.com/questions/2808398/easily-measure-elapsed-time,26,,[],
24901,Is there a performance difference between i++ and ++i in C++?,https://stackoverflow.com/questions/24901/is-there-a-performance-difference-between-i-and-i-in-c,20,505.0,"['[Executive Summary: Use \n```\n++i\n```\n if you don\'t have a specific reason to use \n```\ni++\n```\n.] For C++, the answer is a bit more complicated. If \n```\ni\n```\n is a simple type (not an instance of a C++ class), then the answer given for C (""No there is no performance difference"") holds, since the compiler is generating the code. However, if \n```\ni\n```\n is an instance of a C++ class, then \n```\ni++\n```\n and \n```\n++i\n```\n are making calls to one of the \n```\noperator++\n```\n functions. Here\'s a standard pair of these functions: \n```\nFoo& Foo::operator++()   // called for ++i\n{\n    this->data += 1;\n    return *this;\n}\n\nFoo Foo::operator++(int ignored_dummy_value)   // called for i++\n{\n    Foo tmp(*this);   // variable ""tmp"" cannot be optimized away by the compiler\n    ++(*this);\n    return tmp;\n}', 'Foo Foo::operator++(int ignored_dummy_value)   // called for i++\n{\n    Foo tmp(*this);   // variable ""tmp"" cannot be optimized away by the compiler\n    ++(*this);\n    return tmp;\n}\n\n```\n Since the compiler isn\'t generating code, but just calling an \n```\noperator++\n```\n function, there is no way to optimize away the \n```\ntmp\n```\n variable and its associated copy constructor. If the copy constructor is expensive, then this can have a significant performance impact.']","[Executive Summary: Use 
```
++i
```
 if you don't have a specific reason to use 
```
i++
```
.] For C++, the answer is a bit more complicated. If 
```
i
```
 is a simple type (not an instance of a C++ class), then the answer given for C (""No there is no performance difference"") holds, since the compiler is generating the code. However, if 
```
i
```
 is an instance of a C++ class, then 
```
i++
```
 and 
```
++i
```
 are making calls to one of the 
```
operator++
```
 functions. Here's a standard pair of these functions: 
```
Foo& Foo::operator++()   // called for ++i
{
    this->data += 1;
    return *this;
}

Foo Foo::operator++(int ignored_dummy_value)   // called for i++
{
    Foo tmp(*this);   // variable ""tmp"" cannot be optimized away by the compiler
    ++(*this);
    return tmp;
}

```
 Since the compiler isn't generating code, but just calling an 
```
operator++
```
 function, there is no way to optimize away the 
```
tmp
```
 variable and its associated copy constructor. If the copy constructor is expensive, then this can have a significant performance impact."
17095324,Fastest way to determine if an integer is between two integers (inclusive) with known sets of values,https://stackoverflow.com/questions/17095324/fastest-way-to-determine-if-an-integer-is-between-two-integers-inclusive-with,7,567.0,"[""There's an old trick to do this with only one comparison/branch. Whether it'll really improve speed may be open to question, and even if it does, it's probably too little to notice or care about, but when you're only starting with two comparisons, the chances of a huge improvement are pretty remote. The code looks like: \n```\n// use a < for an inclusive lower bound and exclusive upper bound\n// use <= for an inclusive lower bound and inclusive upper bound\n// alternatively, if the upper bound is inclusive and you can pre-calculate\n// upper-lower, simply add + 1 to upper-lower and use the < operator.\nif ((unsigned)(number-lower) <= (upper-lower))\n    in_range(number);"", ""```\n With a typical, modern computer (i.e., anything using twos complement), the conversion to unsigned is really a nop -- just a change in how the same bits are viewed. Note that in a typical case, you can pre-compute \n```\nupper-lower\n```\n outside a (presumed) loop, so that doesn't normally contribute any significant time. Along with reducing the number of branch instructions, this also (generally) improves branch prediction. In this case, the same branch is taken whether the number is below the bottom end or above the top end of the range. As to how this works, the basic idea is pretty simple: a negative number, when viewed as an unsigned number, will be larger than anything that started out as a positive number. In practice this method translates \n```\nnumber\n```\n and the interval to the point of origin and checks if \n```\nnumber\n```\n is in the interval \n```\n[0, D]\n```\n, where \n```\nD = upper - lower\n```\n. If \n```\nnumber\n```"", '```\nnumber\n```\n and the interval to the point of origin and checks if \n```\nnumber\n```\n is in the interval \n```\n[0, D]\n```\n, where \n```\nD = upper - lower\n```\n. If \n```\nnumber\n```\n below lower bound: negative, and if above upper bound: larger than \n```\nD\n```\n.']","There's an old trick to do this with only one comparison/branch. Whether it'll really improve speed may be open to question, and even if it does, it's probably too little to notice or care about, but when you're only starting with two comparisons, the chances of a huge improvement are pretty remote. The code looks like: 
```
// use a < for an inclusive lower bound and exclusive upper bound
// use <= for an inclusive lower bound and inclusive upper bound
// alternatively, if the upper bound is inclusive and you can pre-calculate
// upper-lower, simply add + 1 to upper-lower and use the < operator.
if ((unsigned)(number-lower) <= (upper-lower))
    in_range(number);

```
 With a typical, modern computer (i.e., anything using twos complement), the conversion to unsigned is really a nop -- just a change in how the same bits are viewed. Note that in a typical case, you can pre-compute 
```
upper-lower
```
 outside a (presumed) loop, so that doesn't normally contribute any significant time. Along with reducing the number of branch instructions, this also (generally) improves branch prediction. In this case, the same branch is taken whether the number is below the bottom end or above the top end of the range. As to how this works, the basic idea is pretty simple: a negative number, when viewed as an unsigned number, will be larger than anything that started out as a positive number. In practice this method translates 
```
number
```
 and the interval to the point of origin and checks if 
```
number
```
 is in the interval 
```
[0, D]
```
, where 
```
D = upper - lower
```
. If 
```
number
```
 below lower bound: negative, and if above upper bound: larger than 
```
D
```
."
17016175,C++ unordered_map using a custom class type as the key,https://stackoverflow.com/questions/17016175/c-unordered-map-using-a-custom-class-type-as-the-key,8,,[],
10681375,Which is better option to use for dividing an integer number by 2?,https://stackoverflow.com/questions/10681375/which-is-better-option-to-use-for-dividing-an-integer-number-by-2,22,855.0,"['Use the operation that best describes what you are trying to do. If you are treating the number as a sequence of bits, use bitshift. If you are treating it as a numerical value, use division. Note that they are not exactly equivalent. They can give different results for negative integers. For example: \n```\n-5 / 2  = -2\n-5 >> 1 = -3\n\n```\n (ideone)']","Use the operation that best describes what you are trying to do. If you are treating the number as a sequence of bits, use bitshift. If you are treating it as a numerical value, use division. Note that they are not exactly equivalent. They can give different results for negative integers. For example: 
```
-5 / 2  = -2
-5 >> 1 = -3

```
 (ideone)"
1657883,Variable number of arguments in C++?,https://stackoverflow.com/questions/1657883/variable-number-of-arguments-in-c,18,194.0,"[""You probably shouldn't, and you can probably do what you want to do in a safer and simpler way. Technically to use variable number of arguments in C you include stdarg.h. From that you'll get the \n```\nva_list\n```\n type as well as three functions that operate on it called \n```\nva_start()\n```\n, \n```\nva_arg()\n```\n and \n```\nva_end()\n```\n. \n```\n#include<stdarg.h>\n\nint maxof(int n_args, ...)\n{\n    va_list ap;\n    va_start(ap, n_args);\n    int max = va_arg(ap, int);\n    for(int i = 2; i <= n_args; i++) {\n        int a = va_arg(ap, int);\n        if(a > max) max = a;\n    }\n    va_end(ap);\n    return max;\n}"", ""```\n If you ask me, this is a mess. It looks bad, it's unsafe, and it's full of technical details that have nothing to do with what you're conceptually trying to achieve. Instead, consider using overloading or inheritance/polymorphism, builder pattern (as in \n```\noperator<<()\n```\n in streams) or default arguments etc. These are all safer: the compiler gets to know more about what you're trying to do so there are more occasions it can stop you before you blow your leg off.""]","You probably shouldn't, and you can probably do what you want to do in a safer and simpler way. Technically to use variable number of arguments in C you include stdarg.h. From that you'll get the 
```
va_list
```
 type as well as three functions that operate on it called 
```
va_start()
```
, 
```
va_arg()
```
 and 
```
va_end()
```
. 
```
#include<stdarg.h>

int maxof(int n_args, ...)
{
    va_list ap;
    va_start(ap, n_args);
    int max = va_arg(ap, int);
    for(int i = 2; i <= n_args; i++) {
        int a = va_arg(ap, int);
        if(a > max) max = a;
    }
    va_end(ap);
    return max;
}

```
 If you ask me, this is a mess. It looks bad, it's unsafe, and it's full of technical details that have nothing to do with what you're conceptually trying to achieve. Instead, consider using overloading or inheritance/polymorphism, builder pattern (as in 
```
operator<<()
```
 in streams) or default arguments etc. These are all safer: the compiler gets to know more about what you're trying to do so there are more occasions it can stop you before you blow your leg off."
6963894,How to use range-based for() loop with std::map?,https://stackoverflow.com/questions/6963894/how-to-use-range-based-for-loop-with-stdmap,5,617.0,"['Each element of the container is a \n```\nmap<K, V>::value_type\n```\n, which is a \n```\ntypedef\n```\n for \n```\nstd::pair<const K, V>\n```\n. Consequently, in C++17 or higher, you can write \n```\nfor (auto& [key, value]: myMap) {\n    std::cout << key << "" has value "" << value << std::endl;\n}\n\n```\n or as \n```\nfor (const auto& [key, value]: myMap) {\n    std::cout << key << "" has value "" << value << std::endl;\n}\n\n```\n if you don\'t plan on modifying the values. In C++11 and C++14, you can use enhanced \n```\nfor\n```\n loops to extract out each pair on its own, then manually extract the keys and values: \n```\nfor (const auto& kv : myMap) {\n    std::cout << kv.first << "" has value "" << kv.second << std::endl;\n}\n\n```\n You could also consider marking the \n```\nkv\n```\n variable \n```\nconst\n```\n if you want a read-only view of the values.']","Each element of the container is a 
```
map<K, V>::value_type
```
, which is a 
```
typedef
```
 for 
```
std::pair<const K, V>
```
. Consequently, in C++17 or higher, you can write 
```
for (auto& [key, value]: myMap) {
    std::cout << key << "" has value "" << value << std::endl;
}

```
 or as 
```
for (const auto& [key, value]: myMap) {
    std::cout << key << "" has value "" << value << std::endl;
}

```
 if you don't plan on modifying the values. In C++11 and C++14, you can use enhanced 
```
for
```
 loops to extract out each pair on its own, then manually extract the keys and values: 
```
for (const auto& kv : myMap) {
    std::cout << kv.first << "" has value "" << kv.second << std::endl;
}

```
 You could also consider marking the 
```
kv
```
 variable 
```
const
```
 if you want a read-only view of the values."
752658,Is the practice of returning a C++ reference variable evil?,https://stackoverflow.com/questions/752658/is-the-practice-of-returning-a-c-reference-variable-evil,17,508.0,"[""In general, returning a reference is perfectly normal and happens all the time. If you mean: \n```\nint& getInt() {\n    int i;\n    return i;  // DON'T DO THIS.\n}\n\n```\n That is all sorts of evil. The stack-allocated \n```\ni\n```\n will go away and you are referring to nothing. This is also evil: \n```\nint& getInt() {\n    int* i = new int;\n    return *i;  // DON'T DO THIS.\n}\n\n```\n Because now the client has to eventually do the strange: \n```\nint& myInt = getInt(); // note the &, we cannot lose this reference!\ndelete &myInt;         // must delete...totally weird and  evil\n\nint oops = getInt(); \ndelete &oops; // undefined behavior, we're wrongly deleting a copy, not the original\n\n```\n Note that rvalue references are still just references, so all the evil applications remain the same. If you want to allocate something that lives beyond the scope of the function, use a smart pointer (or in general, a container): \n```\nstd::unique_ptr<int> getInt() {\n    return std::make_unique<int>(0);\n}"", ""```\n And now the client stores a smart pointer: \n```\nstd::unique_ptr<int> x = getInt();\n\n```\n References are also okay for accessing things where you know the lifetime is being kept open on a higher-level, e.g.: \n```\nstruct immutableint {\n    immutableint(int i) : i_(i) {}\n\n    const int& get() const { return i_; }\nprivate:\n    int i_;\n};\n\n```\n Here we know it's okay to return a reference to \n```\ni_\n```\n because whatever is calling us manages the lifetime of the class instance, so \n```\ni_\n```\n will live at least that long. And of course, there's nothing wrong with just: \n```\nint getInt() {\n   return 0;\n}\n\n```\n If the lifetime should be left up to the caller, and you're just computing the value. Summary: it's okay to return a reference if the lifetime of the object won't end after the call.""]","In general, returning a reference is perfectly normal and happens all the time. If you mean: 
```
int& getInt() {
    int i;
    return i;  // DON'T DO THIS.
}

```
 That is all sorts of evil. The stack-allocated 
```
i
```
 will go away and you are referring to nothing. This is also evil: 
```
int& getInt() {
    int* i = new int;
    return *i;  // DON'T DO THIS.
}

```
 Because now the client has to eventually do the strange: 
```
int& myInt = getInt(); // note the &, we cannot lose this reference!
delete &myInt;         // must delete...totally weird and  evil

int oops = getInt(); 
delete &oops; // undefined behavior, we're wrongly deleting a copy, not the original

```
 Note that rvalue references are still just references, so all the evil applications remain the same. If you want to allocate something that lives beyond the scope of the function, use a smart pointer (or in general, a container): 
```
std::unique_ptr<int> getInt() {
    return std::make_unique<int>(0);
}

```
 And now the client stores a smart pointer: 
```
std::unique_ptr<int> x = getInt();

```
 References are also okay for accessing things where you know the lifetime is being kept open on a higher-level, e.g.: 
```
struct immutableint {
    immutableint(int i) : i_(i) {}

    const int& get() const { return i_; }
private:
    int i_;
};

```
 Here we know it's okay to return a reference to 
```
i_
```
 because whatever is calling us manages the lifetime of the class instance, so 
```
i_
```
 will live at least that long. And of course, there's nothing wrong with just: 
```
int getInt() {
   return 0;
}

```
 If the lifetime should be left up to the caller, and you're just computing the value. Summary: it's okay to return a reference if the lifetime of the object won't end after the call."
306316,Determine if two rectangles overlap each other?,https://stackoverflow.com/questions/306316/determine-if-two-rectangles-overlap-each-other,22,844.0,"['```\nif (RectA.Left < RectB.Right && RectA.Right > RectB.Left &&\n     RectA.Top > RectB.Bottom && RectA.Bottom < RectB.Top ) \n\n```\n or, using Cartesian coordinates (With X1 being left coord, X2 being right coord, increasing from left to right and Y1 being Top coord, and Y2 being Bottom coord, increasing from bottom to top -- if this is not how your coordinate system [e.g. most computers have the Y direction reversed], swap the comparisons below) ... \n```\nif (RectA.X1 < RectB.X2 && RectA.X2 > RectB.X1 &&\n    RectA.Y1 > RectB.Y2 && RectA.Y2 < RectB.Y1)', ""```\n Say you have Rect A, and Rect B. Proof is by contradiction. Any one of four conditions guarantees that no overlap can exist: Cond1. If A's left edge is to the right of the B's right edge, - then A is Totally to right Of B Cond2. If A's right edge is to the left of the B's left edge, - then A is Totally to left Of B Cond3. If A's top edge is below B's bottom edge, - then A is Totally below B Cond4. If A's bottom edge is above B's top edge, - then A is Totally above B So condition for Non-Overlap is NON-Overlap => Cond1 Or Cond2 Or Cond3 Or Cond4 Therefore, a sufficient condition for Overlap is the opposite. Overlap => NOT (Cond1 Or Cond2 Or Cond3 Or Cond4) De Morgan's law says \n```\nNot (A or B or C or D)\n```\n is the same as \n```\nNot A And Not B And Not C And Not D\n```\n so using De Morgan, we have Not Cond1 And Not Cond2 And Not Cond3 And Not Cond4 This is equivalent to: A's Left Edge to left of B's right edge, [\n```\nRectA.Left < RectB.Right\n```"", ""```\n so using De Morgan, we have Not Cond1 And Not Cond2 And Not Cond3 And Not Cond4 This is equivalent to: A's Left Edge to left of B's right edge, [\n```\nRectA.Left < RectB.Right\n```\n], and A's right edge to right of B's left edge, [\n```\nRectA.Right > RectB.Left\n```\n], and A's top above B's bottom, [\n```\nRectA.Top > RectB.Bottom\n```\n], and A's bottom below B's Top [\n```\nRectA.Bottom < RectB.Top\n```\n] Note 1: It is fairly obvious this same principle can be extended to any number of dimensions. Note 2: It should also be fairly obvious to count overlaps of just one pixel, change the \n```\n<\n```\n and/or the \n```\n>\n```\n on that boundary to a \n```\n<=\n```\n or a \n```\n>=\n```"", '```\n<\n```\n and/or the \n```\n>\n```\n on that boundary to a \n```\n<=\n```\n or a \n```\n>=\n```\n. Note 3: This answer, when utilizing Cartesian coordinates (X, Y) is based on standard algebraic Cartesian coordinates (x increases left to right, and Y increases bottom to top). Obviously, where a computer system might mechanize screen coordinates differently, (e.g., increasing Y from top to bottom, or X From right to left), the syntax will need to be adjusted accordingly/']","
```
if (RectA.Left < RectB.Right && RectA.Right > RectB.Left &&
     RectA.Top > RectB.Bottom && RectA.Bottom < RectB.Top ) 

```
 or, using Cartesian coordinates (With X1 being left coord, X2 being right coord, increasing from left to right and Y1 being Top coord, and Y2 being Bottom coord, increasing from bottom to top -- if this is not how your coordinate system [e.g. most computers have the Y direction reversed], swap the comparisons below) ... 
```
if (RectA.X1 < RectB.X2 && RectA.X2 > RectB.X1 &&
    RectA.Y1 > RectB.Y2 && RectA.Y2 < RectB.Y1) 

```
 Say you have Rect A, and Rect B. Proof is by contradiction. Any one of four conditions guarantees that no overlap can exist: Cond1. If A's left edge is to the right of the B's right edge, - then A is Totally to right Of B Cond2. If A's right edge is to the left of the B's left edge, - then A is Totally to left Of B Cond3. If A's top edge is below B's bottom edge, - then A is Totally below B Cond4. If A's bottom edge is above B's top edge, - then A is Totally above B So condition for Non-Overlap is NON-Overlap => Cond1 Or Cond2 Or Cond3 Or Cond4 Therefore, a sufficient condition for Overlap is the opposite. Overlap => NOT (Cond1 Or Cond2 Or Cond3 Or Cond4) De Morgan's law says 
```
Not (A or B or C or D)
```
 is the same as 
```
Not A And Not B And Not C And Not D
```
 so using De Morgan, we have Not Cond1 And Not Cond2 And Not Cond3 And Not Cond4 This is equivalent to: A's Left Edge to left of B's right edge, [
```
RectA.Left < RectB.Right
```
], and A's right edge to right of B's left edge, [
```
RectA.Right > RectB.Left
```
], and A's top above B's bottom, [
```
RectA.Top > RectB.Bottom
```
], and A's bottom below B's Top [
```
RectA.Bottom < RectB.Top
```
] Note 1: It is fairly obvious this same principle can be extended to any number of dimensions. Note 2: It should also be fairly obvious to count overlaps of just one pixel, change the 
```
<
```
 and/or the 
```
>
```
 on that boundary to a 
```
<=
```
 or a 
```
>=
```
. Note 3: This answer, when utilizing Cartesian coordinates (X, Y) is based on standard algebraic Cartesian coordinates (x increases left to right, and Y increases bottom to top). Obviously, where a computer system might mechanize screen coordinates differently, (e.g., increasing Y from top to bottom, or X From right to left), the syntax will need to be adjusted accordingly/"
20895648,Difference in make_shared and normal shared_ptr in C++,https://stackoverflow.com/questions/20895648/difference-in-make-shared-and-normal-shared-ptr-in-c,8,480.0,"['The difference is that \n```\nstd::make_shared\n```\n performs one heap-allocation, whereas calling the \n```\nstd::shared_ptr\n```\n constructor performs two. Where do the heap-allocations happen? \n```\nstd::shared_ptr\n```\n manages two entities: the control block (stores meta data such as ref-counts, type-erased deleter, etc) the object being managed \n```\nstd::make_shared\n```\n performs a single heap-allocation accounting for the space necessary for both the control block and the data. In the other case, \n```\nnew Obj(""foo"")\n```\n invokes a heap-allocation for the managed data and the \n```\nstd::shared_ptr\n```', '```\nnew Obj(""foo"")\n```\n invokes a heap-allocation for the managed data and the \n```\nstd::shared_ptr\n```\n constructor performs another one for the control block. For further information, check out the implementation notes at cppreference. Update I: Exception-Safety NOTE (2019/08/30): This is not a problem since C++17, due to the changes in the evaluation order of function arguments. Specifically, each argument to a function is required to fully execute before evaluation of other arguments. Since the OP seem to be wondering about the exception-safety side of things, I\'ve updated my answer. Consider this example, \n```\nvoid F(const std::shared_ptr<Lhs> &lhs, const std::shared_ptr<Rhs> &rhs) { /* ... */ }', 'F(std::shared_ptr<Lhs>(new Lhs(""foo"")),\n  std::shared_ptr<Rhs>(new Rhs(""bar"")));\n\n```\n Because C++ allows arbitrary order of evaluation of subexpressions, one possible ordering is: \n```\nnew Lhs(""foo""))\n```\n \n```\nnew Rhs(""bar""))\n```\n \n```\nstd::shared_ptr<Lhs>\n```\n \n```\nstd::shared_ptr<Rhs>\n```\n Now, suppose we get an exception thrown at step 2 (e.g., out of memory exception, \n```\nRhs\n```\n constructor threw some exception). We then lose memory allocated at step 1, since nothing will have had a chance to clean it up. The core of the problem here is that the raw pointer didn\'t get passed to the \n```\nstd::shared_ptr\n```\n constructor immediately. One way to fix this is to do them on separate lines so that this arbitary ordering cannot occur. \n```\nauto lhs = std::shared_ptr<Lhs>(new Lhs(""foo""));\nauto rhs = std::shared_ptr<Rhs>(new Rhs(""bar""));\nF(lhs, rhs);', '```\n The preferred way to solve this of course is to use \n```\nstd::make_shared\n```\n instead. \n```\nF(std::make_shared<Lhs>(""foo""), std::make_shared<Rhs>(""bar""));', ""```\n Update II: Disadvantage of \n```\nstd::make_shared\n```\n Quoting Casey's comments: Since there there's only one allocation, the pointee's memory cannot be deallocated until the control block is no longer in use. A \n```\nweak_ptr\n```\n can keep the control block alive indefinitely. Why do instances of \n```\nweak_ptr\n```\ns keep the control block alive? There must be a way for \n```\nweak_ptr\n```\ns to determine if the managed object is still valid (eg. for \n```\nlock\n```\n). They do this by checking the number of \n```\nshared_ptr\n```\ns that own the managed object, which is stored in the control block. The result is that the control blocks are alive until the \n```\nshared_ptr\n```\n count and the \n```\nweak_ptr\n```\n count both hit 0. Back to \n```\nstd::make_shared\n```\n Since \n```\nstd::make_shared\n```"", '```\nshared_ptr\n```\n count and the \n```\nweak_ptr\n```\n count both hit 0. Back to \n```\nstd::make_shared\n```\n Since \n```\nstd::make_shared\n```\n makes a single heap-allocation for both the control block and the managed object, there is no way to free the memory for control block and the managed object independently. We must wait until we can free both the control block and the managed object, which happens to be until there are no \n```\nshared_ptr\n```\ns or \n```\nweak_ptr\n```\ns alive. Suppose we instead performed two heap-allocations for the control block and the managed object via \n```\nnew\n```\n and \n```\nshared_ptr\n```\n constructor. Then we free the memory for the managed object (maybe earlier) when there are no \n```\nshared_ptr\n```\ns alive, and free the memory for the control block (maybe later) when there are no \n```\nweak_ptr\n```\ns alive.']","The difference is that 
```
std::make_shared
```
 performs one heap-allocation, whereas calling the 
```
std::shared_ptr
```
 constructor performs two. Where do the heap-allocations happen? 
```
std::shared_ptr
```
 manages two entities: the control block (stores meta data such as ref-counts, type-erased deleter, etc) the object being managed 
```
std::make_shared
```
 performs a single heap-allocation accounting for the space necessary for both the control block and the data. In the other case, 
```
new Obj(""foo"")
```
 invokes a heap-allocation for the managed data and the 
```
std::shared_ptr
```
 constructor performs another one for the control block. For further information, check out the implementation notes at cppreference. Update I: Exception-Safety NOTE (2019/08/30): This is not a problem since C++17, due to the changes in the evaluation order of function arguments. Specifically, each argument to a function is required to fully execute before evaluation of other arguments. Since the OP seem to be wondering about the exception-safety side of things, I've updated my answer. Consider this example, 
```
void F(const std::shared_ptr<Lhs> &lhs, const std::shared_ptr<Rhs> &rhs) { /* ... */ }

F(std::shared_ptr<Lhs>(new Lhs(""foo"")),
  std::shared_ptr<Rhs>(new Rhs(""bar"")));

```
 Because C++ allows arbitrary order of evaluation of subexpressions, one possible ordering is: 
```
new Lhs(""foo""))
```
 
```
new Rhs(""bar""))
```
 
```
std::shared_ptr<Lhs>
```
 
```
std::shared_ptr<Rhs>
```
 Now, suppose we get an exception thrown at step 2 (e.g., out of memory exception, 
```
Rhs
```
 constructor threw some exception). We then lose memory allocated at step 1, since nothing will have had a chance to clean it up. The core of the problem here is that the raw pointer didn't get passed to the 
```
std::shared_ptr
```
 constructor immediately. One way to fix this is to do them on separate lines so that this arbitary ordering cannot occur. 
```
auto lhs = std::shared_ptr<Lhs>(new Lhs(""foo""));
auto rhs = std::shared_ptr<Rhs>(new Rhs(""bar""));
F(lhs, rhs);

```
 The preferred way to solve this of course is to use 
```
std::make_shared
```
 instead. 
```
F(std::make_shared<Lhs>(""foo""), std::make_shared<Rhs>(""bar""));

```
 Update II: Disadvantage of 
```
std::make_shared
```
 Quoting Casey's comments: Since there there's only one allocation, the pointee's memory cannot be deallocated until the control block is no longer in use. A 
```
weak_ptr
```
 can keep the control block alive indefinitely. Why do instances of 
```
weak_ptr
```
s keep the control block alive? There must be a way for 
```
weak_ptr
```
s to determine if the managed object is still valid (eg. for 
```
lock
```
). They do this by checking the number of 
```
shared_ptr
```
s that own the managed object, which is stored in the control block. The result is that the control blocks are alive until the 
```
shared_ptr
```
 count and the 
```
weak_ptr
```
 count both hit 0. Back to 
```
std::make_shared
```
 Since 
```
std::make_shared
```
 makes a single heap-allocation for both the control block and the managed object, there is no way to free the memory for control block and the managed object independently. We must wait until we can free both the control block and the managed object, which happens to be until there are no 
```
shared_ptr
```
s or 
```
weak_ptr
```
s alive. Suppose we instead performed two heap-allocations for the control block and the managed object via 
```
new
```
 and 
```
shared_ptr
```
 constructor. Then we free the memory for the managed object (maybe earlier) when there are no 
```
shared_ptr
```
s alive, and free the memory for the control block (maybe later) when there are no 
```
weak_ptr
```
s alive."
9025084,Sorting a vector in descending order,https://stackoverflow.com/questions/9025084/sorting-a-vector-in-descending-order,11,156.0,"['With c++14 you can do this: \n```\nstd::sort(numbers.begin(), numbers.end(), std::greater<>());\n\n```']","With c++14 you can do this: 
```
std::sort(numbers.begin(), numbers.end(), std::greater<>());

```
"
421573,Best way to extract a subvector from a vector?,https://stackoverflow.com/questions/421573/best-way-to-extract-a-subvector-from-a-vector,18,490.0,"[""```\nvector<T>::const_iterator first = myVec.begin() + 100000;\nvector<T>::const_iterator last = myVec.begin() + 101000;\nvector<T> newVec(first, last);\n\n```\n It's an O(N) operation to construct the new vector, but there isn't really a better way.""]","
```
vector<T>::const_iterator first = myVec.begin() + 100000;
vector<T>::const_iterator last = myVec.begin() + 101000;
vector<T> newVec(first, last);

```
 It's an O(N) operation to construct the new vector, but there isn't really a better way."
7959573,"Declaring variables inside loops, good practice or bad practice?",https://stackoverflow.com/questions/7959573/declaring-variables-inside-loops-good-practice-or-bad-practice,10,515.0,"['This is excellent practice. By creating variables inside loops, you ensure their scope is restricted to inside the loop. It cannot be referenced nor called outside of the loop. This way: If the name of the variable is a bit ""generic"" (like ""i""), there is no risk to mix it with another variable of same name somewhere later in your code (can also be mitigated using the \n```\n-Wshadow\n```', '```\n-Wshadow\n```\n warning instruction on GCC) The compiler knows that the variable scope is limited to inside the loop, and therefore will issue a proper error message if the variable is by mistake referenced elsewhere. Last but not least, some dedicated optimization can be performed more efficiently by the compiler (most importantly register allocation), since it knows that the variable cannot be used outside of the loop. For example, no need to store the result for later re-use. In short, you are right to do it. Note however that the variable is not supposed to retain its value between each loop. In such case, you may need to initialize it every time. You can also create a larger block, encompassing the loop, whose sole purpose is to declare variables which must retain their value from one loop to another. This typically includes the loop counter itself. \n```\n{\n    int i, retainValue;\n    for (i=0; i<N; i++)\n    {\n       int tmpValue;\n       /* tmpValue is uninitialized */', '```\n{\n    int i, retainValue;\n    for (i=0; i<N; i++)\n    {\n       int tmpValue;\n       /* tmpValue is uninitialized */\n       /* retainValue still has its previous value from previous loop */', '/* Do some stuff here */\n    }\n    /* Here, retainValue is still valid; tmpValue no longer */\n}\n\n```\n For question #2: The variable is allocated once, when the function is called. In fact, from an allocation perspective, it is (nearly) the same as declaring the variable at the beginning of the function. The only difference is the scope: the variable cannot be used outside of the loop. It may even be possible that the variable is not allocated, just re-using some free slot (from other variable whose scope has ended). With restricted and more precise scope come more accurate optimizations. But more importantly, it makes your code safer, with less states (i.e. variables) to worry about when reading other parts of the code. This is true even outside of an \n```\nif(){...}\n```\n block. Typically, instead of : \n```\n    int result;\n    (...)\n    result = f1();\n    if (result) then { (...) }\n    (...)\n    result = f2();\n    if (result) then { (...) }', ""```\n it's safer to write : \n```\n    (...)\n    {\n        int const result = f1();\n        if (result) then { (...) }\n    }\n    (...)\n    {\n        int const result = f2();\n        if (result) then { (...) }\n    }"", ""```\n The difference may seem minor, especially on such a small example. But on a larger code base, it will help : now there is no risk to transport some \n```\nresult\n```\n value from \n```\nf1()\n```\n to \n```\nf2()\n```\n block. Each \n```\nresult\n```\n is strictly limited to its own scope, making its role more accurate. From a reviewer perspective, it's much nicer, since he has less long range state variables to worry about and track. Even the compiler will help better : assuming that, in the future, after some erroneous change of code, \n```\nresult\n```\n is not properly initialized with \n```\nf2()\n```\n. The second version will simply refuse to work, stating a clear error message at compile time (way better than run time). The first version will not spot anything, the result of \n```\nf1()\n```\n will simply be tested a second time, being confused for the result of \n```\nf2()\n```"", '```\nf1()\n```\n will simply be tested a second time, being confused for the result of \n```\nf2()\n```\n. Complementary information The open-source tool CppCheck (a static analysis tool for C/C++ code) provides some excellent hints regarding optimal scope of variables. In response to comment on allocation: The above rule is true in C, but might not be for some C++ classes. For standard types and structures, the size of variable is known at compilation time. There is no such thing as ""construction"" in C, so the space for the variable will simply be allocated into the stack (without any initialization), when the function is called. That\'s why there is a ""zero"" cost when declaring the variable inside a loop. However, for C++ classes, there is this constructor thing which I know much less about. I guess allocation is probably not going to be the issue, since the compiler shall be clever enough to reuse the same space, but the initialization is likely to take place at each loop iteration.']","This is excellent practice. By creating variables inside loops, you ensure their scope is restricted to inside the loop. It cannot be referenced nor called outside of the loop. This way: If the name of the variable is a bit ""generic"" (like ""i""), there is no risk to mix it with another variable of same name somewhere later in your code (can also be mitigated using the 
```
-Wshadow
```
 warning instruction on GCC) The compiler knows that the variable scope is limited to inside the loop, and therefore will issue a proper error message if the variable is by mistake referenced elsewhere. Last but not least, some dedicated optimization can be performed more efficiently by the compiler (most importantly register allocation), since it knows that the variable cannot be used outside of the loop. For example, no need to store the result for later re-use. In short, you are right to do it. Note however that the variable is not supposed to retain its value between each loop. In such case, you may need to initialize it every time. You can also create a larger block, encompassing the loop, whose sole purpose is to declare variables which must retain their value from one loop to another. This typically includes the loop counter itself. 
```
{
    int i, retainValue;
    for (i=0; i<N; i++)
    {
       int tmpValue;
       /* tmpValue is uninitialized */
       /* retainValue still has its previous value from previous loop */

       /* Do some stuff here */
    }
    /* Here, retainValue is still valid; tmpValue no longer */
}

```
 For question #2: The variable is allocated once, when the function is called. In fact, from an allocation perspective, it is (nearly) the same as declaring the variable at the beginning of the function. The only difference is the scope: the variable cannot be used outside of the loop. It may even be possible that the variable is not allocated, just re-using some free slot (from other variable whose scope has ended). With restricted and more precise scope come more accurate optimizations. But more importantly, it makes your code safer, with less states (i.e. variables) to worry about when reading other parts of the code. This is true even outside of an 
```
if(){...}
```
 block. Typically, instead of : 
```
    int result;
    (...)
    result = f1();
    if (result) then { (...) }
    (...)
    result = f2();
    if (result) then { (...) }

```
 it's safer to write : 
```
    (...)
    {
        int const result = f1();
        if (result) then { (...) }
    }
    (...)
    {
        int const result = f2();
        if (result) then { (...) }
    }

```
 The difference may seem minor, especially on such a small example. But on a larger code base, it will help : now there is no risk to transport some 
```
result
```
 value from 
```
f1()
```
 to 
```
f2()
```
 block. Each 
```
result
```
 is strictly limited to its own scope, making its role more accurate. From a reviewer perspective, it's much nicer, since he has less long range state variables to worry about and track. Even the compiler will help better : assuming that, in the future, after some erroneous change of code, 
```
result
```
 is not properly initialized with 
```
f2()
```
. The second version will simply refuse to work, stating a clear error message at compile time (way better than run time). The first version will not spot anything, the result of 
```
f1()
```
 will simply be tested a second time, being confused for the result of 
```
f2()
```
. Complementary information The open-source tool CppCheck (a static analysis tool for C/C++ code) provides some excellent hints regarding optimal scope of variables. In response to comment on allocation: The above rule is true in C, but might not be for some C++ classes. For standard types and structures, the size of variable is known at compilation time. There is no such thing as ""construction"" in C, so the space for the variable will simply be allocated into the stack (without any initialization), when the function is called. That's why there is a ""zero"" cost when declaring the variable inside a loop. However, for C++ classes, there is this constructor thing which I know much less about. I guess allocation is probably not going to be the issue, since the compiler shall be clever enough to reuse the same space, but the initialization is likely to take place at each loop iteration."
17944,How to round up the result of integer division?,https://stackoverflow.com/questions/17944/how-to-round-up-the-result-of-integer-division,20,587.0,"['Found an elegant solution: \n```\nint pageCount = (records + recordsPerPage - 1) / recordsPerPage;\n\n```\n Source: Number Conversion, Roland Backhouse, 2001']","Found an elegant solution: 
```
int pageCount = (records + recordsPerPage - 1) / recordsPerPage;

```
 Source: Number Conversion, Roland Backhouse, 2001"
8480640,How to throw a C++ exception,https://stackoverflow.com/questions/8480640/how-to-throw-a-c-exception,6,537.0,"['Simple: \n```\n#include <stdexcept>\n\nint compare( int a, int b ) {\n    if ( a < 0 || b < 0 ) {\n        throw std::invalid_argument( ""received negative value"" );\n    }\n}\n\n```\n The Standard Library comes with a nice collection of built-in exception objects you can throw. Keep in mind that you should always throw by value and catch by reference: \n```\ntry {\n    compare( -1, 3 );\n}\ncatch( const std::invalid_argument& e ) {\n    // do stuff with exception... \n}\n\n```\n You can have multiple catch() statements after each try, so you can handle different exception types separately if you want. You can also re-throw exceptions: \n```\ncatch( const std::invalid_argument& e ) {\n    // do something\n\n    // let someone higher up the call stack handle it if they want\n    throw;\n}\n\n```\n And to catch exceptions regardless of type: \n```\ncatch( ... ) { };\n\n```']","Simple: 
```
#include <stdexcept>

int compare( int a, int b ) {
    if ( a < 0 || b < 0 ) {
        throw std::invalid_argument( ""received negative value"" );
    }
}

```
 The Standard Library comes with a nice collection of built-in exception objects you can throw. Keep in mind that you should always throw by value and catch by reference: 
```
try {
    compare( -1, 3 );
}
catch( const std::invalid_argument& e ) {
    // do stuff with exception... 
}

```
 You can have multiple catch() statements after each try, so you can handle different exception types separately if you want. You can also re-throw exceptions: 
```
catch( const std::invalid_argument& e ) {
    // do something

    // let someone higher up the call stack handle it if they want
    throw;
}

```
 And to catch exceptions regardless of type: 
```
catch( ... ) { };

```
"
40127965,How exactly is std::string_view faster than const std::string&?,https://stackoverflow.com/questions/40127965/how-exactly-is-stdstring-view-faster-than-const-stdstring,5,364.0,"['```\nstd::string_view\n```\n is faster in a few cases. First, \n```\nstd::string const&\n```\n requires the data to be in a \n```\nstd::string\n```\n, and not a raw C array, a \n```\nchar const*\n```\n returned by a C API, a \n```\nstd::vector<char>\n```\n produced by some deserialization engine, etc. The avoided format conversion avoids copying bytes, and (if the string is longer than the SBO¹ for the particular \n```\nstd::string\n```\n implementation) avoids a memory allocation. \n```\nvoid foo( std::string_view bob ) {\n  std::cout << bob << ""\\n"";\n}\nint main(int argc, char const*const* argv) {\n  foo( ""This is a string long enough to avoid the std::string SBO"" );\n  if (argc > 1)\n    foo( argv[1] );\n}', '```\n No allocations are done in the \n```\nstring_view\n```\n case, but there would be if \n```\nfoo\n```\n took a \n```\nstd::string const&\n```\n instead of a \n```\nstring_view\n```\n. The second really big reason is that it permits working with substrings without a copy. Suppose you are parsing a 2 gigabyte json string (!)². If you parse it into \n```\nstd::string\n```\n, each such parse node where they store the name or value of a node copies the original data from the 2 gb string to a local node. Instead, if you parse it to \n```\nstd::string_view\n```\ns, the nodes refer to the original data. This can save millions of allocations and halve memory requirements during parsing. The speedup you can get is simply ridiculous. This is an extreme case, but other ""get a substring and work with it"" cases can also generate decent speedups with \n```\nstring_view\n```\n. An important part to the decision is what you lose by using \n```\nstd::string_view\n```\n. First you lose ownership. \n```\nstring_view\n```', ""```\nstring_view\n```\n. An important part to the decision is what you lose by using \n```\nstd::string_view\n```\n. First you lose ownership. \n```\nstring_view\n```\n is a dumb pointer to someone else's memory. Tracking that is a headache. Of course the same is true of a\n```\nconst&\n```\n to a \n```\nstd::string\n```\n. Second, lose implicit null termination. And that is about it. So if the same string will be passed to 3 functions all of which require a null terminator, converting to \n```\nstd::string\n```\n once may be wise. Thus if your code is known to need a null terminator, and you don't expect strings fed from C-style sourced buffers or the like, maybe take a \n```\nstd::string const&\n```\n. Otherwise take a \n```\nstd::string_view\n```\n. If \n```\nstd::string_view\n```\n had a flag that stated if it was null terminated (or something fancier) it would remove even that last reason to use a \n```\nstd::string const&\n```\n. There is a case where taking a \n```\nstd::string\n```\n with no \n```\nconst&\n```"", ""```\nstd::string const&\n```\n. There is a case where taking a \n```\nstd::string\n```\n with no \n```\nconst&\n```\n is optimal over a \n```\nstd::string_view\n```\n. If you need to own a copy of the string indefinitely after the call, taking by-value is efficient. You'll either be in the SBO case (and no allocations, just a few character copies to duplicate it), or you'll be able to move the heap-allocated buffer into a local \n```\nstd::string\n```\n. Having two overloads \n```\nstd::string&&\n```\n and \n```\nstd::string_view\n```\n might be faster, but only marginally, and it would cause modest code bloat (which could cost you all of the speed gains). ¹ Small Buffer Optimization ² Actual use case.""]","
```
std::string_view
```
 is faster in a few cases. First, 
```
std::string const&
```
 requires the data to be in a 
```
std::string
```
, and not a raw C array, a 
```
char const*
```
 returned by a C API, a 
```
std::vector<char>
```
 produced by some deserialization engine, etc. The avoided format conversion avoids copying bytes, and (if the string is longer than the SBO¹ for the particular 
```
std::string
```
 implementation) avoids a memory allocation. 
```
void foo( std::string_view bob ) {
  std::cout << bob << ""\n"";
}
int main(int argc, char const*const* argv) {
  foo( ""This is a string long enough to avoid the std::string SBO"" );
  if (argc > 1)
    foo( argv[1] );
}

```
 No allocations are done in the 
```
string_view
```
 case, but there would be if 
```
foo
```
 took a 
```
std::string const&
```
 instead of a 
```
string_view
```
. The second really big reason is that it permits working with substrings without a copy. Suppose you are parsing a 2 gigabyte json string (!)². If you parse it into 
```
std::string
```
, each such parse node where they store the name or value of a node copies the original data from the 2 gb string to a local node. Instead, if you parse it to 
```
std::string_view
```
s, the nodes refer to the original data. This can save millions of allocations and halve memory requirements during parsing. The speedup you can get is simply ridiculous. This is an extreme case, but other ""get a substring and work with it"" cases can also generate decent speedups with 
```
string_view
```
. An important part to the decision is what you lose by using 
```
std::string_view
```
. First you lose ownership. 
```
string_view
```
 is a dumb pointer to someone else's memory. Tracking that is a headache. Of course the same is true of a
```
const&
```
 to a 
```
std::string
```
. Second, lose implicit null termination. And that is about it. So if the same string will be passed to 3 functions all of which require a null terminator, converting to 
```
std::string
```
 once may be wise. Thus if your code is known to need a null terminator, and you don't expect strings fed from C-style sourced buffers or the like, maybe take a 
```
std::string const&
```
. Otherwise take a 
```
std::string_view
```
. If 
```
std::string_view
```
 had a flag that stated if it was null terminated (or something fancier) it would remove even that last reason to use a 
```
std::string const&
```
. There is a case where taking a 
```
std::string
```
 with no 
```
const&
```
 is optimal over a 
```
std::string_view
```
. If you need to own a copy of the string indefinitely after the call, taking by-value is efficient. You'll either be in the SBO case (and no allocations, just a few character copies to duplicate it), or you'll be able to move the heap-allocated buffer into a local 
```
std::string
```
. Having two overloads 
```
std::string&&
```
 and 
```
std::string_view
```
 might be faster, but only marginally, and it would cause modest code bloat (which could cost you all of the speed gains). ¹ Small Buffer Optimization ² Actual use case."
17434,When should you use 'friend' in C++?,https://stackoverflow.com/questions/17434/when-should-you-use-friend-in-c,31,375.0,"[""Firstly (IMO) don't listen to people who say \n```\nfriend\n```\n is not useful. It IS useful. In many situations you will have objects with data or functionality that are not intended to be publicly available. This is particularly true of large codebases with many authors who may only be superficially familiar with different areas. There ARE alternatives to the friend specifier, but often they are cumbersome (cpp-level concrete classes/masked typedefs) or not foolproof (comments or function name conventions). Onto the answer; The \n```\nfriend\n```"", '```\nfriend\n```\n specifier allows the designated class access to protected data or functionality within the class making the friend statement. For example in the below code anyone may ask a child for their name, but only the mother and the child may change the name. You can take this simple example further by considering a more complex class such as a Window. Quite likely a Window will have many function/data elements that should not be publicly accessible, but ARE needed by a related class such as a WindowManager. \n```\nclass Child\n{\n//Mother class members can access the private parts of class Child.\nfriend class Mother;', 'public:\n\n  string name( void );\n\nprotected:\n\n  void setName( string newName );\n};\n\n```']","Firstly (IMO) don't listen to people who say 
```
friend
```
 is not useful. It IS useful. In many situations you will have objects with data or functionality that are not intended to be publicly available. This is particularly true of large codebases with many authors who may only be superficially familiar with different areas. There ARE alternatives to the friend specifier, but often they are cumbersome (cpp-level concrete classes/masked typedefs) or not foolproof (comments or function name conventions). Onto the answer; The 
```
friend
```
 specifier allows the designated class access to protected data or functionality within the class making the friend statement. For example in the below code anyone may ask a child for their name, but only the mother and the child may change the name. You can take this simple example further by considering a more complex class such as a Window. Quite likely a Window will have many function/data elements that should not be publicly accessible, but ARE needed by a related class such as a WindowManager. 
```
class Child
{
//Mother class members can access the private parts of class Child.
friend class Mother;

public:

  string name( void );

protected:

  void setName( string newName );
};

```
"
10673585,Start thread with member function,https://stackoverflow.com/questions/10673585/start-thread-with-member-function,5,506.0,"['```\n#include <thread>\n#include <iostream>\n\nclass bar {\npublic:\n  void foo() {\n    std::cout << ""hello from member function"" << std::endl;\n  }\n};\n\nint main()\n{\n  std::thread t(&bar::foo, bar());\n  t.join();\n}\n\n```\n EDIT: Accounting your edit, you have to do it like this: \n```\n  std::thread spawn() {\n    return std::thread(&blub::test, this);\n  }', '```', 'UPDATE: I want to explain some more points, some of them have also been discussed in the comments. The syntax described above is defined in terms of the INVOKE definition (§20.8.2.1): Define INVOKE (f, t1, t2, ..., tN) as follows: (t1.*f)(t2, ..., tN) when f is a pointer to a member function of a class T and t1 is an object of type T or a reference to an object of type T or a reference to an object of a type derived from T; ((*t1).*f)(t2, ..., tN) when f is a pointer to a member function of a class T and t1 is not one of the types described in the previous item; t1.*f when N == 1 and f is a pointer to member data of a class T and t 1 is an object of type T or a reference to an object of type T or a reference to an object of a type derived from T; (*t1).*f when N == 1 and f is a pointer to member data of a class T and t 1 is not one of the types described in the previous item; f(t1, t2, ..., tN) in all other cases. Another general fact which I want to point out is that by default the', 'member data of a class T and t 1 is not one of the types described in the previous item; f(t1, t2, ..., tN) in all other cases. Another general fact which I want to point out is that by default the thread constructor will copy all arguments passed to it. The reason for this is that the arguments may need to outlive the calling thread, copying the arguments guarantees that. Instead, if you want to really pass a reference, you can use a', '```\nstd::reference_wrapper\n```\n created by \n```\nstd::ref\n```\n. \n```\nstd::thread (foo, std::ref(arg1));', '```\n By doing this, you are promising that you will take care of guaranteeing that the arguments will still exist when the thread operates on them. Note that all the things mentioned above can also be applied to \n```\nstd::async\n```\n and \n```\nstd::bind\n```\n.']","
```
#include <thread>
#include <iostream>

class bar {
public:
  void foo() {
    std::cout << ""hello from member function"" << std::endl;
  }
};

int main()
{
  std::thread t(&bar::foo, bar());
  t.join();
}

```
 EDIT: Accounting your edit, you have to do it like this: 
```
  std::thread spawn() {
    return std::thread(&blub::test, this);
  }

```
 UPDATE: I want to explain some more points, some of them have also been discussed in the comments. The syntax described above is defined in terms of the INVOKE definition (§20.8.2.1): Define INVOKE (f, t1, t2, ..., tN) as follows: (t1.*f)(t2, ..., tN) when f is a pointer to a member function of a class T and t1 is an object of type T or a reference to an object of type T or a reference to an object of a type derived from T; ((*t1).*f)(t2, ..., tN) when f is a pointer to a member function of a class T and t1 is not one of the types described in the previous item; t1.*f when N == 1 and f is a pointer to member data of a class T and t 1 is an object of type T or a reference to an object of type T or a reference to an object of a type derived from T; (*t1).*f when N == 1 and f is a pointer to member data of a class T and t 1 is not one of the types described in the previous item; f(t1, t2, ..., tN) in all other cases. Another general fact which I want to point out is that by default the thread constructor will copy all arguments passed to it. The reason for this is that the arguments may need to outlive the calling thread, copying the arguments guarantees that. Instead, if you want to really pass a reference, you can use a 
```
std::reference_wrapper
```
 created by 
```
std::ref
```
. 
```
std::thread (foo, std::ref(arg1));

```
 By doing this, you are promising that you will take care of guaranteeing that the arguments will still exist when the thread operates on them. Note that all the things mentioned above can also be applied to 
```
std::async
```
 and 
```
std::bind
```
."
2616906,How do I output coloured text to a Linux terminal?,https://stackoverflow.com/questions/2616906/how-do-i-output-coloured-text-to-a-linux-terminal,16,579.0,"['You need to output ANSI colour codes. Note that not all terminals support this; if colour sequences are not supported, garbage will show up. Example: \n```\n cout << ""\\033[1;31mbold red text\\033[0m\\n"";\n\n```\n Here, \n```\n\\033\n```\n is the ESC character, ASCII 27. It is followed by \n```\n[\n```\n, then zero or more numbers separated by \n```\n;\n```\n, and finally the letter \n```\nm\n```\n. The numbers describe the colour and format to switch to from that point onwards. The codes for foreground and background colours are: \n```\n         foreground background\nblack        30         40\nred          31         41\ngreen        32         42\nyellow       33         43\nblue         34         44\nmagenta      35         45\ncyan         36         46\nwhite        37         47', '```\n Additionally, you can use these: \n```\nreset             0  (everything back to normal)\nbold/bright       1  (often a brighter shade of the same colour)\nunderline         4\ninverse           7  (swap foreground and background colours)\nbold/bright off  21\nunderline off    24\ninverse off      27\n\n```\n See the table on Wikipedia for other, less widely supported codes. To determine whether your terminal supports colour sequences, read the value of the \n```\nTERM\n```\n environment variable. It should specify the particular terminal type used (e.g. \n```\nvt100\n```\n, \n```\ngnome-terminal\n```\n, \n```\nxterm\n```\n, \n```\nscreen\n```\n, ...). Then look that up in the terminfo database; check the \n```\ncolors\n```\n capability.']","You need to output ANSI colour codes. Note that not all terminals support this; if colour sequences are not supported, garbage will show up. Example: 
```
 cout << ""\033[1;31mbold red text\033[0m\n"";

```
 Here, 
```
\033
```
 is the ESC character, ASCII 27. It is followed by 
```
[
```
, then zero or more numbers separated by 
```
;
```
, and finally the letter 
```
m
```
. The numbers describe the colour and format to switch to from that point onwards. The codes for foreground and background colours are: 
```
         foreground background
black        30         40
red          31         41
green        32         42
yellow       33         43
blue         34         44
magenta      35         45
cyan         36         46
white        37         47

```
 Additionally, you can use these: 
```
reset             0  (everything back to normal)
bold/bright       1  (often a brighter shade of the same colour)
underline         4
inverse           7  (swap foreground and background colours)
bold/bright off  21
underline off    24
inverse off      27

```
 See the table on Wikipedia for other, less widely supported codes. To determine whether your terminal supports colour sequences, read the value of the 
```
TERM
```
 environment variable. It should specify the particular terminal type used (e.g. 
```
vt100
```
, 
```
gnome-terminal
```
, 
```
xterm
```
, 
```
screen
```
, ...). Then look that up in the terminfo database; check the 
```
colors
```
 capability."
4424579,std::vector versus std::array in C++,https://stackoverflow.com/questions/4424579/stdvector-versus-stdarray-in-c,6,422.0,"['```\nstd::vector\n```\n is a template class that encapsulate a dynamic array1, stored in the heap, that grows and shrinks automatically if elements are added or removed. It provides all the hooks (\n```\nbegin()\n```\n, \n```\nend()\n```\n, iterators, etc) that make it work fine with the rest of the STL. It also has several useful methods that let you perform operations that on a normal array would be cumbersome, like e.g. inserting elements in the middle of a vector (it handles all the work of moving the following elements behind the scenes). Since it stores the elements in memory allocated on the heap, it has some overhead in respect to static arrays. \n```\nstd::array\n```', ""```\nstd::array\n```\n is a template class that encapsulate a statically-sized array, stored inside the object itself, which means that, if you instantiate the class on the stack, the array itself will be on the stack. Its size has to be known at compile time (it's passed as a template parameter), and it cannot grow or shrink. It's more limited than \n```\nstd::vector\n```\n, but it's often more efficient, especially for small sizes, because in practice it's mostly a lightweight wrapper around a C-style array. However, it's more secure, since the implicit conversion to pointer is disabled, and it provides much of the STL-related functionality of \n```\nstd::vector\n```\n and of the other containers, so you can use it easily with STL algorithms & co. Anyhow, for the very limitation of fixed size it's much less flexible than \n```\nstd::vector\n```\n. For an introduction to \n```\nstd::array\n```\n, have a look at this article; for a quick introduction to \n```\nstd::vector\n```"", ""```\nstd::vector\n```\n. For an introduction to \n```\nstd::array\n```\n, have a look at this article; for a quick introduction to \n```\nstd::vector\n```\n and to the the operations that are possible on it, you may want to look at its documentation. Actually, I think that in the standard they are described in terms of maximum complexity of the different operations (e.g. random access in constant time, iteration over all the elements in linear time, add and removal of elements at the end in constant amortized time, etc), but AFAIK there's no other method of fulfilling such requirements other than using a dynamic array. As stated by @Lucretiel, the standard actually requires that the elements are stored contiguously, so it is a dynamic array, stored where the associated allocator puts it.""]","
```
std::vector
```
 is a template class that encapsulate a dynamic array1, stored in the heap, that grows and shrinks automatically if elements are added or removed. It provides all the hooks (
```
begin()
```
, 
```
end()
```
, iterators, etc) that make it work fine with the rest of the STL. It also has several useful methods that let you perform operations that on a normal array would be cumbersome, like e.g. inserting elements in the middle of a vector (it handles all the work of moving the following elements behind the scenes). Since it stores the elements in memory allocated on the heap, it has some overhead in respect to static arrays. 
```
std::array
```
 is a template class that encapsulate a statically-sized array, stored inside the object itself, which means that, if you instantiate the class on the stack, the array itself will be on the stack. Its size has to be known at compile time (it's passed as a template parameter), and it cannot grow or shrink. It's more limited than 
```
std::vector
```
, but it's often more efficient, especially for small sizes, because in practice it's mostly a lightweight wrapper around a C-style array. However, it's more secure, since the implicit conversion to pointer is disabled, and it provides much of the STL-related functionality of 
```
std::vector
```
 and of the other containers, so you can use it easily with STL algorithms & co. Anyhow, for the very limitation of fixed size it's much less flexible than 
```
std::vector
```
. For an introduction to 
```
std::array
```
, have a look at this article; for a quick introduction to 
```
std::vector
```
 and to the the operations that are possible on it, you may want to look at its documentation. Actually, I think that in the standard they are described in terms of maximum complexity of the different operations (e.g. random access in constant time, iteration over all the elements in linear time, add and removal of elements at the end in constant amortized time, etc), but AFAIK there's no other method of fulfilling such requirements other than using a dynamic array. As stated by @Lucretiel, the standard actually requires that the elements are stored contiguously, so it is a dynamic array, stored where the associated allocator puts it."
3789340,Combining C++ and C - how does #ifdef __cplusplus work?,https://stackoverflow.com/questions/3789340/combining-c-and-c-how-does-ifdef-cplusplus-work,5,358.0,"['```\nextern ""C""\n```\n doesn\'t really change the way that the compiler reads the code. If your code is in a .c file, it will be compiled as C, if it is in a .cpp file, it will be compiled as C++ (unless you do something strange to your configuration). What \n```\nextern ""C""\n```\n does is affect linkage. C++ functions, when compiled, have their names mangled -- this is what makes overloading possible. The function name gets modified based on the types and number of parameters, so that two functions with the same name will have different symbol names. Code inside an \n```\nextern ""C""\n```\n is still C++ code. There are limitations on what you can do in an extern ""C"" block, but they\'re all about linkage. You can\'t define any new symbols that can\'t be built with C linkage. That means no classes or templates, for example. \n```\nextern ""C""\n```\n blocks nest nicely. There\'s also \n```\nextern ""C++""\n```\n if you find yourself hopelessly trapped inside of \n```\nextern ""C""\n```', '```\nextern ""C""\n```\n blocks nest nicely. There\'s also \n```\nextern ""C++""\n```\n if you find yourself hopelessly trapped inside of \n```\nextern ""C""\n```\n regions, but it isn\'t such a good idea from a cleanliness perspective. Now, specifically regarding your numbered questions: Regarding #1: __cplusplus will stay defined inside of \n```\nextern ""C""\n```\n blocks. This doesn\'t matter, though, since the blocks should nest neatly. Regarding #2: __cplusplus will be defined for any compilation unit that is being run through the C++ compiler. Generally, that means .cpp files and any files being included by that .cpp file. The same .h (or .hh or .hpp or what-have-you) could be interpreted as C or C++ at different times, if different compilation units include them. If you want the prototypes in the .h file to refer to C symbol names, then they must have \n```\nextern ""C""\n```\n when being interpreted as C++, and they should not have \n```\nextern ""C""\n```\n when being interpreted as C -- hence the \n```', '```\nextern ""C""\n```\n when being interpreted as C++, and they should not have \n```\nextern ""C""\n```\n when being interpreted as C -- hence the \n```\n#ifdef __cplusplus\n```\n checking. To answer your question #3: functions without prototypes will have C++ linkage if they are in .cpp files and not inside of an \n```\nextern ""C""\n```\n block. This is fine, though, because if it has no prototype, it can only be called by other functions in the same file, and then you don\'t generally care what the linkage looks like, because you aren\'t planning on having that function be called by anything outside the same compilation unit anyway. For #4, you\'ve got it exactly. If you are including a header for code that has C linkage (such as code that was compiled by a C compiler), then you must \n```\nextern ""C""\n```\n the header -- that way you will be able to link with the library. (Otherwise, your linker would be looking for functions with names like \n```\n_Z1hic\n```\n when you were looking for \n```\nvoid h(int, char)', '```\n_Z1hic\n```\n when you were looking for \n```\nvoid h(int, char)\n```\n 5: This sort of mixing is a common reason to use \n```\nextern ""C""\n```\n, and I don\'t see anything wrong with doing it this way -- just make sure you understand what you are doing.']","
```
extern ""C""
```
 doesn't really change the way that the compiler reads the code. If your code is in a .c file, it will be compiled as C, if it is in a .cpp file, it will be compiled as C++ (unless you do something strange to your configuration). What 
```
extern ""C""
```
 does is affect linkage. C++ functions, when compiled, have their names mangled -- this is what makes overloading possible. The function name gets modified based on the types and number of parameters, so that two functions with the same name will have different symbol names. Code inside an 
```
extern ""C""
```
 is still C++ code. There are limitations on what you can do in an extern ""C"" block, but they're all about linkage. You can't define any new symbols that can't be built with C linkage. That means no classes or templates, for example. 
```
extern ""C""
```
 blocks nest nicely. There's also 
```
extern ""C++""
```
 if you find yourself hopelessly trapped inside of 
```
extern ""C""
```
 regions, but it isn't such a good idea from a cleanliness perspective. Now, specifically regarding your numbered questions: Regarding #1: __cplusplus will stay defined inside of 
```
extern ""C""
```
 blocks. This doesn't matter, though, since the blocks should nest neatly. Regarding #2: __cplusplus will be defined for any compilation unit that is being run through the C++ compiler. Generally, that means .cpp files and any files being included by that .cpp file. The same .h (or .hh or .hpp or what-have-you) could be interpreted as C or C++ at different times, if different compilation units include them. If you want the prototypes in the .h file to refer to C symbol names, then they must have 
```
extern ""C""
```
 when being interpreted as C++, and they should not have 
```
extern ""C""
```
 when being interpreted as C -- hence the 
```
#ifdef __cplusplus
```
 checking. To answer your question #3: functions without prototypes will have C++ linkage if they are in .cpp files and not inside of an 
```
extern ""C""
```
 block. This is fine, though, because if it has no prototype, it can only be called by other functions in the same file, and then you don't generally care what the linkage looks like, because you aren't planning on having that function be called by anything outside the same compilation unit anyway. For #4, you've got it exactly. If you are including a header for code that has C linkage (such as code that was compiled by a C compiler), then you must 
```
extern ""C""
```
 the header -- that way you will be able to link with the library. (Otherwise, your linker would be looking for functions with names like 
```
_Z1hic
```
 when you were looking for 
```
void h(int, char)
```
 5: This sort of mixing is a common reason to use 
```
extern ""C""
```
, and I don't see anything wrong with doing it this way -- just make sure you understand what you are doing."
4748083,Should I declare a constant instead of writing a constexpr function?,https://stackoverflow.com/questions/4748083/should-i-declare-a-constant-instead-of-writing-a-constexpr-function,15,358.0,"['Suppose it does something a little more complicated. \n```\nconstexpr int MeaningOfLife ( int a, int b ) { return a * b; }\n\nconst int meaningOfLife = MeaningOfLife( 6, 7 );\n\n```\n Now you have something that can be evaluated down to a constant while maintaining good readability and allowing slightly more complex processing than just setting a constant to a number. It basically provides a good aid to maintainability as it becomes more obvious what you are doing. Take \n```\nmax( a, b )\n```\n for example: \n```\ntemplate< typename Type > constexpr Type max( Type a, Type b ) { return a < b ? b : a; }', '```\n Its a pretty simple choice there but it does mean that if you call \n```\nmax\n```\n with constant values it is explicitly calculated at compile time and not at runtime. Another good example would be a \n```\nDegreesToRadians\n```\n function. Everyone finds degrees easier to read than radians. While you may know that 180 degrees is 3.14159265 (Pi) in radians it is much clearer written as follows: \n```\nconst float oneeighty = DegreesToRadians( 180.0f );\n\n```\n Lots of good info here: http://en.cppreference.com/w/cpp/language/constexpr']","Suppose it does something a little more complicated. 
```
constexpr int MeaningOfLife ( int a, int b ) { return a * b; }

const int meaningOfLife = MeaningOfLife( 6, 7 );

```
 Now you have something that can be evaluated down to a constant while maintaining good readability and allowing slightly more complex processing than just setting a constant to a number. It basically provides a good aid to maintainability as it becomes more obvious what you are doing. Take 
```
max( a, b )
```
 for example: 
```
template< typename Type > constexpr Type max( Type a, Type b ) { return a < b ? b : a; }

```
 Its a pretty simple choice there but it does mean that if you call 
```
max
```
 with constant values it is explicitly calculated at compile time and not at runtime. Another good example would be a 
```
DegreesToRadians
```
 function. Everyone finds degrees easier to read than radians. While you may know that 180 degrees is 3.14159265 (Pi) in radians it is much clearer written as follows: 
```
const float oneeighty = DegreesToRadians( 180.0f );

```
 Lots of good info here: http://en.cppreference.com/w/cpp/language/constexpr"
1596668,Logical XOR operator in C++?,https://stackoverflow.com/questions/1596668/logical-xor-operator-in-c,12,714.0,['The \n```\n!=\n```\n operator serves this purpose for \n```\nbool\n```\n values.'],"The 
```
!=
```
 operator serves this purpose for 
```
bool
```
 values."
2354210,Can a class member function template be virtual?,https://stackoverflow.com/questions/2354210/can-a-class-member-function-template-be-virtual,16,,[],
5120768,How to implement the factory method pattern in C++ correctly,https://stackoverflow.com/questions/5120768/how-to-implement-the-factory-method-pattern-in-c-correctly,11,127.0,"[""First of all, there are cases when object construction is a task complex enough to justify its extraction to another class. I believe this point is incorrect. The complexity doesn't really matter. The relevance is what does. If an object can be constructed in one step (not like in the builder pattern), the constructor is the right place to do it. If you really need another class to perform the job, then it should be a helper class that is used from the constructor anyway. \n```\nVec2(float x, float y);\nVec2(float angle, float magnitude); // not a valid overload!\n\n```\n There is an easy workaround for this: \n```\nstruct Cartesian {\n  inline Cartesian(float x, float y): x(x), y(y) {}\n  float x, y;\n};\nstruct Polar {\n  inline Polar(float angle, float magnitude): angle(angle), magnitude(magnitude) {}\n  float angle, magnitude;\n};\nVec2(const Cartesian &cartesian);\nVec2(const Polar &polar);\n\n```\n The only disadvantage is that it looks a bit verbose: \n```\nVec2 v2(Vec2::Cartesian(3.0f, 4.0f));"", '```', ""But the good thing is that you can immediately see what coordinate type you're using, and at the same time you don't have to worry about copying. If you want copying, and it's expensive (as proven by profiling, of course), you may wish to use something like Qt's shared classes to avoid copying overhead. As for the allocation type, the main reason to use the factory pattern is usually polymorphism. Constructors can't be virtual, and even if they could, it wouldn't make much sense. When using static or stack allocation, you can't create objects in a polymorphic way because the compiler needs to know the exact size. So it works only with pointers and references. And returning a reference from a factory doesn't work too, because while an object technically can be deleted by reference, it could be rather confusing and bug-prone, see Is the practice of returning a C++ reference variable, evil? for example. So pointers are the only thing that's left, and that includes smart pointers too. In"", ""be rather confusing and bug-prone, see Is the practice of returning a C++ reference variable, evil? for example. So pointers are the only thing that's left, and that includes smart pointers too. In other words, factories are most useful when used with dynamic allocation, so you can do things like this:"", '```\nclass Abstract {\n  public:\n    virtual void do() = 0;\n};', ""class Factory {\n  public:\n    Abstract *create();\n};\n\nFactory f;\nAbstract *a = f.create();\na->do();\n\n```\n In other cases, factories just help to solve minor problems like those with overloads you have mentioned. It would be nice if it was possible to use them in a uniform way, but it doesn't hurt much that it is probably impossible.""]","First of all, there are cases when object construction is a task complex enough to justify its extraction to another class. I believe this point is incorrect. The complexity doesn't really matter. The relevance is what does. If an object can be constructed in one step (not like in the builder pattern), the constructor is the right place to do it. If you really need another class to perform the job, then it should be a helper class that is used from the constructor anyway. 
```
Vec2(float x, float y);
Vec2(float angle, float magnitude); // not a valid overload!

```
 There is an easy workaround for this: 
```
struct Cartesian {
  inline Cartesian(float x, float y): x(x), y(y) {}
  float x, y;
};
struct Polar {
  inline Polar(float angle, float magnitude): angle(angle), magnitude(magnitude) {}
  float angle, magnitude;
};
Vec2(const Cartesian &cartesian);
Vec2(const Polar &polar);

```
 The only disadvantage is that it looks a bit verbose: 
```
Vec2 v2(Vec2::Cartesian(3.0f, 4.0f));

```
 But the good thing is that you can immediately see what coordinate type you're using, and at the same time you don't have to worry about copying. If you want copying, and it's expensive (as proven by profiling, of course), you may wish to use something like Qt's shared classes to avoid copying overhead. As for the allocation type, the main reason to use the factory pattern is usually polymorphism. Constructors can't be virtual, and even if they could, it wouldn't make much sense. When using static or stack allocation, you can't create objects in a polymorphic way because the compiler needs to know the exact size. So it works only with pointers and references. And returning a reference from a factory doesn't work too, because while an object technically can be deleted by reference, it could be rather confusing and bug-prone, see Is the practice of returning a C++ reference variable, evil? for example. So pointers are the only thing that's left, and that includes smart pointers too. In other words, factories are most useful when used with dynamic allocation, so you can do things like this: 
```
class Abstract {
  public:
    virtual void do() = 0;
};

class Factory {
  public:
    Abstract *create();
};

Factory f;
Abstract *a = f.create();
a->do();

```
 In other cases, factories just help to solve minor problems like those with overloads you have mentioned. It would be nice if it was possible to use them in a uniform way, but it doesn't hurt much that it is probably impossible."
4850473,Pretty-print C++ STL containers,https://stackoverflow.com/questions/4850473/pretty-print-c-stl-containers,0,,[],
20772893,How to detect a Christmas Tree?,https://stackoverflow.com/questions/20772893/how-to-detect-a-christmas-tree,10,192.0,"['I have an approach which I think is interesting and a bit different from the rest. The main difference in my approach, compared to some of the others, is in how the image segmentation step is performed--I used the DBSCAN clustering algorithm from Python\'s scikit-learn; it\'s optimized for finding somewhat amorphous shapes that may not necessarily have a single clear centroid. At the top level, my approach is fairly simple and can be broken down into about 3 steps. First I apply a threshold (or actually, the logical ""or"" of two separate and distinct thresholds). As with many of the other answers, I assumed that the Christmas tree would be one of the brighter objects in the scene, so the first threshold is just a simple monochrome brightness test; any pixels with values above 220 on a 0-255 scale (where black is 0 and white is 255) are saved to a binary black-and-white image. The second threshold tries to look for red and yellow lights, which are particularly prominent in the trees in the', '(where black is 0 and white is 255) are saved to a binary black-and-white image. The second threshold tries to look for red and yellow lights, which are particularly prominent in the trees in the upper left and lower right of the six images, and stand out well against the blue-green background which is prevalent in most of the photos. I convert the rgb image to hsv space, and require that the hue is either less than 0.2 on a 0.0-1.0 scale (corresponding roughly to the border between yellow and green) or greater than 0.95 (corresponding to the border between purple and red) and additionally I require bright, saturated colors: saturation and value must both be above 0.7. The results of the two threshold procedures are logically ""or""-ed together, and the resulting matrix of black-and-white binary images is shown below: You can clearly see that each image has one large cluster of pixels roughly corresponding to the location of each tree, plus a few of the images also have some other small', 'images is shown below: You can clearly see that each image has one large cluster of pixels roughly corresponding to the location of each tree, plus a few of the images also have some other small clusters corresponding either to lights in the windows of some of the buildings, or to a background scene on the horizon. The next step is to get the computer to recognize that these are separate clusters, and label each pixel correctly with a cluster membership ID number. For this task I chose DBSCAN. There is a pretty good visual comparison of how DBSCAN typically behaves, relative to other clustering algorithms, available here. As I said earlier, it does well with amorphous shapes. The output of DBSCAN, with each cluster plotted in a different color, is shown here: There are a few things to be aware of when looking at this result. First is that DBSCAN requires the user to set a ""proximity"" parameter in order to regulate its behavior, which effectively controls how separated a pair of points', 'of when looking at this result. First is that DBSCAN requires the user to set a ""proximity"" parameter in order to regulate its behavior, which effectively controls how separated a pair of points must be in order for the algorithm to declare a new separate cluster rather than agglomerating a test point onto an already pre-existing cluster. I set this value to be 0.04 times the size along the diagonal of each image. Since the images vary in size from roughly VGA up to about HD 1080, this type of scale-relative definition is critical. Another point worth noting is that the DBSCAN algorithm as it is implemented in scikit-learn has memory limits which are fairly challenging for some of the larger images in this sample. Therefore, for a few of the larger images, I actually had to ""decimate"" (i.e., retain only every 3rd or 4th pixel and drop the others) each cluster in order to stay within this limit. As a result of this culling process, the remaining individual sparse pixels are difficult', 'retain only every 3rd or 4th pixel and drop the others) each cluster in order to stay within this limit. As a result of this culling process, the remaining individual sparse pixels are difficult to see on some of the larger images. Therefore, for display purposes only, the color-coded pixels in the above images have been effectively ""dilated"" just slightly so that they stand out better. It\'s purely a cosmetic operation for the sake of the narrative; although there are comments mentioning this dilation in my code, rest assured that it has nothing to do with any calculations that actually matter. Once the clusters are identified and labeled, the third and final step is easy: I simply take the largest cluster in each image (in this case, I chose to measure ""size"" in terms of the total number of member pixels, although one could have just as easily instead used some type of metric that gauges physical extent) and compute the convex hull for that cluster. The convex hull then becomes the', ""of member pixels, although one could have just as easily instead used some type of metric that gauges physical extent) and compute the convex hull for that cluster. The convex hull then becomes the tree border. The six convex hulls computed via this method are shown below in red: The source code is written for Python 2.7.6 and it depends on numpy, scipy, matplotlib and scikit-learn. I've divided it into two parts. The first part is responsible for the actual image processing:"", '```\nfrom PIL import Image\nimport numpy as np\nimport scipy as sp\nimport matplotlib.colors as colors\nfrom sklearn.cluster import DBSCAN\nfrom math import ceil, sqrt', '""""""\nInputs:\n\n    rgbimg:         [M,N,3] numpy array containing (uint, 0-255) color image\n\n    hueleftthr:     Scalar constant to select maximum allowed hue in the\n                    yellow-green region\n\n    huerightthr:    Scalar constant to select minimum allowed hue in the\n                    blue-purple region\n\n    satthr:         Scalar constant to select minimum allowed saturation\n\n    valthr:         Scalar constant to select minimum allowed value\n\n    monothr:        Scalar constant to select minimum allowed monochrome\n                    brightness\n\n    maxpoints:      Scalar constant maximum number of pixels to forward to\n                    the DBSCAN clustering algorithm\n\n    proxthresh:     Proximity threshold to use for DBSCAN, as a fraction of\n                    the diagonal size of the image\n\nOutputs:\n\n    borderseg:      [K,2,2] Nested list containing K pairs of x- and y- pixel\n                    values for drawing the tree border', 'Outputs:\n\n    borderseg:      [K,2,2] Nested list containing K pairs of x- and y- pixel\n                    values for drawing the tree border\n\n    X:              [P,2] List of pixels that passed the threshold step\n\n    labels:         [Q,2] List of cluster labels for points in Xslice (see\n                    below)\n\n    Xslice:         [Q,2] Reduced list of pixels to be passed to DBSCAN\n\n""""""\n\ndef findtree(rgbimg, hueleftthr=0.2, huerightthr=0.95, satthr=0.7, \n             valthr=0.7, monothr=220, maxpoints=5000, proxthresh=0.04):\n\n    # Convert rgb image to monochrome for\n    gryimg = np.asarray(Image.fromarray(rgbimg).convert(\'L\'))\n    # Convert rgb image (uint, 0-255) to hsv (float, 0.0-1.0)\n    hsvimg = colors.rgb_to_hsv(rgbimg.astype(float)/255)', '# Initialize binary thresholded image\n    binimg = np.zeros((rgbimg.shape[0], rgbimg.shape[1]))\n    # Find pixels with hue<0.2 or hue>0.95 (red or yellow) and saturation/value\n    # both greater than 0.7 (saturated and bright)--tends to coincide with\n    # ornamental lights on trees in some of the images\n    boolidx = np.logical_and(\n                np.logical_and(\n                  np.logical_or((hsvimg[:,:,0] < hueleftthr),\n                                (hsvimg[:,:,0] > huerightthr)),\n                                (hsvimg[:,:,1] > satthr)),\n                                (hsvimg[:,:,2] > valthr))\n    # Find pixels that meet hsv criterion\n    binimg[np.where(boolidx)] = 255\n    # Add pixels that meet grayscale brightness criterion\n    binimg[np.where(gryimg > monothr)] = 255', '# Prepare thresholded points for DBSCAN clustering algorithm\n    X = np.transpose(np.where(binimg == 255))\n    Xslice = X\n    nsample = len(Xslice)\n    if nsample > maxpoints:\n        # Make sure number of points does not exceed DBSCAN maximum capacity\n        Xslice = X[range(0,nsample,int(ceil(float(nsample)/maxpoints)))]\n\n    # Translate DBSCAN proximity threshold to units of pixels and run DBSCAN\n    pixproxthr = proxthresh * sqrt(binimg.shape[0]**2 + binimg.shape[1]**2)\n    db = DBSCAN(eps=pixproxthr, min_samples=10).fit(Xslice)\n    labels = db.labels_.astype(int)', ""# Find the largest cluster (i.e., with most points) and obtain convex hull   \n    unique_labels = set(labels)\n    maxclustpt = 0\n    for k in unique_labels:\n        class_members = [index[0] for index in np.argwhere(labels == k)]\n        if len(class_members) > maxclustpt:\n            points = Xslice[class_members]\n            hull = sp.spatial.ConvexHull(points)\n            maxclustpt = len(class_members)\n            borderseg = [[points[simplex,0], points[simplex,1]] for simplex\n                          in hull.simplices]\n\n    return borderseg, X, labels, Xslice\n\n```\n and the second part is a user-level script which calls the first file and generates all of the plots above: \n```\n#!/usr/bin/env python\n\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom findtree import findtree\n\n# Image files to process\nfname = ['nmzwj.png', 'aVZhC.png', '2K9EF.png',\n         'YowlH.png', '2y4o5.png', 'FWhSP.png']"", ""# Image files to process\nfname = ['nmzwj.png', 'aVZhC.png', '2K9EF.png',\n         'YowlH.png', '2y4o5.png', 'FWhSP.png']\n\n# Initialize figures\nfgsz = (16,7)        \nfigthresh = plt.figure(figsize=fgsz, facecolor='w')\nfigclust  = plt.figure(figsize=fgsz, facecolor='w')\nfigcltwo  = plt.figure(figsize=fgsz, facecolor='w')\nfigborder = plt.figure(figsize=fgsz, facecolor='w')\nfigthresh.canvas.set_window_title('Thresholded HSV and Monochrome Brightness')\nfigclust.canvas.set_window_title('DBSCAN Clusters (Raw Pixel Output)')\nfigcltwo.canvas.set_window_title('DBSCAN Clusters (Slightly Dilated for Display)')\nfigborder.canvas.set_window_title('Trees with Borders')\n\nfor ii, name in zip(range(len(fname)), fname):\n    # Open the file and convert to rgb image\n    rgbimg = np.asarray(Image.open(name))\n\n    # Get the tree borders as well as a bunch of other intermediate values\n    # that will be used to illustrate how the algorithm works\n    borderseg, X, labels, Xslice = findtree(rgbimg)"", ""# Get the tree borders as well as a bunch of other intermediate values\n    # that will be used to illustrate how the algorithm works\n    borderseg, X, labels, Xslice = findtree(rgbimg)\n\n    # Display thresholded images\n    axthresh = figthresh.add_subplot(2,3,ii+1)\n    axthresh.set_xticks([])\n    axthresh.set_yticks([])\n    binimg = np.zeros((rgbimg.shape[0], rgbimg.shape[1]))\n    for v, h in X:\n        binimg[v,h] = 255\n    axthresh.imshow(binimg, interpolation='nearest', cmap='Greys')"", ""# Display color-coded clusters\n    axclust = figclust.add_subplot(2,3,ii+1) # Raw version\n    axclust.set_xticks([])\n    axclust.set_yticks([])\n    axcltwo = figcltwo.add_subplot(2,3,ii+1) # Dilated slightly for display only\n    axcltwo.set_xticks([])\n    axcltwo.set_yticks([])\n    axcltwo.imshow(binimg, interpolation='nearest', cmap='Greys')\n    clustimg = np.ones(rgbimg.shape)    \n    unique_labels = set(labels)\n    # Generate a unique color for each cluster \n    plcol = cm.rainbow_r(np.linspace(0, 1, len(unique_labels)))\n    for lbl, pix in zip(labels, Xslice):\n        for col, unqlbl in zip(plcol, unique_labels):\n            if lbl == unqlbl:\n                # Cluster label of -1 indicates no cluster membership;\n                # override default color with black\n                if lbl == -1:\n                    col = [0.0, 0.0, 0.0, 1.0]\n                # Raw version\n                for ij in range(3):\n                    clustimg[pix[0],pix[1],ij] = col[ij]"", ""if lbl == -1:\n                    col = [0.0, 0.0, 0.0, 1.0]\n                # Raw version\n                for ij in range(3):\n                    clustimg[pix[0],pix[1],ij] = col[ij]\n                # Dilated just for display\n                axcltwo.plot(pix[1], pix[0], 'o', markerfacecolor=col, \n                    markersize=1, markeredgecolor=col)\n    axclust.imshow(clustimg)\n    axcltwo.set_xlim(0, binimg.shape[1]-1)\n    axcltwo.set_ylim(binimg.shape[0], -1)"", ""# Plot original images with read borders around the trees\n    axborder = figborder.add_subplot(2,3,ii+1)\n    axborder.set_axis_off()\n    axborder.imshow(rgbimg, interpolation='nearest')\n    for vseg, hseg in borderseg:\n        axborder.plot(hseg, vseg, 'r-', lw=3)\n    axborder.set_xlim(0, binimg.shape[1]-1)\n    axborder.set_ylim(binimg.shape[0], -1)\n\nplt.show()\n\n```""]","I have an approach which I think is interesting and a bit different from the rest. The main difference in my approach, compared to some of the others, is in how the image segmentation step is performed--I used the DBSCAN clustering algorithm from Python's scikit-learn; it's optimized for finding somewhat amorphous shapes that may not necessarily have a single clear centroid. At the top level, my approach is fairly simple and can be broken down into about 3 steps. First I apply a threshold (or actually, the logical ""or"" of two separate and distinct thresholds). As with many of the other answers, I assumed that the Christmas tree would be one of the brighter objects in the scene, so the first threshold is just a simple monochrome brightness test; any pixels with values above 220 on a 0-255 scale (where black is 0 and white is 255) are saved to a binary black-and-white image. The second threshold tries to look for red and yellow lights, which are particularly prominent in the trees in the upper left and lower right of the six images, and stand out well against the blue-green background which is prevalent in most of the photos. I convert the rgb image to hsv space, and require that the hue is either less than 0.2 on a 0.0-1.0 scale (corresponding roughly to the border between yellow and green) or greater than 0.95 (corresponding to the border between purple and red) and additionally I require bright, saturated colors: saturation and value must both be above 0.7. The results of the two threshold procedures are logically ""or""-ed together, and the resulting matrix of black-and-white binary images is shown below: You can clearly see that each image has one large cluster of pixels roughly corresponding to the location of each tree, plus a few of the images also have some other small clusters corresponding either to lights in the windows of some of the buildings, or to a background scene on the horizon. The next step is to get the computer to recognize that these are separate clusters, and label each pixel correctly with a cluster membership ID number. For this task I chose DBSCAN. There is a pretty good visual comparison of how DBSCAN typically behaves, relative to other clustering algorithms, available here. As I said earlier, it does well with amorphous shapes. The output of DBSCAN, with each cluster plotted in a different color, is shown here: There are a few things to be aware of when looking at this result. First is that DBSCAN requires the user to set a ""proximity"" parameter in order to regulate its behavior, which effectively controls how separated a pair of points must be in order for the algorithm to declare a new separate cluster rather than agglomerating a test point onto an already pre-existing cluster. I set this value to be 0.04 times the size along the diagonal of each image. Since the images vary in size from roughly VGA up to about HD 1080, this type of scale-relative definition is critical. Another point worth noting is that the DBSCAN algorithm as it is implemented in scikit-learn has memory limits which are fairly challenging for some of the larger images in this sample. Therefore, for a few of the larger images, I actually had to ""decimate"" (i.e., retain only every 3rd or 4th pixel and drop the others) each cluster in order to stay within this limit. As a result of this culling process, the remaining individual sparse pixels are difficult to see on some of the larger images. Therefore, for display purposes only, the color-coded pixels in the above images have been effectively ""dilated"" just slightly so that they stand out better. It's purely a cosmetic operation for the sake of the narrative; although there are comments mentioning this dilation in my code, rest assured that it has nothing to do with any calculations that actually matter. Once the clusters are identified and labeled, the third and final step is easy: I simply take the largest cluster in each image (in this case, I chose to measure ""size"" in terms of the total number of member pixels, although one could have just as easily instead used some type of metric that gauges physical extent) and compute the convex hull for that cluster. The convex hull then becomes the tree border. The six convex hulls computed via this method are shown below in red: The source code is written for Python 2.7.6 and it depends on numpy, scipy, matplotlib and scikit-learn. I've divided it into two parts. The first part is responsible for the actual image processing: 
```
from PIL import Image
import numpy as np
import scipy as sp
import matplotlib.colors as colors
from sklearn.cluster import DBSCAN
from math import ceil, sqrt

""""""
Inputs:

    rgbimg:         [M,N,3] numpy array containing (uint, 0-255) color image

    hueleftthr:     Scalar constant to select maximum allowed hue in the
                    yellow-green region

    huerightthr:    Scalar constant to select minimum allowed hue in the
                    blue-purple region

    satthr:         Scalar constant to select minimum allowed saturation

    valthr:         Scalar constant to select minimum allowed value

    monothr:        Scalar constant to select minimum allowed monochrome
                    brightness

    maxpoints:      Scalar constant maximum number of pixels to forward to
                    the DBSCAN clustering algorithm

    proxthresh:     Proximity threshold to use for DBSCAN, as a fraction of
                    the diagonal size of the image

Outputs:

    borderseg:      [K,2,2] Nested list containing K pairs of x- and y- pixel
                    values for drawing the tree border

    X:              [P,2] List of pixels that passed the threshold step

    labels:         [Q,2] List of cluster labels for points in Xslice (see
                    below)

    Xslice:         [Q,2] Reduced list of pixels to be passed to DBSCAN

""""""

def findtree(rgbimg, hueleftthr=0.2, huerightthr=0.95, satthr=0.7, 
             valthr=0.7, monothr=220, maxpoints=5000, proxthresh=0.04):

    # Convert rgb image to monochrome for
    gryimg = np.asarray(Image.fromarray(rgbimg).convert('L'))
    # Convert rgb image (uint, 0-255) to hsv (float, 0.0-1.0)
    hsvimg = colors.rgb_to_hsv(rgbimg.astype(float)/255)

    # Initialize binary thresholded image
    binimg = np.zeros((rgbimg.shape[0], rgbimg.shape[1]))
    # Find pixels with hue<0.2 or hue>0.95 (red or yellow) and saturation/value
    # both greater than 0.7 (saturated and bright)--tends to coincide with
    # ornamental lights on trees in some of the images
    boolidx = np.logical_and(
                np.logical_and(
                  np.logical_or((hsvimg[:,:,0] < hueleftthr),
                                (hsvimg[:,:,0] > huerightthr)),
                                (hsvimg[:,:,1] > satthr)),
                                (hsvimg[:,:,2] > valthr))
    # Find pixels that meet hsv criterion
    binimg[np.where(boolidx)] = 255
    # Add pixels that meet grayscale brightness criterion
    binimg[np.where(gryimg > monothr)] = 255

    # Prepare thresholded points for DBSCAN clustering algorithm
    X = np.transpose(np.where(binimg == 255))
    Xslice = X
    nsample = len(Xslice)
    if nsample > maxpoints:
        # Make sure number of points does not exceed DBSCAN maximum capacity
        Xslice = X[range(0,nsample,int(ceil(float(nsample)/maxpoints)))]

    # Translate DBSCAN proximity threshold to units of pixels and run DBSCAN
    pixproxthr = proxthresh * sqrt(binimg.shape[0]**2 + binimg.shape[1]**2)
    db = DBSCAN(eps=pixproxthr, min_samples=10).fit(Xslice)
    labels = db.labels_.astype(int)

    # Find the largest cluster (i.e., with most points) and obtain convex hull   
    unique_labels = set(labels)
    maxclustpt = 0
    for k in unique_labels:
        class_members = [index[0] for index in np.argwhere(labels == k)]
        if len(class_members) > maxclustpt:
            points = Xslice[class_members]
            hull = sp.spatial.ConvexHull(points)
            maxclustpt = len(class_members)
            borderseg = [[points[simplex,0], points[simplex,1]] for simplex
                          in hull.simplices]

    return borderseg, X, labels, Xslice

```
 and the second part is a user-level script which calls the first file and generates all of the plots above: 
```
#!/usr/bin/env python

from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from findtree import findtree

# Image files to process
fname = ['nmzwj.png', 'aVZhC.png', '2K9EF.png',
         'YowlH.png', '2y4o5.png', 'FWhSP.png']

# Initialize figures
fgsz = (16,7)        
figthresh = plt.figure(figsize=fgsz, facecolor='w')
figclust  = plt.figure(figsize=fgsz, facecolor='w')
figcltwo  = plt.figure(figsize=fgsz, facecolor='w')
figborder = plt.figure(figsize=fgsz, facecolor='w')
figthresh.canvas.set_window_title('Thresholded HSV and Monochrome Brightness')
figclust.canvas.set_window_title('DBSCAN Clusters (Raw Pixel Output)')
figcltwo.canvas.set_window_title('DBSCAN Clusters (Slightly Dilated for Display)')
figborder.canvas.set_window_title('Trees with Borders')

for ii, name in zip(range(len(fname)), fname):
    # Open the file and convert to rgb image
    rgbimg = np.asarray(Image.open(name))

    # Get the tree borders as well as a bunch of other intermediate values
    # that will be used to illustrate how the algorithm works
    borderseg, X, labels, Xslice = findtree(rgbimg)

    # Display thresholded images
    axthresh = figthresh.add_subplot(2,3,ii+1)
    axthresh.set_xticks([])
    axthresh.set_yticks([])
    binimg = np.zeros((rgbimg.shape[0], rgbimg.shape[1]))
    for v, h in X:
        binimg[v,h] = 255
    axthresh.imshow(binimg, interpolation='nearest', cmap='Greys')

    # Display color-coded clusters
    axclust = figclust.add_subplot(2,3,ii+1) # Raw version
    axclust.set_xticks([])
    axclust.set_yticks([])
    axcltwo = figcltwo.add_subplot(2,3,ii+1) # Dilated slightly for display only
    axcltwo.set_xticks([])
    axcltwo.set_yticks([])
    axcltwo.imshow(binimg, interpolation='nearest', cmap='Greys')
    clustimg = np.ones(rgbimg.shape)    
    unique_labels = set(labels)
    # Generate a unique color for each cluster 
    plcol = cm.rainbow_r(np.linspace(0, 1, len(unique_labels)))
    for lbl, pix in zip(labels, Xslice):
        for col, unqlbl in zip(plcol, unique_labels):
            if lbl == unqlbl:
                # Cluster label of -1 indicates no cluster membership;
                # override default color with black
                if lbl == -1:
                    col = [0.0, 0.0, 0.0, 1.0]
                # Raw version
                for ij in range(3):
                    clustimg[pix[0],pix[1],ij] = col[ij]
                # Dilated just for display
                axcltwo.plot(pix[1], pix[0], 'o', markerfacecolor=col, 
                    markersize=1, markeredgecolor=col)
    axclust.imshow(clustimg)
    axcltwo.set_xlim(0, binimg.shape[1]-1)
    axcltwo.set_ylim(binimg.shape[0], -1)

    # Plot original images with read borders around the trees
    axborder = figborder.add_subplot(2,3,ii+1)
    axborder.set_axis_off()
    axborder.imshow(rgbimg, interpolation='nearest')
    for vseg, hseg in borderseg:
        axborder.plot(hseg, vseg, 'r-', lw=3)
    axborder.set_xlim(0, binimg.shape[1]-1)
    axborder.set_ylim(binimg.shape[0], -1)

plt.show()

```
"
81656,Where do I find the current C or C++ standard documents?,https://stackoverflow.com/questions/81656/where-do-i-find-the-current-c-or-c-standard-documents,11,575.0,"['PDF versions of the standard As of 1st September 2014 March 2022, the best locations by price for the official C and C++ standards documents in PDF seem to be: C++20 – ISO/IEC 14882:2020: 212 CAD (about $165 US) from csagroup.org C++17 – ISO/IEC 14882:2017: $90 NZD (about $65 US) from Standards New Zealand C++14 – ISO/IEC 14882:2014: $90 NZD (about $65 US) from Standards New Zealand C++11 – ISO/IEC 14882-2011: $60 from ansi.org or $60 from Techstreet C++03 – INCITS/ISO/IEC 14882:2003: $30 from ansi.org C++98 – ISO/IEC 14882:1998: $95 NZD (about $65 US) from Standards New Zealand C17/C18 – INCITS/ISO/IEC 9899:2018: $116 from INCITS/ANSI / N2176 / c17_updated_proposed_fdis.pdf draft from November 2017 (Link broken, see Wayback Machine N2176) C11 – ISO/IEC 9899:2011: $60 from ansi.org / WG14 draft version N1570 C99 – INCITS/ISO/IEC 9899-1999(R2005): $60 from ansi.org / WG14 draft version N1256 C90 – ISO/IEC 9899:1990: $90 NZD (about $65 USD) from Standards New Zealand Non-PDF electronic', 'draft version N1570 C99 – INCITS/ISO/IEC 9899-1999(R2005): $60 from ansi.org / WG14 draft version N1256 C90 – ISO/IEC 9899:1990: $90 NZD (about $65 USD) from Standards New Zealand Non-PDF electronic versions of the standard Warning: most copies of standard drafts are published in PDF format, and errors may have been introduced if the text/HTML was transcribed or automatically generated from the PDF. latest C standard – ISO Online Browsing Platform, viewable but not downloadable: (https://www.iso.org/obp/ui/#iso:std:iso-iec:9899) C89 – Draft version in ANSI text format: (https://web.archive.org/web/20161223125339/http://flash-gordon.me.uk/ansi.c.txt) C89 – Draft version as HTML document: (https://port70.net/~nsz/c/c89/c89-draft.html) C90 TC1; ISO/IEC 9899 TCOR1, single-page HTML document: (https://www.open-std.org/jtc1/sc22/wg14/www/docs/tc1.htm) C90 TC2; ISO/IEC 9899 TCOR2, single-page HTML document: (https://www.open-std.org/jtc1/sc22/wg14/www/docs/tc2.htm) C99 – Draft version', ""(https://www.open-std.org/jtc1/sc22/wg14/www/docs/tc1.htm) C90 TC2; ISO/IEC 9899 TCOR2, single-page HTML document: (https://www.open-std.org/jtc1/sc22/wg14/www/docs/tc2.htm) C99 – Draft version (N1256) as HTML document: (https://port70.net/~nsz/c/c99/n1256.html) C11 – Draft version (N1570) as HTML document: (https://port70.net/~nsz/c/c11/n1570.html) C++11 – Working draft (N3337) as plain text document: (https://port70.net/~nsz/c/c%2B%2B/c%2B%2B11_n3337.txt) (The site hosting the plain text version of the C++11 working draft also has some C++14 drafts in this format. But none of them are copies of the final working draft, N4140.) Print versions of the standard Print copies of the standards are available from national standards bodies and ISO but are very expensive. If you want a hard copy of the C90 standard for much less money than above, you may be able to find a cheap used copy of Herb Schildt's book The Annotated ANSI Standard at Amazon, which contains the actual text of the"", ""copy of the C90 standard for much less money than above, you may be able to find a cheap used copy of Herb Schildt's book The Annotated ANSI Standard at Amazon, which contains the actual text of the standard (useful) and commentary on the standard (less useful - it contains several dangerous and misleading errors). The C99 and C++03 standards are available in book form from Wiley and the BSI (British Standards Institute): C++03 Standard on Amazon C99 Standard on Amazon Standards committee draft versions (free) The working drafts for future standards are often available from the committee websites: C++ committee website C committee website If you want to get drafts from the current or earlier C/C++ standards, there are some available for free on the internet: For C: ANSI X3.159-198 (C89): I cannot find a PDF of C89, but it is almost the same as C90. The only major differences are in the boilerplate and section numbering, although there are some slight textual differences ISO/IEC"", 'I cannot find a PDF of C89, but it is almost the same as C90. The only major differences are in the boilerplate and section numbering, although there are some slight textual differences ISO/IEC 9899:1990 (C90): (Almost the same as ANSI X3.159-198 (C89) except for the frontmatter and section numbering. There is at least one textual difference in section 6.5.7 (previously 3.5.7), where ""a list"" became ""a brace-enclosed list"". Note that the conversion between ANSI and ISO/IEC Standard is seen inside this document, the document refers to its name as ""ANSI/ISO: 9899/99"" although this isn\'t the right name of the later made standard of it, the right name is ""ISO/IEC 9899:1990"") TC1 for C90: https://www.open-std.org/jtc1/sc22/wg14/www/docs/n423.pdf There isn\'t a PDF link for TC2 on the WG14 website, sadly. ISO/IEC 9899:1999 (C99 incorporating all three Technical Corrigenda): https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf An earlier version of C99 incorporating only TC1 and TC2:', 'sadly. ISO/IEC 9899:1999 (C99 incorporating all three Technical Corrigenda): https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf An earlier version of C99 incorporating only TC1 and TC2: https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1124.pdf Working draft for the original (i.e. pre-corrigenda) C99: https://www.open-std.org/jtc1/sc22/wg14/www/docs/n843.htm (HTML) and https://web.archive.org/web/20240307022041/http://std.dkuug.dk/JTC1/SC22/WG14/www/docs/n843.pdf (PDF). Note that there were two later working drafts: N869 and N878, but they seem to have been removed from the WG14 website, so this is the latest one available. List of changes between C89/C90 and C99: https://port70.net/~nsz/c/c89/c9x_changes.html TC1 for C99 (only the TC, not the standard incorporating it): https://www.open-std.org/jtc1/sc22/wg14/www/docs/9899tc1/n32071.PDF TC2 for C99 (only the TC, not the standard incorporating it): https://www.open-std.org/jtc1/sc22/wg14/www/docs/9899-1999_cor_2-2004.pdf', ""TC2 for C99 (only the TC, not the standard incorporating it): https://www.open-std.org/jtc1/sc22/wg14/www/docs/9899-1999_cor_2-2004.pdf ISO/IEC 9899:2011 (C11): https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf For information on the differences between N1570 and the final, published version of C11, see Latest changes in C11 and https://groups.google.com/g/comp.std.c/c/v5hsWOu5vSw ISO/IEC 9899:2011/Cor 1:2012 (C11's only technical corrigendum): This can be viewed at https://www.iso.org/obp/ui/#iso:std:iso-iec:9899:ed-3:v1:cor:1:v1:en but cannot be downloaded. It is the actual corrigendum, not a draft. ISO/IEC 9899:2018 (C17/C18): https://web.archive.org/web/20181230041359if_/http://www.open-std.org/jtc1/sc22/wg14/www/abq/c17_updated_proposed_fdis.pdf (N2176) C23 work-in-progress - latest working draft as of April 1st, 2023 (N3096): https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3096.pdf C2y work-in-progress - latest working draft as of July 26, 2024 (N3301):"", '- latest working draft as of April 1st, 2023 (N3096): https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3096.pdf C2y work-in-progress - latest working draft as of July 26, 2024 (N3301): https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3301.pdf For C++: ISO/IEC 14882:1998 (C++98): https://web.archive.org/web/20221121042402/http://www.lirmm.fr/~ducour/Doc-objets/ISO+IEC+14882-1998.pdf ISO/IEC 14882:2003 (C++03): https://web.archive.org/web/20180922024431/https://cs.nyu.edu/courses/fall11/CSCI-GA.2110-003/documents/c++2003std.pdf ISO/IEC 14882:2011 (C++11): https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3337.pdf ISO/IEC 14882:2014 (C++14): https://github.com/cplusplus/draft/blob/master/papers/n4140.pdf?raw=true ISO/IEC 14882:2017 (C++17): https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4659.pdf ISO/IEC 14882:2020 (C++20): https://isocpp.org/files/papers/N4860.pdf ISO/IEC 14882:2023 (C++23): https://open-std.org/jtc1/sc22/wg21/docs/papers/2023/n4950.pdf Note that', 'ISO/IEC 14882:2020 (C++20): https://isocpp.org/files/papers/N4860.pdf ISO/IEC 14882:2023 (C++23): https://open-std.org/jtc1/sc22/wg21/docs/papers/2023/n4950.pdf Note that these documents are not the same as the standard, though the versions just prior to the meetings that decide on a standard are usually very close to what is in the final standard. The FCD (Final Committee Draft) versions are password protected; you need to be on the standards committee to get them. Even though the draft versions might be very close to the final ratified versions of the standards, some of this post\'s editors would strongly advise you to get a copy of the actual documents — especially if you\'re planning on quoting them as references. Of course, starving students should go ahead and use the drafts if strapped for cash. It appears that, if you are willing and able to wait a few months after ratification of a standard, to search for ""INCITS/ISO/IEC"" instead of ""ISO/IEC"" when looking for a standard is the', 'for cash. It appears that, if you are willing and able to wait a few months after ratification of a standard, to search for ""INCITS/ISO/IEC"" instead of ""ISO/IEC"" when looking for a standard is the key. By doing so, one of this post\'s editors was able to find the C11 and C++11 standards at reasonable prices. For example, if you search for ""INCITS/ISO/IEC 9899:2011"" instead of ""ISO/IEC 9899:2011"" on webstore.ansi.org you will find the reasonably priced PDF version. The site https://wg21.link/ provides short-URL links to the C++ current working draft and draft standards, and committee papers: https://wg21.link/std11 - C++11 https://wg21.link/std14 - C++14 https://wg21.link/std17 - C++17 https://wg21.link/std20 - C++20 https://wg21.link/std - current working draft (as of May 2022 still points to the 2021 version) The current draft of the standard is maintained as LaTeX sources on Github. These sources can be converted to HTML using cxxdraft-htmlgen. The following sites maintain HTML pages', 'to the 2021 version) The current draft of the standard is maintained as LaTeX sources on Github. These sources can be converted to HTML using cxxdraft-htmlgen. The following sites maintain HTML pages so generated: Tim Song - Current working draft - C++11 - C++14 - C++17 - C++20 Eelis - Current working draft Tim Song also maintains generated HTML and PDF versions of the Networking TS and Ranges TS. POSIX extensions to the C standard The POSIX standard (IEEE 1003.1) requires a compliant operating system to include a C compiler. This compiler must in turn be compliant with the C standard, and must also support various extensions defined in the ""System Interfaces"" section of POSIX (such as the', '```\noff_t\n```\n data type, the \n```\n<aio.h>\n```\n header, the \n```\nclock_gettime()\n```\n function and the \n```\n_POSIX_C_SOURCE\n```\n macro.) So if you\'ve tried to look up a particular function, been informed ""This function is part of POSIX, not the C standard"", and wondered why an operating system standard was mandating compiler features and language extensions... now you know! POSIX.1-2001: The System Interfaces section can be downloaded as a separate document from https://mirror.math.princeton.edu/pub/oldlinux/download/c951.pdf. Section 1.7 states that the relevant version of the C standard is C99. The ""Shell and Utilities"" section (https://mirror.math.princeton.edu/pub/oldlinux/download/c952.pdf) mandates not only that a C99-compliant compiler should exist, but that it should be invokable from the command line under the name ""c99"". One way in which this can be implemented is to place a shell script called ""c99"" in /usr/bin, which calls gcc with the \n```\n-std=c99\n```', ""option added to the list of command-line parameters, and blocks any competing standards from being specified. POSIX.1-2001 had two technical corrigenda, one dated 2002 and one dated 2004. I don't think they're incorporated into the documents as linked above. There's an online HTML version incorporating the corrigenda at https://pubs.opengroup.org/onlinepubs/009695399/ - but I should add that I've had some trouble with the search box and so using Google to search the site is probably your best bet. There is a paywalled link to download the first corrigendum at https://standards.ieee.org/standard/1003_1-2001-Cor1-2002.html. There is also a paywalled link for the second at https://standards.ieee.org/standard/1003_1-2001-Cor2-2004.html There is a draft version of POSIX.1-2008 at https://www.open-std.org/jtc1/sc22/open/n4217.pdf. POSIX.1-2008 also had two technical corrigenda, the latter of the two being dated 2016. There is an online HTML version of the standard incorporating the"", 'POSIX.1-2008 also had two technical corrigenda, the latter of the two being dated 2016. There is an online HTML version of the standard incorporating the corrigenda at https://pubs.opengroup.org/onlinepubs/9699919799.2016edition/ - though, again, I have had situations where the site\'s own search box wasn\'t good for finding information. There is an online HTML version of POSIX.1-2017 at https://pubs.opengroup.org/onlinepubs/9699919799/ - though, again, I recommend using Google instead of that site\'s searchbox. According to the Open Group website ""IEEE 1003.1-2017 ... is a revision to the 1003.1-2008 standard to rollup the standard including its two technical corrigenda (as-is)"". Linux manpages describe it as ""technically identical"" to POSIX.1-2008 with Technical Corrigenda 1 and 2 applied. This is therefore not a major revision and does not change the value of the', '```\n_POSIX_C_SOURCE\n```\n macro. There is an online HTML version of POSIX.1-2024 (currently the latest version of POSIX.1) at https://pubs.opengroup.org/onlinepubs/9799919799/ - though, once again, I still recommend using Google instead of the site\'s searchbox. The Open Group website referred in 2019 to ""a major revision anticipated to be available in 2023"", and consistent with this, the \n```\n_POSIX_C_SOURCE\n```\n macro has a new value of \n```\n202405L\n```\n to indicate POSIX.1-2024. (source: https://pubs.opengroup.org/onlinepubs/9799919799/basedefs/V1_chap02.html)']","PDF versions of the standard As of 1st September 2014 March 2022, the best locations by price for the official C and C++ standards documents in PDF seem to be: C++20 – ISO/IEC 14882:2020: 212 CAD (about $165 US) from csagroup.org C++17 – ISO/IEC 14882:2017: $90 NZD (about $65 US) from Standards New Zealand C++14 – ISO/IEC 14882:2014: $90 NZD (about $65 US) from Standards New Zealand C++11 – ISO/IEC 14882-2011: $60 from ansi.org or $60 from Techstreet C++03 – INCITS/ISO/IEC 14882:2003: $30 from ansi.org C++98 – ISO/IEC 14882:1998: $95 NZD (about $65 US) from Standards New Zealand C17/C18 – INCITS/ISO/IEC 9899:2018: $116 from INCITS/ANSI / N2176 / c17_updated_proposed_fdis.pdf draft from November 2017 (Link broken, see Wayback Machine N2176) C11 – ISO/IEC 9899:2011: $60 from ansi.org / WG14 draft version N1570 C99 – INCITS/ISO/IEC 9899-1999(R2005): $60 from ansi.org / WG14 draft version N1256 C90 – ISO/IEC 9899:1990: $90 NZD (about $65 USD) from Standards New Zealand Non-PDF electronic versions of the standard Warning: most copies of standard drafts are published in PDF format, and errors may have been introduced if the text/HTML was transcribed or automatically generated from the PDF. latest C standard – ISO Online Browsing Platform, viewable but not downloadable: (https://www.iso.org/obp/ui/#iso:std:iso-iec:9899) C89 – Draft version in ANSI text format: (https://web.archive.org/web/20161223125339/http://flash-gordon.me.uk/ansi.c.txt) C89 – Draft version as HTML document: (https://port70.net/~nsz/c/c89/c89-draft.html) C90 TC1; ISO/IEC 9899 TCOR1, single-page HTML document: (https://www.open-std.org/jtc1/sc22/wg14/www/docs/tc1.htm) C90 TC2; ISO/IEC 9899 TCOR2, single-page HTML document: (https://www.open-std.org/jtc1/sc22/wg14/www/docs/tc2.htm) C99 – Draft version (N1256) as HTML document: (https://port70.net/~nsz/c/c99/n1256.html) C11 – Draft version (N1570) as HTML document: (https://port70.net/~nsz/c/c11/n1570.html) C++11 – Working draft (N3337) as plain text document: (https://port70.net/~nsz/c/c%2B%2B/c%2B%2B11_n3337.txt) (The site hosting the plain text version of the C++11 working draft also has some C++14 drafts in this format. But none of them are copies of the final working draft, N4140.) Print versions of the standard Print copies of the standards are available from national standards bodies and ISO but are very expensive. If you want a hard copy of the C90 standard for much less money than above, you may be able to find a cheap used copy of Herb Schildt's book The Annotated ANSI Standard at Amazon, which contains the actual text of the standard (useful) and commentary on the standard (less useful - it contains several dangerous and misleading errors). The C99 and C++03 standards are available in book form from Wiley and the BSI (British Standards Institute): C++03 Standard on Amazon C99 Standard on Amazon Standards committee draft versions (free) The working drafts for future standards are often available from the committee websites: C++ committee website C committee website If you want to get drafts from the current or earlier C/C++ standards, there are some available for free on the internet: For C: ANSI X3.159-198 (C89): I cannot find a PDF of C89, but it is almost the same as C90. The only major differences are in the boilerplate and section numbering, although there are some slight textual differences ISO/IEC 9899:1990 (C90): (Almost the same as ANSI X3.159-198 (C89) except for the frontmatter and section numbering. There is at least one textual difference in section 6.5.7 (previously 3.5.7), where ""a list"" became ""a brace-enclosed list"". Note that the conversion between ANSI and ISO/IEC Standard is seen inside this document, the document refers to its name as ""ANSI/ISO: 9899/99"" although this isn't the right name of the later made standard of it, the right name is ""ISO/IEC 9899:1990"") TC1 for C90: https://www.open-std.org/jtc1/sc22/wg14/www/docs/n423.pdf There isn't a PDF link for TC2 on the WG14 website, sadly. ISO/IEC 9899:1999 (C99 incorporating all three Technical Corrigenda): https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf An earlier version of C99 incorporating only TC1 and TC2: https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1124.pdf Working draft for the original (i.e. pre-corrigenda) C99: https://www.open-std.org/jtc1/sc22/wg14/www/docs/n843.htm (HTML) and https://web.archive.org/web/20240307022041/http://std.dkuug.dk/JTC1/SC22/WG14/www/docs/n843.pdf (PDF). Note that there were two later working drafts: N869 and N878, but they seem to have been removed from the WG14 website, so this is the latest one available. List of changes between C89/C90 and C99: https://port70.net/~nsz/c/c89/c9x_changes.html TC1 for C99 (only the TC, not the standard incorporating it): https://www.open-std.org/jtc1/sc22/wg14/www/docs/9899tc1/n32071.PDF TC2 for C99 (only the TC, not the standard incorporating it): https://www.open-std.org/jtc1/sc22/wg14/www/docs/9899-1999_cor_2-2004.pdf ISO/IEC 9899:2011 (C11): https://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf For information on the differences between N1570 and the final, published version of C11, see Latest changes in C11 and https://groups.google.com/g/comp.std.c/c/v5hsWOu5vSw ISO/IEC 9899:2011/Cor 1:2012 (C11's only technical corrigendum): This can be viewed at https://www.iso.org/obp/ui/#iso:std:iso-iec:9899:ed-3:v1:cor:1:v1:en but cannot be downloaded. It is the actual corrigendum, not a draft. ISO/IEC 9899:2018 (C17/C18): https://web.archive.org/web/20181230041359if_/http://www.open-std.org/jtc1/sc22/wg14/www/abq/c17_updated_proposed_fdis.pdf (N2176) C23 work-in-progress - latest working draft as of April 1st, 2023 (N3096): https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3096.pdf C2y work-in-progress - latest working draft as of July 26, 2024 (N3301): https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3301.pdf For C++: ISO/IEC 14882:1998 (C++98): https://web.archive.org/web/20221121042402/http://www.lirmm.fr/~ducour/Doc-objets/ISO+IEC+14882-1998.pdf ISO/IEC 14882:2003 (C++03): https://web.archive.org/web/20180922024431/https://cs.nyu.edu/courses/fall11/CSCI-GA.2110-003/documents/c++2003std.pdf ISO/IEC 14882:2011 (C++11): https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3337.pdf ISO/IEC 14882:2014 (C++14): https://github.com/cplusplus/draft/blob/master/papers/n4140.pdf?raw=true ISO/IEC 14882:2017 (C++17): https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4659.pdf ISO/IEC 14882:2020 (C++20): https://isocpp.org/files/papers/N4860.pdf ISO/IEC 14882:2023 (C++23): https://open-std.org/jtc1/sc22/wg21/docs/papers/2023/n4950.pdf Note that these documents are not the same as the standard, though the versions just prior to the meetings that decide on a standard are usually very close to what is in the final standard. The FCD (Final Committee Draft) versions are password protected; you need to be on the standards committee to get them. Even though the draft versions might be very close to the final ratified versions of the standards, some of this post's editors would strongly advise you to get a copy of the actual documents — especially if you're planning on quoting them as references. Of course, starving students should go ahead and use the drafts if strapped for cash. It appears that, if you are willing and able to wait a few months after ratification of a standard, to search for ""INCITS/ISO/IEC"" instead of ""ISO/IEC"" when looking for a standard is the key. By doing so, one of this post's editors was able to find the C11 and C++11 standards at reasonable prices. For example, if you search for ""INCITS/ISO/IEC 9899:2011"" instead of ""ISO/IEC 9899:2011"" on webstore.ansi.org you will find the reasonably priced PDF version. The site https://wg21.link/ provides short-URL links to the C++ current working draft and draft standards, and committee papers: https://wg21.link/std11 - C++11 https://wg21.link/std14 - C++14 https://wg21.link/std17 - C++17 https://wg21.link/std20 - C++20 https://wg21.link/std - current working draft (as of May 2022 still points to the 2021 version) The current draft of the standard is maintained as LaTeX sources on Github. These sources can be converted to HTML using cxxdraft-htmlgen. The following sites maintain HTML pages so generated: Tim Song - Current working draft - C++11 - C++14 - C++17 - C++20 Eelis - Current working draft Tim Song also maintains generated HTML and PDF versions of the Networking TS and Ranges TS. POSIX extensions to the C standard The POSIX standard (IEEE 1003.1) requires a compliant operating system to include a C compiler. This compiler must in turn be compliant with the C standard, and must also support various extensions defined in the ""System Interfaces"" section of POSIX (such as the 
```
off_t
```
 data type, the 
```
<aio.h>
```
 header, the 
```
clock_gettime()
```
 function and the 
```
_POSIX_C_SOURCE
```
 macro.) So if you've tried to look up a particular function, been informed ""This function is part of POSIX, not the C standard"", and wondered why an operating system standard was mandating compiler features and language extensions... now you know! POSIX.1-2001: The System Interfaces section can be downloaded as a separate document from https://mirror.math.princeton.edu/pub/oldlinux/download/c951.pdf. Section 1.7 states that the relevant version of the C standard is C99. The ""Shell and Utilities"" section (https://mirror.math.princeton.edu/pub/oldlinux/download/c952.pdf) mandates not only that a C99-compliant compiler should exist, but that it should be invokable from the command line under the name ""c99"". One way in which this can be implemented is to place a shell script called ""c99"" in /usr/bin, which calls gcc with the 
```
-std=c99
```
 option added to the list of command-line parameters, and blocks any competing standards from being specified. POSIX.1-2001 had two technical corrigenda, one dated 2002 and one dated 2004. I don't think they're incorporated into the documents as linked above. There's an online HTML version incorporating the corrigenda at https://pubs.opengroup.org/onlinepubs/009695399/ - but I should add that I've had some trouble with the search box and so using Google to search the site is probably your best bet. There is a paywalled link to download the first corrigendum at https://standards.ieee.org/standard/1003_1-2001-Cor1-2002.html. There is also a paywalled link for the second at https://standards.ieee.org/standard/1003_1-2001-Cor2-2004.html There is a draft version of POSIX.1-2008 at https://www.open-std.org/jtc1/sc22/open/n4217.pdf. POSIX.1-2008 also had two technical corrigenda, the latter of the two being dated 2016. There is an online HTML version of the standard incorporating the corrigenda at https://pubs.opengroup.org/onlinepubs/9699919799.2016edition/ - though, again, I have had situations where the site's own search box wasn't good for finding information. There is an online HTML version of POSIX.1-2017 at https://pubs.opengroup.org/onlinepubs/9699919799/ - though, again, I recommend using Google instead of that site's searchbox. According to the Open Group website ""IEEE 1003.1-2017 ... is a revision to the 1003.1-2008 standard to rollup the standard including its two technical corrigenda (as-is)"". Linux manpages describe it as ""technically identical"" to POSIX.1-2008 with Technical Corrigenda 1 and 2 applied. This is therefore not a major revision and does not change the value of the 
```
_POSIX_C_SOURCE
```
 macro. There is an online HTML version of POSIX.1-2024 (currently the latest version of POSIX.1) at https://pubs.opengroup.org/onlinepubs/9799919799/ - though, once again, I still recommend using Google instead of the site's searchbox. The Open Group website referred in 2019 to ""a major revision anticipated to be available in 2023"", and consistent with this, the 
```
_POSIX_C_SOURCE
```
 macro has a new value of 
```
202405L
```
 to indicate POSIX.1-2024. (source: https://pubs.opengroup.org/onlinepubs/9799919799/basedefs/V1_chap02.html)"
9387610,What XML parser should I use in C++?,https://stackoverflow.com/questions/9387610/what-xml-parser-should-i-use-in-c,6,,[],
266168,Simple example of threading in C++,https://stackoverflow.com/questions/266168/simple-example-of-threading-in-c,7,718.0,"['Create a function that you want the thread to execute, for example: \n```\nvoid task1(std::string msg)\n{\n    std::cout << ""task1 says: "" << msg;\n}\n\n```\n Now create the \n```\nthread\n```\n object that will ultimately invoke the function above like so: \n```\nstd::thread t1(task1, ""Hello"");\n\n```\n (You need to \n```\n#include <thread>\n```\n to access the \n```\nstd::thread\n```\n class.) The constructor\'s first argument is the function the thread will execute, followed by the function\'s parameters. The thread is automatically started upon construction. If later on you want to wait for the thread to be done executing the function, call: \n```\nt1.join();\n\n```\n (Joining means that the thread who invoked the new thread will wait for the new thread to finish execution, before it will continue its own execution.) The Code \n```\n#include <string>\n#include <iostream>\n#include <thread>\n\nusing namespace std;', 'using namespace std;\n\n// The function we want to execute on the new thread.\nvoid task1(string msg)\n{\n    cout << ""task1 says: "" << msg;\n}\n\nint main()\n{\n    // Constructs the new thread and runs it. Does not block execution.\n    thread t1(task1, ""Hello"");\n\n    // Do other things...\n\n    // Makes the main thread wait for the new thread to finish execution, therefore blocks its own execution.\n    t1.join();\n}\n\n```\n More information about std::thread here On GCC, compile with \n```\n-std=c++0x -pthread\n```\n. This should work for any operating-system, granted your compiler supports this (C++11) feature.']","Create a function that you want the thread to execute, for example: 
```
void task1(std::string msg)
{
    std::cout << ""task1 says: "" << msg;
}

```
 Now create the 
```
thread
```
 object that will ultimately invoke the function above like so: 
```
std::thread t1(task1, ""Hello"");

```
 (You need to 
```
#include <thread>
```
 to access the 
```
std::thread
```
 class.) The constructor's first argument is the function the thread will execute, followed by the function's parameters. The thread is automatically started upon construction. If later on you want to wait for the thread to be done executing the function, call: 
```
t1.join();

```
 (Joining means that the thread who invoked the new thread will wait for the new thread to finish execution, before it will continue its own execution.) The Code 
```
#include <string>
#include <iostream>
#include <thread>

using namespace std;

// The function we want to execute on the new thread.
void task1(string msg)
{
    cout << ""task1 says: "" << msg;
}

int main()
{
    // Constructs the new thread and runs it. Does not block execution.
    thread t1(task1, ""Hello"");

    // Do other things...

    // Makes the main thread wait for the new thread to finish execution, therefore blocks its own execution.
    t1.join();
}

```
 More information about std::thread here On GCC, compile with 
```
-std=c++0x -pthread
```
. This should work for any operating-system, granted your compiler supports this (C++11) feature."
9688200,"Difference between shared objects (.so), static libraries (.a), and DLL's (.so)?",https://stackoverflow.com/questions/9688200/difference-between-shared-objects-so-static-libraries-a-and-dlls-so,5,128.0,"[""I've always thought that DLLs and shared objects are just different terms for the same thing - Windows calls them DLLs, while on UNIX systems they're shared objects, with the general term - dynamically linked library - covering both (even the function to open a .so on UNIX is called \n```\ndlopen()\n```"", ""after 'dynamic library'). They are indeed only linked at application startup, however your notion of verification against the header file is incorrect. The header file defines prototypes which are required in order to compile the code which uses the library, but at link time the linker looks inside the library itself to make sure the functions it needs are actually there. The linker has to find the function bodies somewhere at link time or it'll raise an error. It ALSO does that at runtime, because as you rightly point out the library itself might have changed since the program was compiled. This is why ABI stability is so important in platform libraries, as the ABI changing is what breaks existing programs compiled against older versions. Static libraries are just bundles of object files straight out of the compiler, just like the ones that you are building yourself as part of your project's compilation, so they get pulled in and fed to the linker in exactly the same way, and unused"", ""straight out of the compiler, just like the ones that you are building yourself as part of your project's compilation, so they get pulled in and fed to the linker in exactly the same way, and unused bits are dropped in exactly the same way.""]","I've always thought that DLLs and shared objects are just different terms for the same thing - Windows calls them DLLs, while on UNIX systems they're shared objects, with the general term - dynamically linked library - covering both (even the function to open a .so on UNIX is called 
```
dlopen()
```
 after 'dynamic library'). They are indeed only linked at application startup, however your notion of verification against the header file is incorrect. The header file defines prototypes which are required in order to compile the code which uses the library, but at link time the linker looks inside the library itself to make sure the functions it needs are actually there. The linker has to find the function bodies somewhere at link time or it'll raise an error. It ALSO does that at runtime, because as you rightly point out the library itself might have changed since the program was compiled. This is why ABI stability is so important in platform libraries, as the ABI changing is what breaks existing programs compiled against older versions. Static libraries are just bundles of object files straight out of the compiler, just like the ones that you are building yourself as part of your project's compilation, so they get pulled in and fed to the linker in exactly the same way, and unused bits are dropped in exactly the same way."
3310737,Should we pass a shared_ptr by reference or by value?,https://stackoverflow.com/questions/3310737/should-we-pass-a-shared-ptr-by-reference-or-by-value,10,301.0,"[""This question has been discussed and answered by Scott, Andrei and Herb during Ask Us Anything session at C++ and Beyond 2011. Watch from 4:34 on \n```\nshared_ptr\n```\n performance and correctness. Shortly, there is no reason to pass by value, unless the goal is to share ownership of an object (eg. between different data structures, or between different threads). Unless you can move-optimise it as explained by Scott Meyers in the talk video linked above, but that is related to actual version of C++ you can use. A major update to this discussion has happened during GoingNative 2012 conference's Interactive Panel: Ask Us Anything! which is worth watching, especially from 22:50.""]","This question has been discussed and answered by Scott, Andrei and Herb during Ask Us Anything session at C++ and Beyond 2011. Watch from 4:34 on 
```
shared_ptr
```
 performance and correctness. Shortly, there is no reason to pass by value, unless the goal is to share ownership of an object (eg. between different data structures, or between different threads). Unless you can move-optimise it as explained by Scott Meyers in the talk video linked above, but that is related to actual version of C++ you can use. A major update to this discussion has happened during GoingNative 2012 conference's Interactive Panel: Ask Us Anything! which is worth watching, especially from 22:50."
11516657,C++ Structure Initialization,https://stackoverflow.com/questions/11516657/c-structure-initialization,17,240.0,"['If you want to make it clear what each initializer value is, just split it up on multiple lines, with a comment on each: \n```\naddress temp_addres = {\n  0,  // street_no\n  nullptr,  // street_name\n  ""Hamilton"",  // city\n  ""Ontario"",  // prov\n  nullptr,  // postal_code\n};\n\n```']","If you want to make it clear what each initializer value is, just split it up on multiple lines, with a comment on each: 
```
address temp_addres = {
  0,  // street_no
  nullptr,  // street_name
  ""Hamilton"",  // city
  ""Ontario"",  // prov
  nullptr,  // postal_code
};

```
"
1041620,What's the most efficient way to erase duplicates and sort a vector?,https://stackoverflow.com/questions/1041620/whats-the-most-efficient-way-to-erase-duplicates-and-sort-a-vector,28,752.0,"[""I agree with R. Pate and Todd Gardner; a \n```\nstd::set\n```\n might be a good idea here. Even if you're stuck using vectors, if you have enough duplicates, you might be better off creating a set to do the dirty work. Let's compare three approaches: Just using vector, sort + unique \n```\nsort( vec.begin(), vec.end() );\nvec.erase( unique( vec.begin(), vec.end() ), vec.end() );\n\n```\n Convert to set (manually) \n```\nset<int> s;\nunsigned size = vec.size();\nfor( unsigned i = 0; i < size; ++i ) s.insert( vec[i] );\nvec.assign( s.begin(), s.end() );\n\n```\n Convert to set (using a constructor) \n```\nset<int> s( vec.begin(), vec.end() );\nvec.assign( s.begin(), s.end() );"", ""```\n Convert to set (using a constructor) \n```\nset<int> s( vec.begin(), vec.end() );\nvec.assign( s.begin(), s.end() );\n\n```\n Here's how these perform as the number of duplicates changes: Summary: when the number of duplicates is large enough, it's actually faster to convert to a set and then dump the data back into a vector. And for some reason, doing the set conversion manually seems to be faster than using the set constructor -- at least on the toy random data that I used.""]","I agree with R. Pate and Todd Gardner; a 
```
std::set
```
 might be a good idea here. Even if you're stuck using vectors, if you have enough duplicates, you might be better off creating a set to do the dirty work. Let's compare three approaches: Just using vector, sort + unique 
```
sort( vec.begin(), vec.end() );
vec.erase( unique( vec.begin(), vec.end() ), vec.end() );

```
 Convert to set (manually) 
```
set<int> s;
unsigned size = vec.size();
for( unsigned i = 0; i < size; ++i ) s.insert( vec[i] );
vec.assign( s.begin(), s.end() );

```
 Convert to set (using a constructor) 
```
set<int> s( vec.begin(), vec.end() );
vec.assign( s.begin(), s.end() );

```
 Here's how these perform as the number of duplicates changes: Summary: when the number of duplicates is large enough, it's actually faster to convert to a set and then dump the data back into a vector. And for some reason, doing the set conversion manually seems to be faster than using the set constructor -- at least on the toy random data that I used."
12030650,When is std::weak_ptr useful?,https://stackoverflow.com/questions/12030650/when-is-stdweak-ptr-useful,15,305.0,"[""A good example would be a cache. For recently accessed objects, you want to keep them in memory, so you hold a strong pointer to them. Periodically, you scan the cache and decide which objects have not been accessed recently. You don't need to keep those in memory, so you get rid of the strong pointer. But what if that object is in use and some other code holds a strong pointer to it? If the cache gets rid of its only pointer to the object, it can never find it again. So the cache keeps a weak pointer to objects that it needs to find if they happen to stay in memory. This is exactly what a weak pointer does -- it allows you to locate an object if it's still around, but doesn't keep it around if nothing else needs it.""]","A good example would be a cache. For recently accessed objects, you want to keep them in memory, so you hold a strong pointer to them. Periodically, you scan the cache and decide which objects have not been accessed recently. You don't need to keep those in memory, so you get rid of the strong pointer. But what if that object is in use and some other code holds a strong pointer to it? If the cache gets rid of its only pointer to the object, it can never find it again. So the cache keeps a weak pointer to objects that it needs to find if they happen to stay in memory. This is exactly what a weak pointer does -- it allows you to locate an object if it's still around, but doesn't keep it around if nothing else needs it."
321068,Returning multiple values from a C++ function,https://stackoverflow.com/questions/321068/returning-multiple-values-from-a-c-function,23,286.0,"[""For returning two values I use a \n```\nstd::pair\n```\n (usually typedef'd). You should look at \n```\nboost::tuple\n```\n (in C++11 and newer, there's \n```\nstd::tuple\n```\n) for more than two return results. With introduction of structured binding in C++ 17, returning \n```\nstd::tuple\n```\n should probably become accepted standard.""]","For returning two values I use a 
```
std::pair
```
 (usually typedef'd). You should look at 
```
boost::tuple
```
 (in C++11 and newer, there's 
```
std::tuple
```
) for more than two return results. With introduction of structured binding in C++ 17, returning 
```
std::tuple
```
 should probably become accepted standard."
39382501,What is the purpose of std::launder?,https://stackoverflow.com/questions/39382501/what-is-the-purpose-of-stdlaunder,3,409.0,"[""```\nstd::launder\n```\n is aptly named, though only if you know what it's for. It performs memory laundering. Consider the example in the paper: \n```\nstruct X { const int n; };\nunion U { X x; float f; };\n...\n\nU u = {{ 1 }};\n\n```\n That statement performs aggregate initialization, initializing the first member of \n```\nU\n```\n with \n```\n{1}\n```\n. Because \n```\nn\n```\n is a \n```\nconst\n```\n variable, the compiler is free to assume that \n```\nu.x.n\n```\n shall always be 1. So what happens if we do this: \n```\nX *p = new (&u.x) X {2};"", ""```\n Because \n```\nX\n```\n is trivial, we need not destroy the old object before creating a new one in its place, so this is perfectly legal code. The new object will have its \n```\nn\n```\n member be 2. So tell me... what will \n```\nu.x.n\n```\n return? The obvious answer will be 2. But that's wrong, because the compiler is allowed to assume that a truly \n```\nconst\n```\n variable (not merely a \n```\nconst&\n```\n, but an object variable declared \n```\nconst\n```\n) will never change. But we just changed it. [basic.life]/8 spells out the circumstances when it is OK to access the newly created object through variables/pointers/references to the old one. And having a \n```\nconst\n```\n member is one of the disqualifying factors. So... how can we talk about \n```\nu.x.n\n```\n properly? We have to launder our memory: \n```\nassert(*std::launder(&u.x.n) == 2); //Will be true."", '```\n Money laundering is used to prevent people from tracing where you got your money from. Memory laundering is used to prevent the compiler from tracing where you got your object from, thus forcing it to avoid any optimizations that may no longer apply. Another of the disqualifying factors is if you change the type of the object. \n```\nstd::launder\n```\n can help here too: \n```\nalignas(int) char data[sizeof(int)];\nnew(&data) int;\nint *p = std::launder(reinterpret_cast<int*>(&data));\n\n```\n [basic.life]/8 tells us that, if you allocate a new object in the storage of the old one, you cannot access the new object through pointers to the old. \n```\nlaunder\n```\n allows us to side-step that.']","
```
std::launder
```
 is aptly named, though only if you know what it's for. It performs memory laundering. Consider the example in the paper: 
```
struct X { const int n; };
union U { X x; float f; };
...

U u = {{ 1 }};

```
 That statement performs aggregate initialization, initializing the first member of 
```
U
```
 with 
```
{1}
```
. Because 
```
n
```
 is a 
```
const
```
 variable, the compiler is free to assume that 
```
u.x.n
```
 shall always be 1. So what happens if we do this: 
```
X *p = new (&u.x) X {2};

```
 Because 
```
X
```
 is trivial, we need not destroy the old object before creating a new one in its place, so this is perfectly legal code. The new object will have its 
```
n
```
 member be 2. So tell me... what will 
```
u.x.n
```
 return? The obvious answer will be 2. But that's wrong, because the compiler is allowed to assume that a truly 
```
const
```
 variable (not merely a 
```
const&
```
, but an object variable declared 
```
const
```
) will never change. But we just changed it. [basic.life]/8 spells out the circumstances when it is OK to access the newly created object through variables/pointers/references to the old one. And having a 
```
const
```
 member is one of the disqualifying factors. So... how can we talk about 
```
u.x.n
```
 properly? We have to launder our memory: 
```
assert(*std::launder(&u.x.n) == 2); //Will be true.

```
 Money laundering is used to prevent people from tracing where you got your money from. Memory laundering is used to prevent the compiler from tracing where you got your object from, thus forcing it to avoid any optimizations that may no longer apply. Another of the disqualifying factors is if you change the type of the object. 
```
std::launder
```
 can help here too: 
```
alignas(int) char data[sizeof(int)];
new(&data) int;
int *p = std::launder(reinterpret_cast<int*>(&data));

```
 [basic.life]/8 tells us that, if you allocate a new object in the storage of the old one, you cannot access the new object through pointers to the old. 
```
launder
```
 allows us to side-step that."
4324763,Can we have functions inside functions in C++?,https://stackoverflow.com/questions/4324763/can-we-have-functions-inside-functions-in-c,13,499.0,"['Modern C++ - Yes with lambdas! In current versions of c++ (C++11, C++14, and C++17), you can have functions inside functions in the form of a lambda: \n```\nint main() {\n    // This declares a lambda, which can be called just like a function\n    auto print_message = [](std::string message) \n    { \n        std::cout << message << ""\\n""; \n    };\n\n    // Prints ""Hello!"" 10 times\n    for(int i = 0; i < 10; i++) {\n        print_message(""Hello!""); \n    }\n}\n\n```\n Lambdas can also modify local variables through **capture-by-reference*. With capture-by-reference, the lambda has access to all local variables declared in the lambda\'s scope. It can modify and change them normally. \n```\nint main() {\n    int i = 0;\n    // Captures i by reference; increments it by one\n    auto addOne = [&] () {\n        i++; \n    };\n\n    while(i < 10) {\n        addOne(); //Add 1 to i\n        std::cout << i << ""\\n"";\n    }\n}', 'while(i < 10) {\n        addOne(); //Add 1 to i\n        std::cout << i << ""\\n"";\n    }\n}\n\n```\n C++98 and C++03 - Not directly, but yes with static functions inside local classes C++ doesn\'t support that directly. That said, you can have local classes, and they can have functions (non-\n```\nstatic\n```\n or \n```\nstatic\n```\n), so you can get this to some extend, albeit it\'s a bit of a kludge: \n```\nint main() // it\'s int, dammit!\n{\n  struct X { // struct\'s as good as class\n    static void a()\n    {\n    }\n  };\n\n  X::a();\n\n  return 0;\n}\n\n```\n However, I\'d question the praxis. Everyone knows (well, now that you do, anyway \n```\n:)\n```\n) C++ doesn\'t support local functions, so they are used to not having them. They are not used, however, to that kludge. I would spend quite a while on this code to make sure it\'s really only there to allow local functions. Not good.']","Modern C++ - Yes with lambdas! In current versions of c++ (C++11, C++14, and C++17), you can have functions inside functions in the form of a lambda: 
```
int main() {
    // This declares a lambda, which can be called just like a function
    auto print_message = [](std::string message) 
    { 
        std::cout << message << ""\n""; 
    };

    // Prints ""Hello!"" 10 times
    for(int i = 0; i < 10; i++) {
        print_message(""Hello!""); 
    }
}

```
 Lambdas can also modify local variables through **capture-by-reference*. With capture-by-reference, the lambda has access to all local variables declared in the lambda's scope. It can modify and change them normally. 
```
int main() {
    int i = 0;
    // Captures i by reference; increments it by one
    auto addOne = [&] () {
        i++; 
    };

    while(i < 10) {
        addOne(); //Add 1 to i
        std::cout << i << ""\n"";
    }
}

```
 C++98 and C++03 - Not directly, but yes with static functions inside local classes C++ doesn't support that directly. That said, you can have local classes, and they can have functions (non-
```
static
```
 or 
```
static
```
), so you can get this to some extend, albeit it's a bit of a kludge: 
```
int main() // it's int, dammit!
{
  struct X { // struct's as good as class
    static void a()
    {
    }
  };

  X::a();

  return 0;
}

```
 However, I'd question the praxis. Everyone knows (well, now that you do, anyway 
```
:)
```
) C++ doesn't support local functions, so they are used to not having them. They are not used, however, to that kludge. I would spend quite a while on this code to make sure it's really only there to allow local functions. Not good."
3016956,How do I install the OpenSSL libraries on Ubuntu?,https://stackoverflow.com/questions/3016956/how-do-i-install-the-openssl-libraries-on-ubuntu,10,777.0,"['You want to install the development package, which is libssl-dev: \n```\nsudo apt-get install libssl-dev\n\n```']","You want to install the development package, which is libssl-dev: 
```
sudo apt-get install libssl-dev

```
"
3450860,check if a std::vector contains a certain object?,https://stackoverflow.com/questions/3450860/check-if-a-stdvector-contains-a-certain-object,3,711.0,"['Checking if \n```\nv\n```\n contains the element \n```\nx\n```\n: \n```\n#include <algorithm>\n\nif(std::find(v.begin(), v.end(), x) != v.end()) {\n    /* v contains x */\n} else {\n    /* v does not contain x */\n}\n\n```\n Checking if \n```\nv\n```\n contains elements (is non-empty): \n```\nif(!v.empty()){\n    /* v is non-empty */\n} else {\n    /* v is empty */\n}\n\n```']","Checking if 
```
v
```
 contains the element 
```
x
```
: 
```
#include <algorithm>

if(std::find(v.begin(), v.end(), x) != v.end()) {
    /* v contains x */
} else {
    /* v does not contain x */
}

```
 Checking if 
```
v
```
 contains elements (is non-empty): 
```
if(!v.empty()){
    /* v is non-empty */
} else {
    /* v is empty */
}

```
"
2629421,How to use Boost in Visual Studio 2010,https://stackoverflow.com/questions/2629421/how-to-use-boost-in-visual-studio-2010,13,516.0,"[""While Nate's answer is pretty good already, I'm going to expand on it more specifically for Visual Studio 2010 as requested, and include information on compiling in the various optional components which requires external libraries. If you are using headers only libraries, then all you need to do is to unarchive the boost download and set up the environment variables. The instruction below set the environment variables for Visual Studio only, and not across the system as a whole. Note you only have to do it once. Unarchive the latest version of boost (1.47.0 as of writing) into a directory of your choice (e.g. \n```\nC:\\boost_1_47_0\n```\n). Create a new empty project in Visual Studio. Open the Property Manager and expand one of the configuration for the platform of your choice. Select & right click \n```\nMicrosoft.Cpp.<Platform>.user\n```\n, and select \n```\nProperties\n```\n to open the Property Page for edit. Select \n```\nVC++ Directories\n```\n on the left. Edit the \n```\nInclude Directories\n```"", '```\nMicrosoft.Cpp.<Platform>.user\n```\n, and select \n```\nProperties\n```\n to open the Property Page for edit. Select \n```\nVC++ Directories\n```\n on the left. Edit the \n```\nInclude Directories\n```\n section to include the path to your boost source files. Repeat steps 3 - 6 for different platform of your choice if needed. If you want to use the part of boost that require building, but none of the features that requires external dependencies, then building it is fairly simple. Unarchive the latest version of boost (1.47.0 as of writing) into a directory of your choice (e.g. \n```\nC:\\boost_1_47_0\n```\n). Start the Visual Studio Command Prompt for the platform of your choice and navigate to where boost is. Run: \n```\nbootstrap.bat\n```\n to build b2.exe (previously named bjam). Run b2: Win32: \n```\nb2 --toolset=msvc-10.0 --build-type=complete stage\n```\n ; x64: \n```\nb2 --toolset=msvc-10.0 --build-type=complete architecture=x86 address-model=64 stage\n```', '```\nb2 --toolset=msvc-10.0 --build-type=complete stage\n```\n ; x64: \n```\nb2 --toolset=msvc-10.0 --build-type=complete architecture=x86 address-model=64 stage\n```\n Go for a walk / watch a movie or 2 / .... Go through steps 2 - 6 from the set of instruction above to set the environment variables. Edit the \n```\nLibrary Directories\n```\n section to include the path to your boost libraries output. (The default for the example and instructions above would be \n```\nC:\\boost_1_47_0\\stage\\lib\n```\n. Rename and move the directory first if you want to have x86 & x64 side by side (such as to \n```\n<BOOST_PATH>\\lib\\x86\n```\n & \n```\n<BOOST_PATH>\\lib\\x64\n```', '```\nC:\\boost_1_47_0\\stage\\lib\n```\n. Rename and move the directory first if you want to have x86 & x64 side by side (such as to \n```\n<BOOST_PATH>\\lib\\x86\n```\n & \n```\n<BOOST_PATH>\\lib\\x64\n```\n). Repeat steps 2 - 6 for different platform of your choice if needed. If you want the optional components, then you have more work to do. These are: Boost.IOStreams Bzip2 filters Boost.IOStreams Zlib filters Boost.MPI Boost.Python Boost.Regex ICU support Boost.IOStreams Bzip2 filters: Unarchive the latest version of bzip2 library (1.0.6 as of writing) source files into a directory of your choice (e.g. \n```\nC:\\bzip2-1.0.6\n```\n). Follow the second set of instructions above to build boost, but add in the option \n```\n-sBZIP2_SOURCE=""C:\\bzip2-1.0.6""\n```\n when running b2 in step 5. Boost.IOStreams Zlib filters Unarchive the latest version of zlib library (1.2.5 as of writing) source files into a directory of your choice (e.g. \n```\nC:\\zlib-1.2.5\n```', 'when running b2 in step 5. Boost.IOStreams Zlib filters Unarchive the latest version of zlib library (1.2.5 as of writing) source files into a directory of your choice (e.g. \n```\nC:\\zlib-1.2.5\n```\n). Follow the second set of instructions above to build boost, but add in the option \n```\n-sZLIB_SOURCE=""C:\\zlib-1.2.5""\n```\n when running b2 in step 5. Boost.MPI Install a MPI distribution such as Microsoft Compute Cluster Pack. Follow steps 1 - 3 from the second set of instructions above to build boost. Edit the file \n```\nproject-config.jam\n```\n in the directory \n```\n<BOOST_PATH>\n```\n that resulted from running bootstrap. Add in a line that read \n```\nusing mpi ;\n```', ""```\nproject-config.jam\n```\n in the directory \n```\n<BOOST_PATH>\n```\n that resulted from running bootstrap. Add in a line that read \n```\nusing mpi ;\n```\n (note the space before the ';'). Follow the rest of the steps from the second set of instructions above to build boost. If auto-detection of the MPI installation fail, then you'll need to look for and modify the appropriate build file to look for MPI in the right place. Boost.Python Install a Python distribution such as ActiveState's ActivePython. Make sure the Python installation is in your PATH. To completely built the 32-bits version of the library requires 32-bits Python, and similarly for the 64-bits version. If you have multiple versions installed for such reason, you'll need to tell b2 where to find specific version and when to use which one. One way to do that would be to edit the file \n```\nproject-config.jam\n```\n in the directory \n```\n<BOOST_PATH>\n```"", ""```\nproject-config.jam\n```\n in the directory \n```\n<BOOST_PATH>\n```\n that resulted from running bootstrap. Add in the following two lines adjusting as appropriate for your Python installation paths & versions (note the space before the ';'). \n```\nusing python : 2.6 : C:\\\\Python\\\\Python26\\\\python ;\n```\n \n```\nusing python : 2.6 : C:\\\\Python\\\\Python26-x64\\\\python :  :  : <address-model>64 ;\n```\n Do note that such explicit Python specification currently cause MPI build to fail. So you'll need to do some separate building with and without specification to build everything if you're building MPI as well. Follow the second set of instructions above to build boost. Boost.Regex ICU support Unarchive the latest version of ICU4C library (4.8 as of writing) source file into a directory of your choice (e.g. \n```\nC:\\icu4c-4_8\n```\n). Open the Visual Studio Solution in \n```\n<ICU_PATH>\\source\\allinone\n```"", '```\nC:\\icu4c-4_8\n```\n). Open the Visual Studio Solution in \n```\n<ICU_PATH>\\source\\allinone\n```\n. Build All for both debug & release configuration for the platform of your choice. There can be a problem building recent releases of ICU4C with Visual Studio 2010 when the output for both debug & release build are in the same directory (which is the default behaviour). A possible workaround is to do a Build All (of debug build say) and then do a Rebuild all in the 2nd configuration (e.g. release build). If building for x64, you\'ll need to be running x64 OS as there\'s post build steps that involves running some of the 64-bits application that it\'s building. Optionally remove the source directory when you\'re done. Follow the second set of instructions above to build boost, but add in the option \n```\n-sICU_PATH=""C:\\icu4c-4_8""\n```\n when running b2 in step 5.']","While Nate's answer is pretty good already, I'm going to expand on it more specifically for Visual Studio 2010 as requested, and include information on compiling in the various optional components which requires external libraries. If you are using headers only libraries, then all you need to do is to unarchive the boost download and set up the environment variables. The instruction below set the environment variables for Visual Studio only, and not across the system as a whole. Note you only have to do it once. Unarchive the latest version of boost (1.47.0 as of writing) into a directory of your choice (e.g. 
```
C:\boost_1_47_0
```
). Create a new empty project in Visual Studio. Open the Property Manager and expand one of the configuration for the platform of your choice. Select & right click 
```
Microsoft.Cpp.<Platform>.user
```
, and select 
```
Properties
```
 to open the Property Page for edit. Select 
```
VC++ Directories
```
 on the left. Edit the 
```
Include Directories
```
 section to include the path to your boost source files. Repeat steps 3 - 6 for different platform of your choice if needed. If you want to use the part of boost that require building, but none of the features that requires external dependencies, then building it is fairly simple. Unarchive the latest version of boost (1.47.0 as of writing) into a directory of your choice (e.g. 
```
C:\boost_1_47_0
```
). Start the Visual Studio Command Prompt for the platform of your choice and navigate to where boost is. Run: 
```
bootstrap.bat
```
 to build b2.exe (previously named bjam). Run b2: Win32: 
```
b2 --toolset=msvc-10.0 --build-type=complete stage
```
 ; x64: 
```
b2 --toolset=msvc-10.0 --build-type=complete architecture=x86 address-model=64 stage
```
 Go for a walk / watch a movie or 2 / .... Go through steps 2 - 6 from the set of instruction above to set the environment variables. Edit the 
```
Library Directories
```
 section to include the path to your boost libraries output. (The default for the example and instructions above would be 
```
C:\boost_1_47_0\stage\lib
```
. Rename and move the directory first if you want to have x86 & x64 side by side (such as to 
```
<BOOST_PATH>\lib\x86
```
 & 
```
<BOOST_PATH>\lib\x64
```
). Repeat steps 2 - 6 for different platform of your choice if needed. If you want the optional components, then you have more work to do. These are: Boost.IOStreams Bzip2 filters Boost.IOStreams Zlib filters Boost.MPI Boost.Python Boost.Regex ICU support Boost.IOStreams Bzip2 filters: Unarchive the latest version of bzip2 library (1.0.6 as of writing) source files into a directory of your choice (e.g. 
```
C:\bzip2-1.0.6
```
). Follow the second set of instructions above to build boost, but add in the option 
```
-sBZIP2_SOURCE=""C:\bzip2-1.0.6""
```
 when running b2 in step 5. Boost.IOStreams Zlib filters Unarchive the latest version of zlib library (1.2.5 as of writing) source files into a directory of your choice (e.g. 
```
C:\zlib-1.2.5
```
). Follow the second set of instructions above to build boost, but add in the option 
```
-sZLIB_SOURCE=""C:\zlib-1.2.5""
```
 when running b2 in step 5. Boost.MPI Install a MPI distribution such as Microsoft Compute Cluster Pack. Follow steps 1 - 3 from the second set of instructions above to build boost. Edit the file 
```
project-config.jam
```
 in the directory 
```
<BOOST_PATH>
```
 that resulted from running bootstrap. Add in a line that read 
```
using mpi ;
```
 (note the space before the ';'). Follow the rest of the steps from the second set of instructions above to build boost. If auto-detection of the MPI installation fail, then you'll need to look for and modify the appropriate build file to look for MPI in the right place. Boost.Python Install a Python distribution such as ActiveState's ActivePython. Make sure the Python installation is in your PATH. To completely built the 32-bits version of the library requires 32-bits Python, and similarly for the 64-bits version. If you have multiple versions installed for such reason, you'll need to tell b2 where to find specific version and when to use which one. One way to do that would be to edit the file 
```
project-config.jam
```
 in the directory 
```
<BOOST_PATH>
```
 that resulted from running bootstrap. Add in the following two lines adjusting as appropriate for your Python installation paths & versions (note the space before the ';'). 
```
using python : 2.6 : C:\\Python\\Python26\\python ;
```
 
```
using python : 2.6 : C:\\Python\\Python26-x64\\python :  :  : <address-model>64 ;
```
 Do note that such explicit Python specification currently cause MPI build to fail. So you'll need to do some separate building with and without specification to build everything if you're building MPI as well. Follow the second set of instructions above to build boost. Boost.Regex ICU support Unarchive the latest version of ICU4C library (4.8 as of writing) source file into a directory of your choice (e.g. 
```
C:\icu4c-4_8
```
). Open the Visual Studio Solution in 
```
<ICU_PATH>\source\allinone
```
. Build All for both debug & release configuration for the platform of your choice. There can be a problem building recent releases of ICU4C with Visual Studio 2010 when the output for both debug & release build are in the same directory (which is the default behaviour). A possible workaround is to do a Build All (of debug build say) and then do a Rebuild all in the 2nd configuration (e.g. release build). If building for x64, you'll need to be running x64 OS as there's post build steps that involves running some of the 64-bits application that it's building. Optionally remove the source directory when you're done. Follow the second set of instructions above to build boost, but add in the option 
```
-sICU_PATH=""C:\icu4c-4_8""
```
 when running b2 in step 5."
2762568,C/C++ include header file order,https://stackoverflow.com/questions/2762568/c-c-include-header-file-order,11,409.0,"['I don\'t think there\'s a recommended order, as long as it compiles! What\'s annoying is when some headers require other headers to be included first... That\'s a problem with the headers themselves, not with the order of includes. My personal preference is to go from local to global, each subsection in alphabetical order, i.e.: h file corresponding to this cpp file (if applicable) headers from the same component, headers from other components, system headers. My rationale for 1. is that it should prove that each header (for which there is a cpp) can be \n```\n#include\n```\nd without prerequisites (technically speaking: header is ""self-contained""). And the rest just seems to flow logically from there.']","I don't think there's a recommended order, as long as it compiles! What's annoying is when some headers require other headers to be included first... That's a problem with the headers themselves, not with the order of includes. My personal preference is to go from local to global, each subsection in alphabetical order, i.e.: h file corresponding to this cpp file (if applicable) headers from the same component, headers from other components, system headers. My rationale for 1. is that it should prove that each header (for which there is a cpp) can be 
```
#include
```
d without prerequisites (technically speaking: header is ""self-contained""). And the rest just seems to flow logically from there."
1238613,What is the difference between the dot (.) operator and -> in C++?,https://stackoverflow.com/questions/1238613/what-is-the-difference-between-the-dot-operator-and-in-c,14,,[],
359237,Why does C++ not have reflection?,https://stackoverflow.com/questions/359237/why-does-c-not-have-reflection,16,669.0,"[""There are several problems with reflection in C++. It's a lot of work to add, and the C++ committee is fairly conservative, and don't spend time on radical new features unless they're sure it'll pay off. (A suggestion for adding a module system similar to .NET assemblies has been made, and while I think there's general consensus that it'd be nice to have, it's not their top priority at the moment, and has been pushed back until well after C++0x. The motivation for this feature is to get rid of the \n```\n#include\n```"", ""system, but it would also enable at least some metadata). You don't pay for what you don't use. That's one of the must basic design philosophies underlying C++. Why should my code carry around metadata if I may never need it? Moreover, the addition of metadata may inhibit the compiler from optimizing. Why should I pay that cost in my code if I may never need that metadata? Which leads us to another big point: C++ makes very few guarantees about the compiled code. The compiler is allowed to do pretty much anything it likes, as long as the resulting functionality is what is expected. For example, your classes aren't required to actually be there. The compiler can optimize them away, inline everything they do, and it frequently does just that, because even simple template code tends to create quite a few template instantiations. The C++ standard library relies on this aggressive optimization. Functors are only performant if the overhead of instantiating and destructing the object can be"", 'quite a few template instantiations. The C++ standard library relies on this aggressive optimization. Functors are only performant if the overhead of instantiating and destructing the object can be optimized away.', '```\noperator[]\n```', ""on a vector is only comparable to raw array indexing in performance because the entire operator can be inlined and thus removed entirely from the compiled code. C# and Java make a lot of guarantees about the output of the compiler. If I define a class in C#, then that class will exist in the resulting assembly. Even if I never use it. Even if all calls to its member functions could be inlined. The class has to be there, so that reflection can find it. Part of this is alleviated by C# compiling to bytecode, which means that the JIT compiler can remove class definitions and inline functions if it likes, even if the initial C# compiler can't. In C++, you only have one compiler, and it has to output efficient code. If you were allowed to inspect the metadata of a C++ executable, you'd expect to see every class it defined, which means that the compiler would have to preserve all the defined classes, even if they're not necessary. And then there are templates. Templates in C++ are nothing"", ""to see every class it defined, which means that the compiler would have to preserve all the defined classes, even if they're not necessary. And then there are templates. Templates in C++ are nothing like generics in other languages. Every template instantiation creates a new type."", ""```\nstd::vector<int>\n```\n is a completely separate class from \n```\nstd::vector<float>\n```\n. That adds up to a lot of different types in a entire program. What should our reflection see? The template \n```\nstd::vector\n```\n? But how can it, since that's a source-code construct, which has no meaning at runtime? It'd have to see the separate classes \n```\nstd::vector<int>\n```\n and \n```\nstd::vector<float>\n```\n. And \n```\nstd::vector<int>::iterator\n```\n and \n```\nstd::vector<float>::iterator\n```\n, same for \n```\nconst_iterator\n```"", ""```\nstd::vector<int>\n```\n and \n```\nstd::vector<float>\n```\n. And \n```\nstd::vector<int>::iterator\n```\n and \n```\nstd::vector<float>::iterator\n```\n, same for \n```\nconst_iterator\n```\n and so on. And once you step into template metaprogramming, you quickly end up instantiating hundreds of templates, all of which get inlined and removed again by the compiler. They have no meaning, except as part of a compile-time metaprogram. Should all these hundreds of classes be visible to reflection? They'd have to, because otherwise our reflection would be useless, if it doesn't even guarantee that the classes I defined will actually be there. And a side problem is that the template class doesn't exist until it is instantiated. Imagine a program which uses \n```\nstd::vector<int>\n```\n. Should our reflection system be able to see \n```\nstd::vector<int>::iterator\n```\n? On one hand, you'd certainly expect so. It's an important class, and it's defined in terms of \n```\nstd::vector<int>\n```"", ""```\nstd::vector<int>::iterator\n```\n? On one hand, you'd certainly expect so. It's an important class, and it's defined in terms of \n```\nstd::vector<int>\n```\n, which does exist in the metadata. On the other hand, if the program never actually uses this iterator class template, its type will never have been instantiated, and so the compiler won't have generated the class in the first place. And it's too late to create it at runtime, since it requires access to the source code. And finally, reflection isn't quite as vital in C++ as it is in C#. The reason is again, template metaprogramming. It can't solve everything, but for many cases where you'd otherwise resort to reflection, it's possible to write a metaprogram which does the same thing at compile-time. \n```\nboost::type_traits\n```\n is a simple example. You want to know about type \n```\nT\n```\n? Check its \n```\ntype_traits\n```"", "". In C#, you'd have to fish around after its type using reflection. Reflection would still be useful for some things (the main use I can see, which metaprogramming can't easily replace, is for autogenerated serialization code), but it would carry some significant costs for C++, and it's just not necessary as often as it is in other languages. Edit: In response to comments: cdleary: Yes, debug symbols do something similar, in that they store metadata about the types used in the executable. But they also suffer from the problems I described. If you've ever tried debugging a release build, you'll know what I mean. There are large logical gaps where you created a class in the source code, which has gotten inlined away in the final code. If you were to use reflection for anything useful, you'd need it to be more reliable and consistent. As it is, types would be vanishing and disappearing almost every time you compile. You change a tiny little detail, and the compiler decides to change"", ""need it to be more reliable and consistent. As it is, types would be vanishing and disappearing almost every time you compile. You change a tiny little detail, and the compiler decides to change which types get inlined and which ones don't, as a response. How do you extract anything useful from that, when you're not even guaranteed that the most relevant types will be represented in your metadata? The type you were looking for may have been there in the last build, but now it's gone. And tomorrow, someone will check in a small innocent change to a small innocent function, which makes the type just big enough that it won't get completely inlined, so it'll be back again. That's still useful for debug symbols, but not much more than that. I'd hate trying to generate serialization code for a class under those terms. Evan Teran: Of course these issues could be resolved. But that falls back to my point #1. It'd take a lot of work, and the C++ committee has plenty of things they feel is more"", ""under those terms. Evan Teran: Of course these issues could be resolved. But that falls back to my point #1. It'd take a lot of work, and the C++ committee has plenty of things they feel is more important. Is the benefit of getting some limited reflection (and it would be limited) in C++ really big enough to justify focusing on that at the expense of other features? Is there really a huge benefit in adding features the core language which can already (mostly) be done through libraries and preprocessors like QT's? Perhaps, but the need is a lot less urgent than if such libraries didn't exist. For your specific suggestions though, I believe disallowing it on templates would make it completely useless. You'd be unable to use reflection on the standard library, for example. What kind of reflection wouldn't let you see a"", ""```\nstd::vector\n```\n? Templates are a huge part of C++. A feature that doesn't work on templates is basically useless. But you're right, some form of reflection could be implemented. But it'd be a major change in the language. As it is now, types are exclusively a compile-time construct. They exist for the benefit of the compiler, and nothing else. Once the code has been compiled, there are no classes. If you stretch yourself, you could argue that functions still exist, but really, all there is is a bunch of jump assembler instructions, and a lot of stack push/pop's. There's not much to go on, when adding such metadata. But like I said, there is a proposal for changes to the compilation model, adding self-contained modules, storing metadata for select types, allowing other modules to reference them without having to mess with \n```\n#include\n```"", ""```\n#include\n```\ns. That's a good start, and to be honest, I'm surprised the standard committee didn't just throw the proposal out for being too big a change. So perhaps in 5-10 years? :)""]","There are several problems with reflection in C++. It's a lot of work to add, and the C++ committee is fairly conservative, and don't spend time on radical new features unless they're sure it'll pay off. (A suggestion for adding a module system similar to .NET assemblies has been made, and while I think there's general consensus that it'd be nice to have, it's not their top priority at the moment, and has been pushed back until well after C++0x. The motivation for this feature is to get rid of the 
```
#include
```
 system, but it would also enable at least some metadata). You don't pay for what you don't use. That's one of the must basic design philosophies underlying C++. Why should my code carry around metadata if I may never need it? Moreover, the addition of metadata may inhibit the compiler from optimizing. Why should I pay that cost in my code if I may never need that metadata? Which leads us to another big point: C++ makes very few guarantees about the compiled code. The compiler is allowed to do pretty much anything it likes, as long as the resulting functionality is what is expected. For example, your classes aren't required to actually be there. The compiler can optimize them away, inline everything they do, and it frequently does just that, because even simple template code tends to create quite a few template instantiations. The C++ standard library relies on this aggressive optimization. Functors are only performant if the overhead of instantiating and destructing the object can be optimized away. 
```
operator[]
```
 on a vector is only comparable to raw array indexing in performance because the entire operator can be inlined and thus removed entirely from the compiled code. C# and Java make a lot of guarantees about the output of the compiler. If I define a class in C#, then that class will exist in the resulting assembly. Even if I never use it. Even if all calls to its member functions could be inlined. The class has to be there, so that reflection can find it. Part of this is alleviated by C# compiling to bytecode, which means that the JIT compiler can remove class definitions and inline functions if it likes, even if the initial C# compiler can't. In C++, you only have one compiler, and it has to output efficient code. If you were allowed to inspect the metadata of a C++ executable, you'd expect to see every class it defined, which means that the compiler would have to preserve all the defined classes, even if they're not necessary. And then there are templates. Templates in C++ are nothing like generics in other languages. Every template instantiation creates a new type. 
```
std::vector<int>
```
 is a completely separate class from 
```
std::vector<float>
```
. That adds up to a lot of different types in a entire program. What should our reflection see? The template 
```
std::vector
```
? But how can it, since that's a source-code construct, which has no meaning at runtime? It'd have to see the separate classes 
```
std::vector<int>
```
 and 
```
std::vector<float>
```
. And 
```
std::vector<int>::iterator
```
 and 
```
std::vector<float>::iterator
```
, same for 
```
const_iterator
```
 and so on. And once you step into template metaprogramming, you quickly end up instantiating hundreds of templates, all of which get inlined and removed again by the compiler. They have no meaning, except as part of a compile-time metaprogram. Should all these hundreds of classes be visible to reflection? They'd have to, because otherwise our reflection would be useless, if it doesn't even guarantee that the classes I defined will actually be there. And a side problem is that the template class doesn't exist until it is instantiated. Imagine a program which uses 
```
std::vector<int>
```
. Should our reflection system be able to see 
```
std::vector<int>::iterator
```
? On one hand, you'd certainly expect so. It's an important class, and it's defined in terms of 
```
std::vector<int>
```
, which does exist in the metadata. On the other hand, if the program never actually uses this iterator class template, its type will never have been instantiated, and so the compiler won't have generated the class in the first place. And it's too late to create it at runtime, since it requires access to the source code. And finally, reflection isn't quite as vital in C++ as it is in C#. The reason is again, template metaprogramming. It can't solve everything, but for many cases where you'd otherwise resort to reflection, it's possible to write a metaprogram which does the same thing at compile-time. 
```
boost::type_traits
```
 is a simple example. You want to know about type 
```
T
```
? Check its 
```
type_traits
```
. In C#, you'd have to fish around after its type using reflection. Reflection would still be useful for some things (the main use I can see, which metaprogramming can't easily replace, is for autogenerated serialization code), but it would carry some significant costs for C++, and it's just not necessary as often as it is in other languages. Edit: In response to comments: cdleary: Yes, debug symbols do something similar, in that they store metadata about the types used in the executable. But they also suffer from the problems I described. If you've ever tried debugging a release build, you'll know what I mean. There are large logical gaps where you created a class in the source code, which has gotten inlined away in the final code. If you were to use reflection for anything useful, you'd need it to be more reliable and consistent. As it is, types would be vanishing and disappearing almost every time you compile. You change a tiny little detail, and the compiler decides to change which types get inlined and which ones don't, as a response. How do you extract anything useful from that, when you're not even guaranteed that the most relevant types will be represented in your metadata? The type you were looking for may have been there in the last build, but now it's gone. And tomorrow, someone will check in a small innocent change to a small innocent function, which makes the type just big enough that it won't get completely inlined, so it'll be back again. That's still useful for debug symbols, but not much more than that. I'd hate trying to generate serialization code for a class under those terms. Evan Teran: Of course these issues could be resolved. But that falls back to my point #1. It'd take a lot of work, and the C++ committee has plenty of things they feel is more important. Is the benefit of getting some limited reflection (and it would be limited) in C++ really big enough to justify focusing on that at the expense of other features? Is there really a huge benefit in adding features the core language which can already (mostly) be done through libraries and preprocessors like QT's? Perhaps, but the need is a lot less urgent than if such libraries didn't exist. For your specific suggestions though, I believe disallowing it on templates would make it completely useless. You'd be unable to use reflection on the standard library, for example. What kind of reflection wouldn't let you see a 
```
std::vector
```
? Templates are a huge part of C++. A feature that doesn't work on templates is basically useless. But you're right, some form of reflection could be implemented. But it'd be a major change in the language. As it is now, types are exclusively a compile-time construct. They exist for the benefit of the compiler, and nothing else. Once the code has been compiled, there are no classes. If you stretch yourself, you could argue that functions still exist, but really, all there is is a bunch of jump assembler instructions, and a lot of stack push/pop's. There's not much to go on, when adding such metadata. But like I said, there is a proposal for changes to the compilation model, adding self-contained modules, storing metadata for select types, allowing other modules to reference them without having to mess with 
```
#include
```
s. That's a good start, and to be honest, I'm surprised the standard committee didn't just throw the proposal out for being too big a change. So perhaps in 5-10 years? :)"
357404,Why are unnamed namespaces used and what are their benefits?,https://stackoverflow.com/questions/357404/why-are-unnamed-namespaces-used-and-what-are-their-benefits,7,296.0,"[""Unnamed namespaces are a utility to make an identifier translation unit local. They behave as if you would choose a unique name per translation unit for a namespace: \n```\nnamespace unique { /* empty */ }\nusing namespace unique;\nnamespace unique { /* namespace body. stuff in here */ }\n\n```\n The extra step using the empty body is important, so you can already refer within the namespace body to identifiers like \n```\n::name\n```\n that are defined in that namespace, since the using directive already took place. This means you can have free functions called (for example) \n```\nhelp\n```\n that can exist in multiple translation units, and they won't clash at link time. The effect is almost identical to using the \n```\nstatic\n```\n keyword used in C which you can put in in the declaration of identifiers. Unnamed namespaces are a superior alternative, being able to even make a type translation unit local. \n```\nnamespace { int a1; }\nstatic int a2;"", ""```\n Both \n```\na\n```\n's are translation unit local and won't clash at link time. But the difference is that the \n```\na1\n```\n in the anonymous namespace gets a unique name. Read the excellent article at comeau-computing Why is an unnamed namespace used instead of static? (Archive.org mirror).""]","Unnamed namespaces are a utility to make an identifier translation unit local. They behave as if you would choose a unique name per translation unit for a namespace: 
```
namespace unique { /* empty */ }
using namespace unique;
namespace unique { /* namespace body. stuff in here */ }

```
 The extra step using the empty body is important, so you can already refer within the namespace body to identifiers like 
```
::name
```
 that are defined in that namespace, since the using directive already took place. This means you can have free functions called (for example) 
```
help
```
 that can exist in multiple translation units, and they won't clash at link time. The effect is almost identical to using the 
```
static
```
 keyword used in C which you can put in in the declaration of identifiers. Unnamed namespaces are a superior alternative, being able to even make a type translation unit local. 
```
namespace { int a1; }
static int a2;

```
 Both 
```
a
```
's are translation unit local and won't clash at link time. But the difference is that the 
```
a1
```
 in the anonymous namespace gets a unique name. Read the excellent article at comeau-computing Why is an unnamed namespace used instead of static? (Archive.org mirror)."
874134,Find out if string ends with another string in C++,https://stackoverflow.com/questions/874134/find-out-if-string-ends-with-another-string-in-c,22,,[],
11635,Case-insensitive string comparison in C++,https://stackoverflow.com/questions/11635/case-insensitive-string-comparison-in-c,30,332.0,"['Boost includes a handy algorithm for this: \n```\n#include <boost/algorithm/string.hpp>\n// Or, for fewer header dependencies:\n//#include <boost/algorithm/string/predicate.hpp>\n\nstd::string str1 = ""hello, world!"";\nstd::string str2 = ""HELLO, WORLD!"";\n\nif (boost::iequals(str1, str2))\n{\n    // Strings are identical\n}\n\n```']","Boost includes a handy algorithm for this: 
```
#include <boost/algorithm/string.hpp>
// Or, for fewer header dependencies:
//#include <boost/algorithm/string/predicate.hpp>

std::string str1 = ""hello, world!"";
std::string str2 = ""HELLO, WORLD!"";

if (boost::iequals(str1, str2))
{
    // Strings are identical
}

```
"
224966,What is the difference between private and protected members of C++ classes?,https://stackoverflow.com/questions/224966/what-is-the-difference-between-private-and-protected-members-of-c-classes,19,477.0,"[""Private members are only accessible within the class defining them. Protected members are accessible in the class that defines them and in classes that inherit from that class. Both are also accessible by friends of their class, and in the case of protected members, by friends of their derived classes. Use whatever makes sense in the context of your problem. You should try to make members private whenever you can to reduce coupling and protect the implementation of the base class, but if that's not possible, then use protected members. Check C++ FAQ for a better understanding of the issue. This question about protected variables might also help.""]","Private members are only accessible within the class defining them. Protected members are accessible in the class that defines them and in classes that inherit from that class. Both are also accessible by friends of their class, and in the case of protected members, by friends of their derived classes. Use whatever makes sense in the context of your problem. You should try to make members private whenever you can to reduce coupling and protect the implementation of the base class, but if that's not possible, then use protected members. Check C++ FAQ for a better understanding of the issue. This question about protected variables might also help."
1434937,Namespace + functions versus static methods on a class,https://stackoverflow.com/questions/1434937/namespace-functions-versus-static-methods-on-a-class,10,,[],
3221812,How to sum up elements of a std::vector?,https://stackoverflow.com/questions/3221812/how-to-sum-up-elements-of-a-stdvector,13,614.0,"[""Actually there are quite a few methods. \n```\nint sum_of_elems = 0;\n\n```\n C++03 Classic for loop: \n```\n for(std::vector<int>::iterator it = vector.begin(); it != vector.end(); ++it)\n     sum_of_elems += *it;\n\n```\n Using a standard algorithm: \n```\n #include <numeric>\n\n sum_of_elems = std::accumulate(vector.begin(), vector.end(), 0);\n\n```\n Important Note: The last argument's type is used not just for the initial value, but for the type of the result as well. If you put an int there, it will accumulate ints even if the vector has float. If you are summing floating-point numbers, change \n```\n0\n```\n to \n```\n0.0\n```\n or \n```\n0.0f\n```\n (thanks to nneonneo). See also the C++11 solution below. C++11 and higher b. Automatically keeping track of the vector type even in case of future changes: \n```\n #include <numeric>\n\n sum_of_elems = std::accumulate(vector.begin(), vector.end(),\n                                decltype(vector)::value_type(0));"", ""sum_of_elems = std::accumulate(vector.begin(), vector.end(),\n                                decltype(vector)::value_type(0));\n\n```\n Using \n```\nstd::for_each\n```\n: \n```\n std::for_each(vector.begin(), vector.end(), [&] (int n) {\n     sum_of_elems += n;\n });\n\n```\n Using a range-based for loop (thanks to Roger Pate): \n```\n for (auto& n : vector)\n     sum_of_elems += n;\n\n```\n C++17 and above Using \n```\nstd::reduce\n```\n which also takes care of the result type, e.g if you have \n```\nstd::vector<int>\n```\n, you get \n```\nint\n```\n as result. If you have \n```\nstd::vector<float>\n```\n, you get \n```\nfloat\n```\n. Or if you have \n```\nstd::vector<std::string>\n```\n, you get \n```\nstd::string\n```\n (all strings concatenated). Interesting, isn't it? \n```\n#include <numeric>       \n\nauto result = std::reduce(v.begin(), v.end());\n\n```\n There are other overloads of this function which you can run even parallelly, in case if you have a large collection and you want to get the result quickly.""]","Actually there are quite a few methods. 
```
int sum_of_elems = 0;

```
 C++03 Classic for loop: 
```
 for(std::vector<int>::iterator it = vector.begin(); it != vector.end(); ++it)
     sum_of_elems += *it;

```
 Using a standard algorithm: 
```
 #include <numeric>

 sum_of_elems = std::accumulate(vector.begin(), vector.end(), 0);

```
 Important Note: The last argument's type is used not just for the initial value, but for the type of the result as well. If you put an int there, it will accumulate ints even if the vector has float. If you are summing floating-point numbers, change 
```
0
```
 to 
```
0.0
```
 or 
```
0.0f
```
 (thanks to nneonneo). See also the C++11 solution below. C++11 and higher b. Automatically keeping track of the vector type even in case of future changes: 
```
 #include <numeric>

 sum_of_elems = std::accumulate(vector.begin(), vector.end(),
                                decltype(vector)::value_type(0));

```
 Using 
```
std::for_each
```
: 
```
 std::for_each(vector.begin(), vector.end(), [&] (int n) {
     sum_of_elems += n;
 });

```
 Using a range-based for loop (thanks to Roger Pate): 
```
 for (auto& n : vector)
     sum_of_elems += n;

```
 C++17 and above Using 
```
std::reduce
```
 which also takes care of the result type, e.g if you have 
```
std::vector<int>
```
, you get 
```
int
```
 as result. If you have 
```
std::vector<float>
```
, you get 
```
float
```
. Or if you have 
```
std::vector<std::string>
```
, you get 
```
std::string
```
 (all strings concatenated). Interesting, isn't it? 
```
#include <numeric>       

auto result = std::reduce(v.begin(), v.end());

```
 There are other overloads of this function which you can run even parallelly, in case if you have a large collection and you want to get the result quickly."
1011339,How do you make a HTTP request with C++?,https://stackoverflow.com/questions/1011339/how-do-you-make-a-http-request-with-c,25,338.0,"['I had the same problem. libcurl is really complete. There is a C++ wrapper curlpp that might interest you as you ask for a C++ library. neon is another interesting C library that also support WebDAV. curlpp seems natural if you use C++. There are many examples provided in the source distribution. To get the content of an URL you do something like that (extracted from examples) : \n```\n// Edit : rewritten for cURLpp 0.7.3\n// Note : namespace changed, was cURLpp in 0.7.2 ...\n\n#include <curlpp/cURLpp.hpp>\n#include <curlpp/Options.hpp>\n\n// RAII cleanup\n\ncurlpp::Cleanup myCleanup;\n\n// Send request and get a result.\n// Here I use a shortcut to get it in a string stream ...\n\nstd::ostringstream os;\nos << curlpp::options::Url(std::string(""http://example.com""));\n\nstring asAskedInQuestion = os.str();\n\n```\n See the \n```\nexamples\n```\n directory in curlpp source distribution, there is a lot of more complex cases, as well as a simple complete minimal one using curlpp. my 2 cents ...']","I had the same problem. libcurl is really complete. There is a C++ wrapper curlpp that might interest you as you ask for a C++ library. neon is another interesting C library that also support WebDAV. curlpp seems natural if you use C++. There are many examples provided in the source distribution. To get the content of an URL you do something like that (extracted from examples) : 
```
// Edit : rewritten for cURLpp 0.7.3
// Note : namespace changed, was cURLpp in 0.7.2 ...

#include <curlpp/cURLpp.hpp>
#include <curlpp/Options.hpp>

// RAII cleanup

curlpp::Cleanup myCleanup;

// Send request and get a result.
// Here I use a shortcut to get it in a string stream ...

std::ostringstream os;
os << curlpp::options::Url(std::string(""http://example.com""));

string asAskedInQuestion = os.str();

```
 See the 
```
examples
```
 directory in curlpp source distribution, there is a lot of more complex cases, as well as a simple complete minimal one using curlpp. my 2 cents ..."
1195675,convert a char* to std::string,https://stackoverflow.com/questions/1195675/convert-a-char-to-stdstring,13,523.0,"['```\nstd::string\n```\n has a constructor for this: \n```\nconst char *s = ""Hello, World!"";\nstd::string str(s);\n\n```\n Note that this construct deep copies the character list at \n```\ns\n```\n and \n```\ns\n```\n should not be \n```\nnullptr\n```\n, or else behavior is undefined.']","
```
std::string
```
 has a constructor for this: 
```
const char *s = ""Hello, World!"";
std::string str(s);

```
 Note that this construct deep copies the character list at 
```
s
```
 and 
```
s
```
 should not be 
```
nullptr
```
, or else behavior is undefined."
614794,Detecting superfluous #includes in C/C++,https://stackoverflow.com/questions/614794/detecting-superfluous-includes-in-c-c,19,43.0,"[""It's not automatic, but Doxygen will produce dependency diagrams for \n```\n#included\n```\n files. You will have to go through them visually, but they can be very useful for getting a picture of what is using what.""]","It's not automatic, but Doxygen will produce dependency diagrams for 
```
#included
```
 files. You will have to go through them visually, but they can be very useful for getting a picture of what is using what."
217911,Why don't C++ compilers define operator== and operator!=?,https://stackoverflow.com/questions/217911/why-dont-c-compilers-define-operator-and-operator,13,82.0,"[""The compiler wouldn't know whether you wanted a pointer comparison or a deep (internal) comparison. It's safer to just not implement it and let the programmer do that themselves. Then they can make all the assumptions they like.""]",The compiler wouldn't know whether you wanted a pointer comparison or a deep (internal) comparison. It's safer to just not implement it and let the programmer do that themselves. Then they can make all the assumptions they like.
7043372,"int a[] = {1,2,}; Why is a trailing comma in an initializer-list allowed?",https://stackoverflow.com/questions/7043372/int-a-1-2-why-is-a-trailing-comma-in-an-initializer-list-allowed,21,457.0,"['It makes it easier to generate source code, and also to write code which can be easily extended at a later date. Consider what\'s required to add an extra entry to: \n```\nint a[] = {\n   1,\n   2,\n   3\n};\n\n```\n ... you have to add the comma to the existing line and add a new line. Compare that with the case where the three already has a comma after it, where you just have to add a line. Likewise if you want to remove a line you can do so without worrying about whether it\'s the last line or not, and you can reorder lines without fiddling about with commas. Basically it means there\'s a uniformity in how you treat the lines. Now think about generating code. Something like (pseudo-code): \n```\noutput(""int a[] = {"");\nfor (int i = 0; i < items.length; i++) {\n    output(""%s, "", items[i]);\n}\noutput(""};"");\n\n```\n No need to worry about whether the current item you\'re writing out is the first or the last. Much simpler.']","It makes it easier to generate source code, and also to write code which can be easily extended at a later date. Consider what's required to add an extra entry to: 
```
int a[] = {
   1,
   2,
   3
};

```
 ... you have to add the comma to the existing line and add a new line. Compare that with the case where the three already has a comma after it, where you just have to add a line. Likewise if you want to remove a line you can do so without worrying about whether it's the last line or not, and you can reorder lines without fiddling about with commas. Basically it means there's a uniformity in how you treat the lines. Now think about generating code. Something like (pseudo-code): 
```
output(""int a[] = {"");
for (int i = 0; i < items.length; i++) {
    output(""%s, "", items[i]);
}
output(""};"");

```
 No need to worry about whether the current item you're writing out is the first or the last. Much simpler."
8054273,How to implement an STL-style iterator and avoid common pitfalls?,https://stackoverflow.com/questions/8054273/how-to-implement-an-stl-style-iterator-and-avoid-common-pitfalls,9,270.0,"[""https://cplusplus.com/reference/iterator/ has a handy chart that details the specs of § 24.2.2 of the C++11 standard. Basically, the iterators have tags that describe the valid operations, and the tags have a hierarchy. Below is purely symbolic, these classes don't actually exist as such. \n```\niterator {\n    iterator(const iterator&);\n    ~iterator();\n    iterator& operator=(const iterator&);\n    iterator& operator++(); //prefix increment\n    reference operator*() const;\n    friend void swap(iterator& lhs, iterator& rhs); //C++11 I think\n};\n\ninput_iterator : public virtual iterator {\n    iterator operator++(int); //postfix increment\n    value_type operator*() const;\n    pointer operator->() const;\n    friend bool operator==(const iterator&, const iterator&);\n    friend bool operator!=(const iterator&, const iterator&); \n};\n//once an input iterator has been dereferenced, it is \n//undefined to dereference one before that."", 'output_iterator : public virtual iterator {\n    reference operator*() const;\n    iterator operator++(int); //postfix increment\n};\n//dereferences may only be on the left side of an assignment\n//once an output iterator has been dereferenced, it is \n//undefined to dereference one before that.\n\nforward_iterator : input_iterator, output_iterator {\n    forward_iterator();\n};\n//multiple passes allowed\n\nbidirectional_iterator : forward_iterator {\n    iterator& operator--(); //prefix decrement\n    iterator operator--(int); //postfix decrement\n};\n\nrandom_access_iterator : bidirectional_iterator {\n    friend bool operator<(const iterator&, const iterator&);\n    friend bool operator>(const iterator&, const iterator&);\n    friend bool operator<=(const iterator&, const iterator&);\n    friend bool operator>=(const iterator&, const iterator&);', 'iterator& operator+=(size_type);\n    friend iterator operator+(const iterator&, size_type);\n    friend iterator operator+(size_type, const iterator&);\n    iterator& operator-=(size_type);  \n    friend iterator operator-(const iterator&, size_type);\n    friend difference_type operator-(iterator, iterator);\n\n    reference operator[](size_type) const;\n};\n\ncontiguous_iterator : random_access_iterator { //C++17\n}; //elements are stored contiguously in memory.', 'reference operator[](size_type) const;\n};\n\ncontiguous_iterator : random_access_iterator { //C++17\n}; //elements are stored contiguously in memory.\n\n```\n You can either specialize \n```\nstd::iterator_traits<youriterator>\n```\n, or put the same typedefs in the iterator itself, or inherit from \n```\nstd::iterator\n```\n (which has these typedefs). I prefer the second option, to avoid changing things in the \n```\nstd\n```\n namespace, and for readability, but most people inherit from \n```\nstd::iterator\n```\n. \n```\nstruct std::iterator_traits<youriterator> {        \n    typedef ???? difference_type; //almost always ptrdiff_t\n    typedef ???? value_type; //almost always T\n    typedef ???? reference; //almost always T& or const T&\n    typedef ???? pointer; //almost always T* or const T*\n    typedef ???? iterator_category;  //usually std::forward_iterator_tag or similar\n};', '```\n Note the iterator_category should be one of \n```\nstd::input_iterator_tag\n```\n, \n```\nstd::output_iterator_tag\n```\n, \n```\nstd::forward_iterator_tag\n```\n, \n```\nstd::bidirectional_iterator_tag\n```\n, or \n```\nstd::random_access_iterator_tag\n```\n, depending on which requirements your iterator satisfies. Depending on your iterator, you may choose to specialize \n```\nstd::next\n```\n, \n```\nstd::prev\n```\n, \n```\nstd::advance\n```\n, and \n```\nstd::distance\n```\n as well, but this is rarely needed. In extremely rare cases you may wish to specialize \n```\nstd::begin\n```\n and \n```\nstd::end\n```\n. Your container should probably also have a \n```\nconst_iterator\n```\n, which is a (possibly mutable) iterator to constant data that is similar to your \n```\niterator\n```\n except it should be implicitly constructable from a \n```\niterator\n```\n and users should be unable to modify the data. It is common for its internal pointer to be a pointer to non-constant data, and have \n```\niterator\n```\n inherit from \n```', '```\niterator\n```\n and users should be unable to modify the data. It is common for its internal pointer to be a pointer to non-constant data, and have \n```\niterator\n```\n inherit from \n```\nconst_iterator\n```\n so as to minimize code duplication. My post at Writing your own STL Container has a more complete container/iterator prototype.']","https://cplusplus.com/reference/iterator/ has a handy chart that details the specs of § 24.2.2 of the C++11 standard. Basically, the iterators have tags that describe the valid operations, and the tags have a hierarchy. Below is purely symbolic, these classes don't actually exist as such. 
```
iterator {
    iterator(const iterator&);
    ~iterator();
    iterator& operator=(const iterator&);
    iterator& operator++(); //prefix increment
    reference operator*() const;
    friend void swap(iterator& lhs, iterator& rhs); //C++11 I think
};

input_iterator : public virtual iterator {
    iterator operator++(int); //postfix increment
    value_type operator*() const;
    pointer operator->() const;
    friend bool operator==(const iterator&, const iterator&);
    friend bool operator!=(const iterator&, const iterator&); 
};
//once an input iterator has been dereferenced, it is 
//undefined to dereference one before that.

output_iterator : public virtual iterator {
    reference operator*() const;
    iterator operator++(int); //postfix increment
};
//dereferences may only be on the left side of an assignment
//once an output iterator has been dereferenced, it is 
//undefined to dereference one before that.

forward_iterator : input_iterator, output_iterator {
    forward_iterator();
};
//multiple passes allowed

bidirectional_iterator : forward_iterator {
    iterator& operator--(); //prefix decrement
    iterator operator--(int); //postfix decrement
};

random_access_iterator : bidirectional_iterator {
    friend bool operator<(const iterator&, const iterator&);
    friend bool operator>(const iterator&, const iterator&);
    friend bool operator<=(const iterator&, const iterator&);
    friend bool operator>=(const iterator&, const iterator&);

    iterator& operator+=(size_type);
    friend iterator operator+(const iterator&, size_type);
    friend iterator operator+(size_type, const iterator&);
    iterator& operator-=(size_type);  
    friend iterator operator-(const iterator&, size_type);
    friend difference_type operator-(iterator, iterator);

    reference operator[](size_type) const;
};

contiguous_iterator : random_access_iterator { //C++17
}; //elements are stored contiguously in memory.

```
 You can either specialize 
```
std::iterator_traits<youriterator>
```
, or put the same typedefs in the iterator itself, or inherit from 
```
std::iterator
```
 (which has these typedefs). I prefer the second option, to avoid changing things in the 
```
std
```
 namespace, and for readability, but most people inherit from 
```
std::iterator
```
. 
```
struct std::iterator_traits<youriterator> {        
    typedef ???? difference_type; //almost always ptrdiff_t
    typedef ???? value_type; //almost always T
    typedef ???? reference; //almost always T& or const T&
    typedef ???? pointer; //almost always T* or const T*
    typedef ???? iterator_category;  //usually std::forward_iterator_tag or similar
};

```
 Note the iterator_category should be one of 
```
std::input_iterator_tag
```
, 
```
std::output_iterator_tag
```
, 
```
std::forward_iterator_tag
```
, 
```
std::bidirectional_iterator_tag
```
, or 
```
std::random_access_iterator_tag
```
, depending on which requirements your iterator satisfies. Depending on your iterator, you may choose to specialize 
```
std::next
```
, 
```
std::prev
```
, 
```
std::advance
```
, and 
```
std::distance
```
 as well, but this is rarely needed. In extremely rare cases you may wish to specialize 
```
std::begin
```
 and 
```
std::end
```
. Your container should probably also have a 
```
const_iterator
```
, which is a (possibly mutable) iterator to constant data that is similar to your 
```
iterator
```
 except it should be implicitly constructable from a 
```
iterator
```
 and users should be unable to modify the data. It is common for its internal pointer to be a pointer to non-constant data, and have 
```
iterator
```
 inherit from 
```
const_iterator
```
 so as to minimize code duplication. My post at Writing your own STL Container has a more complete container/iterator prototype."
2745074,Fast ceiling of an integer division in C / C++,https://stackoverflow.com/questions/2745074/fast-ceiling-of-an-integer-division-in-c-c,11,539.0,"['For positive numbers where you want to find the ceiling (q) of x when divided by y. \n```\nunsigned int x, y, q;\n\n```\n To round up ... \n```\nq = (x + y - 1) / y;\n\n```\n or (avoiding overflow in x+y) \n```\nq = 1 + ((x - 1) / y); // if x != 0\n\n```']","For positive numbers where you want to find the ceiling (q) of x when divided by y. 
```
unsigned int x, y, q;

```
 To round up ... 
```
q = (x + y - 1) / y;

```
 or (avoiding overflow in x+y) 
```
q = 1 + ((x - 1) / y); // if x != 0

```
"
110157,How to retrieve all keys (or values) from a std::map and put them into a vector?,https://stackoverflow.com/questions/110157/how-to-retrieve-all-keys-or-values-from-a-stdmap-and-put-them-into-a-vector,25,237.0,"['While your solution should work, it can be difficult to read depending on the skill level of your fellow programmers. Additionally, it moves functionality away from the call site. Which can make maintenance a little more difficult. I\'m not sure if your goal is to get the keys into a vector or print them to cout so I\'m doing both. You may try something like this: \n```\nstd::map<int, int> m;\nstd::vector<int> key, value;\nfor(std::map<int,int>::iterator it = m.begin(); it != m.end(); ++it) {\n  key.push_back(it->first);\n  value.push_back(it->second);\n  std::cout << ""Key: "" << it->first << std::endl;\n  std::cout << ""Value: "" << it->second << std::endl;\n}\n\n```\n Or even simpler, if you are using the Boost library: \n```\nmap<int,int> m;\npair<int,int> me; // what a map<int, int> is made of\nvector<int> v;\nBOOST_FOREACH(me, m) {\n  v.push_back(me.first);\n  cout << me.first << ""\\n"";\n}', '```\n Personally, I like the BOOST_FOREACH version because there is less typing and it is very explicit about what it is doing.']","While your solution should work, it can be difficult to read depending on the skill level of your fellow programmers. Additionally, it moves functionality away from the call site. Which can make maintenance a little more difficult. I'm not sure if your goal is to get the keys into a vector or print them to cout so I'm doing both. You may try something like this: 
```
std::map<int, int> m;
std::vector<int> key, value;
for(std::map<int,int>::iterator it = m.begin(); it != m.end(); ++it) {
  key.push_back(it->first);
  value.push_back(it->second);
  std::cout << ""Key: "" << it->first << std::endl;
  std::cout << ""Value: "" << it->second << std::endl;
}

```
 Or even simpler, if you are using the Boost library: 
```
map<int,int> m;
pair<int,int> me; // what a map<int, int> is made of
vector<int> v;
BOOST_FOREACH(me, m) {
  v.push_back(me.first);
  cout << me.first << ""\n"";
}

```
 Personally, I like the BOOST_FOREACH version because there is less typing and it is very explicit about what it is doing."
3385229,C++ Erase vector element by value rather than by position?,https://stackoverflow.com/questions/3385229/c-erase-vector-element-by-value-rather-than-by-position,4,577.0,"['How about \n```\nstd::remove()\n```\n instead: \n```\n#include <algorithm>\n...\nvec.erase(std::remove(vec.begin(), vec.end(), 8), vec.end());\n\n```\n This combination is also known as the erase-remove idiom.']","How about 
```
std::remove()
```
 instead: 
```
#include <algorithm>
...
vec.erase(std::remove(vec.begin(), vec.end(), 8), vec.end());

```
 This combination is also known as the erase-remove idiom."
1845482,What is the uintptr_t data type?,https://stackoverflow.com/questions/1845482/what-is-the-uintptr-t-data-type,6,275.0,"['```\nuintptr_t\n```\n is an unsigned integer type that is capable of storing a data pointer (whether it can hold a function pointer is unspecified). That typically means that it\'s the same size as a pointer. It is optionally defined in C++11 and later standards. A common reason to want an integer type that can hold an architecture\'s pointer type is to perform integer-specific operations on a pointer, or to obscure the type of a pointer by providing it as an integer ""handle"".']","
```
uintptr_t
```
 is an unsigned integer type that is capable of storing a data pointer (whether it can hold a function pointer is unspecified). That typically means that it's the same size as a pointer. It is optionally defined in C++11 and later standards. A common reason to want an integer type that can hold an architecture's pointer type is to perform integer-specific operations on a pointer, or to obscure the type of a pointer by providing it as an integer ""handle""."
655065,When should I use the new keyword in C++?,https://stackoverflow.com/questions/655065/when-should-i-use-the-new-keyword-in-c,12,381.0,"[""Method 1 (using \n```\nnew\n```\n) Allocates memory for the object on the free store (This is frequently the same thing as the heap) Requires you to explicitly \n```\ndelete\n```\n your object later. (If you don't delete it, you could create a memory leak) Memory stays allocated until you \n```\ndelete\n```\n it. (i.e. you could \n```\nreturn\n```\n an object that you created using \n```\nnew\n```\n) The example in the question will leak memory unless the pointer is \n```\ndelete\n```\nd; and it should always be deleted, regardless of which control path is taken, or if exceptions are thrown. Method 2 (not using \n```\nnew\n```\n) Allocates memory for the object on the stack (where all local variables go) There is generally less memory available for the stack; if you allocate too many objects, you risk stack overflow. You won't need to \n```\ndelete\n```\n it later. Memory is no longer allocated when it goes out of scope. (i.e. you shouldn't \n```\nreturn\n```"", ""```\ndelete\n```\n it later. Memory is no longer allocated when it goes out of scope. (i.e. you shouldn't \n```\nreturn\n```\n a pointer to an object on the stack) As far as which one to use; you choose the method that works best for you, given the above constraints. Some easy cases: If you don't want to worry about calling \n```\ndelete\n```\n, (and the potential to cause memory leaks) you shouldn't use \n```\nnew\n```\n. If you'd like to return a pointer to your object from a function, you must use \n```\nnew\n```""]","Method 1 (using 
```
new
```
) Allocates memory for the object on the free store (This is frequently the same thing as the heap) Requires you to explicitly 
```
delete
```
 your object later. (If you don't delete it, you could create a memory leak) Memory stays allocated until you 
```
delete
```
 it. (i.e. you could 
```
return
```
 an object that you created using 
```
new
```
) The example in the question will leak memory unless the pointer is 
```
delete
```
d; and it should always be deleted, regardless of which control path is taken, or if exceptions are thrown. Method 2 (not using 
```
new
```
) Allocates memory for the object on the stack (where all local variables go) There is generally less memory available for the stack; if you allocate too many objects, you risk stack overflow. You won't need to 
```
delete
```
 it later. Memory is no longer allocated when it goes out of scope. (i.e. you shouldn't 
```
return
```
 a pointer to an object on the stack) As far as which one to use; you choose the method that works best for you, given the above constraints. Some easy cases: If you don't want to worry about calling 
```
delete
```
, (and the potential to cause memory leaks) you shouldn't use 
```
new
```
. If you'd like to return a pointer to your object from a function, you must use 
```
new
```
"
20509734,NULL vs nullptr (Why was it replaced?),https://stackoverflow.com/questions/20509734/null-vs-nullptr-why-was-it-replaced,4,491.0,"[""```\nnullptr\n```\n has type \n```\nstd::nullptr_t\n```\n. It's implicitly convertible to any pointer type. Thus, it'll match \n```\nstd::nullptr_t\n```\n or pointer types in overload resolution, but not other types such as \n```\nint\n```\n. \n```\n0\n```\n (aka. C's NULL bridged over into C++) could cause ambiguity in overloaded function resolution, among other things: \n```\nf(int);\nf(foo *);\n\n```\n (Thanks to Caleth pointing this out in the comments.)""]","
```
nullptr
```
 has type 
```
std::nullptr_t
```
. It's implicitly convertible to any pointer type. Thus, it'll match 
```
std::nullptr_t
```
 or pointer types in overload resolution, but not other types such as 
```
int
```
. 
```
0
```
 (aka. C's NULL bridged over into C++) could cause ambiguity in overloaded function resolution, among other things: 
```
f(int);
f(foo *);

```
 (Thanks to Caleth pointing this out in the comments.)"
4190703,Is it safe to delete a NULL pointer?,https://stackoverflow.com/questions/4190703/is-it-safe-to-delete-a-null-pointer,9,316.0,"[""```\ndelete\n```\n performs the check anyway, so checking it on your side adds overhead and looks uglier. A very good practice is setting the pointer to NULL after \n```\ndelete\n```\n (helps avoiding double deletion and other similar memory corruption problems). I'd also love if \n```\ndelete\n```\n by default was setting the parameter to NULL like in \n```\n#define my_delete(x) {delete x; x = NULL;}\n\n```\n (I know about R and L values, but wouldn't it be nice?)""]","
```
delete
```
 performs the check anyway, so checking it on your side adds overhead and looks uglier. A very good practice is setting the pointer to NULL after 
```
delete
```
 (helps avoiding double deletion and other similar memory corruption problems). I'd also love if 
```
delete
```
 by default was setting the parameter to NULL like in 
```
#define my_delete(x) {delete x; x = NULL;}

```
 (I know about R and L values, but wouldn't it be nice?)"
5685471,Error: Jump to case label in switch statement,https://stackoverflow.com/questions/5685471/error-jump-to-case-label-in-switch-statement,4,660.0,"[""The problem is that variables declared in one \n```\ncase\n```\n are still visible in the subsequent \n```\ncase\n```\ns unless an explicit \n```\n{\xa0}\n```\n block is used, but they will not be initialized because the initialization code belongs to another \n```\ncase\n```\n. In the following code, if \n```\nfoo\n```\n equals 1, everything is ok, but if it equals 2, we'll accidentally use the \n```\ni\n```\n variable which does exist but probably contains garbage. \n```\nswitch(foo) {\n  case 1:\n    int i = 42; // i exists all the way to the end of the switch\n    dostuff(i);\n    break;\n  case 2:\n    dostuff(i*2); // i is *also* in scope here, but is not initialized!\n}\n\n```\n Wrapping the case in an explicit block solves the problem: \n```\nswitch(foo) {\n  case 1:\n    {\n        int i = 42; // i only exists within the {\xa0}\n        dostuff(i);\n        break;\n    }\n  case 2:\n    dostuff(123); // Now you cannot use i accidentally\n}"", ""```\n Edit To further elaborate, \n```\nswitch\n```\n statements are just a particularly fancy kind of a \n```\ngoto\n```\n. Here's an analoguous piece of code exhibiting the same issue but using a \n```\ngoto\n```\n instead of a \n```\nswitch\n```\n: \n```\nint main() {\n    if(rand() % 2) // Toss a coin\n        goto end;\n\n    int i = 42;\n\n  end:\n    // We either skipped the declaration of i or not,\n    // but either way the variable i exists here, because\n    // variable scopes are resolved at compile time.\n    // Whether the *initialization* code was run, though,\n    // depends on whether rand returned 0 or 1.\n    std::cout << i;\n}\n\n```""]","The problem is that variables declared in one 
```
case
```
 are still visible in the subsequent 
```
case
```
s unless an explicit 
```
{ }
```
 block is used, but they will not be initialized because the initialization code belongs to another 
```
case
```
. In the following code, if 
```
foo
```
 equals 1, everything is ok, but if it equals 2, we'll accidentally use the 
```
i
```
 variable which does exist but probably contains garbage. 
```
switch(foo) {
  case 1:
    int i = 42; // i exists all the way to the end of the switch
    dostuff(i);
    break;
  case 2:
    dostuff(i*2); // i is *also* in scope here, but is not initialized!
}

```
 Wrapping the case in an explicit block solves the problem: 
```
switch(foo) {
  case 1:
    {
        int i = 42; // i only exists within the { }
        dostuff(i);
        break;
    }
  case 2:
    dostuff(123); // Now you cannot use i accidentally
}

```
 Edit To further elaborate, 
```
switch
```
 statements are just a particularly fancy kind of a 
```
goto
```
. Here's an analoguous piece of code exhibiting the same issue but using a 
```
goto
```
 instead of a 
```
switch
```
: 
```
int main() {
    if(rand() % 2) // Toss a coin
        goto end;

    int i = 42;

  end:
    // We either skipped the declaration of i or not,
    // but either way the variable i exists here, because
    // variable scopes are resolved at compile time.
    // Whether the *initialization* code was run, though,
    // depends on whether rand returned 0 or 1.
    std::cout << i;
}

```
"
